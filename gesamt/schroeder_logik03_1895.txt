VORLESUNGEN ÜBER DIE ALGEBRA DER LOGIK (EXAKTE LOGIK) VON Dr. ERNST SCHRÖDER, ORD. PROFESSOR DER MATHEMATIK AN DER TECHNISCHEN HOCHSCHULE ZU KARLSRUHE IN BADEN. DRITTER BAND. ALGEBRA UND LOGIK DER RELATIVE. LEIPZIG, DRUCK UND VERLAG VON B. G. TEUBNER. 1895.
ALGEBRA UND LOGIK DER RELATIVE, DER VORLESUNGEN ÜBER DIE ALGEBRA DER LOGIK DRITTER BAND. VON ERNST SCHRÖDER.
ERSTE ABTEILUNG.
MIT VIEL FIGUREN IM TEXTE.
Du gleichst dem Geist, den du begreifst, Nicht mir!
Goethe (Geist).
An ihren Früchten sollt ihr sie erkennen. Matthäus.
LEIPZIG, DRUCK UND VERLAG VON B. G. TEUBNER. 1895.
Alle Rechte, einschliesslich des Übersetzungsrechts, vorbehalten.
Inhalt von Bd. 3, I.
Erste Vorlesung.
Zur Einführung.
Seite
§ 1. Plan.
Der Operationskreis der Algebra der binären Relative 1
§ 2.
Die Denkbereiche der verschiednen Ordnungen und ihre Individuen 4
Zweite Vorlesung.
Die formalen Grundlagen, insbesondre zur Algebra der binären Relative.
§ 3.
Die 29 zu 31 fundamentalen Festsetzungen.
Summendarstellung der Relative.
Aussagenschemata 17
§ 4.
Die Matrix eines Relativs und deren Augen.
Beispiele.
Geometrische Repräsentation.
Die dreifachen Evidenzen 42
§ 5. Haushalt mit Klammern 68
Dritte Vorlesung.
Die Sätze von allgemeinster Natur in der Algebra der binären Relative.
§ 6. Gesetze der Spezies, soweit nur allgemeine Relative in deren Ausdruck eingehen.
Dualismus und Konjugation 76
§ 7. Beweis jener Grundgesetze.
Nebst einigen Hülfsschemata des Aussagenkalkuls 101
Vierte Vorlesung.
Einfachste Sätze von speziellerem Charakter in der Algebra der binären Relative. Modulknüpfungen.
§ 8.
Noch einige weitre Grundformeln.
Die reduziblen primären Modulknüpfungen.
Der Abacus vervollständigt.
Produktdarstellung der Relative 117
§ 9.
Die 12 irreduziblen primären Modulknüpfungen und die 64 Diagonalabwandlungen eines allgemeinen Relativs 130
§ 10. Erste 6 „ausgezeichnete“ Relative 146
Fünfte Vorlesung.
Das Auflösungsproblem in der Algebra der binären Relative.
§ 11. Gesamtaussage der Data eines Problems und allgemeinste Aufgabe 150
§ 12. Allgemeine und rigorose Lösungen 161
§ 13. Fortsetzung.
Iterationen.
Grenzwerte und Konvergenz.
Potenz 178
§ 14. Beispiele einfachster Art. 192
Sechste Vorlesung.
Die Parallelreihentransformationen und -Probleme. § 15.
Die 256 Zeilenabwandlungen eines allgemeinen Relativs.
Ebensoviele Kolonnenabwandlungen.
Einschlägige Sätze 201
§ 16.
Die inversen Zeilen- oder Kolonnenprobleme 223
Siebente Vorlesung.
Seite
Die elementaren Inversionsprobleme.
§ 17. Erste 4 Inversionsprobleme und -Theoreme 241
§ 18.
Die 4 zweiten Inversionsprobleme nebst zugehörigen Theoremen 247
§ 19.
Die 4 dritten Inversionsprobleme 256
§ 20. Vorübergehend „Transoperationen“ genannte Knüpfungen und deren Inversionsprobleme.
Quaderrelative 278
Achte Vorlesung.
Die einfachsten Auflösungsprobleme der Theorie.
§ 21. Probleme, welche in zwei Buchstaben möglich sind.
Erste Stufe der Probleme in drei Buchstaben.
Das allgemeinste Problem von universaler Natur auf dieser Stufe.
Solvirender Faktor 293
§ 22. Zweite Stufe der Auflösungsprobleme in drei Buchstaben.
Kettenproblem, Transitivität und anderes 321
Neunte Vorlesung.
Die Theorie der Ketten.
§ 23. Dedekind’s Kettentheorie und der Schluss der vollständigen Induktion.
Vereinfachung jener 346
§ 24. Nebenstudien zur Kettentheorie 387
Zehnte Vorlesung.
Individuen im ersten und zweiten Denkbereich.
Die Theorie der uninären Relative. § 25.
Das Element als Einzeiler und der Einkolonner.
Charakteristik und Knüpfungsgesetze beider 405
§ 26.
Das Einauge, dessen Charakteristik und Knüpfungen 424
§ 27. Sätze über Knüpfung mit den absoluten Moduln.
Systeme, Klassen oder absolute Terme als binäre und als uninäre Relative 443
Elfte Vorlesung.
Studien über Elimination, Produktir- und Summiraufgaben. § 28.
Eine Studie gemäss Peirce über Elimination 468
§ 29.
Über von Peirce so genannte „Entwickelungsformeln“: Summationen und Produktevaluationen.
Zum Inversionsproblem 491
Zwölfte Vorlesung.
Theorie der Abbildung.
Ihre 15 Arten.
Eindeutigkeit bei Zuordnungen und Gleichmächtigkeit von Systemen.
§ 30. Direkt sowie umgekehrt nie undeutige und nie mehrdeutige Zuordnung.
Funktion, Argument und Substitution (Permutation) als Relative 553
§ 31. Dedekind’s ähnliche Abbildung eines Systems in ein anderes.
Ähnliche oder gleichmächtige Systeme 596
Berichtigungen zu Bd. 3, I.
Seite 25, Zeile 5 v. u. ist zu sagen: identischen „oder absoluten“ Moduln.
Seite 39 ist Z. 15 und 16 v. o. sowie Z. 10 und 9 v. u. zu tilgen: [die nicht chiffrirten beiden Schemata über ζ) und ϑ) sind falsch und durch κ) auf S. 40 vertreten zu denken.]
Seite 61 ist Fig. 14 und 15 vertauscht.
Seite 64, Zeile 16 v. o. wäre zuzufügen, dass statt excepting einfacher auch except und eventuell exclusive of gesagt werden kann.
Seite 67, Zeile 17 v. o. wäre hinter „Konventionen“ im ersten Satz des dritten Absatzes streng genommen einzuschalten: und den wenigen sog.
Prinzipien der allgemeinen Logik, welche sich aber (wesentlich, wenn auch nicht förmlich) als in jenen Konventionen schon mit enthalten ansehn lassen.
Seite 91, Zeile 12 v. u. sollte unter Hinzufügung der kursiv gedruckten Worte gesagt sein:
Im letzten Falle, der jedoch bei Formeln mit lauter allgemeinen Relativen nicht vorzukommen scheint.
—.
Kommen auch Moduln vor, so ist der Fall möglich, wie das Beispiel von S. 125 zeigt:
[Formel] . Wir haben dann also in Wahrheit dreierlei Arten von Zweigespannen zu unterscheiden: duale, sowie konjugirte, und solche, die wie 7) S. 91 beides zugleich sind.
Seite 127, Z. 6 v. o. statt des zweiten b lies b̄̆.
Seite 131, Z. 8 v. o. st. Selbstrelativen l. individuellen Selbstrelativen.
Seite 133, Z. 16 v. o. st. least lies greatest.
[Man könnte auch highest im Gegensatz zu lowest sagen.]
Seite 137, Z. 8 v. u. ebenso wie Seite 131, Z. 8 v. o.
Seite 149, Z. 8 v. o. wäre hinzuzufügen, dass die Frage nur eine solche der Form ist, indem mein Relativ 0 ɟ 0'; (a ɟ 0), gleich 0 ɟ 0' (0 ɟ ă); 1 nach einem späteren Satze 10) S. 444, mithin in ein Peirce’sches transformirbar ist.
Im Hinblick auf den Satz am Schluss von S. 148 könnte man sagen, dass es blos eine Art von ausgezeichneten Relativen gebe, indem sich ja alle schon als 1; c; 1 darstellen lassen.
Seite 173, dritter Absatz (Z. 11 bis 13 v. o.) sollte der Funktionsbuchstabe F durchweg als ein neuer, F, gesetzt sein.
Seite 214, Z. 19 v. o. steht vor dem letzten γ eine 0 zu viel.
Seite 227, Z. 12 v. u. bei 7) fehlt } hinter der letzten 1.
Seite 255 unten sind die Formeln 26) falsch.
Zur Richtigstellung der ersten wäre das a rechts durch a(1; b) zu ersetzen, und entsprechend sind die übrigen zu modifiziren, wonach die 26) aber nur als Umformungen von 8) gemäss spätern Satzes 9) S. 444 erscheinen.
Zudem ist in den zwei letzten Formeln ein Negationsstrich deplacirt, sollten mithin die in 26) rechts gleich x gesetzten Ausdrücke heissen:
[Formel] .
Seite 274, Z. 18 v. u. streiche den Zusatz: — worin … ersetzbar.
Seite 281, Z. 9 v. o. st. b l. c.
Seite 306 untere Figur links statt g lies ḡ.
Seite 321, Z. 16 v. o. st. Pluszeichen l. Piuzeichen.
Seite 330, Z. 3 v. o. verbessere man von denjenigen u, die kein übergesetztes Zeichen tragen, das zweite, fünfte und sechste in ū̆, zudem das letzte ū̆ in u.
ibid., Z. 5 v. o. verbessere das fünfte u in ū̆.
Seite 338, Z. 7 v. o. st. Russel l. Russell.
Seite 344, Z. 6 v. o. lies: x als Aliorelativ resp. Aliorelativnegat.
Seite 366, Z. 18 v. u. st. welche l. die.
Seite 383, Z. 7 v. o. füge hinzu: — cf. S. 366.
Seite 389, Z. 8 v. u. st. Augabe l. Aufgabe.
Seite 406, Z. 11 v. o. st. 0 l. 0'.
Seite 418 empfiehlt sich zu 23) eine Vorverweisung auf 25) S. 502.
Seite 438, Z. 2 v. o. sollte ein Gedankenstrich nebst Durchschuss folgen.
Seite 440 könnten die Aussagensubsumtionen 30) auch als Äquivalenzen angesetzt werden.
Seite 449, Z. 4 v. o. st. 5 l. 5.
Seite 452 [Z. 12 v. u. st. sofern l. weil ja, und streiche Z. 11 v. u., besser:] ist Z. 13 bis 11 v. u. zu ersetzen durch:
Ein Element von einem Element ist immer das erstere Element selbst — cf. S. 412.
Seite 470, Z. 12 v. u. st. 10)
l. 100).
Seite 502, Z. 5 v. u. st. u l. a.
Seite 509 sq. ist zu Aufg. 11 zu bemerken, dass wegen u = 1 u; 1' ihre Lösung sich schnellstens aus 6) S. 496 als Sonderfall ergibt.
Seite 520, Z. 9 v. o. st. des Faktors i lies ĭ.
Seite 526, Z. 1 v. u. st. 1'l lies 1'k l.
Seite 529, Z. 10 v. o. st. ci l. c(i).
Seite 552, Z. 4 v. o. hinter Wurzeln schalte ein: (Radikale).
Seite 554, Z. 14 v. o. st. h i l. h ĭ.
ibidem, Z. 1 v. u. st. des letzten = lies ⋹.
Seite 594, Z. 7 v. u. statt des zweiten A2 l. A3.
Seite 620, Z. 20 v. u. st. „mehrzig“ l. „mehrig“.
Erste Vorlesung.
Zur Einführung.
§ 1. Plan.
Der Operationskreis der Algebra der binären Relative.
α)
Es ist eine grossartige Disziplin, reich an Ausdrucksmitteln und mächtigen Schlussmethoden, fast überreich an Sätzen, wenn auch von unvergleichlichem Ebenmaasse, in welche ich versuchen will den Leser hiermit einzuführen.
Dürften auch ihre ersten Anfänge — mit Augustus De Morgan — kaum über die Mitte dieses Jahrhunderts zurückreichen, so ist die Literatur dieser Disziplin doch schon eine ziemlich umfangreiche, zudem ihre Kenntnissnahme eigentümlich erschwert nicht nur durch ihr Zerstreutsein in verschiedenen nicht leicht zugänglichen Schriftwerken, sondern auch durch die Verschiedenartigkeit der — ich kann nur sagen: „Hieroglyphen“systeme, deren sich die Urheber der Disziplin bedienten und welche sogar bei ihrem Hauptförderer Charles S. Peirce zuweilen fast unvermittelt gewechselt haben.
Ausser diesen beiden Hauptschöpfern der Theorie dürfte dieselbe mittelbar den Arbeiten von Herrn R. Dedekind am meisten Förderung verdanken, und liegt es dem Verfasser ob, nun die Gesamtheit der bisherigen Leistungen zu dem gegenwärtigen Stande der Disziplin gleichsam aufzurunden.
Bei der fast unermesslichen Mannigfaltigkeit der Richtungen, nach welchen sich die Disziplin entwickelungsfähig zeigt, der Fülle ihrer Anwendungsmöglichkeiten auf die verschiedensten Gebiete — zu denen die Begriffe von „Endlichkeit“, „Anzahl“, „Funktion“ und „Substitution ebensowol gehören als wie z. B. die „menschlichen Verwandtschaftsverhältnisse“ —, bei ihrer Doppelnatur als einer Algebra einerseits und einer Entwickelungsform der Logik andrerseits, nämlich ihrer Ausgestaltung zur Logik der Beziehungen (und Beziehungsbegriffe, „Relative“) überhaupt, scheint es unerlässlich — soll nicht die Übersicht leiden und der Eindruck der Schönheit und Konsequenz des Ganzen verloren gehen — dass wir die verschiedenen Gesichtspunkte, unter welchen unsre Theorie zu betrachten sein wird, thunlichst scharf von einander getrennt halten.
Ich werde deshalb zunächst eine Seite der Theorie fast ausschliesslich bevorzugen, und zwar dieselbe lediglich als eine Algebra, einen Kalkul aufbauen, der seine Gesetze aus einer geringen Anzahl bestimmt formulirter fundamentaler Festsetzungen denknotwendig ableitet.
Erst wenn auf diesem Wege ein gewisser Grundstock geschaffen und ein schon recht ansehnliches Kapital von absolut feststehenden Wahrheiten — Thatsachen der Deduktion — gesichert ist, gedenke ich in sehr viel spätern Vorlesungen auf die Fundamente der Disziplin zurückzukommen, um deren zuerst nur einfach hingestellte Festsetzungen dann auch heuristisch zu motiviren und aus allgemein logischen Gesichtspunkten reflektirend zu erörtern, insbesondre sie als den Zwecken ebendieser Wissenschaft, der Logik, dienstbare nachzuweisen.
Bis dahin mögen logische Interpretationen von Ausdrücken oder Formeln des Kalkuls höchstens nebenher in Form von Seitenblicken erfolgen, bestimmt, das Interesse des Lesers zu wecken und denselben zu der später systematisch zu erwerbenden Deutungskunst allmälig heranzuziehen.
Ebenso wird es zur Vereinfachung des Ganzen beitragen, wenn wir dasjenige, was zur Sicherung des Anteils der andern Forscher an den Errungenschaften der Theorie gesagt werden muss, und was zumeist von literarhistorisch-kritischen Erörterungen unzertrennlich sein wird, erst nachträglich in eignem Paragraphen zusammenstellen — die Theorie selber thunlichst von allem Beiwerk entlastend.
Meine Bezeichnungsweisen schliessen sich sehr nahe an die von Peirce in einer 9c seiner Abhandlungen gebrauchten an, und werden die Abweichungen späterhin gekennzeichnet und gerechtfertigt.
Den zahlreich zu verwendenden Suffixen zuliebe und um zugleich den Platz frei zu halten für die „Exponenten“ von „Potenzen“, deren Begriff auch in unsre Disziplin Eingang findet, musste vom vertikalen zu dem horizontal übergesetzten Negationsstriche übergegangen werden.
Zudem wird sich Veranlassung ergeben, die beiden — wenn auch nicht bei Aussagen — so doch bei binären Relativen (sowie solchen von noch höhrer Ordnung) unterscheidend zu verwenden — ein Punkt auf den wir noch zurückkommen.
Nach dem Gesagten gehe ich sogleich zu dem Versuche über:
β) Vorweg über den Operationskreis der relativen Logik einen kurzen Überblick zu geben — den Operationskreis der arithmetischen Algebra zur Vergleichung heranziehend.
Ich fasse dabei ausschliesslich den weitaus wichtigsten Teil der ersteren: die Algebra der binären Relative (bei Peirce „dual relatives“ genannt) in’s Auge, welche den naturgemässen Ausgangspunkt der ganzen Theorie bildet.
Ebendiese ist bis jetzt allein auch einigen Ausbaues teilhaftig geworden und wird auf sie die Wissenschaft, um damit für ihre vornehmsten Probleme auszukommen, vielleicht sogar sich wesentlich beschränken dürfen.
Im identischen (Gebiete- oder Klassen-)Kalkul hatten wir uns mit drei Rechnungsarten, „Spezies“ vertraut zu machen: mit der identischen Multiplikation, der identischen Addition und der Negation.
Von diesen waren die beiden erstgenannten „knüpfende“ Operationen, die zu ihrer Ausführung mindestens zwei Operanden (Terme) als gegeben voraussetzten; die letztgenannte eine „nicht-knüpfende“ Operation, welche schon an einem Operanden (Term) vollziehbar.
Die knüpfenden Operationen waren hier assoziative sowol als kommutative.
Denselben drei identischen Spezies begegnen wir auch in der Logik der Relative wieder, woselbst sie in der That die erste Hauptstufe der elementaren Operationen ausmachen.
Zu diesen treten aber als zweite Hauptstufe hier noch drei weitere Spezies hinzu: die drei „relativen Elementaroperationen, als da sind: die relative Multiplikation (oder Komposition), die relative Addition und die Konversion; jene beiden knüpfende und zwar assoziative aber (im allgemeinen) nicht kommutative Operationen, diese eine nicht knüpfende Operation, die bereits an einem Operanden vollziehbar.
Mit ihren sechs Spezies ist mithin die Logik der Relative, gegenüber der allgemeinen Arithmetik mit ihren sieben algebraischen Operationen, immer noch im Vorteil.
Zugunsten der letztern kann allerdings geltend gemacht werden, dass durch die bekannte Erweiterung des Zahlengebietes zum Gebiet der gemeinen komplexen Zahlen es sich habe ermöglichen lassen, die 7 Spezies der Algebra auf viere zu reduziren, nämlich auf Addition, Multiplikation, Potenzirung und Logarithmirung — indem die Subtraktion als eine Addition der entgegengesetzten Zahl, die Division als eine Multiplikation und die Radizirung als eine Potenzirung mit der reziproken Zahl in Wegfall gekommen, drei von den vier inversen Operationen mithin in den direkten aufgegangen seien.
Demgegenüber ist aber zu betonen, dass auch die 6 Spezies der relativen Logik wesentlich sich auf viere (und zwar schon von vornherein) reduziren, indem vermittelst der Negation die beiden Additionen zurückführbar sind auf die entsprechenden Multiplikationen (oder umgekehrt), mithin, bei Verzicht auf die Symmetrie, diese auch durch jene könnten entbehrlich gemacht werden.
In der definitiven Anzahl der unentbehrlichen Grundoperationen stehen somit beide Disziplinen auf gleicher Linie.
In ihrer durchgängigen Symmetrie aber besitzt die Algebra der Relative einen ästhetischen Vorzug vor der Algebra der Zahlen.
Verfügt sie doch über zwei Prinzipien zur Vervielfältigung, Verdoppelung ihrer Theoreme und tritt ein jeder ihrer allgemeinen Sätze mit drei zumeist andern gekoppelt als eine Tetrade, ein Quadrupel, ein Gespann von Sätzen (oder Formeln) auf, indem er mittelst Kontraposition, beiderseitigem Negiren, einen ihm „dual entsprechenden“ Satz, das Paar aber mittelst beiderseitigen Konvertirens, ein zweites dazu „konjugirtes Sätzepaar liefert, dessen Geltung von ihm mitbedingt und garantirt wird.
γ)
Wenn demnach der identische Kalkul als ein blosser Teil — der elementarste — der relativen Logik erscheinen wird, die letztre also als eine Erweiterung (spezielle Anwendungsweise und Fortsetzung) des erstern sich darstellt, so bieten sich anscheinend zwei Möglichkeiten dar, die Algebra der Relative zu begründen.
Die eine: im Anschluss an den bisherigen Lehrgang, bei welchem wir vom Begriff der Subsumtion ausgegangen waren um gegen Ende zu einer wissenschaftlichen Definition des Individuums zu gelangen.
Die andre: als die Möglichkeit einer selbständigen Begründung, als ein Aufbau der ganzen Disziplin sozusagen auf einer tabula rasa.
Eine solche Begründung, die von der Betrachtung von „Elementen (oder Individuen) ihren Ausgang nimmt, hat Peirce gegeben, und kann der Vergleich der damit geschaffenen ganz eigenartigen Grundlage der gesamten Logik mit ihren anderweitigen Fundirungen nur lehrreich sein.
Wir schliessen uns darum diesem letztern Lehrgange an, zumal von da der erwähnte „Anschluss“ sehr leicht und rasch zu gewinnen sein wird.
§ 2.
Die Denkbereiche der verschiednen Ordnungen und ihre Individuen.
Als gegeben, irgendwie begrifflich bestimmt, denken wir uns die „Elemente“ oder Individuen 1) A, B, C, D, E, … einer „gewöhnlichen“ Mannigfaltigkeit (vergl. Bd. 1, S. 342). Dieselben sollen durchweg von einander und vom Nichts (von 0) verschieden geachtet werden.
Sie müssen unter sich verträglich (konsistent) sein, sodass nicht etwa die Setzung eines von ihnen der Denkbarkeit eines andern vorbeugt, und sie müssen einander gegenseitig ausschliessen (unter sich disjunkt sein), sodass auch keines der Elemente als eine Klasse gedeutet werden dürfte, die ein andres von ihnen unter sich begreift.
Ich bemerke dieses, und noch einiges andre mehr, zum voraus, um die Erwartung des Lesers angemessen zu dirigiren, nicht aber aus dem Grunde, weil etwa schon auf diese letzteren Bemerkungen wesentliche Schlüsse zu bauen wären.
Auch wer diese Bemerkungen für ganz ungenügend fundirt erachten wollte, der könnte sich doch nicht ablehnend verhalten gegenüber der formalen Denknotwendigkeit, kraft welcher mit den fundamentalen Festsetzungen des nächsten Paragraphen als deren Konsequenz auch das ganze Gebäude unsrer Theorie gesichert sein wird.
Die Gesamtheit der gedachten Elemente stellen wir, indem wir deren Namen mittelst Pluszeichen verbinden, als eine „identische Summe“ (logical aggregate) dar und nennen sie den ursprünglichen oder Denkbereich der ersten Ordnung: 11 (gelesen Eins hoch eins), sodass uns: 2)
[Formel] gilt.
Der Denkbereich 11 soll mehr als ein Element enthalten.
Diese Voraussetzung ist zur Geltung fast aller Sätze der Theorie erforderlich.
Den Fall, wo der Denkbereich blos ein Element enthielte, wollen wir „den Ausnahmefall“ nennen.
Bei manchen Formeln wird sogar, damit sie Geltung beanspruchen können, es unerlässlich sein vorauszusetzen, dass der Denkbereich mehr als zwei Elemente umfasse.
Solche Formeln sollen durch einen ihrer Chiffre beigesetzten Stern * gekennzeichnet werden.
Im übrigen kann die Menge der Elemente, welche unser Denkbereich zusammenfasst, eine „endliche“ (oder begrenzte) sein, indem der Denkbereich besteht aus einer beliebig zu wählenden „Anzahl“ von Elementen.
Oder aber das System der Elemente ist ein „unendliches (unbegrenztes), wo dann von ihrer „Anzahl“ nicht gesprochen werden kann.
Im letzteren Falle mögen die Elemente entweder „diskrete sein, etwa ein sogenanntes „einfach unendliches“ System bildend, oder auch nicht, d. h. sie dürfen ebensogut auch als „konkrete“ gedacht werden, welche z. B. ein „Kontinuum“ ausfüllen, wie die Punkte einer Linie, einer Fläche, eines Körpers, insbesondre einer Geraden, einer Ebene oder des Raumes.
Auch diese Bemerkungen sind vorgreifende.
Ist es doch eine der vornehmsten Aufgaben der Theorie selbst, den Begriff der „Endlichkeit“ eines Systems von Elementen erst aufzustellen, was eine Vorbedingung für die Gewinnung des so hochwichtigen „Anzahl“-Begriffes bildet, desgleichen sodann, die verschiedenen Arten von „Unendlichkeit“ unterscheidend zu definiren!
Um nicht in Fehlschlüsse zu verfallen wird der Leser aber gut thun, die Möglichkeit auch der letzterwähnten Annahmen nicht aus dem Auge zu verlieren.
Wir mögen nun zwar zur Illustration einen Denkbereich „bevorzugen“, der aus den sämtlichen Punkten einer Geraden (nämlich beiderseits unbegrenzten geraden Linie) besteht (denen bekanntlich die reellen Zahlen der Arithmetik ein-eindeutig entsprechen) — oder auch blos aus einem Teile dieses Punktgebietes, wie etwa seiner Hälfte: dem Strahle, welchem sich das Gebiet der positiven Realzahlen eindeutig zuordnen lässt — vielleicht auch blos aus der Reihe der den ganzen Zahlen entsprechenden äquidistanten Punkte unsrer Geraden oder deren positiver Hälfte.
Immer aber wird dies unwesentlich bleiben müssen.
Es darf von vornherein in der Theorie nicht vorausgesetzt werden, dass die Elemente in einer bestimmten Reihenfolge sich befinden oder überhaupt in eine solche sich bringen liessen.
Nie wird a priori von „benachbarten“ Elementen, von den Vorgängern oder Nachfolgern eines Elementes gesprochen werden dürfen — wie es denn schon zu einem Punkte auf der geraden Linie (wenn sie auch etwa von links nach rechts durchlaufen wird) keinen unmittelbar vorhergehenden und keinen unmittelbar folgenden Punkt, keine unmittelbar benachbarten Punkte gibt.
Wie man Urteile fällen kann über alle Punkte, resp. über jeden Punkt einer Fläche (z. B.) — um aus diesen Urteilen andre Urteile logisch abzuleiten — ohne doch diesen Punkten damit irgendeine Reihenfolge zuzuschreiben, ebenso muss in der Theorie inbezug auf die Elemente unsres Denkbereiches schliessend vorgegangen werden.
Die „Elemente“ brauchen auch nicht etwa gleichzeitig zu existiren; sie dürften uns z. B. „Ereignisse“ aus Vergangenheit, Gegenwart und Zukunft repräsentiren (koexistirende oder simultane, wie successive); es genügt, dass sie zusammen gedacht werden können.
Zu Zwecken der Exemplifikation auf logischem Gebiete empfiehlt sich oft die Deutung der Elemente als „Personen“ der menschlichen Gesellschaft, Menschheit überhaupt.
Neben den grossen lateinischen Buchstaben, die uns bestimmte Elemente vorzustellen haben, falls wir einzelne von diesen hervorzuheben beabsichtigen, bedürfen wir auch noch einer Kategorie von Zeichen zur Darstellung von oder als Namen für unbestimmte oder allgemeine Elemente.
Dieses Bedürfniss tritt bereits zutage, macht sich geltend schon bei dem ersten und einfachsten Akte — zu welchem wir jetzt schreiten wollen — dem Akte: irgend zwei Elemente in eine Beziehung zu einander zu setzen oder unter dem Gesichtspunkte einer solchen zu betrachten.
Die Elemente, zwischen denen dergestalt — sagen wir:
— „ein Verhältniss“ konstatirt werden soll, können nämlich entweder verschiedene, oder sie können auch die nämlichen, können „einerlei“ sein.
Der Gesichtspunkt, das „fundamentum relationis“ sei z. B. die Zuneigung, Liebe einer Person zu einer Person.
Wenn die Person A die Person B liebt, so wird unter diesem Gesichtspunkt das Elementepaar „A : B“ in Betracht kommen.
Wenn etwa zugleich die Person B die Person A nicht liebt, so wird das Elementepaar „B : A“ (welches demnach vom vorigen zu unterscheiden ist) nicht in Betracht kommen.
Wenn die Person A sich selbst liebt, so wird als „Elementepaar auch „A : A“ in Betracht zu ziehen sein.
Schon diese beiden Fälle, der erste mit dem letzten, lassen sich — bei Beschränkung auf den bisherigen Zeichenvorrat — nicht gemeinsam erledigen oder abhandeln, und zwar aus dem Grunde, weil die Annahme:
B = A, welche den letzten Fall unter den ersten subsumiren würde, sich in Widerspruch befindet mit der eingeführten und unverbrüchlich festzuhaltenden Voraussetzung A ≠ B. Zudem wird man so doch immer nur am Beispiele kleben bleiben.
Wir bedürfen neuer Zeichen — und diese wählen wir vorderhand ausschliesslich aus der Reihe der folgenden: 3)
i, j, h, k, l, m, n, p, q — um irgend eines der Elemente A, B, C, D, … unsres Denkbereiches 11 vorzustellen.
Heben wir jetzt ein Elementepaar i : j hervor, etwa wieder um damit zu konstatiren, dass eine Person i eine Person j liebt, so wird ebensogut die Annahme j = i als die Annahme j ≠ i zulässig bleiben, und lassen sich alle Vorteile der Allgemeinheit für unsre Betrachtungen sichern, in Verbindung mit den Vorteilen, welche die Einführung knappster Zeichenschrift gewährt.
Also: während zwei verschiedene von den Buchstaben A, B, C, … immer zwei verschiedene Elemente vorzustellen haben, sind zwei verschiedene Buchstaben aus der Reihe i, j, h, … einer solchen Beschränkung nicht unterworfen.
Dieser Gegensatz ist darin begründet, dass während A, B, C, … uns als bestimmte sozusagen „spezifizirte Elemente gelten, die Symbole i, j, … vielmehr zu verwenden sein werden als Repräsentanten, Stellvertreter von irgend welchen, von unbestimmt gelassenen oder „allgemeinen Elementen“.
Jenen entsprechen in der Arithmetik die numerischen, diesen die literalen oder Buchstaben-Zahlen.
Und wie die letztern sind sie gleichermassen unentbehrlich und ermöglichen uns die Realisirung analoger Vorteile.
Die allgemeinen Elementsymbole i, j, h, k, … lassen insbesondre auch als „Indizes“, „laufende Zeiger“, „Summations-“ und „Produktationsvariable“, sich verwenden, und werden zunächst sogar vorwiegend als solche in Betracht kommen.
In der That können wir mit ihrer Beihülfe die Gleichung, welche uns den Denkbereich 11 darstellte, jetzt konziser schreiben, wie folgt: 4)
[Formel] , wobei zur korrekten Auslegung, zur „Auswertung“ oder „Evaluation der Summe rechterhand nur erforderlich ist, dass man der Summationsvariablen i auferlege, jedes der Elemente A, B, C, … als seine Bedeutung anzunehmen, oder — wie man sich ausdrückt — die Gesamtheit der Individuen des Denkbereiches 11 „zu durchlaufen“.
Dieser Prozess, der in unsrer Theorie mit jedem Ausdruck von der Form Σi oder Σj, Σh, … von einem f (i, j, h, …) in Gedanken zu vollziehen sein wird, ist wohl zu unterscheiden von dem Auslegungsverfahren bei solchen Ausdrücken wie [Formel] , wie sie im ersten und zweiten Bande häufig vorkamen (und auch hier in modifizirter Bedeutung bald eine Rolle spielen werden), wo nämlich die Summationsvariable u zu durchlaufen hatte nicht blos alle Elemente, sondern alle erdenklichen Gebiete oder Klassen, das ist alle Elementesummen aus dem vorliegenden Denkbereiche.
Also: jedem auf ein Symbol der Reihe 3) bezüglichen Summenzeichen wird (woferne nicht ausdrücklich anderes stipulirt ist) die vorhin beschriebene „Erstreckung“ zuzuschreiben sein.
Der Denkbereich 11 bildet eine Mannigfaltigkeit, auf welche ohne weitres der gesamte „identische Kalkul“ anwendbar sein würde.
Doch soll von dieser Thatsache bis zur Neubegründung des letztern hier kein Gebrauch gemacht werden.
Jede (identische) Summe von Elementen dieses Denkbereiches 11 wird späterhin als ein „absoluter Term“, als ein „System“ (Gebiet) oder auch eine „Klasse“ (class-term) schlechtweg zu bezeichnen sein.
Nunmehr können wir auch das oben am Beispiel Ausgeführte allgemein statuiren:
Werden aus unserm Denkbereiche 11 irgend zwei Elemente i und j in bestimmter Reihenfolge hervorgehoben und in dieser — gleichviel aus welchem Beweggrunde, einerlei unter welchem Gesichtspunkte — zu einem „Paare“ zusammengehalten, so mag das Ergebniss der Zusammenstellung vermittelst eines Doppelpunktes dargestellt werden in Gestalt von 5)
[Formel] — gesprochen: i zu j.
Dies ist zunächst unverfänglich, weil der Doppelpunkt zwar in § 23 des Bd. 1 provisorisch zur Darstellung der identischen Division verwendet, daselbst aber als definitiv entbehrlich nachgewiesen und dadurch zu andern Zwecken verfügbar geworden ist.
Wenn unter dem Gesichtspunkte einer bestimmten von i zu j bestehenden Beziehung ein Elementepaar hervorgehoben und mit i : j in derselben Weise dargestellt wird, wie man in der Arithmetik ein (geometrisches) Verhältniss darzustellen pflegt, so empfiehlt sich dies schon darum nicht übel, weil in der Sprache des gemeinen Lebens die Worte „Beziehung und „Verhältniss“ ohnehin beinahe als synonyme gelten dürften.
Zudem werden mit der arithmetischen Gleichung (i : h) × (h : j) = i : j bei der Lehre von der Zusammensetzung der Relative Analogieen zutage treten, die unser dem Peirce’schen sich anschliessendes Vorgehen noch weiter rechtfertigen.
An sich betrachtet hat zwar der Doppelpunkt — schon als Divisionszeichen, gleichwie auch das Minuszeichen — den Fehler, eine unsymmetrische Knüpfung durch ein symmetrisches, nach rechts und links gleich ausschauendes Zeichen darzustellen.
Dafür tröstet der Umstand, dass man (demungeachtet) von der Arithmetik her doch schon gewöhnt ist, die Knüpfung nicht als eine kommutative anzusehen.
Übrigens sei bemerkt, dass auch hier die Bezeichnung später entbehrlich gemacht werden kann, sobald mit ihrer Hülfe die Algebra der Relative eine bestimmte Stufe der Entwickelung erreicht hat.
Wir nennen i : j ein „Elementepaar“, und zwar i den Antezedenten (das Vorderglied) oder das Relat, j den Konsequenten (das Hinterglied) oder das Korrelat desselben.
Nach dem Gesagten wird uns j : i als ein andres Elementepaar wie i : j zu gelten haben, sobald j von i verschieden ist.
Oder wir mögen hinstellen: 6)
[Formel] als gültig für alle i und j.
In diesen beiden Aussagenäquivalenzen sind vier Aussagensubsumtionen enthalten, von welchen diese beiden:
[Formel] als selbstverständlich, beziehungsweise durch unsre soeben getroffenen Abmachungen gegeben, anzusehen sind.
Aus ihnen ergeben sich die beiden andern, die umgekehrten Aussagensubsumtionen (kreuz- oder) wechselweise vermittelst Kontraposition.
Übrigens sei betont, dass auch diese Bemerkung nur zur vorläufigen Orientirung ausgesprochen ist, indem sich 6) als Theorem aus den fundamentalen Festsetzungen des nächsten Paragraphen späterhin beweisen lassen wird.
Dasselbe gilt von dem Ansatze: 7)
[Formel] durch welchen wir zum Ausdruck bringen, dass uns jedes Elementepaar als von dem Nichts verschieden zu gelten habe.
Das Elementepaar j : i heisst „das konverse“ von dem Elementepaar i : j.
Bei der Allgemeingültigkeit dieser Festsetzung wird es auch gestattet sein in ihr die Namen i und j auszutauschen und muss also auch das Elementepaar i : j das konverse sein von j : i.
Die Beziehung zwischen konversen Elementepaaren ist eine gegenseitige.
Es können nun alle erdenklichen Elementepaare, zu deren Bildung unser Denkbereich 11 die Elemente liefert, zu einer Tafel, in ein Tableau zusammengestellt, geordnet werden (may be arrayed oder arranged in a „block“): 8)
[Formel] und sei bemerkt, dass wir diese „spezifizirten“ oder speziellen Elementepaare auch als „individuelle binäre Relative hinzustellen oder zu bezeichnen haben werden, deren irgend eines durch i : j allgemein repräsentirt werden kann.
Die Gesamtheit dieser individuellen binären Relative oder Elementepaare bildet einen neuen, einen eignen Denkbereich, den wir als den „Denkbereich der zweiten Ordnung“ mittelst 12 (gesprochen: eins hoch zwei) darstellen, sodass wir haben: 9)
[Formel] — wo die Klammern um die Elementepaare auch weggelassen werden könnten — oder in der durch das Summenzeichen ermöglichten Abkürzung: 10) [Formel] .
Der Denkbereich 12 ist hiernach gebildet aus den sämtlichen „Variationen zur zweiten Klasse mit Wiederholungen“ von den Elementen des Denkbereiches 11 — wie der Mathematiker sich ausdrücken würde; er ist die zweite Klasse der genannten Variationen.
Er enthält die Elemente von 11 zu Paaren vereinigt in allen erdenklichen Verbindungen (Kombinationen) und Anordnungen (Permutationen).
Als selbstverständlich erscheint es wieder (soll indess nicht wesentlich benutzt werden), dass auch dieser Denkbereich eine Mannigfaltigkeit vorstellt, auf welche der identische Kalkul anwendbar ist.
In diesem Denkbereiche werden sich die Untersuchungen der Theorie im vorliegenden Bande vornehmlich, ja fast ausschliesslich bewegen, weshalb wir — den Exponenten 2 zumeist und namentlich in allen Formeln (seltner im Texte) weglassend — denselben kürzer mit 1 selber bezeichnen werden.
In einfachster Schreibung seien demnach die Gleichungen 9) und 10) zusammenfassend wiederholt als: 11) [Formel]
Ein individuelles binäres Relativ i : j steht in dieser Tafel allemal in der durch i markirten Zeile und in der durch j markirten Kolonne (oder Spalte) — wären die Elemente i, j die natürlichen Zahlen, so könnten wir kürzer sagen:
in der iten Zeile und in der jten Kolonne.
Obwohl, wie bereits erklärt, die Voraussetzung einer bestimmten Reihenfolge oder Anordnung schon bei den Elementen des ersten, nicht minder also auch bei den Elementepaaren des zweiten Denkbereichs den Schlüssen der Theorie nicht zugrunde gelegt werden darf, wollen wir doch der Übersicht und der Bequemlichkeit der Ausdrucksweise zuliebe die vorstehenden Redensarten acceptiren:
Soll von solchen individuellen Relativen i : j, i : h, i : k, … gesprochen werden, welche im Relate übereinstimmen, so werden wir häufig sagen, dass sie aus derselben Horizontalreihe oder Zeile stammen, und „die zu i gehörige Zeile“ der Tafel 12 selbst wird uns dann eben einfach bedeuten: die Gesamtheit (identische Summe) aller der Elementepaare unsres zweiten Denkbereichs, welche i zum Relate haben.
Ebenso werden alle Elementepaare i : j, h : j, k : j, …, die im Korrelate übereinstimmen, von uns der nämlichen Vertikalreihe oder Kolonne zugewiesen.
Und wir unterscheiden demgemäss in unsrer Tafel 12 Reihen“ von Elementepaaren als parallele oder zu einander normale, sowie als horizontale oder vertikale.
Fasst man die individuellen Elementepaare unsres Denkbereiches 12 in’s Auge, so wahrnimmt man solche von zweierlei Art, je nachdem in i : j das i = j oder aber i ≠ j ist.
Im ersten Falle haben wir ein Elementepaar von der Form i : i.
Ein solches soll ein individuelles (binäres) „Selbstrelativ“ genannt werden.
Falls dagegen i ≠ j ist, so heisse i : j ein individuelles (binäres) „Aliorelativ“.
Ich übersetze hiemit einfach die von Peirce gegebnen Namen „selfrelative“ und „aliorelative“.
Es kann anstössig gefunden werden, dass „self-“ oder „Selbst-“ nicht, wie die andern zur Zusammensetzung dieser Namen benutzten Wörter, aus dem Lateinischen stammt.
Wenn man nicht „Ipsirelativ“ sagen will, so könnte man auch „Idemrelativ“ für unser „Selbstrelativ“ nehmen.
Andre Möglichkeiten wären die, zu sagen: Autorelativ und Heterorelativ, oder Idio(Homo-?)relativ „ Allorelativ zur ersten Hälfte aus dem Griechischen, zur zweiten aus dem Lateinischen genommen, desgleichen zur ersten Hälfte dem Deutschen entstammend: Selbstrelativ und Anderrelativ Eigenrelativ „ Fremdrelativ.
Auch schlug mir ein Kollege vor, für Relativ „Beziehnis(s)“ zu sagen.
Ich habe mich nach sorgfältiger Erwägung keinem dieser Vorschläge anzubequemen vermocht.
Dem letzten nicht, weil für die Wissenschaft zur Deckung ihres Neubedarfs an Wörtern internationale Ausdrücke aus toten, den klassischen Sprachen weitaus den Vorzug verdienen.
Der Ausdruck „Anderrelativ“ gibt zu unangenehmen Anklängen Veranlassung, wenn neben den Anderrelativen von andern Relativen oder gar von andern Anderrelativen gesprochen werden muss.
Die übrigen Ausdrücke erscheinen weniger zutreffend, decken wol den Begriff minder genau.
Obwol nun also „Selbstrelativ“ den erwähnten internationalen Rücksichten nicht ganz gerecht wird, will ich es beibehalten, den romanischen Kulturvölkern es überlassend, sich ein Wort nach ihrem Geschmacke dafür zu bilden; jenes erscheint mir als das beste und bezeichnendste wenigstens für die germanische Sprachengruppe mit Einschluss der englischen Sprache.
In unsrer Tafel 12 stehen die individuellen Selbstrelative A : A, B : B, etc. alle auf einer geraden Linie, welche von links oben nach rechts unten diese Tafel mitten durchschneidet, und — gemäss einer in der Lehre von den Determinanten und den Matrices geläufigen Übung — als die „Hauptdiagonale“ der Tafel bezeichnet wird.
Unter der Hauptdiagonale von 12 verstehen wir also — analytisch gefasst, wenn man es unabhängig von geometrischen Veranschaulichungen, die eine bestimmte Anordnung der Elementepaare auf einer Fläche vorauszusetzen scheinen, aussprechen will — weiter nichts als: die Gesamtheit (identische Summe) aller individuellen Selbstrelative aus unserm zweiten Denkbereiche.
Die individuellen Aliorelative liegen ausserhalb, stehen seitlich von, oberhalb und unterhalb der Hauptdiagonale.
Jedes individuelle Selbstrelativ ist das konverse von sich selber.
Zu einander konverse individuelle Aliorelative stehen dagegen „symmetrisch zur Hauptdiagonale, sodass, wenn man diese letztere als spiegelnde Linie ansieht, irgend eines der beiden das Spiegelbild sein müsste vom andern.
Wenn wir sonach über die „individuellen binären Relative“ nunmehr Bescheid wissen, so drängt sich die Frage auf: was ist zu verstehen unter einem „binären Relativ“ überhaupt?
Obwol dies systematisch erst im nächsten Paragraphen festgesetzt werden soll, wollen wir die Antwort hier schon vorgreifend geben.
Darunter wird zu verstehen sein: eine identische Summe (ein Inbegriff) von irgendwelchen individuellen binären Relativen.
Aus unserm Denkbereiche 12 können wir irgendwelche Elementepaare herausgreifen und sie — sei es kollektiv zu einem „Systeme von Elementepaaren“, sei es generell zu einer „Klasse von Elementepaaren“ — mittelst identischer Addition vereinigen.
Das Ergebniss wird ein binäres Relativ (schlechtweg) zu nennen sein.
Der Gesichtspunkt, unter welchem wir solche Aushebung von Elementepaaren vornehmlich vollziehen, wird allerdings der sein, dass wir zu einer Klasse oder identischen Summe von Elementepaaren alle diejenigen individuellen Relative i : j jeweils vereinigen, bei welchen das Relat i zum Korrelat j in einer „Beziehung“ von bestimmter Art steht, einer Beziehung, charakterisirt durch ein gewisses „fundamentum relationis“, auf welches sich gerade das Interesse konzentrirt.
Gleichwie jedoch in der (weiteren) Umfangslogik der Klassenbildung keinerlei Schranken gesetzt waren, und die Individuen einer Klasse nicht etwa, der Forderung der (engeren) Inhaltslogik entsprechend, dadurch zusammengehalten werden mussten, dass sie einen regelrechten „Begriff“ konstituiren, so sollen auch hier die Aushebungsmöglichkeiten für die zu einem binären Relativ zu vereinigenden Elementepaare durch keinerlei Schranke eingeengt sein, und mag ein Gesichtspunkt, wie der erwähnte, zumeist zwar maassgebend sein als Beweggrund für deren Aushebung aus dem Denkbereiche 12, ohne dass jedoch sein Vorhandensein eine unerlässliche Bedingung für diese Aushebungen bildete, welche vielmehr (von vornherein) auch ganz nach Willkür vollzogen werden können (um von da ab festgehalten zu werden).
Eine Zusammenstellung von irgend drei Elementen i, j und h aus unserm ursprünglichen Denkbereich 11, wenn dieselben in dieser bestimmten Reihenfolge geschrieben werden, mag nun weiter ein „Elementetripel“ oder „individuelles ternäres Relativ“ genannt und mit 12) [Formel] dargestellt werden.
Die Gesamtheit, identische Summe aller erdenklichen Elementetripel bildet einen neuen Denkbereich, den wir als den „Denkbereich der dritten Ordnung“ mit 13 bezeichnen, sodass uns gilt: 13) [Formel] .
Spezifizirt könnten die Elementetripel übersichtlich nur in Gestalt eines Blockes — etwa ein Buch füllend — angegeben werden, auf dessen erster Seite die Elementepaare von 12 in 11) mit dahintergesetztem „:A“ stünden, dessen zweite Seite (besser: Vorderseite des zweiten Blattes) dieselben Elementepaare mit dahintergesetztem „:B enthielte, die dritte Seite (resp. drittes Blatt auf seiner Vorderseite) ebenjene mit dahinter gesetztem „:C“ und so weiter, weshalb wir auf deren spezifizirte Angabe hier verzichten.
Mathematisch gesprochen besteht der Denkbereich 13 aus der „dritten Klasse der Variationen (oder permutirten Kombinationen) mit Wiederholungen“ von den Elementen des ursprünglichen Denkbereiches 11.
Jenachdem in i : j : h alle drei Elemente einander gleich (d. h. identisch, einerlei) sind, oder — was auf drei Arten möglich — nur zweie derselben, oder endlich keines von ihnen mit einem andern zusammenfällt, d. h. alle drei verschieden sind, hätten wir fünferlei individuelle ternäre Relative zu unterscheiden, für welche bezüglich die Beispiele: 14) [Formel] vorbildlich sind.
Eine identische Summe aus Elementetripeln, irgendwie hervorgehoben aus dem Denkbereiche 13, wird nun ein „ternäres Relativ zu nennen sein.
Indem alle individuellen ternären Relative als unter sich und vom Nichts verschieden zu gelten haben, wird auch auf den Denkbereich 13 und die in ihm denkbaren ternären Relative mindestens zunächst der identische Kalkul (als Gebiete- sowol wie als Klassenkalkul) anwendbar sein.
Und so weiter.
Es ist klar, wie man in dieser Weise fortfahren kann, auch alle erdenklichen Quadrupel, Quintupel, Sextupel, … von Elementen des Denkbereiches 11 zu einem Denkbereiche 14, 15, 16, … der vierten, fünften, sechsten, …
Ordnung vereinigend und in ihm den Begriff des quaternären, quinären, senären, …
Relativs aufstellend.
Zum Schlusse sei noch bemerkt, dass auch die „absoluten Terme“, (Gebiete oder) Systeme“, „Klassen“ schlechtweg, das ist — wie gesagt — die Summen, welche aus Elementen des ursprünglichen Denkbereiches 11 gebildet gedacht werden können, sich werden ansehen, darstellen und bezeichnen lassen als „uninäre Relatice“ (bei Peirce simple relatives“) — wie denn in der That von vornherein nichts im Wege steht, die Elemente i des Denkbereiches 11 auch „individuelle uninäre Relative“ zu nennen.
Ich habe schon anderwärts diese Neubildung gewagt, da mir der Ausdruck „semelär“, welcher eigentlich der Reihe semel, bis, ter, ‥, der Stammwörter unsrer Nomenklatur zu entnehmen wäre, zu befremdlich vorkommt.
Das der Reihe singuli, bini, terni, … angehörige Wort „singulär“ ist bereits mit allzu viel Nebenbedeutungen im Gebrauche.
Obwohl in „binär“ etc. die Endung -arius, und nicht -narius, verwendet ist, und demnach „unär, multär“ vielleicht korrekter als wie „uninär, multinär“ gebildet erschiene, glaube ich doch als Neubildungen diesen letztern den Vorzug geben zu sollen.
Als obersten Einteilungsgrund für die Klassifikation aller erdenklichen Relative haben wir dann also: die „Ordnung“ derselben.
Wir haben Relative der ersten, zweiten, dritten etc.
Ordnung zu unterscheiden.
Und es ist ein Relativ von bestimmter Ordnung weiter nichts als die (identische) Summe von irgendwelchen „individuellen Relativen ebendieser Ordnung, während unter den „individuellen Relativen“ einer bestimmten Ordnung zu verstehen sind: die „Variationen (mit Wiederholungen) zur gleichen Klasse“ aus den Elementen des ersten Denkbereiches.
Letztere werden — bei den höheren Ordnungen (die „Variationen zur ersten Klasse“ sind bekanntlich die Elemente selbst) — symbolisch dargestellt, indem man die in bestimmter Reihenfolge in sie eingehenden Elemente mittelst Doppelpunkten verknüpft.
Endlich aber soll im voraus darauf hingewiesen werden, dass die Theorie der Relative die Möglichkeit schaffen und ein Verfahren aufstellen wird, um Ausdrücke, sowol als Relationen, Formeln oder Sätze, von Relativen einer bestimmten Ordnung aus diesem ihrem gemeinsamen Denkbereiche umzudeuten in einen Denkbereich von andrer Ordnung.
Nämlich, je nach Wunsch, entweder:
sie „vorzudeuten“ in einen Denkbereich von höherer Ordnung, indem alle den Ausdruck zusammensetzenden, resp. in die Relation oder Formel eingehenden, Relative der gegebenen Ordnung gültig umgeschrieben (transformirt) werden in lauter solche von dieser verlangten höheren Ordnung.
Oder (sofern der Denkbereich, dem die gegebenen Relative angehören, nicht schon von der niedersten also ersten Ordnung ist) auch: sie „zurückzudeuten“ in einen Denkbereieh von niedrerer Ordnung.
Bei der Zurückdeutung jedoch gehen gewisse Momente (Elemente) unsrer Kenntniss über die Konstitution der betreffenden Relative verloren, resp. sie werden ignorirt, es wird von ihnen abstrahirt, m. a. W. es werden gewisse Teile unsres Wissens fallen gelassen, preisgegeben, welche hernach bei einer etwa darauf folgenden Wieder-Vordeutung nicht wieder gewonnen werden, sich nicht mehr restituiren, sodass der durch eine Zurückdeutung herbeigeführte Verlust an Erkenntnisskapital ein dauernder bleibt — natürlich unbeschadet der Zulässigkeit und Berechtigung des ganzen Prozesses.
Im richtigen Erfassen dieser Prozesse, in der angemessenen Interpretation und Verwertung der für einen Denkbereich aufgestellten Formeln für einen andern unsrer Denkbereiche, liegen wol die Hauptschwierigkeiten, denen das Verständniss unsrer Theorie begegnen mag und welche behufs Erzielung solchen Verständnisses überkommen werden müssen.
Die Umdeutung aus dem zweiten in den ersten Denkbereich — sowie umgekehrt — wird hiefür vorbildlich sein.
Wir wollen deshalb an die Frage erst wieder herantreten, nachdem wir uns in diesen beiden Denkbereichen gründlich orientirt haben werden, und gehn darum jetzt zur eingehenden Betrachtung des zweiten Denkbereiches, 12, über, dem wir unsre Aufmerksamkeit auf lange Zeit fast ausschliesslich zuwenden, d. h. wir beschränken unsre Betrachtungen auf die Algebra und Logik, die Theorie der binären Relative.
Zweite Vorlesung.
Die formalen Grundlagen, insbesondre zur Algebra der binären Relative.
§ 3.
Die 29 zu 31 fundamentalen Festsetzungen.
Summendarstellung der Relative. Aussagenschemata.
Wesentlich — wenn wir absehen von den Abkürzungen, die noch durch Einführung der Summen- und Produktzeichen Σ, Π angestrebt worden sind, sowie von den Übereinkünften behufs Klammern-Ersparniss und dergleichen Äusserlichkeiten oder Nebendingen mehr — beruht die ganze Algebra der binären (und der uninären) Relative — ja wenn man will: die gesamte Logik — auf nur 29 konventionellen Festsetzungen, die sich (ohne die allerdings dazu wünschenswerten Erläuterungen) bequem auf einer halben Druckseite übersichtlich würden zusammenstellen lassen.
Gleichwie in den beiden früheren Bänden sehen wir auch hier die durch das Zeichen ⋹ auszudrückende Beziehung der Einordnung, Subsumtion als die fundamentale an, mittelst welcher (oder deren Verneinung ⋹) alle übrigen Beziehungen erst ihre Erklärung finden müssen.
Und wir stellen darum an die Spitze als eine für alle Symbole a, b unsrer Theorie maassgebende die Definition der Gleichheit (das ist hier immer: Einerleiheit, Identität), welche wir in der — sogleich nachher von neuem zu rechtfertigenden — Schreibweise des „Aussagenkalkuls“ wie früher formuliren als:
(1)
[Formel] .
Die folgenden 14 (es geht schnell!) fundamentalen Festsetzungen lauten:
(2)
[Formel] [Formel] (4)
1̅ = 0, 0̅ = 1.
Nachdem wir hiermit schon über die Hälfte der formalen Grundlagen unsrer Theorie statuirt haben, wollen wir in deren Aufzählung eine Pause eintreten lassen um uns das Bisherige etwas näher anzusehen.
Für einen Wertbereich der aus nur zwei Symbolen 0 (identische Null) und 1 (identische Eins) besteht, sind mit dem Vorstehenden vollständig — obzwar in nuce — festgelegt: die Gesetze der Einordnung und Nichteinordnung, der Gleichheit und der Ungleichheit, zudem eines Kalkuls, der zu Grundrechnungsarten die „drei identischen Spezies“: Multiplikation, Addition und Negation hat.
Die 4 Konventionen (2) setzen fest, welche von den in jenem Wertbereich überhaupt denkbaren Subsumtionen gelten und welche nicht gelten sollen.
Dreien wird Geltung zugeschrieben, der vierten abgesprochen.
Im Hinblick auf (1) wird sich daraus auch ableiten lassen, dass von den 4 ebenda denkbaren Gleichungen diese beiden: 0 = 0 und 1 = 1, von den 4 denkbaren Ungleichungen diese: 1 ≠ 0 und 0 ≠ 1 zu gelten haben.
Die 8 Konventionen (3) stellen den „Abacus“, das Einmaleins und das Einspluseins für jenen auf die Symbole 0 und 1 restringirten Wertbereich vor.
Für diesen Wertbereich definiren sie vollständig das Produkt a · b oder ab und die Summe a + b zweier Werte a und b — wie immer letztere „allgemeinen“ Werte auch bestimmt, angenommen oder gedacht werden mögen innerhalb jenes Wertbereiches.
Das Einmaleins stimmt vollständig mit dem numerischen überein, wie es etwa für das dyadische Zahlensystem lauten würde und als ein Teil des weltläufigen dekadischen Einmaleinses ohnehin jedermann geläufig ist.
Das Einspluseins zeigt nur die eine Abweichung von dem numerischen Einspluseinse, dass hier 1 + 1 = 1 festgesetzt ist.
Zur Motivirung dieser Abweichung wird vielleicht der Hinweis nicht überflüssig sein, dass, weil in unsrer Disziplin für „gleich“ nur gelten soll, was identisch, einerlei ist, ein wiederholtes Setzen von „Gleichem nicht anders denkbar sein wird, denn in Form einer tautologischen und darum belanglosen Wiederholung — vergleichbar der Bethätigung jenes Kindes, welches seinem Freunde einunddasselbe, „das nämliche Objekt zu wiederholten malen schenkt.
Gerade dieser Abweichung aber wird unsre Disziplin ihre wundervolle Symmetrie hauptsächlich verdanken.
Die 2 Konventionen (4) definiren allgemein die Negation ā („a strich“ oder „nicht-a“) für jeden Wert a jenes Bereiches.
Was die Anzahl unsrer Konventionen betrifft, so ist ja unverkennbar, dass in unsrer Art, sie zu zählen etwas Willkürliches liegt.
Man könnte mittelst Anwendung von Buchstaben als allgemeiner Wertzeichen die Menge der als selbständige hinzustellenden fundamentalen Konventionen noch weiter verringern oder reduziren.
So würden sich die erste und die dritte Konvention (2) in die Formel a ⋹ a — unser früheres Prinzip I — zusammenfassen lassen, und würden die 6 Festsetzungen der ersten Zeile von (3) schon durch die viere a · 0 = 0 = 0 · a, a + 1 = 1 = 1 + a ersetzbar sein.
Ebensogut lassen aber auch die drei ersten Konventionen (2) in die beiden sich zusammenziehen 0 ⋹ a ⋹ 1, die uns als „Def. (2)“ von Bd. 1 her wohlbekannt sind, und — noch besser — fassen sich schon alle 8 Konventionen (3) zu den 4 wohlbekannten Gesetzen zusammen: a · 0 = 0, a + 1 = 1, a · 1 = a = a + 0.
Am wirksamsten dürfte aber zur Reduktion unsres Konventionensystems — sofern man solche überhaupt noch begehren mag — ein Verfahren sich erweisen, welches darauf hinausliefe, die Begründungsweise des identischen Kalkuls wie sie in Bd. 1 für eine viel umfassendere Mannigfaltigkeit bereits gegeben worden, hier, für unsern so beschränkten Wertbereich 0, 1, im wesentlichen zu wiederholen.
Insbesondre wären dabei die 8 Konventionen (3) durch die „Definitionen (3)“ in Bd. 1 S. 196 sq. von Produkt und Summe, — statuirt in allgemeinen Wertzeichen a, b, c — zu ersetzen, und aus diesen der Abacus — so wie Bd. 1 S. 271 sq. die „Theoreme 21) und 22)“ — zu beweisen.
Unstreitig liesse sich also hinbringen, dass man für das Bisherige auf eine geringere Zahl von selbständigen Festsetzungen blos sich zu berufen brauchte.
Man könnte deren aber auch eine grössere Anzahl herausbringen [statt 15 bis jetzt im Maximum 26].
Denn: auch darin lag etwas Willkürliches, dass wir Subsumtionen wie Gleichungen unterschiedlos als „Festsetzungen“ zählten, während doch kraft (1) jede Gleichung ein Paar von Subsumtionen in sich schliesst.
Über die genaue Anzahl der als selbständige Konventionen ganz unumgänglichen Festsetzungen, welche die formale Grundlage für unsre gesamte Theorie zu bilden hätten, will ich daher mit niemand rechten.
Mit ihrer Aufzählung bezwecke ich blos, einen praktisch vorzüglich brauchbaren Ausgangspunkt zu schaffen und eine vollkommene Übersicht anzubahnen.
Da bilden denn in der That die bisherigen 15 Daten jedenfalls den Kern und spezifizirten Inhalt dessen, was ein damit äquivalentes System von Konventionen allgemeinerer Form aussagen (in sich begreifen, involviren) würde, welches etwa diese Data noch konziser zusammenzufassen strebte — wie immer auch solches formulirt sein möge.
Dieser Kern erscheint hier in kunstloser Enumeration in’s Einzelne („detaillirt“) auseinander-gesetzt.
Von vornherein leuchtet ein, was auch die Folge bekräftigen wird, dass unser Konventionensystem ein widerspruchsfreies ist, wie denn überhaupt dieselben von vornherein als von einander unabhängige erscheinen.
Beide Überzeugungen sind aus der Wahrnehmung zu schöpfen, dass jede einzelne von diesen Festsetzungen (1) bis (4) sozusagen „ein neues Symbol“ definirt, welches in den vorhergehenden noch niemals erwähnt war, sodass durch diese darüber auch nicht präjudizirt sein konnte.
So — um mit dem Ende anzufangen: wenn erst ausgemacht worden, was unter 1̅ zu verstehen sei, so ist damit noch offen gelassen, was wir unter 0̅ verstehen wollen, und wie immer wir letzteres ausmachen wollen (weil eben noch nichts darüber ausgemacht ist, sind wir auch zu nichts verpflichtet), so wird die Abmachung weder in der oder den vorhergehenden enthalten sein, noch mit ihnen in Widerspruch treten können.
Beim Abacus (3) — in dessen erster Zeile die Produkte resp. Summen nicht sowohl einander als vielmehr dem letzten Symbole 0 resp. 1 jeweils gleichgesetzt zu lesen sind — enthält jede der (so geschieden zu denkenden) Gleichungen auch eine neue sonst überhaupt nicht vorkommende Knüpfung zwischen 0 und 1. Und dass z. B. die Gleichung 1 + 1 = 1 nicht aus den andern folgen kann, lässt schon die Exemplifikation auf das numerische Einmaleins erkennen, wo zwar die andern Gleichungen ebenfalls gelten, sie (allein) gleichwol nicht gilt.
Dass sie auch nicht in Widerspruch mit den übrigen stehen kann, erscheint darum als selbstverständlich, weil sie des bislang noch unerklärten Ausdrucks 1 + 1 erstmals und ausschliesslich Erwähnung thut, sodass über die demselben beizumessende Bedeutung Entgegenstehendes unmöglich schon ausgemacht sein kann.
Die Konventionen (2) endlich enthalten unabhängig von einander die Festsetzungen über die 0 resp. 1 als Subjekt (oder als Prädikat) zur 0 oder 1.
Hätten wir die 14 letzten Konventionen konziser, d. h. in eine geringere Zahl von — sonach allgemeineren — formalen Festsetzungen (unter Gebrauch von Buchstaben) zusammengefasst, so würde diese Überzeugung von der Unabhängigkeit und Widerspruchslosigkeit der fundamentalen Konventionen minder bequem und leicht zu gewinnen gewesen sein — was uns nicht zum wenigsten veranlasste, der obigen Form ihrer Statuirung den Vorzug zu geben.
Wie schon angedeutet bilden nun die bisherigen 15 Festsetzungen die Basis, ausreichende Grundlage einer Buchstabenrechnung, eines „Kalkuls“, in welchem von jedem „allgemeinen Wertsymbole“ oder Buchstaben — wie a, b, c … — zu unterstellen ist, dass er irgend einen der beiden Werte 0 und 1 repräsentire.
Die formalen Gesetze, Sätze und Formeln dieser Buchstabenrechnung sind keine andern als die des „Aussagenkalkuls“, jenes (noch formelreicheren) Unterfalles des „identischen Kalkuls“, den wir in Bd. 1 und 2 näher kennen gelernt haben.
Was wir dem Leser nunmehr zumuten müssen ist: dass er sich hiervon gründlich überzeuge, d. h. zum wenigsten, nachsehe, dass die l. c. zur Grundlage jener Kalkuln genommenen Definitionen und Prinzipien sich auch aus unsern 15 Festsetzungen ergeben, womit dann auch deren sämtliche Konsequenzen durch ebensie verbürgt sein werden.
Dies mag ganz kunstlos geschehen in der Form einer blossen Verifikation jener Grundlagen aus dem Abacus, aus unsern Festsetzungen.
Da für jeden Buchstaben nur die beiden Fälle zu unterscheiden sind, wo er 0 und wo er 1 bedeutet, so werden bei einer Formel, in der blos 1, 2 oder 3 Buchstaben vorkommen, auch nur 2, 22 = 4 resp.
23 = 8 Einsetzungen (von Wertsystemen 0 oder 1 für die Buchstaben) zu vollziehen sein, um dieselbe für alle erdenklichen Fälle zu bewahrheiten.
Beispielsweise können so das „Prinzip II“ des Bd. 1: (a ⋹ b)(b ⋹ c) ⋹ (a ⋹ c), die Definitionen (3) daselbst: (c ⋹ a)(c ⋹ b) = (c ⋹ ab), etc., das Assoziationsgesetz, und das volle Distributionsgesetz a(b + c) = ab + ac mit Leichtigkeit als kraft unsrer 15 Festsetzungen gültige nachgewiesen werden.
Mehr wie drei Buchstaben kamen in den zur formalen Grundlage des Aussagenkalkuls seinerzeit genommenen „Definitionen“ und „Prinzipien überhaupt nicht vor.
In gleicher Weise könnte man sich aber natürlich auch jedes komplizirtere Theorem, jeden Folgesatz des Aussagenkalkuls, den wir aus jenen formalen Grundlagen in der Theorie desselben deduzirten, unmittelbar verifizirt denken und aufgrund unsrer 15 Festsetzungen ihn nötigenfalls verifiziren.
Wir dürfen hienach nun mit einem Schlage die volle Vertrautheit mit dem gesamten Formalismus des Aussagenkalkuls (implicite damit zugleich also auch des identischen Kalkuls) beim Leser voraussetzen.
Und es erscheint mit dem Vorstehenden die wichtige Thatsache gesichert: dass es uns jederzeit freistehen wird, die 1 als eine „wahre“, die 0 als eine „falsche“ Aussage zu interpretiren — wo dann alle wahren Aussagen als einander gleich („äquivalent“) zu gelten haben werden, und ebenso alle falschen Aussagen — wofern wir zugleich die Subsumtion zwischen Aussagen, sowie die Aussagennegation, das Aussagenprodukt und die Aussagensumme, in der üblichen Weise deuten.
Mit dieser Bemerkung ist den Verwendungen, die wir mit denselben Wertsymbolen 0 und 1 im Wertbereich der Relative noch beabsichtigen, in keiner Weise vorgegriffen.
Der Studirende aber bleibe sich bewusst und halte fortgesetzt sein Augenmerk darauf gerichtet, dass wenn nunmehr aus den ferner hinzutretenden Festsetzungen werden Schlüsse, Folgerungen gezogen werden, dieses Folgern stets nach den Gesetzen ebenjenes Aussagenkalkuls vor sich geht, dessen Grundlage die bisherigen Festsetzungen bilden, und welche keine andern sind als die der allgemeinen Logik — auch der traditionellen, jedoch in ihrer knappsten und strengsten Fassung.
Die vierte Konvention (2) formulirt zwar für Aussagen den Gegensatz von „wahr“ und „falsch“, bringt ihn als einen solchen auf die knappste Weise zum Ausdruck.
Bei Relativen jedoch wird dieselbe erst dann eine wesentliche Rolle spielen, wenn partikulare Urteile in Betracht gezogen werden, und kann man zuvor derselben längere Zeit entraten.
Eine fernere Gruppe von — 7 — fundamentalen Festsetzungen ist dazu bestimmt, das allgemeine „binäre Relativ“ und gewisse spezielle Relative eben dieser (der zweiten) Ordnung zu definiren.
Mit diesen Konventionen treten wir eigentlich erst in die Algebra „der Relative“ ein, sintemal die vorhergehenden noch den elementareren Zweigen unsrer Disziplin der exakten Logik angehörten.
Die auch verbal zu gebenden Definitionen wollen wir alsbald mittelst Ansatzes von Gleichungen formuliren.
Die Gleichung involvirt zwei Subsumtionen und setzt nach dem bei Konvention (1) aufgestellten Ideale zum vollen Verständniss ihrer Tragweite eigentlich voraus, dass man schon wisse, was eine Subsumtion zwischen zwei binären Relativen bedeute.
Das hinwiederum lässt sich nicht (gut) sagen, bevor man weiss, was unter einem binären Relativ selbst zu verstehen ist.
Wir wollen oder müssen demnach die Frage nach dem Sinn einer Subsumtion zwischen Relativen a und b vorläufig (bis an’s Ende der Aufzählung) zurückstellen und den Begriff der Gleichheit, Identität — so, wie es überhaupt beim „Definiren üblich — hiernächst als den ursprünglichern gelten lassen.
Ich möchte sagen: „aus didaktischen Gründen“ doch mag man — worauf wenig Gewicht zu legen sein dürfte — über das Zutreffende dieser Bezeichnung verschiedener Meinung sein.
„Binäres Relativ“ nennen wir eine Summe von Elementepaaren, hervorgehoben aus dem Denkbereich 12 — und zwar von keinen, von irgendwelchen, oder auch von allen.
Als die allgemeine Form irgendeines binären Relativs a lässt sich demnach hinstellen der Ausdruck:
(5)
[Formel] — wo in der Summe Σi j die Indizes i und j unabhängig von einander alle Elemente aus dem Denkbereiche 11 (als ihre Bedeutung oder „Werte“) zu durchlaufen haben — sofern man nur die „Koeffizienten ai j (gesprochen: a tief ij), mit welchen die Elementepaare i : j (als die zugehörigen „Konstituenten“) behaftet oder „multiplizirt“ erscheinen, auf den Bereich der beiden Werte 1 und 0 beschränkt, was die Formel ausdrücken würde: (5α)
[Formel] und erstern Koeffizientenwert mittelst der Festsetzung (5β)
[Formel] das Vorhandensein von i : j als Glied der Summe garantiren, letzteren Koeffizientenwert mittelst der Festsetzung (5γ)
[Formel] den Ausfall des Elementepaares i : j als eines Gliedes der Summe bewirken lässt.
Die „Relativkoeffizienten“, kenntlich an dem Suffixe, mit welchem sie stets (in der Regel in Form eines doppelten Index) behaftet sind, werden demnach den Gesetzen des reinen Aussagenkalkuls unterliegen.
Die Operationen und Knüpfungen welche an, mit oder zwischen ihnen zu vollziehen sein werden, sind mit unsern ersten 15 Festsetzungen bereits vollständig erklärt und nach ihren Gesetzen geregelt.
Andre als die drei identischen Spezies (können und) werden nicht bezüglich ihrer in Betracht kommen.
Mit einfachen Buchstaben des kleinen lateinischen Alphabets, d. h. mit solchen ohne Suffix, werden wir — im Gegensatz hierzu — fortan immer binäre Relative darstellen; sogar mit jenen, die wir bereits für die Darstellung der Indizes uns reservirt haben, und unbeschadet dieser ihrer Verwendung, was allerdings noch näherer Erläuterung bedarf, die später (nach und nach) wird gegeben werden.
Der Gleichung (5) für sich allein würde, wegen der ursprünglichen Unerklärtheit der Koeffizienten ai j und von deren Wirkung, die Verständlichkeit noch abgehen, woferne man sie nicht in Verbindung mit ihren verbalen Zusätzen oder Zusatzformeln nähme, welche — cf. (5α) — jeden dieser Koeffizienten auf einen der beiden Werte 0 und 1 verweisen, und die Wirkung solchen Faktors 1 oder 0 auf einen Konstituenten mittelst (5β) und (5γ) erläutern.
Rationeller Weise kann man deshalb die vier Ansätze (5), (5α), (5β) und (5γ) doch nur als „eine Festsetzung“ hinstellen, und zwar jene (5) nicht blos als Formel betrachtet, sondern in Verbindung mit dem Worttexte genommen.
Namentlich ist hierbei unsre [nur der Übersicht zuliebe ebenfalls in Formeln gesetzte] Erläuterung (5γ) eigentlich in der verbalen Fassung der Theorie zugrunde gelegt zu denken, wonach für den Fall, wo ein Koeffizient den Wert 0 besitzt, einfach der Ausfall des zugehörigen Konstituenten i : j als eines Gliedes der a zu nennenden Summe gefordert wird — ansonst wir streng genommen genötigt sein würden auch noch den Satz a + 0 = a für Relative a von vornherein zu postuliren, und zu dem kleinen (übrigens in der That nicht sehr bedenklichen) Zirkel kämen, dass dieses vorweg als eine Konvention stipulirte Postulat sich später doch aus den noch hinzutretenden Konventionen beweisen lassen würde.
Einmal gesagt muss auch noch sein, dass bei mehrfachen Indizes, wie ij, ijh, …, sei es im Suffixe von Σ oder Π Zeichen, sei es im Suffixe eines Relativ-Symbols, wie a, ā, a + b, etc., die Elementbuchstaben eigentlich durch Kommata getrennt zu denken sind — was wir ausdrücklich zu thun blos der Druck- und Raumersparniss halber unterlassen: im Suffixe ist i j stets als Repräsentant von i,j und nicht etwa als „Produkt von i und j (welches ja allerdings korrekt mit i j darzustellen wäre) aufzufassen!
Da die Bezeichnung der Summationsvariabeln von vornherein gleichgültig ist, nämlich dazu uns jeder nicht schon anderweitig vergebene Name zur Verfügung steht, so konnten wir natürlich (5) auch schreiben:
[Formel] , und zu solcher Abänderung der Indizesbenennung müssten wir behufs Anwendung des Schema’s (5) jedenfalls schreiten in solchen Fällen, wo etwa einer der Namen i und j (vielleicht zur Darstellung eines bestimmten Elementes) bereits anderweitig vergeben, nicht mehr disponibel wäre.
Für a kann aber auch b oder c, und so weiter, in (5) durchweg gesetzt werden, kurzum ein jedes Symbol, sei es einfach oder zusammengesetzt, welches uns ein binäres Relativ vorzustellen bestimmt ist oder das wir unter die binären Relative aufnehmen.
Die Konvention (5) sollte als eine allgemeine hingestellt sein und das „Schema“ für alle binären Relative abgeben.
Soferne also in den nachstehenden Gleichungen die Symbole linkerhand uns als binäre Relative zu gelten haben werden, ist implicite mit (5) zugleich schon folgendes festgesetzt:
[Formel] — was zur Erleichterung des Verständnisses von allem Nachfolgenden hiermit ausdrücklich statuirt sei. —
Weiss man für einen bestimmten Denkbereich zu jedem erdenklichen Suffix ij, welcher Wert dem Koeffizienten ai j eines binären Relatives a zukommt, nämlich ob derselbe = 0 oder ob er = 1 (für ebendies gedachte Suffix ij) ist, so weiss man auch, welche Elementepaare in die Summe a ausschliesslich eingehen, man kennt die Art, wie das binäre Relativ a sich aus individuellen binären Relativen des Denkbereiches 12 zusammensetzt, m. a. W. man kennt das binäre Relativ a selbst.
Ein Relativ kann durch die Angabe seiner sämtlichen Koeffizienten, nämlich der Werte, die diesen zukommen, „bestimmt“, ausreichend beschrieben, bekannt gegeben werden.
Zur Determination, völligen Bestimmung eines binären Relativs, m. a. W. zur „Definition“ eines speziellen binären Relativs genügt es und ist es im Hinblick auf (5) nur mehr erforderlich, festzusetzen welche Werte seine Koeffizienten haben sollen.
Die Beschreibung, Spezifikation des Relativs reduzirt sich fortan auf die Angabe, Spezifizirung seiner Koeffizienten.
Hienach ist klar, dass durch die folgenden 6 Festsetzungen (6)
(7)
— oder, besser auseinandergelegt (7)
[Formel] und (8)
[Formel] (9)
[Formel] — welche für jedes Suffix i, j, beziehungsweise — bei (8) und (9) — h, k getroffen zu denken sind — die Symbole 1, 0, 1', 0' und i sowie i : j (auch) als „binäre Relative“ ihre Erklärung gefunden haben werden.
1i j = 1 0i j = 0
1'i j = (i = j) 0'i j = (i ≠ j)
Diese Festsetzungen bilden mit (5) zusammen die „zweite“ Gruppe der fundamentalen Konventionen, und sehen wir uns dieselben zunächst etwas näher an.
Die Symbole 1 und 0 sollen, wenn als Relative gedeutet, die beiden identischen Moduln genannt werden.
Durch die erste Konvention (6) ist der identische Modul 1 (Eins) zu einem binären Relativ gestempelt, welches mit dem Denkbereiche 12 zusammenfällt.
Er ist das Universum, die Vollsumme, das Totum oder Ganze des Denkbereichs, die Summe von allen seinen Individuen oder Elementepaaren.
Die zweite Konvention (6) stempelt den identischen Modul 0 (Null) zu einem völlig leeren Relative, zu einem solchen nämlich, welches gar kein Elementepaar unsres Denkbereiches 12 (und auch sonst nichts) enthält.
Wir haben kraft (6) mit Rücksicht auf (5), (5β) und (5γ): wo die letzte Gleichung, obwohl als rechte Seite derselben nichts zu sehen ist, dennoch als eine vollständige Gleichung anzusehen wäre.
Rechte Seite ist hier eine Summe, deren sämtliche Glieder „ausfallen“, d. h. in der That buchstäblich: „Nichts“.
Um die Verwechselung mit einer unfertigen Gleichung, deren rechte Seite erst noch herzustellen wäre, zu vermeiden, muss in solchen Fällen, wo alle Glieder auf einer Seite ausfallen, inskünftige stets das Symbol 0 eintreten.
1 = Σi ji : j 0 =
Die identischen Moduln repräsentiren die äussersten oder Grenzfälle, die beiden Extreme unter den denkbaren binären Relativen.
Kein Relativ (innerhalb 12) kann mehr individuelle binäre Relative oder Elementepaare enthalten als der Modul 1, keines kann deren weniger enthalten als der Modul 0, und man könnte darum auch 1 als das „Maximalrelativ“, 0 als das „Minimalrelativ“ hinstellen.
Auf die Zulässigkeit dieser Grenzfälle musste schon bei der allgemeinen Definition eines binären Relativs hingewiesen werden
Ausser diesen beiden „identischen“ Moduln treten aber noch zwei spezielle (binäre) Relative in der Theorie hervor, die sich durch die beiden Konventionen (7) definirt finden, nämlich die beiden „relativen Moduln“ 1' und 0' — gesprochen etwa: Einsap und Nullap (als Abkürzung von „Eins-Apostroph“ etc.).
Wir haben für sie kraft (5) die Darstellungen:
1' = Σi j(i = j)(i : j) = Σi(i : i) 0' = Σi j(i ≠ j)(i : j).
Ist nämlich — links vom Mittelstriche — j ≠ i, so ist der Aussagenfaktor (i = j) gleich 0 und fällt allemal das Glied i : j in der Summe aus.
Ist dagegen j = i, so hat der Aussagenfaktor (i = j) den Wert 1, und ist das Glied i : j in der Summe vertreten.
Dann aber dürfen wir für das j, welches einerlei mit i, auch den Namen i verwenden, wonach die vorhandenen Glieder sich in der Form i : i darstellen werden, und diese sind nun einfach für jedes i gebildet zu denken.
Das heisst nun: 1' ist die Summe „das Universum, der Bereich aller individuellen Selbstrelative des Denkbereichs 12, 0' ist die Summe aller individuellen Aliorelative jenes Denkbereiches, bildet „das Universum der Aliorelative“ (vergl. § 9).
Unsre Theorie der binären Relative kennt sonach vier „Moduln“, 1, 0, 1', 0', deren Benennung als solche sich bald noch genauer motiviren lassen wird. —
Bevor wir in die Besprechung der Konvention (8) eintreten, sei vorgreifend und als für die Algebra der Relative unwesentlich, dagegen für die Logik der Relative, für ihre Interpretation und Anwendung fundamental — somit hauptsächlich im Interesse der Anwendungen, die wir zur Illustration schon in die Algebra einzuflechten beabsichtigen — das folgende bemerkt.
Die Relativkoeffizienten, welche wie betont dem Aussagenkalkul unterliegen, werden sich jederzeit auch als Aussagen deuten, interpretiren lassen, und zwar wird man lesen können:
[Formel] .
Der Name a des binären Relativs gibt sich hienach als ein „relativer Name“ zu erkennen (vergl. Bd. 1, S. 76 sq.) äquivalent mit: „ein a von-“, wie „ein Liebender von-, Bild von-, Wirkung von-, Vater von-“ etc., als ein Name, der zu seiner Vervollständigung noch der Anfügung eines Korrelates bedarf. Dieselben Namen können aber auch als „absolute“ gebraucht werden, indem man sprechen kann von „Liebenden, Bildern, Wirkungen, Vätern“ etc. — ohne Anfügung von Korrelaten.
Die wesentlich von Peirce aufgestellte Festsetzung (8) — der ich nur diese ihre konziseste Fassung dortselbst gegeben — bildet nun die Grundlage für den Übergang von jener Verwendungsweise der Namen als relativer zu dieser, ihrer Verwendungsweise als absoluter Namen, und umgekehrt.
Sie lehrt nämlich zunächst: irgendein Individuum oder Element i des Denkbereichs 11 als ein binäres Relativ zu betrachten und darzustellen.
Und darnach wird sich denn späterhin von selbst ergeben, auf welche Weise überhaupt ein „absoluter Term“ — nämlich ein System“ oder eine „Klasse“ als die identische Summe von Elementen, Individuen i des Denkbereichs 11 — jederzeit darzustellen ist als ein binäres Relativ; sowie umgekehrt: wie binäre Relative zu interpretiren sind im ursprünglichen Denkbereiche, m. a. W. wie sie aus 12 in 11 zurückzudeuten sein werden.
Ich stehe nicht an, die Aufstellung dieser Konvention (8), so unscheinbar sie ist, für die höchste und belangreichste Leistung in der ganzen Theorie zu erklären.
Doch wird der Studirende in das volle Verständniss ihrer Tragweite, in ihre angemessene Handhabung und Verwertung nur allmälig hereinzuwachsen in der Lage sein.
Für die Darstellung von i werden wir kraft (8) und (5) haben: [Formel] , das heisst: i ist hingestellt als die Summe aller der Elementepaare, welche i zum Relate haben; es umfasst das Relativ i gerade die Glieder, welche in der Tafel 12 in der mit dem Element i markirten Zeile stehen.
Die Algebra der binären Relative kann aber schon auf eine hohe Stufe der Entwickelung gebracht werden, ohne dass jemals von der Konvention (8) Gebrauch zu machen wäre.
Es mag deshalb für den Leser der Rat am Platze sein, für den ersten und allgemeinsten Teil der Theorie diese Konvention vorderhand zu ignoriren; andernfalles würden ihm wol Schwierigkeiten des Verständnisses in den Weg treten — Einwürfe, die ihn irre machen, können sich aufdrängen, die er dann selbständig und ohne Führer zu überkommen resp. zu entkräften hätte, während wir im Systeme unsrer Theorie erst später daran kommen, sie doch mit Leichtigkeit — weil systematisch — zu beseitigen.
In der vollständigen Aufzählung der formalen Grundlagen musste diese Konvention (8) gleichwol ihre Stelle finden.
Die Konvention (9) läuft, nach den vorhergehenden:
(7) links, (5), und (3) links, wesentlich hinaus auf die Anerkennung der Gleichung [Formel] . Sie lässt nämlich erkennen, dass der allgemeine Koeffizient [Formel] eines mit i : j zu bezeichnenden binären Relativs nur dann nicht verschwindet, wenn die beiden Gleichungen h = i und k = j gleichzeitig den Wahrheitswert 1 haben — wonach denn in der sechsten Doppelsumme unsres „Korollars zu (5)“ nur das Elementepaar h : k nicht ausfallen, stehen bleiben wird, bei welchem h = i und k = j bedeutet.
Mit andern Worten garantirt uns die Konvention (9) die Zulässigkeit des Elementepaares i : j selbst als einer („eingliedrigen, monomischen“) Summe von Elementepaaren; sie reiht die Elementepaare förmlich ein unter die „binären Relative“ und gibt uns nachträglich und ausdrücklich Indemnität dafür, dass wir uns vorweg die Freiheit genommen, diese Elementepaare auch als „individuelle binäre Relative hinzustellen oder zu bezeichnen.
Gemäss einer bei Summen, Polynomen, Aggregaten der arithmetischen Analysis längst eingebürgerten Gepflogenheit mochte wol die Erklärung des binären Relativs, wie sie verbal unter (5) gegeben ist, von vornherein einer so weiten Auffassung begegnen, dass man sich bei (9) — ähnlich wie auch schon bei (6) — geneigt fühlen wird zu behaupten, diese Konventionen seien als ausdrückliche gar nicht mehr erforderlich, vielmehr als Selbstverständlichkeiten bereits mit dem Übrigen gegeben.
Ich will darüber mit niemand rechten.
Der deutlichen und bequemen Bezugnahme halber empfiehlt es sich jedenfalls, beim Chiffriren der fundamentalen Konventionen liberal, freigebig zuwerke zu gehn und lieber eine zuviel als eine zuwenig aufzuführen.
Auch von der Konvention (9) wird die Theorie imstande sein lange Zeit keinen wesentlichen Gebrauch zu machen.
Eine dritte Gruppe von — 6 — fundamentalen Festsetzungen definirt diejenigen binären Relative, welche aus gegebenen vermittelst der in § 1 erwähnten sechs Spezies oder Grundrechnungsarten ableitbar sind; sie erklärt die Resultate dieser 6 Operationen (an oder mit binären Relativen) als wiederum binäre Relative.
Dieselben lauten: (10) (11) [Formel] (12) (13) [Formel] , und sollen als allgemein, für jedes Suffix ij getroffene Vereinbarungen verstanden werden, was aussagenrechnerisch bei jeder von diesen Konventionen — ähnlich wie schon bei denen (6) ‥ (9) der vorigen Gruppe — eigentlich auszudrücken wäre durch ein Zeichen Πi j, vorangeschrieben der alsdann in Klammern { } zu setzenden Aussage, durch welche vorstehend die Konvention statuirt erscheint — bei der letzten z. B. mittelst: Πi j{ăi j = aj i}.
(ab)i j = ai jbi j (a + b)i j = ai j + bi j
(a; b)i j = Σhai hbh j (a ɟ b)i j = Πh(ai h + bh j)
Im Hinblick auf das unter (5)
Gesagte definiren die drei ersten (10) und (11) von obigen Festsetzungen das identische Produkt a · b oder ab, ferner die identische Summe a + b zweier Relative a und b, sowie endlich das Negat („die Negation“) ā (gelesen: a strich) eines Relativs a.
Weil nach bekannten Sätzen des Aussagenkalkuls — vergleiche auch den Abacus (3) — obiges (ab)i j nur gleich 1 sein kann, wenn ai j und bi j zugleich den Wert 1 haben, wogegen (a + b)i j allemal schon gleich 1 sein wird, wenn ai j oder bi j den Wert 1 besitzt, so sieht man, dass das identische Produkt ab dasjenige Relativ sein wird, welches die den Faktor-Relativen a und b gemeinsamen Elementepaare ausschliesslich enthält, wogegen die identische Summe a + b alle die Elementepaare, und diese allein, umfasst, welche entweder dem a oder dem b, oder auch diesen beiden Summanden, angehören.
Das Negat ā oder „nicht-a von-“ eines binären Relativs a aber wird kraft Konvention (4) gerade diejenigen Elementepaare des Denkbereichs 12 in sich vereinigen, welche in dem Neganden a unvertreten sind.
Die ersten 25 Festsetzungen (1) bis (11) zusammen mit der noch ausstehenden Festsetzung (14), welche den Abschluss unsrer Aufzählung zu bilden hat, indem sie schliesslich die „Einordnung“ zwischen binären Relativen definirt — diese 26 Konventionen werden sich als die ausreichende formale Grundlage dafür erkennen lassen, dass die binären Relative dem „identischen Kalkul“ unterworfen sind, wogegen die „spezifischen“ Gesetze des Aussagenkalkuls keineswegs für sie zu gelten brauchen.
Im Hinblick auf das unter (5)
Gesagte definiren nun ferner die drei letzten (12) und (13) von obigen Festsetzungen zweier binären Relative a, b, und endlich: das Konverse („die Konversion“) ă — gesprochen: a konvers — eines binären Relativs a.
das relative Produkt die relative Summe a; b — gesprochen: a von b — a ɟ b — ich spreche: a piu b —
Die „relative Multiplikation“, welche aus zwei binären Relativen a und b ein drittes binäres Relativ „a; b“ ableitet, darf auch deren Zusammensetzung oder Komposition genannt werden; wenn man indessen auch die „relativen Faktoren“ a und b als die „Komponenten“ bezeichnen mag, so würde doch der Name „Kompos(i)t“ oder „Kompot“ für relatives Produkt“ fataler Anklänge halber nicht annehmbar erscheinen — wogegen im englischen „compound“ angeht.
Die Festsetzungen (12) und (13) werden — später — sich aus den Bedürfnissen des verbalen Denkens auch motiviren lassen.
Was z. B. die erste von diesen Festsetzungen betrifft, so pflegt schon das verbale Denken auf Schritt und Tritt aus gegebenen Relativen wie „Liebender von-“ und Wohlthäter von-“ neue Relative, wie „Liebender von einem Wohlthäter von-“ zusammenzusetzen.
Übrigens muss noch bemerkt werden, dass — wegen der Nichtkommutativität der relativen Knüpfungen — die beiden relativen Faktoren in ganz verschiedener Weise in den Begriff des relativen Produktes eingehen und darum wohl zu unterscheiden sind als „erster relativer Faktor“, „relativer Vorfaktor“ oder „Multiplikand“ und „zweiter relativer Faktor“, „relativer Nachfaktor“ oder „Multiplikator“.
Wenn a; b gebildet wird, werden wir zu sagen haben, dass man b mit a „relativ vormultiplizire“, oder a mit b „relativ nachmultiplizire“.
Ebenso wird bei der Bildung einer relativen Summe a ɟ b der „erste (relative) Summand“, das „erste relative Glied“ a zum „zweiten“ b „voraddirt“, dieses zu jenem „nachaddirt“.
Wenn von relativem Addiren oder „Summiren“ (resp. Multipliziren) gegebener Terme schlechtweg gesprochen wird, so muss man sich allemal die Reihenfolge derselben beibehalten denken, in der sie angegeben wurden:
man verknüpfe dann die Terme in der Ordnung, in welcher sie Erwähnung gefunden haben.
Während das Konverse ă eines Relativs a leicht mit Worten zu beschreiben ist: als dasjenige binäre Relativ, welches ausschliesslich in sich vereinigt alle die individuellen binären Relative oder Elementepaare, die zu den in a enthaltenen „konvers“ sind (vergl. S. 10) — ist die Bildungsweise von a; b und a ɟ b eine verwickeltere, und behalten wir uns vor, dieselbe an andrer Stelle noch eingehender zu betrachten.
Hiernächst sei nur hervorgehoben, dass diese beiden mittelst relativer Knüpfung aus zwei gegebenen a, b zich zusammensetzenden Relative in (12) definirt erscheinen durch die Art, wie ihre Koeffizienten aus denen der beiden Terme a und b jeweils abzuleiten sind.
Zu dem Ende müssen diese letztern Koeffizienten auf jede erdenkliche Weise aus den Zeilen von a und aus den Kolonnen von b entnommen und nach Vorschrift der Formeln (11) miteinander verknüpft werden und zwar vermittelst „identischer“ Multiplikation resp. Addition, mithin durch Rechnungsarten, die dem Operationskreise des Aussagenkalkuls angehören.
Auch zur Erklärung und zum Verständniss der beiden relativen Knüpfungen ist lediglich die Kenntniss des Aussagenkalkuls vonnöten.
In einer Weise, die den Mathematiker an die (zeilenkolonnenweise) „Multiplikation der Determinanten“ erinnern wird.
Kraft des Abacus (3) — nebst (4) — sind die Operationen dieser letztern Disziplin unbedingt ausführbare und liefern in jedem Falle ihrer Anwendung ein „eindeutig“ oder unzweifelhaft bestimmtes Ergebniss.
Identisches Produkt und identische Summe irgend zweier Werte aus dem Wertbereich 0, 1 ist in jedem Falle wieder ein ganz bestimmter Wert aus ebendiesem Wertbereiche — nicht minder wie das Negat eines solchen.
Die Ausdrücke sind „vollkommen eindeutige“, d. h. nie undeutig“ und „nie mehrdeutig“.
Und diese Eigenschaft überträgt sich offenbar auf unsre sechs Spezies, für die Ermittelung der Koeffizienten von deren Erzeugnisse ein stets gangbarer Weg vorgezeichnet ist, nämlich ein bestimmtes Verfahren vorgeschrieben erscheint, welches sich lediglich aus Prozessen der vorerwähnten Art zusammensetzt — mit Ausnahme (wenn man will) der Konversion, bei der an jener Statt eine blosse Vertauschung der beiden Indizes einzutreten hat, die bewirkt, dass an die Stelle eines Koeffizienten des Operanden a ein gewisser andrer von dessen Koeffizienten tritt.
Kurz, wir können jedenfalls sagen:
Die sechs Spezies unsrer Disziplin — die identischen gleichwie die relativen Grundrechnungsarten — sind „vollkommen eindeutige“ Operationen.
Sie sind in unserm Denkbereiche stets unbedingt ausführbar; wenn a, b gegebene binäre Relative bedeuten, so sind die Symbole [Formel] welche die Resultate dieser Spezies als solche kennzeichnen, niemals sinnlose oder undeutige Zeichen, auch niemals mehrdeutige Namen, d. h. es kommt ihnen im Gebiete der binären Relative stets ein und nur ein Wert — in völliger Bestimmtheit — zu.
So schätzbar dieser Fingerzeig in didaktischer Hinsicht für den in die Theorie Eintretenden sein mag, soll derselbe hier doch nur als ein allgemeinphilosophischer Gesichtspunkt zur richtigen Erfassung der Theorie betont sein.
Als eine ihrer vornehmsten Aufgaben wird es dieser Theorie ja zufallen, das Wesen der „Eindeutigkeit“, eindeutigen Zuordnung erst zu ergründen, deren Begriff exakt zu formuliren und deren Gesetze zu deduziren.
Zuvor dürfen auf einen Begriff von so abstrakt philosophischem Klange, solang er noch von einem Nimbus phrasenhafter Unbestimmtheit umflossen, hier nicht Schlüsse gegründet werden.
Als letzte unsrer fundamentalen Festsetzungen, welche wir hiermit noch deren dritter Gruppe angliedern, ist hinzustellen: die Definition der Einordnung, Subsumtion zwischen binären Relativen.
Dieselbe lautet: (14) [Formel] und führt den fraglichen Begriff zurück auf den bereits bekannten, weil durch die Festsetzungen (2) erklärten, Begriff der Einordnung zwischen den gleichstelligen Koeffizicnten ebendieser Relative.
Von zwei binären Relativen a und b ist a eingeordnet b, a ⋹ b dann und nur dann zu nennen, wenn für jedes Suffix ij ist ai j ⋹ bi j. Darnach wird also a ⋹ b besagen, dass alle Elementepaare von a sich unter denen von b vorfinden.
Wir sagen dann auch: a ist Teil (echter Teil oder auch das Ganze) von b, ist in b enthalten.
Kraft (1) muss nun auch, wie leicht zu sehen, sein: Korollar zu (14) (a = b) = Πi j(ai j = bi j) — wonach denn zwei Relative dann und nur dann einander gleich zu nennen sein werden, wenn sie in den gleichstelligen Koeffizienten übereinstimmen, d. h. identisch die nämlichen Elementepaare ausschliesslich umfassen.
Damit findet auch unsre oben noch verbal geführte Überlegung, dass ein binäres Relativ durch seine Koeffizienten bestimmt sei, ihre rechnerische Bestätigung, und es wird den bereits in Gleichungenform gegebenen Festsetzungen (5) bis (13) durch (14) und (1) ihr voller Inhalt gesichert.
Wenn gelegentlich auch von Beziehungen der Unterordnung wie a ⊂ b (wo a „echter“ Teil von b zu nennen), vielleicht der Sekanz a ￼ b, etc. wird gesprochen werden, so können wir diese gleichwie die Beziehungen a ≠ b (a ungleich b), a ⋹ b (a nicht eingeordnet b), gemäss Bd. 2 nun auch als auf der Grundlage von (14) definirt erachten.
Zum Schlusse noch ein Wort der Rechtfertigung über die Abweichungen meines Bezeichnungssystems von den Peirce’schen, resp. dem uns am nächsten kommenden von diesen:
Wegen des nicht kommutativen Charakters der relativen Addition habe ich das Piu-Zeichen unsymmetrisch gestaltet, während Peirce 9c sich noch mit dem steifen bei Todesanzeigen üblichen Kreuze behalf.
Aus ähnlichem Grunde ist für die relative Multiplikation der Strichpunkt, das Semikolon, als ein unsymmetrisches Knüpfungszeichen von mir gewählt, während ich die identische Multiplikation als eine kommutative Knüpfung auch symmetrisch ausdrücke, sei es vermittelst des Punktes als Malzeichens, sei es — wie zumeist — durch einfaches Nebeneinanderstellen der Faktoren (ohne ausdrückliches Verbindungszeichen).
In letztrer Hinsicht weiche ich wesentlich von Peirce ab.
Peirce bezeichnet das identische Produkt mit „a,b“.
Ganz abgesehen davon, dass dieses Komma als Malzeichen für eine kommutative Knüpfung wegen seiner Unsymmetrie hinsichtlich rechts und links als weniger geeignet erscheint, muss ich solche Verwendung eines so häufig als Interpunktionszeichen gebrauchten Trennungszeichens nach wie vor für gänzlich unannehmbar erklären wegen der Verwirrung die sie anzurichten nicht verfehlen kann sowohl und vor allem im Texte, als auch in den Formeln, wo Funktionen von mehreren Argumenten in Betracht kommen, die ja auch durch Kommata zu trennen wären.
Vergl. Bd. 1, S. 193 sq.
Die relative Multiplikation sodann drückt Peirce sozusagen symmetrisch mittelst einfachen Nebeneinanderstellens der Faktoren aus.
Hiezu konnte ich mich schon darum, weil letztres Verfahren anderweitig vergeben war, nicht mehr bequemen.
Allerdings lassen sich zwei Umstände zugunsten dieses Peirce’schen Verfahrens anführen.
Der eine ist geringfügiger Art: wird ein Relativ a interpretirt als „ein a von-“ und zugleich, wie ich es vorschlage, das Semikolon als „von“ gelesen, so scheint dann „a; b“ als „ein a von von b gelesen werden zu müssen, wobei ich die tautologische Wiederholung des „von“ begreiflich ablehne.
Ich begegne dem Einwand, indem ich sage: a kann sowohl als absoluter Term, wie als Relativ gedeutet werden; im letztern Falle interpretirt man nicht sowohl a, als vielmehr eigentlich „a;“, d. h. „a von-“ scilicet (von) irgend einem dahinter gesetzt zu denkenden Korrelate.
Der zweite mehr in die Wagschale fallende Umstand ist dieser.
Unter den Begriff des binären Relativs fällt auch — wie wir sehen werden — der Begriff der mathematischen Substitution, nicht minder wie derjenige der Funktion.
Man schreibt nun allerdings nicht „f; x“ für eine Funktion von x, „f(x)“, jedoch auch ebensowenig „fx“.
Und ferner wird die relative Multiplikation der Substitutionen keine andre als deren eigentliche Multiplikation sein, welche die Substitutionentheorie ohne Knüpfungszeichen durch das blosse Nebeneinanderstellen der Faktor-Symbole schon längst auszudrücken pflegt.
Der Vorteile einer so einfachen Bezeichnungsweise will nun auch ich die Substitutionentheorie — solange sie (wie bisher) immer nur mit der einen Operation des gewöhnlichen (also „relativen“) Multiplizirens der Substitutionen zu schaffen hat, keineswegs berauben.
Vereinfachende Abweichungen von der systematischen Bezeichnungsweise zugunsten eines spezielleren Forschungsgebietes sind in einem solchen jederzeit zulässig, aber auch dessen Gepflogenheiten für eine so sehr viel allgemeinere Disziplin nicht maassgebend.
Gegen Peirce spricht hierbei ferner noch der Umstand, dass mittelst einfachen Nebeneinanderstellens der Terme bei ihm doch (gleichwie bei mir) das Produkt von Koeffizienten sowie Aussagen dargestellt wird, sodass also bei ihm, je nachdem a und b Relative oder Aussagen bedeuten, die Knüpfungen ab nicht durchaus denselben Gesetzen unterliegen, Verwechselungen näher gelegt erscheinen.
Die Koeffizienten werden sich zudem, obwol sie Aussagen sind, auch als (binäre, sogenannte „ausgezeichnete“) Relative darstellen lassen! (Siehe Ende des § 25).
Der „relative Modul“ 1' — der in der That sich deckt mit der „identischen Substitution“ 1 der Substitutionentheorie — wird von Peirce auch mit 1 selbst (ohne meinen Apostroph) bezeichnet — was nur darum bei ihm angängig, weil Peirce auch meinen „identischen“ oder „absoluten Modul“ 1 durch das Symbol ∞ (unendlich) ersetzt — nicht ohne aber für die Koeffizienten und Aussagen wieder meine (d. i. die Boole’sche) 1 beizubehalten!
Gegen diese Verwendung des ∞ glaube ich mich in Bd. 1, S. 274 sq. hinreichend ausführlich geäussert zu haben, wozu noch kommt, dass wir hier des ∞ auch noch zu ganz andern Zwecken — mehr im mathematischen Sinne — bedürfen werden, und dass die schönen Analogieen zwischen den absoluten und den relativen Moduln in Peirce’s Bezeichnungssystem verschleiert, im meinigen besser zutage treten.
Den relativen Modul 0' stellt Peirce dar durch ein gothisches n (wonicht das lateinische n) als dem Anfangsbuchstaben von „naught“ oder „nought“ (nichts).
Den fundamentalen Festsetzungen könnten (was anfangs unterblieb) endlich noch diejenigen zugezählt werden, welche die Verwendungsweise des Produkt- und Summenzeichens Π und Σ erklären und regeln.
Unter dem „laufenden Zeiger“ (d. i. der „Produktations“- resp. „Summations-Variabeln“) u stellen wir uns ein Relativsymbol vor, welchem alle Werte aus einem bestimmten (als irgendwie gegeben zu denkenden) Wertbereiche beigelegt werden sollen.
Dieser Wertbereich heisst die „Erstreckung“ des „nach u genommenen“ „Produktes Π“, resp. der Summe Σ“, und wird im allgemeinsten Falle eine wohldefinirte „Klasse von (binären) Relativen sein.
Unter dem „allgemeinen Term (Faktor resp. Summand)“ des Produktes [Formel] resp. der Summe [Formel] — welcher immer hinter diesem Zeichen zu erblicken ist — stellen wir uns irgend eine „Funktion von u“, f(u) vor, d. h. einen Ausdruck, welcher in irgendwie gegebner Weise vermittelst lauter Operationen aus der Gruppe der sechs Spezies unsrer Disziplin aufgebaut ist aus u selber und irgendwelchen andern Relativen a, b, c, …, x, y, …, deren Bedeutungen (Werte) aber, auch wenn die Bedeutung von u (innerhalb jener Erstreckung) wechselt, stets konstant festgehalten werden müssen.
Diese letzteren Relative heissen — im Gegensatz zum „Argument“ u — die „Parameter“ der Funktion f(u), und können sowol als allgemeine Relative aufgefasst werden, wie auch spezielle Werte haben, insbesondre können sie oder einzelne von ihnen auch durch Moduln vertreten sein.
Alsdann wird die Funktion f(u) selbst ein binäres Relativ sein, dessen Wert für jeden angenommenen Wert von u und fixirte Werte der allgemeinen Buchstabenparameter ein völlig bestimmter sein muss — aus dem Grunde, weil auch die Ergebnisse der den Ausdruck f(u) zusammensetzenden, in ihm vorgeschrieben erscheinenden Operationen oder Spezies durch unsre Festsetzungen als binäre Relative jeweils eindeutig erklärt worden.
In der That wird sich auch der allgemeine Koeffizient zum Suffix ij dieses Relativs f(u) vermittelst kombinirter Anwendung unsrer 6 Schemata (10) bis (13) durch die allgemeinen Koeffizienten des Argumentes u und sämtlicher Parameter nach einem vollkommen bestimmt vorgeschriebnen Verfahren als eine Aussagenfunktion derselben unschwer darstellen lassen.
Mit f(u) zugleich kennen wir also für jedes ij auch dessen Relativkoeffizienten {f(u)}i j.
Es handelt sich nun darum auch die Symbole:
[Formel] als binäre Relative zu erklären.
Diese Erklärung hat, wie immer, zu erfolgen vermittelst allgemeiner Angabe ihrer Koeffizienten.
Und letztere leisten im vorliegenden Falle die beiden Festsetzungen: (15) welche für jedes Suffix ij hiermit „ausgemacht“ sein sollen.
Diesen Festsetzungen werden wir im § 6 auch die einfachere Fassung zu geben vermögen: (15) . Rechnet man dieselben hinzu, so werden wir im Ganzen 29 + 2 = 31 fundamentale Festsetzungen zu zählen gehabt haben.
In der That kann über den Sinn und Wert der Koeffizienten- (id est Aussagen)produkte oder Summen rechterhand, durch welchen unser Koeffizient zur linken eben explizirt werden soll, in keinem Falle mehr ein Zweifel bestehen.
Im Hinblick auf die in unsrer neunten Vorlesung (§ 23 und 24) verfolgten Ziele ist es jedoch wichtig, letzteres noch eingehender zu erörtern und namentlich die Überzeugung zu gewinnen, dass es zur Evaluation solcher Aussagen-Π und Σ keineswegs erforderlich ist, den Begriff von Aussagenprodukt Π (resp. -summe Σ) etwa dadurch etablirt zu denken, dass man denselben so, wie es in Anhang 3 des Bd. 1 gesehah — aufgrund der mittelst „Schlusses von n auf n + 1“ von dreien auf beliebig (auch unbegrenzt) viele Terme ausgedehnten Assoziationsgesetze der Aussagenmultiplikation und Addition — fundirt, nämlich „induktorisch“ gewinnt.
Vielmehr genügt es, zur Aufstellung dieses Begriffes und zur Begründung der vornehmsten auf ihn bezüglichen Sätze, schon: auch nur das Recht in Anspruch zu nehmen, eine Überlegung allgemein zu führen, nämlich in universalen und Existenzialurteilen überhaupt zu denken.
Wir gehen darum auf die Rolle der Π und Σ im Aussagenkalkul hiernächst noch etwas näher ein.
Die Begriffe beider sollen hier als selbständig (independent, nicht rekurrirend oder induktorisch) aufgestellte zugrund gelegt sein, wie folgt.
Stellt Au irgend eine auf ein Gedankending u bezügliche Aussage, eine „Aussage über u“ vor, so hat uns von den beiden Symbolen [Formel] — erstreckt über einen irgendwie gegebnen Bereich von „Werten“ als den dem Symbole u unterzulegenden Bedeutungen — von diesen beiden hat uns das erstre vorzustellen: die Aussage, dass Au für jedes dieser Objekte u (innerhalb der „Erstreckung“) zutrifft, das letztre aber: die Aussage, dass Au für gewisse u (innerhalb dieser Erstreckung) zutrifft, mithin dass es mindestens ein u im Erstreckungsbereiche gibt, für welches Au zutrifft.
Hienach wird der Aussage [Formel] der Wahrheitswert 1 immer dann und nur dann zukommen, wenn, für jedes der gedachten u, Au = 1 ist, der Wahrheitswert 0 dagegen, falls es unter jenen mindestens ein u gibt, für welches Au nicht zutrifft, wo also Au = 0 ist.
Der Aussage [Formel] wird der Wahrheitswert 1 schon zukommen, wenn es im Erstreckungsbereiche nur überhaupt ein u gibt, für welches Au = 1 ist, dagegen wird ihr der Wahrheitswert 0 dann und nur dann zukommen, wenn es daselbst kein solches u gibt, d. h. wenn für jedes u des Erstreckungsbereiches Au nicht zutrifft, Au = 0 ist.
Stellt demnach v einen Wert vor, beliebig hervorgehoben aus dem Erstreckungsbereiche für u, so müssen wir haben:
[Formel] oder kürzer: α) [Formel] womit auch gegeben ist: β) . Letzteres zeigt, dass für jeden Wert (v oder u) aus dem Erstreckungsbereiche der sogenannte „allgemeine Faktor“ Au des Aussagen-Π auch angesehen und hingestellt werden kann als ein wirklicher („eigentlicher“) „Faktor“ des ohne Π-zeichen als ein „binäres“ (zweifaktoriges) bereits anderweitig erklärten Aussagen-„Produktes“ im engsten Sinne; und ebenso, dass das sog. „allgemeine Glied“ einer Aussagen-Σ auch wirklicher (oder „eigentlicher“) Summand ist einer binomischen Aussagensumme, d. h. einer Aussagensumme im engsten Sinne, als welche sich eben unsre Aussagen-Σ jederzeit muss hinstellen lassen.
Ferner erkennt man im Hinblick auf das oben Gesagte als unmittelbar einleuchtend, dass die Negation an unsern Aussagen-Π und Σ nach folgenden Schemata „auszuführen“ ist: γ) .
Und in dem hier bethätigten „dictum de omni et de nullo“, durch welches wir die sämtlichen vorstehenden Formeln gewinnen (deren Anerkennung wir ja fordern müssen), ist nicht etwa ein wirkliches „Axiom zu erblicken; vielmehr hat das dictum nur den Charakter eines „Prinzips“ (im Sinne des Bd. 1); es vertritt uns nämlich — und ist in der That weiter nichts, als:
— die Erklärung der Begriffe:
— welche Erklärung anders „förmlich“, als eine „regelrechte Definition“, wol nicht gegeben zu werden vermöchte.
Vergl. S. 67 sq.
„jedes“ (every) u, resp.
„einige“ oder „gewisse“ u (sive „überhaupt ein“ u, kürzer: „ein u“, some u, an u)
Das deutsche „irgend ein“ ist hier weniger geeignet, vonwegen seiner doppelsinnigen Gebrauchsweise, indem es bald für das englische „some“, bald für das „any“ steht, welches letztre als = „irgend ein beliebiges“ hier ausgeschlossen werden muss (da es vielmehr synonym mit „jedes“ wäre).
Umfasst der Erstreckungsbereich von u blos ein Objekt v, so ist leicht zu sehn, dass die Bedeutung sowol des ΠA als des ΣA alsdann die auf dieses eine v bezügliche Aussage A selbst sein wird, nämlich dass [Formel] alsdann sein wird.
Die Π und Σ bestehen hier nur aus einem Term, sind „monomisch“.
Umfasst der Erstreckungsbereich von u gerade zwei Objekte v und w, so erkennt man ebensoleicht, dass dann die Bedeutung von [Formel] zusammenfällt mit derjenigen vom, durch den Abacus (3) bereits (ohne Π und Σ-zeichen) erklärten binären Produkte, resp. der binären (= binomischen) Summe der auf v und w bezüglichen beiden Einzelaussagen.
Umfasst — um es nur mehr für das Π auszusprechen — der Erstreckungsbereich genau drei Objekte, welche uns für den Augenblick die Buchstaben u, v, w repräsentiren mögen, so liesse sich ähnlich einsehn, dass die Bedeutung des ΠA zusammenfällt mit dem — aufgrund des Assoziationsgesetzes der Aussagenmultiplikation — als der übereinstimmende Wert der beiden binären Aussagenprodukte Au(AvAw) und (AuAv)Aw erklärten ternären (dreifaktorigen) Produkte AuAvAw, und so weiter.
Für einen auf eine beliebige „Anzahl“, eine „endliche Menge“ von Objekten u beschränkten, „begrenzten“ Erstreckungsbereich nun ähnlich darzuthun, dass das Aussagen-Π sich auch mittelst successiven immer nur binären Multiplizirens zwischen seinen Faktoraussagen aus diesen ableiten lässt, dies auch zu statuiren und davon wesentlich Gebrauch zu machen, können wir in unsrer Theorie sehr wohl unterlassen, uns dessen enthalten, wenigstens bis dahin, wo in der neunten Vorlesung der „Schluss von n auf n + 1“ seine strenge Begründung gefunden haben wird.
Sobald aber letztere erfolgt ist, wird auch die angeregte Sache als mit einem Schlage durch unsern Anhang 3 des Bd. 1 vorweg erledigt zu betrachten sein.
[Noch weniger aber brauchen wir zuvor auch davon noch Notiz zu nehmen, dass für einen aus einer „unbegrenzten“ und zwar „einfach unendlichen“ Reihe von diskreten Objekten u bestehenden Erstreckungsbereich, unser ΠA sich auch sozusagen als ein „Grenzwert“ mittelst unbegrenzt fortzusetzenden binären Multiplizirens aus den Faktoraussagen ableiten lassen würde!]
Ist Au unabhängig von, konstant bezüglich u, das heisst: ist in der Aussage, welche hier als allgemeiner Term figurirt, von u gar nicht die Rede, so mögen wir (auch in den Formeln) das Suffix u bei der Aussage Au als belanglos unterdrücken, dieselbe blos mit A selbst darstellen.
Alsdann gilt wiederum selbstverständlicherweise: δ)
[Formel] . Ist ebenso Bu eine auf u bezügliche und B eine bezüglich u konstante Aussage, so haben wir ferner die Schemata: ε) welche beiden sich zu dem allgemeinern Schema zusammenfassen lassen:
[Formel] oder auch zu dem noch allgemeinern: ζ)
[Formel] , worin der Erstreckungsbereich für v ein beliebig andrer als der für u sein mag.
Analog zu vorstehenden Peirce’schen gelten aber auch die (meine) beiden Schemata: η) die sich zu dem allgemeinern:
[Formel] sowie zu dem noch allgemeinern: ϑ)
[Formel] zusammenfassen lassen.
Spezialisirt man in ε) und η) A = 1 (indem man hernach A für das verbleibende B sagt) oder B = 0, so ergeben sich die Schemata: ι) von welchen das erste und letzte im Hinblick auf das „spezifizische Prinzip“ des Aussagenkalkuls (A = 1) = A sich als nichtssagend darstellen, die beiden andern aber von der häufigsten Anwendung sind.
Endlich ist, als von häufigstem Gebrauche, noch das Aussagenschema anzuführen: κ)
[Formel] worin von den beiden mittleren, den untereinander stehenden Subsumtionen, sei es als Thesis (Behauptung, Folgerung) sei es als Hypothesis (Voraussetzung, Bedingung) blos die eine (oder die andre) genommen zu werden braucht. Dieselben gestatten namentlich das überschiebende Produktiren sowie Summiren von für den Erstreckungsbereich allgegemein geltenden Subsumtionen, etc.
Hiermit haben wir wol die wichtigsten Schemata oder Sätze des Aussagenkalkuls soweit sie Aussagen-Π und Σ betreffen, rekapitulirt und zur Bequemlichkeit des Studirenden übersichtlichst zusammengestellt — solche jedenfalls, mit denen (und ein paar sogleich folgenden Beiträgen) sich wird auskommen lassen.
Sie sind ausdrücklich oder in nuce in Bd. 2 schon vorgekommen, wenngleich etwas zerstreut (ibid. S. 40, 180, 194, 258, 261, u. a.).
Man erkennt in α) die Theoreme 6) des Bd. 1 und 2 wieder, in β) nah liegende Korollare dazu kraft R. Grassmann’s Theoremen 20), in γ)
De Morgan’s Theoreme 36), in δ) die Tautologiegesetze 14), in ε) die Bd. 1 und 2 mit (3) chiffrirte (dort) „Definition“ von Peirce, in η) aber das von mir Bd. 2 S. 258 (als blos für Aussagen gültig) dazu gelieferte Gegenstück, in ι) das Th. 24) nebst einem Bd. 2, S. 261 dazu gelieferten (blos für Aussagen gültigen) Gegenstück, in κ) endlich Erweiterungen der Theoreme 17).
Nicht mitangeführt sind noch die Distributionsgesetze für die Aussagen Π und Σ: λ) nebst ihren Erweiterungen zur Multiplikationsregel für (Aussagen-) Polynome und deren dualem Gegenstück: μ) .
Das Pendant zu λ): ν) versteht sich aus δ) von selbst nach den Identitäten: ξ) deren jeweilig letzte jedoch nur gilt sofern u und v die nämliche Erstreckung haben.
Auch würden sich über mehrfache Summen und Produkte noch weitre Schemata anreihen lassen.
Als bemerkenswertester neuer schliesst sich diesen der von Herrn Peirce aufgestellte Satz an:
Stellt Au,v eine auf zwei Objekte u und v bezügliche Aussage vor, welche je in einem eignen Erstreckungsbereiche variabel gedacht werden sollen, so ist stets ο)
[Formel] — worin natürlich das Symbol Au,v auch a priori durch das Av,u ersetzbar.
Gibt es nämlich mindestens ein u derart, dass für dieses u und jedes v die Aussage A gilt, so wird es auch für jedes v mindestens ein u geben (nämlich eben das genannte) derart, dass von beiden die Aussage A zutrifft.
Der Schluss ist jedoch augenscheinlich nicht umkehrbar.
Wir werden aber die gedachten Schemata vorwiegend, wenn nicht ausschliesslich, auf solche Objekte u, v, ‥ anzuwenden bekommen, welche nicht sowol allgemeine Relative, als vielmehr blos „Elemente i, j, ‥ sive „Individuen des ersten Denkbereiches“ sind.
In solchem Falle hängen wir, anstatt sie unter das Σ oder Π zu schreiben, die laufenden Zeiger den Σ und Π (wie bisher schon) als Suffixum an.
Um nicht Überflüssiges zu leisten und uns zu sehr zu wiederholen, wollen wir deshalb die einschlägigen oder noch ausstehenden von den beachtenswertern Schemata blos mit obiger Beschränkung und erst in § 7 in’s Auge fassen.
Schon bei dieser Beschränkung der laufenden Zeiger auf Elemente sei jedoch darauf hingewiesen und betont, dass der Erstreckungsbereich unsrer Aussagen-Π und Σ allemal auch ein „Kontinuum“ sein darf, wie es beispielsweise die reellen Zahlen, oder die Punkte einer Geraden insgesamt bilden.
In solchen Fällen bleiben die Zeichen Π und Σ definitiv unentbehrlich und würde es nimmermehr thunlich sein, das mittelst des Π (z. B.) „symbolisch“ dargestellte Aussagenprodukt als ein „aktuelles Produkt mit allen seinen Faktoren explicite hinzuschreiben.
Stets werden es in unsrer Theorie — wenn nicht blosse Aussagen-Produkte resp. Summen — so doch „identische“ Produkte Π und Summen Σ sein, welche uns diese Zeichen darstellen helfen. M. a. W. die Zeichen Π, Σ werden als solche nur für die erste Hauptstufe von uns verwendet: um eine identische Multiplikation resp. Addition von (zumeist unbegrenzt vielen) Relativen anzudeuten.
Sollten jemals diese Symbole zur Abkürzung auch von relativen Produkten und Summen in Bedarf kommen, so werden wir sie uns zur Unterscheidung (ähnlich wie die Moduln) in Gestalt von Π', Σ' mit einem Apostroph versehen.
Begreiflich wird jedoch solche Verwendung noch eingehendere Vorbetrachtungen, eventuell gerichtet auf die Bestimmung des allgemeinen Koeffizienten, erheischen.
Die oben resumirten Aussagenschemata α) ‥ ο) muss der Studirende [so wie wir es unter ο) zur Illustration ausgeführt] sich gründlich überlegen und dieselben in succum et sanguinem aufzunehmen suchen.
Ein Übriges wird die Übung, die unsre Theorie gewährt, hinzuthun.
§ 4.
Die Matrix eines Relativs und deren Augen.
Beispiele.
Geometrische Repräsentation.
Die dreifachen Evidenzen.
Wir sahen: zur völligen Bestimmung, Determination oder unzweifelhaften Beschreibung eines (binären) Relativs in gegebnem Denkbereiche (12) genügt die Angabe seiner Koeffizienten.
Die mit Bezug auf die Elementepaare der Tafel 12 in Reihen geordnet zusammengestellten, je als 0 oder aber 1 spezifizirten Werte der Koeffizienten: 1)
[Formel] eines speziellen Relativs a bilden die sogenannte „Matrix“ desselben, und kann auch ohne jene Spezifizirung das vorstehende Schema wol als die Matrix eines allgemeinen binären Relativs a bezeichnet werden.
Man mag die Matrizen der Relative zwischen zwei vertikale, sogenannte „Kolonnenstriche“ einschliessen, wonach sie gerade so aussehen werden, wie „Determinanten“, deren sämtliche „Elemente“ nur „Nullen oder Einser“ wären.
Wird Unterscheidung von Determinanten auch im Äusserlichen gewünscht, so kann man unten die Kolonnenstriche noch mit einem Horizontalstriche behufs Hufeisen- oder U-förmiger Umrahmung der Matrix verbinden — der obere Teil muss für den Negationsstrich und event. das Konversionshyphen frei bleiben.
Mit dem Relativ zugleich ist seine Matrix bekannt, und umgekehrt.
Für viele Zwecke ist es aber bequemer, nur von dessen Matrix zu reden, blos diese zu schildern.
Beispielsweise wenn für einen Denkbereich von 4 Elementen A, B, C, D die Matrix eines Relativs a die folgende ist, so wird das Relativ den daneben angegebnen Wert haben: 2)
[Formel] und umgekehrt ist auch aus der rechts für a gemachten Angabe — selbst wenn die Glieder gänzlich zusammengerückt sein sollten — mit Leichtigkeit das Schema zur Linken als die Matrix von a zu entnehmen.
Man ermisst hier bereits, welche Druckersparniss durch die Angabe ihrer Matrizes an Stelle der Relative selbst erzielt zu werden vermag.
Der Vorgang besitzt ein bemerkenswertes Analogon und Präzedens in der Arithmetik bei der üblichen Darstellung der natürlichen Zahlen im dekadischen Zahlensysteme.
Daselbst ist eine natürliche Zahl ja eigentlich ein Aggregat oder Polynom, welches nach fallenden Potenzen der Grundzahl Zehn unsres Zahlensystems geordnet ist und als dessen Koeffizienten lauter „Ziffern“ auftreten, wie z. B. [Formel] , [Formel] .
Aus der Wahrnehmung nun, dass in dieser Weise dargestellt alle Zahlen in einem gewissen (nach links weit genug fortgesetzt zu denkenden) „Gerippe“: … + ‥ × 103 + ‥ × 102 + ‥ × 101 + ‥ × 100 übereinstimmen, entspringt die Berechtigung ebendieses Gerippe als selbstverständlich zu unterdrücken und die Zahlen mittelst einfachen Nebeneinanderstellens ihrer Ziffern (nämlich der Polynom-Koeffizienten) darzustellen — so, wie es links in den Klammern vorgreifend für sie angegeben ist — somit jene Schreibersparniss zu verwirklichen, die durch die Einführung der Ziffer 0 erst ermöglicht worden.
Ganz ähnlich in der That lassen wir hier beim Übergang von den Relativen zu ihrer Matrix weg: das Gerippe der Konstituenten oder Elementepaare (samt den sie verbindenden Pluszeichen) und behalten als das, was eben das Unterscheidende ist für verschiedene Relative (im gegebenen Denkbereiche), blos das System ihrer Koeffizienten bei — wobei es ebenfalls zur unzweifelhaften Darstellung der Relative erforderlich ist oder wenigstens zur Deutlichkeit ihrer Beschreibung beitragen wird, dass der Ausfall, das Fehlen gewisser Elementepaare oder Konstituenten durch Nullkoeffizienten markirt werde.
Man könnte nun die Koeffizienten eines Relativs auch als die „Elemente“ seiner Matrix bezeichnen; doch wollen wir um jeden Doppelsinn zu vermeiden, hier blos von „Stellen“ der Matrix reden.
Eine mit 1 besetzte Stelle der Matrix soll schlechtweg eine besetzte Stelle, eine „Vollstelle“ oder auch ein „Auge“ derselben genannt werden; jede mit einer 0 besetzte Stelle derselben heisse eine unbesetzte Stelle oder „Leerstelle“ — eventuell „Lücke“.
Wol weniger gut qualifiziren sich — weil auf der zu speziellen Anschauung von einer Lotterie beruhend — die Benennungen „Treffer“ und Niete“.
Auch die Bezeichnung als „Stift“ und „Loch“ oder „Kontakt“ und Unterbrechung“ — bei denen an die Möglichkeit einer (sicherlich bevorstehenden!) mechanischen oder maschinellen Ausführung der relativen Operationen, eventuell unter Beihülfe der Elektrotechnik, zu denken wäre — dürften vorderhand als „vorgreifende“ beiseite zu lassen sein.
Zur Darstellung von binären Relativen vermittelst ihrer Matrix empfiehlt sich ungemein die Verwendung von „karrirtem Papiere“.
Man kann die Zeilen eines solchen Blattes mit den Namen A, B, C, … der Elemente des Denkbereiches 11 markiren und ebendiese Namen auch den vertikalen Linien zur Überschrift geben.
Die Gitterpunkte markiren alsdann die „Stellen“ der Matrix.
In solchem Falle ist es nur erforderlich, ist es ausreichend, die als Vollstellen zu kennzeichnenden Gitterpunkte (in Druck oder Schrift) mit einem fetten oder schwarzen Punkte zu besetzen — vergleichbar den „Augen“ eines Dominosteines oder Würfels im Spiele; die unbesetzt gelassenen Gitterpunkte geben sich dann von selbst als die Leerstellen der Matrix zu erkennen.
Fig. 1.
Auf diese Weise würde beispielsweise die Matrix des obigen Relativs sich als die nebenstehende Figur präsentiren.
Die Vor- und Überschriften der Reihen kann man eventuell als selbstverständliche auch weglassen.
Dies vorausgeschickt wird nun der Leser praktisch am schnellsten von der Natur eines „binären Relativs sich einen richtigen Begriff verschaffen, wenn er sich ein wenig vertieft in den Anblick der beiden folgenden Figuren, durch welche ich für einen Denkbereich 11, bestehend aus den natürlichen Zahlen 0, 1, 2, 3, 4 … die Relative „Teiler von-“ und „teilerfremd mit“ (d. h. „relativ prim zu-“) vermittelst ihrer Matrix dargestellt habe.
Fig. 2.
Matrix des Relativs: „Teiler von-“.
Wenn ich bei Exemplifikationen auf den Denkbereich der Zahlen die bekannten Zeichen für die Zahlen Null und Eins mit einem Tupfen versehe, so geschieht dies natürlich blos ad hoc, zum Zwecke ihrer Unterscheidung von den beiden Wahrheitswerten der Aussagen sowie auch von den absoluten Moduln unsrer Theorie.
Und bei dem so spärlichen Vorkommen dieser Symbole als Zahlzeichen in unserm Buche erwächst daraus auch wie figura zeigt keine nennenswerte Belästigung.
Keineswegs jedoch soll damit etwa auf eine allgemeinere Annahme solcher Gepflogenheiten in der Arithmetik und anderwärts hingewirkt oder dafür plädirt werden.
Im Gegenteil, ich müsste dringend davor warnen: der Studirende, welcher die Zahl Eins stets mit Tupfen schreibt, muss im schriftlichen Rechnen hinter Andern zurückbleiben.
Die Elemente i, j sind hier natürliche Zahlen.
Um die Darstellung Fig. 2 des Relativs „Teiler von-“ zu gewinnen, hat man sich für jede Stelle, wo eine mit i markirt gedachte Zeile von der Kolonne zu einem j geschnitten wird, die Frage vorzulegen:
Ist i ein Teiler von j?
Im Bejahungsfalle ist der Gitterpunkt mit einem Auge zu besetzen, im Verneinungsfalle unbesetzt zu lassen.
Man erhält so ein Tableau, das an das „Sieb des Eratosthenes“ cribrum Eratosthenis (behufs Auffindung der Primzahlen) erinnert.
Dasselbe veranschaulicht für das Gebiet der natürlichen Zahlen den ganzen Umfang des (relativen) Begriffes „Teiler von- (einer Zahl).
Jede Zahl ist Teiler von sich selbst, weshalb denn die Hauptdiagonale voll mit Augen besetzt ist.
Unser Relativ — t mag es für den Augenblick heissen — enthält alle individuellen Selbstrelative unsres Denkbereiches, begreift sie unter sich: es ist 1' ⋹ t.
Unser t ist in Peirce’s Ausdrucksweise sowol Selbstrelativ als Negat eines Aliorelativs.
Die Zahl Null (0̇) ist sonst — ausser von sich selbst — Teiler von keiner Zahl, darum die erste Horizontallinie sonst eine leere.
Dagegen ist jede Zahl Teiler von Null, geht in der Null ohne Rest (und zwar nullmal) auf, darum die erste Vertikallinie eine vollbesetzte, eine „Vollkolonne“.
Die Zahl Eins (1̇) geht in jeder Zahl auf, daher die zweite Zeile überall mit Augen besetzt, eine „Vollzeile“.
Auch in jeder folgenden Zeile bilden die Augen eine Reihe von äquidistanten Punkten — mit immer grösserem Abstande.
Ebenso erscheinen sie aber auch auf Strahlen gereiht, die vom Anfangspunkt der Hauptdiagonale ihren Ausgang nehmen und sich asymptotisch der ersten Horizontale nähern. …
Das Relativ t ist ein hervorragendes Beispiel zu derjenigen Klasse von Relativen, die wir, weil t; t ⋹ t ist, „transitive“ zu nennen haben: ein Teiler von einem Teiler von“ (einer Zahl) ist immer auch ein „Teiler von“ (ebendieser Zahl).
Es ist hier sogar (weil auch das Umgekehrte gilt): t; t = t.
Um die Darstellung Fig. 3 des Relativs p = „teilerfremd mit-“ zu gewinnen, muss man sich ebenso für jeden Gitterpunkt die Frage vorlegen:
Ist das Element i, welches die Zeile markirt, d. h. die Zahl i, teilerfremd (relativ prim) mit der Zahl j, welche die Kolonne markirt? — um im Bejahungsfalle ein Auge einzutragen.
Dabei darf bekanntlich die Zahl Eins als ein allen Zahlen selbstverständlich „gemeinsamer“ Teiler als solcher nicht berücksichtigt werden.
Die Frage ist also: haben i und j noch (einen) gemeinsame(n) Teiler ausser der 1̇?
Im Verneinungsfalle sind sie „teilerfremd“ zu nennen.
Gewöhnlich wird der Begriff aber nur auf die Zahlen von 2 an aufwärts angewendet und haben wir nur für diese die Augen als fette in die Figur eingetragen.
Bei Einbeziehung, indessen, auch der Zahlen 0̇ und 1̇ würden als mit Augen zu besetzende auch noch diejenigen Gitterpunkte in Betracht kommen, die sich in der Figur mit hohlen Ringeln (unfett) markirt finden.
Bei der ganz strengen Fassung des Begriffes, wie sie oben durch die entscheidende „Frage“ charakterisirt erscheint, muss in der That dann jede Zahl zur Eins, und auch diese zu sich selber, teilerfremd genannt werden, auf welch letzteren Umstand das (einzige) Ringelchen auf der Hauptdiagonale hinweist.
Fig. 3.
Matrix des Relativs: „teilerfremd mit-“.
Für den engeren Denkbereich (der Zahlen von 2 an) gilt jedoch: dass keine Zahl teilerfremd mit sich selbst ist; bei dem Relativ mit fetten Augen bleibt die Hauptdiagonale eine unbesetzte oder leere und ist p ⋹ 0', unser p enthält nur individuelle Aliorelative und ist deshalb, in Peirce’s Terminologie, selbst ein „Aliorelativ“ zu nennen.
Das Relativ p exemplifizirt zudem jene Klasse von binären Relativen, welche eine „gegenseitige“ Beziehung zum fundamentum relationis haben, es ist p ein „symmetrisches“ (nach Einigen auch: „umkehrbares“, „konvertibles“) Relativ — symmetrisch inbezug auf die Hauptdiagonale — indem p̆ = p ist.
Aus den bisherigen Betrachtungen erhellt, dass — äusserlich genommen (m. a. W. in der suppositio nominalis, cf. Bd. 1, S. 44) — binäre Relative „Namen“ sind, welche, sei es mit bestimmtem, sei es mit offen gelassnem unbestimmten Korrelate, sowol als Subjekt, wie als Prädikat von kategorischen Urteilen figuriren können.
Als Prädikat finden sich solche schon mehrfach illustrirt.
Der Satz: Ein Teiler von einer Zahl ist (weil Teiler auch von sich selber) immer zugleich Teiler von einem Teiler dieser Zahl — dieser Satz illustrirt auch als Subjekt unser Relativ „Teiler von-“.
„Relative“ also sind nicht etwa Aussagen; vielmehr sind sie wirklich Namen von Dingen.
Sie sind aber — nach Mill so zu nennende — „mitbezeichnende“ oder „konnotative“ Namen, d. h. Namen, welche eine Aussage involviren.
Inbezug auf das hierüber in Bd. 1, S. 62 von mir Gesagte ist eine Bemerkung nachzutragen, welche weiter unten folgt.
Das durch Angabe seiner Matrix Fig. 2 spezifizirte Relativ „Teiler von“ — z. B. — gibt erschöpfend die Antwort auf die „Doppelfrage“: welche natürliche Zahlen Teiler sind von welchen natürlichen Zahlen.
Die durch das spezifizirte Relativ mitabgegebne Aussage ist eine völlig bestimmte, sobald das fundamentum relationis gegeben ist.
Alsdann haben nämlich die Gleichungen, vermittelst deren wir die Koeffizienten als = 0 oder = 1 spezifiziren, auch einen bestimmten Sinn.
Und das aus diesen Gleichungen gebildete Aussagenprodukt ist die von unserm Relativ involvirte Aussage.
So involvirt das als erstes Beispiel gebrachte und durch Fig. 1 dargestellte Relativ die Aussage: 3)
(aA A = 0)(aA B = 1)(aA C = 0)(aA D = 1) . . (aB A = 1)(aB B = 1)(aB C = 0)(aB D = 0) . . (aC A = 1)(aC B = 1)(aC C = 1)(aC D = 0) . . (aD A = 0)(aD B = 1)(aD C = 0)(aD D = 0) und gibt, wenn etwa a = „amans“ = „Liebender von-“ bedeutet, die Antwort auf die Frage: welche von den Personen A, B, C, D unsres Denkbereiches welche Personen lieben? — und zwar dahingehend, dass A den B und den D liebt, B den A und sich selber, C den A, den B und sich selber, D den B, sonst aber (von den Genannten) niemand jemanden (aus ihrer Mitte) liebt.
Ich habe die vorstehenden Beispiele gebracht, um vorweg das Interesse des Lesers für die Relative zu erregen, deren richtige Auffassung wenigstens anzubahnen.
Über die hierbei in Betracht kommenden und zum Teil erst flüchtig gestreiften Dinge werden wir uns in dem spezifisch logischen Teil unsrer Disziplin noch eingehender zu verbreiten haben.
Zur Stelle muss ich nur über den „konnotativen“ Charakter der relativen Namen zur Berichtigung noch folgendes aussprechen.
Wenn ich mich in Bd. 1 gegen eine Einteilung der Namen in „mitbezeichnende (konnotative)“ und „nichtkonnotative“ ablehnend verhalten habe, so geschah dies insofern mit Recht, als solche Einteilung — wie sich zeigen wird — zusammenfallen würde mit der Einteilung der Namen in absolute und relative, die wir ohnehin adoptirten.
Zu weit bin ich aber gegangen — und hat dies auch ein Kritiker (Herr Husserl1) beanstandet — indem ich durch die (wie ich fand und noch finde) unzutreffend gewählten Beispiele Mill’s mich verleiten liess, auch dem Begriffe der Konnotativität eines Namens die Berechtigung abzusprechen (Bd. 1, S. 62).
Auf dem durch die Bearbeitung der Theorie der Relative gewonnenen Standpunkte kann ich nicht umhin, diesem Begriffe eine gewisse Bedeutung zuzuerkennen, welche wie mir scheint gerade durch die Logik der Relative erst in das rechte Licht gesetzt wird.
(Darüber später noch Näheres!)
Als fernere Illustrationen von Relativen durch ihre Matrizes sollen die der vier Moduln (S. 50) hergesetzt werden — für den Fall der Verwendbarkeit von karrirtem Papiere.
Die Matrix des absoluten oder identischen Moduls 1 ist durchaus vollbesetzt, trägt an jedem Gitterpunkte ein Auge; die Matrix von 0 ist eine durchaus leere (enthält blos Leerstellen).
Die Matrix des relativen Moduls 1' hat die Hauptdiagonale mit Augen vollbesetzt, ausserhalb dieser Linie aber lauter Leerstellen; bei der Matrix von 0' ist es umgekehrt:
da enthält die Hauptdiagonale lauter Leerstellen während der ganze Aussenraum derselben mit Augen voll besetzt ist.
Man sieht auch hier, dass die Angabe der Matrix einfacher ist, als wie die der Relative 1', 0' selbst (die 1 und 0 wurden bereits in extenso angegeben, S. 11 und 26): 4)
1' = A : A + 0' = A : B + A : C + A : D + … + B : B + + B : A + B : C + B : D + … + C : C + + C : A + C : B + C : D + … + D : D + + D : A + D : B + D : C + … + … + . . . . . . . . . .
Ganz nebenher sei auch schon hier bemerkt, dass es freistehn wird, die absoluten Moduln 1 und 0 als „etwas“ (resp. „etwas von“) — eine Kategorie unter welche „Alles“ fällt — und „nichts“ (resp. „nichts von“) zu deuten — übrigens sehr cum grano salis.
Fig. 4.
Matrix von 1.
Fig. 5.
Matrix von 0.
Fig. 6.
Matrix von 1'.
Fig. 7.
Matrix von 0'.
a; 1 könnte also mit Worten beschrieben werden als a, zusammengedacht mit (bei Peirce minder genau: „coexistent with“) irgend etwas.
Etc.
Genaueres siehe im logischen Teile.
Der relative Modul 1' aber kann als „einerlei, identisch mit“, „gleich oder „selbst“ (identical with), der 0' als „ein andres als“ (other than), ungleich mit“, „verschieden von“ gedeutet werden.
Kraft Festsetzung (8) des § 3 haben wir ferner noch: 5) i = i : A + i : B + i : C + i : D + … und besteht hienach die Matrix des Elementes oder Individuums i des Denkbereiches 11, wenn dasselbe als binäres Relativ aufgefasst, im Denkbereiche 12 gedeutet wird, aus lauter leeren oder unbesetzten Zeilen mit Ausnahme der einen mit i markirten Zeile, in der nun alle Stellen mit Augen voll besetzt sein werden.
Die nebenstehende Figur stellt beispielsweise die Matrix des Elementes D vor. —
Die Matrix des Elementepaars oder individuellen binären Relativs i : j trägt kraft Festsetzung (9) blos an der einen Stelle, wo die ite Zeile sich mit der jten Kolonne schneidet, ein Auge, während sie überall sonst nur Leerstellen aufweist.
Man könnte sie füglich als „Einauge“ („Punkt“) charakterisiren.
Wir überlassen es dem Leser sie sich zu veranschaulichen.
Fig. 8.
Umfasst der Denkbereich 11 eine begrenzte Menge, eine „Anzahl von Individuen i, so besteht die Matrix jedes binären Relativs aus n × n = n2 Stellen, deren jede entweder mit 1 oder mit 0 besetzt zu denken ist, d. h. leer sein oder aber ein Auge tragen wird.
Die Mannigfaltigkeit der alsdann möglichen oder denkbaren binären Relative ist in solchem Falle ebenfalls eine endlich begrenzte, und zwar ist die AnzahI dieser Relative, wie leicht zu sehen, [Formel] mithin 16 bei n = 2, ferner 512 bei n = 3 und 65536 bei n = 4, etc.
Umfasst dagegen der Denkbereich 11 eine unbegrenzte Menge von Elementen i, so wird auch die Mannigfaltigkeit der möglichen binären Relative eine unendlich grosse.
Die Begriffe: „endlich“, „Anzahl“, „unendlich“ und insbesondre „einfach unendlich“ sowie „mehrfach unendlich“ werden ja systematisch erst später einzuführen und strenge zu definiren sein.
Doch muss behufs Besprechung der geometrischen Veranschaulichung unsrer Relative vermittelst ihrer Matrizen hier vorgreifend von diesen Begriffen schon ein populärer Gebrauch gemacht werden.
Nur bei „einfach unendlichem“ Denkbereiche 11, d. h. populär gesprochen: falls die natürlichen (oder auch die ganzen) Zahlen zur Numerirung seiner Elemente ausreichen würden, genügen auch die Gitterpunkte (eines unbegrenzt zu denkenden Blattes) von karrirtem Papiere um die Matrixstellen aller binären Relative zu repräsentiren.
Das quadratische Schema der Matrix eines solchen Relativs, wie wir es bei endlichem Denkbereiche hatten, degenerirt alsdann, indem es mindestens nach rechts und unten unbegrenzt bleibt, in ein den Winkelraum eines Rechten oder Quadranten erfüllendes Schema von in Reihen geordneten Stellen, deren jede für sich entweder unbesetzt ist oder ein Auge trägt.
(Es kann jedoch auch dieses Schema nach links und oben so fortgesetzt werden, dass es die ganze Ebene überdeckt.)
Bilden dagegen die Elemente des Denkbereiches 11 als eine mehrfach unendliche Mannigfaltigkeit etwa ein „Kontinuum“, so empfiehlt es sich zumeist, diese Elemente den Punkten einer (begrenzten oder unbegrenzten) geraden Linie eindeutig zugeordnet zu denken.
Die Möglichkeit solcher Zuordnung zu den Punkten einer geraden Linie oder auch schon Strecke ist ja für jeden stetigen unendlichen wenn auch mehrdimensionalen Denkbereich in der Georg Cantor’schen „Mannigfaltigkeitslehre“ mathematisch bewiesen (so namentlich für alle Punkte des Raumes).
Doch mögen wir — davon absehend — sie hiernächst einfach zur Voraussetzung erheben.
Ein hervorragendes Interesse wird somit jedenfalls die Supposition beanspruchen dürfen, wo als Elemente (oder Repräsentanten der Elemente) des Denkbereiches 11 die sämtlichen Punkte einer unbegrenzten — sagen wir horizontalen — Geraden angesehen werden können, sodass in dem ursprünglichen Denkbereiche das Element i irgend einen Punkt dieser Geraden markirt.
Wir können alsdann in bekannter Weise auch die reellen Zahlen zur Bestimmung unsrer Elemente i verwenden, die genannte Gerade als die x-Axe eines rechtwinkligen Koordinatensystems in der Ebene hinstellen, deren positive Seite sich rechts von einem in ihr angenommenen Ursprunge (oder Nullpunkte) befindet, und können von da die positive y-Axe nach unten gehen lassen.
Für den Denkbereich der zweiten Ordnung, 12, wird alsdann jeder Punkt der Koordinatenebene eine Matrixstelle repräsentiren und als Träger zu dienen haben für den Koeffizienten eines ganz bestimmten Elementepaares.
Und zwar des Elementepaares i : j, wenn in ihm die mit i (auf der y-Axe) markirte Horizontallinie oder Zeile zusammentrifft mit der mit j (auf der x-Axe) markirten Kolonne — kurz wenn i als Ordinate und j als Abszisse die rechtwinkligen Koordinaten des gedachten Punktes sind.
Eine den Koeffizienten 1 tragende Matrixstelle wird als ein „Auge fortan ein mittelst schwarzen Druckes hervorzuhebender Punkt sein, wogegen eine den Koeffizienten 0 tragende Matrixstelle weiss, unbedruckt zu bleiben hat.
Die Augen der Matrix eines binären Relativs bilden somit irgend eine Figur in der Koordinatenebene und umgekehrt wird jede Figur in der Ebene — wie immer sie auch aus Punkten, Linien (Kurven) und eventuell auch Flächen zusammengesetzt sei — sich ansehen lassen als die Matrix eines (durch sie völlig bestimmten) binären Relatives.
Die Theorie der binären Relative gewinnt bei dieser Veranschaulichungsweise den Reiz sich zu präsentiren als eine ganz eigentümliche Form von „analytischer Geometrie der Ebene“.
Wir werden sie kurz „die geometrische Repräsentation“ der Relative nennen.
Insbesondre wird nun die ganze schwarz bedruckte Ebene den Modul 1, dieselbe, weiss oder unbedruckt gelassen, den Modul 0 repräsentiren.
Der Modul 1' ist (schwarz ausgezogen gedacht) die den Koordinatenwinkel halbirende Gerade (deren Gleichung in der gewöhnlichen Darstellung y = x wäre), das ist die (eine) „Symmetriegerade“ der beiden Koordinatenaxen, welche immer noch den Namen „Hauptdiagonale“ weiter führen mag.
Der Modul 0' ist die ganze Aussenfläche eben dieser Symmetriegeraden (d. h. sonst die ganze Ebene schwarz bedruckt gedacht und nur die Hauptdiagonale weiss gelassen).
Das „Element“ i als binäres Relativ gedeutet ist Funktionskurve einer konstanten Funktion, nämlich die im Abstand i zur x-Axe parallele Gerade, als deren Gleichung gemeinhin y = i anzusetzen wäre.
Ein einzelner Punkt aber in der Ebene (auch wenn er auf der x-Axe gelegen) repräsentirt — wenn schwarz bedruckt oder hervorgehoben gedacht — allemal jetzt (d. h. für den Denkbereich 12) ein „individuelles binäres Relativ“ oder „Elementepaar“ i : j (und nicht mehr, wie oben sub 11, ein Element i selber).
Dieser geometrischen Repräsentation der binären Relative durch Punktsysteme („Gebiete“) in der Ebene ordnen offenbar auch die vorhergehenden Matrixdarstellungen (bei endlichem oder einfach unendlichem Denkbereiche) sich ein, indem sie eben nur einen Teil der verfügbaren Koordinatenebene in Anspruch nehmen — sodass wir für alle Fälle werden von der geometrischen Repräsentation reden und Gebrauch machen können.
Interessant ist es z. B. sich zu vergegenwärtigen, welche Figur das S. 45 sq. betrachtete Relativ „Teiler von-“ für unser Kontinuum bilden wird.
Der Begriff des Teilers ist ja in der That längst von den ganzen auch auf beliebige Zahlen ausgedehnt: a ist Teiler von b, sooft b/a eine ganze Zahl ist.
Darnach sieht man leicht, dass die Figur ein Büschel wird von unendlich vielen (voll ausgezogenen) diskreten Geraden (Doppelstrahlen), die vom Ursprunge ausgehen und sich der x-Axe asymptotisch nähern — und zwar symmetrisch zu beiden Seiten der y-Axe, welche selbst zu dem Büschel gehört, wogegen die x-Axe frei bleibt.
Es wäre nicht schwer auch „die Gleichung“ dieser Geradenschar aufzustellen.
Im Anschluss an diese Betrachtungen müssen wir jetzt auch die Frage beantworten, als welche Figuren — wenn die geometrische Repräsentation der binären Relative a und b bekannt ist — sich die Resultate der sechs Spezies: ā, ab, a + b, ă, a; b, a ɟ b nunmehr darstellen werden?
Es leuchtet sofort ein, dass die drei ersten von diesen Ausdrücken die aus dem identischen Kalkul bekannte Bedeutung haben.
Das Negat ā von a hat ausschliesslich die Leerstellen von a mit Augen besetzt; seine geometrische Repräsentation wird erhalten, indem man in der Figur von a sozusagen schwarz und weiss vertauscht; die Figur von ā ist die Aussenfigur derjenigen von a.
Das identische Produkt ab stellt sich geometrisch dar als der Schnitt (Dedekind’s „Gemeinheit“) der Figuren a und b; es ist der Inbegriff, die Gesamtheit der den Relativen a und b gemeinsamen Punkte oder Augen.
Man lasse also behufs Bildung von ab alle die Punkte (Augen) weg, die blos dem einen oder blos dem andern der beiden Relative a, b angehören.
Die Matrix von ab enthält ausschliesslich diejenigen Augen, welche dem Relativ a und dem Relativ b zugleich angehören — in bekannter Analogie mit dem grössten gemeinschaftlichen Divisor zweier Zahlen, insofern ab das weiteste (umfassendste, ausgedehnteste, „grösste“, augenreichste) Relativ sein wird, welches sowol in a als in b enthalten ist.
Die identische Summe a + b stellt sich geometrisch dar als die Figur, das Punktsystem, zu welchem die Figuren von a und von b einander gegenseitig ergänzen.
Die Zeichnung zu dieser Figur wird erhalten, indem man beide Figuren — die von a und die von b — in die Ebene einträgt, die eine sozusagen über die andre hinweg druckend; die doppelt bedruckten Stellen werden dabei gleichwie die blos einfach bedruckten nur eben schlechtweg schwarz erscheinen.
Die Matrix von a + b umfasst ausschliesslich diejenigen Augen, welche dem Relativ a oder dem Relativ b angehören.
In Analogie zu dem kleinsten gemeinschaftlichen Vielfachen zweier Zahlen wird a + b das engste (mindestumfassende, „kleinste“, augenärmste) Relativ sein, welches sowol a als b in sich enthält.
Besteht überhaupt zwischen zwei Relativen die Beziehung der Einordnung, ist a ⋹ b, so wird die Matrix von a Teil sein (echter Teil oder das Ganze) von der Matrix von b.
Die Figur von a liegt alsdann ganz in der Figur, dem Punktsysteme von b, d. h. wirklich innerhalb derselben, oder aber indem sie sich mit demselben deckt). M. a. W.
Die Figur von b enthält, begreift in sich die Figur von a.
Die geometrische Repräsentation des Konversen ă zu einem gegebenen Relativ a wird ferner erhalten, indem man die Matrix, Figur von a umklappt um die Hauptdiagonale, sodass von den beiden positiven Axenrichtungen, der x- und der y-Axe, eine jede in diejenige Lage kommt, welche zuvor die andre inne hatte.
Dem Analysten ist das Umklappen von Determinanten, dem Geometer die Vertauschung der Koordinatenaxen ein längst geläufiger Prozess.
Mehr neu und unsrer Disziplin eigentümlich sind die Prozesse der beiden relativen Knüpfungen, wenngleich auch sie in der Analysis schon ein Präzedenz besitzen in Gestalt der „Zusammensetzung von Funktionen“ — noch allgemeiner: in der Elimination einer Variabeln aus zwei Gleichungen oder Ungleichungen.
Diese Operationen sind auch von verwickelterem Charakter wie die vorhergehenden.
Um zu entscheiden, ob das relative Produkt c = a; b an einer bestimmten Stelle, die dem Elementepaar i : j entspricht (in der Sprache der analytischen Geometrie: an der Stelle x = j, y = i) ein Auge trägt oder nicht, hat man sich die Kolonne j des Relativs b so über die Zeile i des Relativs a umgelegt zu denken, dass das obere Ende, der Fusspunkt jener Kolonne in der x-Axe auf den linkseitigen Anfang oder Fusspunkt dieser Zeile auf der y-Axe zu liegen kommt.
Fallen dann irgendwo zwei Augen zusammen, kommt nämlich ein Auge von a zur Deckung mit einem Auge von b, indem eben beide in ihrer Reihe (Zeile resp. Kolonne) die gleiche (hte) Stelle einnehmen, so ist ci j = 1, d. h. c an der fraglichen Stelle mit einem Auge zu versehen, andernfalles behält c daselbst eine Leerstelle.
Fig. 9.
Bei dem gleichen Verfahren des Superponirens, Übereinanderlegens wird die relative Summe d = a ɟ b immer und nur dann an der Stelle ij ein Auge bekommen, wenn auf jede Stelle der iten Zeile ein Auge zu liegen kommt — sei es ein solches von a allein, sei es eines nur von b, sei es auch in Deckstellung ein Auge von a zusammen mit einem Auge von b.
Für gewöhnlich wird man sich die gegebnen Relative in verschiedene Blätter eintragen, weil bei Eintragung in das nämliche Blatt betreffs irgend eines Auges zweifelhaft erschiene, ob es als ein Auge von a oder als ein solches von b anzusehen ist.
Bei Eintragung der Figuren von a und b in einunddasselbe Blatt würde die Deutlichkeit erfordern, dass man die Augen von a von denen von b etwa als Tupfen und Kreuze, am besten vielleicht (als Tupfen) durch verschiedene Färbung unterscheide — wobei aus rot und blau z. B. in Fällen der Deckung violett entstünde (sofern man nicht vorzieht, die linke Hälfte des Tupfens alsdann rot, die rechte blau zu zeichnen, oder auch die gefärbten Augentupfen des einen Relativs, diejenigen des andern an Grösse übertreffen zu lassen).
Bei solcher Eintragung liesse sich die Ermittelung des ci j und di j dadurch gewinnen, dass man die Schenkel eines rechten Winkels h, h aus der Anfangslage des Axensystems in Parallelbewegung mit seinem Scheitel der Hauptdiagonale entlang (eventuell blos durch deren Gitterpunkte hindurch) führte.
Nur wenn mindestens einmal diese Schenkel gleichzeitig ein Auge treffen und zwar eines von a auf der iten Zeile, und eines von b auf der jten Kolonne, nur dann wird ci j mit einem Auge zu versehen sein — sobald dies jedoch für eine Lage unsres rechten Winkels erkannt ist, braucht dessen Gleitbewegung nicht weiter fortgesetzt zu werden; alsdann ist nämlich für das dieser Lage entsprechende h erkannt, dass ai hbh j = 1 ist und kann nach dem Abacus (3) das Hinzutreten noch weitrer Glieder 0 oder 1 in der Summe Σhai hbh j, als welche ci j = (a; b)i j definirt ist, an diesem Ergebniss nichts mehr ändern; die Summe muss = 1 sein, sobald auch nur ein Glied derselben = 1 ist.
Dagegen wird di j = (a ɟ b)i j = Πh(ai h + bh j) = 1 also mit einem Auge zu versehen sein, immer und nur dann, wenn für jede Lage des gleitenden rechten Winkels (eventuell nur an den durch die Gitterpunkte der Hauptdiagonale gebotenen Stationen) mindestens einer seiner beiden Schenkel ein Auge trifft und zwar der vertikale Schenkel ein Auge des Relativs a in dessen iter Zeile oder der horizontale Schenkel ein Auge von b in dessen jter Kolonne.
Versagt dies Kennzeichen für eine Lage des rechten Winkels (nämlich auch nur für einen Gitterpunkt der Hauptdiagonale), indem beide Schenkel auf den zugehörigen Fluchten kein solches Auge treffen, so braucht diesmal wiederum die Gleitbewegung nicht weiter fortgesetzt zu werden; alsdann ist nämlich erkannt, dass der eine Faktor ai h + bh j = 0 ist, was das Verschwinden des ganzen Produktes bedingt, als welches di j definirt wurde.
Übrigens ist anzuraten, dass der Studirende sich an Beispielen für Denkbereiche von nur wenig Elementen darauf einübe, die relativen Knüpfungen an durch ihre Matrizes gegebenen Relativen zu vollziehen.
Den Schematismus oder die Technik des Verfahrens sich anzueignen ist in der That nicht schwer, und genügt es schon, dieselbe für einen Denkbereich 1 ⅓ aus drei Elementen zu erfassen:
Bezeichnen wir in Gestalt von [Formel] die (Koeffizienten 1 vertretenden) Augen, sowie die (Nullkoeffizienten repräsentirenden) Leerstellen der Matrix für den Augenblick mit chiffrirten Buchstaben, so wird die Matrix des relativen Produktes nach folgendem Vorbilde erhalten:
[Formel] und ist die Matrix von a ɟ b dual entsprechend zu bilden, sodass z. B. (a1 + α1)(a2 + β1)(a3 + γ1) deren Anfangselement sein wird, u. s. w.
Darnach werden wir beispielsweise für [Formel] und mag man für letzteres die Probe machen, dass:
[Formel] .
Allerdings wäre bei der Eintönigkeit des rein mechanischen Verfahrens eine maschinelle Auṡführung desselben sehr zu wünschen — und wird solche beim weitern Fortschreiten unsrer Disziplin auch sicherlich nicht ausbleiben.
Nach alledem ist, wenn a und b zwei Figuren in der Koordinatenebene bedeuten, auch die Figur vollkommen bestimmt, welche das Relativ a; b, desgleichen diejenige, welche das Relativ a ɟ b vorstellen wird.
Was ist nun z. B. eine Kreislinie „von“ einer Kreislinie, sowie eine Kreisfläche „von“ einer Kreislinie, oder wiederum „von“ einer Kreisfläche (etc.)?
Herr Gustav Mie hatte die Güte, sich mit diesen Fragen zu beschäftigen und veranschaulichen die Figuren 10 bis 17 für verschiedene nach Lage und Grösse charakteristische Annahmen der beiden gegebenen Kreise a, b die spezielleren Resultate seiner dankenswerten Untersuchung.
Bevor wir noch das zur nähern Erläuterung dieser Figuren Erforderliche sagen, wollen wir auch die allgemeineren Ergebnisse dieser Untersuchung — für den Mathematiker — statuiren.
Sind im rechtwinkligen Koordinatensystem der Ebene y = f(x) und y = φ(x) die Gleichungen zweier Kurven, die wir mit den verwendeten Funktionsbuchstaben f und φ selbst kurz bezeichnen wollen, so ist y = f{φ(x)}, mithin die Resultante der Elimination von h aus den beiden Gleichungen: y = f(h), h = φ(x), die Gleichung der Kurve, als welche sich uns das Relativ „f; φ“, also f von φ“, darstellt.
Die zu einem relativen Produkte a; b sich „zusammensetzenden“ Faktoren a = f, b = φ sind hier „Funktionen im Sinne der Mathematik“ und das relative Produkt a; b = f; φ ist „die aus beiden zusammengesetzte Funktion“ — das Wort „Funktion“ im gleichen Sinne genommen.
Dieser Sinn ist, nebenbei gesagt, ein etwas weiterer als derjenige, in welchem das Wort „Funktion“ in unsrer Theorie späterhin zu gebrauchen sein wird, wo nämlich gelegentliche Undeutigkeit sowie Mehrdeutigkeit (der Zuordnung der y-Werte zu den x-Werten) strengstens ausgeschlossen bleiben muss.
Sind — noch allgemeiner gesprochen — Φ(x, y) = 0 und Ψ(x, y) = 0 die Gleichungen zweier Kurven, welche selbst wieder mit den gleichnamigen Funktionsbuchstaben Φ und Ψ bezeichnet und unter den binären Relativen a und b demnächst verstanden werden mögen, so wird die Gleichung der als a; b = Φ; Ψ zu bezeichnenden Kurve einfach erhalten, indem man eine Variable h aus den beiden als zusammenbestehend gedachten Gleichungen Φ(h, y) = 0, Ψ(x, h) = 0 eliminirt.
Wird ferner für die eine oder für die andre der beiden Kurven (oder für beide) die von ihr begrenzte Fläche genommen, als welche bekanntlich — für die erstere sei es gesagt — diejenige gilt, deren Punkte x, y der Ungleichung Φ(x, y) < 0 genügen, so braucht in dem vorstehend Gesagten nur das betreffende Gleichheitszeichen durch das Zeichen <, das Wort „Gleichung, Kurve“ eventuell durch „Ungleichung, Fläche“ ersetzt zu werden.
Auch hat man das Zeichen ≦ (kleiner oder gleich) zu nehmen, falls das zusammensetzende Relativ etwa die Fläche der Kurve mitsamt ihrer Umgrenzung bedeuten soll.
Die Linie, welche man als „die eine Kurve (a) von der andern Kurve (b)“ erhält, wird im Allgemeinen mit beitragen zur Begrenzung der Fläche, welche sich bezüglich ergibt als die „Kurve a von der Fläche b resp. die „Fläche a von der Kurve b“ sowie die „Fläche a von der Fläche b“.
Bei der Anwendung auf die zwei Kreise a) (x - α)2 + (y - β)2 - γ2 = 0, b) (x - δ)2 + (y - ε)2 - ζ2 = 0 ist jene Linie nun die Projektion auf die x, y-Ebene der Raumkurve vierter Ordnung, in welcher sich die beiden Kreiszylinder mit zu einander normalen Axen schneiden (das h als Applikate, z-Koordinate gedacht): (h - α)2 + (y - β)2 - γ2 = 0, (x - δ)2 + (h - ε)2 - ζ2 = 0.
Wir haben nun in den Figuren die Kreisfläche a horizontal, die b vertikal schraffirt — jedoch nicht die ganzen Kreisflächen, sondern nur dasjenige Segment derselben, welches zu dem relativen Produkte a; b bei der Konstruktion desselben Punkte beisteuert.
Es zeigt sich nämlich, dass oft nicht alle Teile der Figuren a und b hierbei in Verwendung kommen, m. a. W. auf die Gestaltung des „a; b“ von Einfluss sind, vielmehr, ohne dass letzteres irgend anders ausfällt, gewisse Segmente von jedem Kreise auch weggelassen werden könnten.
Die „Kreislinie a von der Kreislinie b ist nun die bei a; b ausgezogen zu erblickende Kurve vierter Ordnung, welche in Fig. 10 die Gestalt eines rundlichen Vierecks hat, bei Fig. 11 und 12 ein, bei 13 zwei Paar eingedrückte Seiten zeigt, bei Figur 14 einen Doppelpunkt besitzt oder Schleifenform annimmt, sich bei Fig. 15 in zwei geschlossene Äste sondert, die in 16 (zusammenschrumpfend) zu offenen (obzwar begrenzten) Hyperbelästen geworden sind und bei Fig. 17 in die Diagonalen des Quadrates (als Asymptoten) degeneriren.
Fig. 10.
Fig. 11.
Fig. 12.
Fig. 13.
Die „Kreisfläche a von der Kreislinie b“ ist nun allemal der horizontal (oder mindestens auch horizontal) schraffirte Teil der in der Figur mit a; b bezeichneten Fläche.
Die „Kreislinie a von der Kreisfläche b“ ist der vertikal (oder mindestens auch vertikal) schraffirte Teil dieser Fläche.
Endlich „die Kreisfläche a von der Kreisfläche b“ ist der überhaupt (sei es horizontal, sei es vertikal, sei es doppelt) schraffirte Teil besagter Fläche — z. B. bei Fig. 13, 14, 15 das Rechteck mit nur ganz wenig abgerundeten Ecken, bei Fig. 16 das volle Rechteck.
Bei Fig. 10 fallen alle drei Flächen in eine zusammen, bei Fig. 11 und 12 fallen noch zwei von den drei Flächen in eine, nämlich die erste mit der dritten zusammen.
Bei Fig. 17 haben wir nur die Schraffur für „die Fläche a von der Linie b“ eingetragen.
Der Kreis b (welcher voll in Betracht kommt) und die beiden leeren Zentridreiecke des mit a; b markirten Quadrates müssten, symmetrisch dazu, vertikal schraffirt werden, um auch „die Linie a von der Fläche b“ zur Darstellung zu bringen, und das ganze Quadrat wird hier „die Fläche a von der Fläche b“ repräsentiren.
Behufs Verdeutlichung des Konstruktionsverfahrens und um den Studirenden in den Stand zu setzen, auch selbst Kontrole zu üben, haben wir fast zum Überfluss noch mit Fig. 18 für zwei aufs Gerathewohl angenommene Kurven a und b die Konstruktion von irgend einem Punkte ihres relativen Produktes a; b veranschaulicht, womit sich bei denselben Hülfslinien noch drei weitre Punkte von letzterm — im Ganzen vier Punkte des a; b — zugleich ergaben.
Der Leser verzeihe hier die kleine Wiederholung des wesentlich bereits zu Fig. 9, obzwar mit ganz andern Worten, Gesagten.
Das Wesentliche wird um so sicherer deutlich werden.
Durch einen beliebigen (im Abstand h von beiden Axen befindlichen) Punkt der Hauptdiagonale 1' sind (vertikal resp. horizontal) Parallelen zu den Axen gezogen, welche Punkte der Figuren a und (resp.) b enthalten, mit letztern zum Schnitt kommen.
Wo die Projizirenden dieser Schnittpunkte zusammentreffen, muss man Punkte des gesuchten Relativs a; b haben.
Fig. 14.
Fig. 15.
Fig. 16.
Fig. 17.
Ist nämlich y = i, x = h — gemeinhin (analytisch - geometrisch) gesprochen — ein Punkt von a, so hat die Matrix dieses Relativs an der Schnittstelle der iten (genauer: der mit i markirten) Zeile und hten Kolonne ein Auge, welches in unsrer Theorie als die Matrix des individuellen Relativs i : h zu bezeichnen wäre; letzteres Elementepaar gehört dem Relative a an, und es ist ai h = 1.
Vergl. Fussnote S. 61.
Ist ebenso y = h, x = j ein Punkt von b, so hat die Matrix von b an der Schnittstelle der hten Zeile mit der jten Kolonne ein Auge, gehört das individuelle Relativ oder Elementepaar h : j dem Relative b an und ist bh j = 1.
Dann ist aber auch ai hbh j = 1 und um so mehr ci j = (a; b)i j = = Σhai hbh j = 1, d. h. es trägt das Relativ c = a; b auch an der Schnittstelle der iten Zeile mit der jten Kolonne ein Auge oder gehört der Punkt y = i, x = j der Figur a; b an.
Imgrunde ist, wie man sieht, nur die in der Geometrie übliche Bezeichnung y = i, x = j eines Punktes der Koordinatenebene für unsre Zwecke durch die Bezeichnung i : j zu ersetzen!
Hält man sich nur dieses gegenwärtig, so wird man darnach auch das Vorhergehende alles leicht zu verstehen und zu rechtfertigen imstande sein.
Die nämlichen Figuren werden — kraft einer in § 6 unter C) folgenden Bemerkung — auch geeignet erscheinen die Konstruktion und Beschaffenheit einer relativen Summe a ɟ b zu illustriren, wofern man nur anstatt der Figuren a, b und a; b deren „Aussenfiguren“ oder Ergänzungen zur ganzen Ebene, Negate in’s Auge fasst.
Ich habe vorstehenden Seitenblick in die analytische Geometrie gewagt, um auch bei dem Mathematiker um Interesse für unsre Disziplin zu werben.
Fig. 18.
Zugunsten etwaiger in die Algebra der Relative einzuflechtender Illustrationen und Exemplifikationen, sei — deren Logik vorgreifend — hier auch noch angeführt:
Die Subsumtion a ⋹ b zwischen binären Relativen wird sich in Worten wiedergeben lassen mit: „alle a von- (scilicet etwas) sind auch b von- (sc. ebendiesem etwas)“, oder m. a. W. „jedes a von- ist ein b von-“.
Es bedeute etwa a (= amans) Liebender von- (lover of) und b (= benefactor) Wohlthäter von-.
So stellt das Negat ā den relativen Begriff vor:
„Nicht-Liebender von-“, das Konverse ă den: „Geliebter (Geliebte, Geliebtes) von-“.
Dass man im Deutschen nichts geschlechtlos, ohne ein bestimmtes genus sagen kann ist für unsre Disziplin sehr hinderlich und begründet einen grossen Vorzug des Englischen, wo einfach „lover“ eintritt für der, die oder das Liebende“.
Auch können wir im Deutschen für b̆ (benefitted by-) nicht „bewohlthatet von-“ sagen sondern müssen zu der Umschreibung „Empfänger oder Empfängerin von Wohlthaten seitens-“ unsre Zuflucht nehmen, u. s. w.
Um nicht zu übergrosser Weitläufigkeit gezwungen zu sein kann ich nur die Bitte an den Leser richten (sofern nicht ausdrücklich das Gegenteil stipulirt wird) das Genus in welchem ein relativer Name eingeführt wird, allemal ignoriren zu wollen.
Ferner bedeutet nun das identische Produkt ab alles was zugleich Liebender und Wohlthäter ist von- (sc. jemand), die identische Summe a + b: was Liebender oder Wohlthäter (eventuell beides) ist von-.
Dagegen wird das relative Produkt a; b zu interpretiren sein als „Liebender von einem Wohlthäter von-“, und die relative Summe a ɟ b als „Liebender von allen ausser Wohlthätern von-“, womit indessen gänzlich offen gelassen (in keiner Weise präjudizirt) sein soll, ob er etwa auch solche Wohlthäter liebe, oder nicht.
Wir werden in unsrer Disziplin fein unterscheiden müssen zwischen den Partikeln „ausser (englisch: but, save?, besides?) und „ausgenommen“ (englisch: excepting).
Sagen wir von den Personen, Menschen auf einem untergegangenen Schiffe:
„Alle wurden gerettet mit Ausnahme der Besatzung“, so wurden blos die Passagiere gerettet und die Mannschaft ist umgekommen, sagen wir dagegen: „alle Personen ausser der Besatzung sind gerettet“, so steht zwar fest, dass die Passagiere gerettet sind; von der Besatzung aber will ganz und gar nichts ausgesagt sein; vielleicht ist sie untergegangen, vielleicht schwebt sie noch in Lebensgefahr, wird teilweise oder ganz (ebenfalls) noch gerettet.
Von grösster Wichtigkeit für das richtige Erfassen unsrer Theorie ist es nunmehr, dass der Leser, bevor er in dieselbe eintritt, folgendes beachte.
Alle Sätze der Algebra der Relative dürfen eine „dreifache Evidenz“ beanspruchen.
In dreierlei Sinne — schon nach den bisherigen Ausführungen — mögen wir von „einer Evidenz“ derselben reden; auf drei grundverschiednen Wegen können wir sie einleuchtend finden, je nachdem wir zum Ausgangspunkt nehmen: die in § 3 aufgestellten fundamentalen Festsetzungen, oder aber: die geometrische Repräsentation der Relative und der mit ihnen zu vollziehenden Operationen, wie wir sie oben an die Betrachtung der Matrix knüpften, oder endlich: die verbale Interpretation der Relativsymbole, ihre Wiedergabe durch relative Namen der Wortsprache zu Zwecken der angewandten Logik — wie wir sie zuletzt, soeben, und vorgreifend, angedeutet.
Kurz, wenn auch nicht vollkommen erschöpfend, will ich diese dreierlei Evidenzen als die analytische, die geometrische und die rhetorische Evidenz bezeichnen.
Die Reinheit der Methode wird jedenfalls erheischen, dass wir dieselben unvermengt lassen, ja dass wir eine von ihnen — bei der Algebra die erste — bevorzugen und sie allein alle wesentlichen Schlüsse beherrschen lassen.
Die erste, die „analytische“ Evidenz ist zu erzielen durch den streng deduktiven „Beweis“ der Formeln oder Sätze unsrer Theorie aus ihrer in § 3 gegebnen formalen Grundlage.
Es wird von jeder Formel gezeigt, dass sie in jenen Konventionen bereits als eine Konsequenz derselben enthalten und durch sie denknotwendig mitgegeben ist.
Und zwar ist solcher Nachweis rechnerisch zu führen, indem man bei jedem Schritte sich bewusst wird, nach welchem Schema des Aussagenkalkuls derselbe vor sich geht, das ist also: durch welche Gesetze der allgemeinen Logik dieser Schritt legitimirt wird.
Für die Natur dieser Evidenz und die Art und Weise ihrer Erlangung werden die folgenden Vorlesungen reichlichste Illustration liefern.
Man könnte unzweideutig sie auch als die „Koeffizienten-Evidenz“ kennzeichnen, weil in den fundamentalen Konventionen die Erzeugnisse der 6 Spezies je als ein Relativ doch nur erklärt erscheinen vermittelst Definition seines allgemeinen Koeffizienten — weshalb bei allen Beweisen unmittelbar oder mittelbar auf diese Koeffizienten muss zurückgegangen werden.
Diese analytische Evidenz also werden wir in der Theorie ausschliesslich gelten lassen, und ein Satz der Algebra der Relative darf nicht als sichergestellt anerkannt werden, solange er nicht auf diesem Wege „erwiesen“ ist.
Man kann nun aber zweitens auch die Beziehungen und Knüpfungen zwischen Relativen — ingestalt etwa einer Vergleichung durch mentales Superponiren, zum-Schnitt-Bringen, Zusammenfügen und Trennen ihrer Raumbilder sowie eventuell mittelst gesetzmässigen Verflechtens der Augenreihen ihrer Matrizes — mit der „geometrischen Anschauung bewerkstelligen resp. verfolgen und begleiten.
So sieht man z. B. im Hinblick auf die Figuren 4 bis 7 augenblicklich, dass 1' · 0' = 0 und 1' + 0' = 1 ist, die beiden relativen Moduln also disjunkt sind und einander zum ganzen Denkbereiche 12 ergänzen, dass sie m. a. W. Negate von einander sind.
Oder — um noch durch ein andres Beispiel die „geometrische Evidenz“ zu illustriren — so wird es — nachdem bereits erkannt ist, dass das Relativ „a; 1“ aus einem Relativ a immer erhalten wird, indem man des letzteren überhaupt mit (einem oder mehrern) Augen besetzte Zeilen in lauter vollbesetzte oder Vollzeilen verwandelt — geometrisch unmittelbar einleuchten, dass: (a = 0) = (a; 1 = 0) und (a ≠ 0) = (a; 1 ≠ 0) ist, d. h. dass Verschwinden oder Nichtverschwinden von a und von a; 1 einander gegenseitig bedingen.
Ebenso ist dann klar, dass a ⋹ a; 1 sein muss, und andres mehr — wie wir denn auch die Sätze des identischen Kalkuls für die Figuren oder Punktsysteme, die unsre Relative geometrisch repräsentiren, schon in Bd. 1 so als unmittelbar einleuchtende erkannten.
Wennschon sie (hier wie dort) beim Aufbau der Theorie nicht wesentlich soll benutzt werden dürfen, ist die geometrische Evidenz jedoch als ein bequemes und fruchtbares Mittel zur Entdeckung von Sätzen nicht zu verachten; auch liefert sie höchst schätzbare Kontrolen und erleichtert das Behalten mancher Sätze.
Derselben wird darum ganz besondre Aufmerksamkeit in der Theorie zu widmen sein; ja die letztere wird eine Tendenz rechtfertigen, die Koeffizientenevidenz nach und nach in analytisch wohlbegründeter Weise durch die geometrische Evidenz „ablösen“ zu lassen.
Die dritte Art von Evidenz, die rhetorische, ist die im gewöhnlichen Denken wirksame.
Wir empfinden sie, werden ihrer gewahr, sobald wir auf Relative von spezieller Natur, wie l = lover = Liebender (von-), b = benefactor = Wohlthäter (von-), s = servant = Dienender (von-) jene allgemeinen Relative, die als Buchstaben in unsern Formeln auftreten, — mit Peirce — exemplifiziren.
Jedermann wird z. B. unmittelbar einleuchtend den Satz finden:
Der Liebende eines Wohlthäters (von-), der zugleich ein Dienender ist (von jemand), ist Liebender eines Wohtthäters (von-) und zugleich auch Liebender eines Dienenden (von diesem jemand) — wie ihn [blos etwas kürzer und wenn man will auch allgemeiner] die Formel ausspricht: l; (bs) ⋹ (l; b)(l; s).
Niemand wird sich sträuben, den Satz von genannten Relativen spezieller Natur auch auf irgend welche andre sei es relative, sei es selbst absolute Terme auszudehnen und darin ein Prinzip anzuerkennen, welches unser gesamtes Denken als eine Selbstverständlichkeit beherrscht.
Ist doch auch das Bild eines verstorbenen Freundes gewisslich Bild eines Verstorbenen und auch Bild eines Freundes, der Käufer eines teuern Pferdes zugleich Käufer von etwas Teuerm und Käufer eines Pferdes, u. s. w.
Auch allgemein wird: a; (bc) ⋹ (a; b)(a; c) sein müssen.
Sobald man sich ein wenig mit dem Übersetzen aus der Zeichensprache in die Wortsprache vertraut gemacht hat, lassen so in der That die einfachern Formeln unsrer Theorie einen hohen Grad von unmittelbarer Intuitivität nicht verkennen.
Die Logik, wenn sie — ebenso für relative wie für absolute Begriffe — die Methoden und Schemata des Folgerns und Schliessens entwickeln will, kann natürlich nicht umhin darnach zu streben, dass sie auch möglichst vollständig registrire und schematisire: die apriorischen, selbstverständlichen, identischen, analytischen oder nichtssagenden Urteile oder „Wahrheiten“ als diejenigen, auf welche bei jeglichem Schliessen jederzeit Berufung erfolgen kann.
Wer aber auf solche Evidenz beim Aufbau unsrer Theorie sich berufen wollte, der würde sich bald zur Anerkennung einer ganz übergrossen Menge von eigenartigen „Prinzipien“ genötigt sehen und die Klage des Herrn Venn 1p. 400 sq. gerechtfertigt erscheinen lassen: dass an Stelle des einen „simple and uniform set of rules“, des so einfachen Systems von Grundsätzen der alten Logik, wir beim Eintritt in die Logik der Relative uns sogleich vor eine verblüffend grosse und verwirrende Mannigfaltigkeit von solchen gestellt sehen (are introduced into a most perplexing variety of them).
Neben oder ausser den in § 3 zusammengestellten fundamentalen Konventionen bedürfen wir in der That in der Theorie keines weiteren „Prinzipes“.
Und wenn die Frage aufgeworfen wird nach den axiomatischen Grundlagen unsrer Disziplin der Algebra und Logik der Relative, so kann ich Herrn Peirce beipflichten, der sich über diese Frage am Schlusse von 2 ausspricht.
Die Grundlagen sind vom selben Range, sind keine andern, als wie die bekannten „Prinzipien“ der allgemeinen Logik.
Im Gegensatz zur Geometrie bedürfen Logik und Arithmetik keiner eigentlichen „Axiome“.
Um nicht missverstanden zu werden, muss ich einschalten:
Freilich kann auch die Geometrie betrachtet werden lediglich unter dem formalen Gesichtspunkte der Folgerichtigkeit ihres Lehrgebäudes.
Natürlich können deren sogenannte Axiome auch hingestellt werden als blosse Annahmen, vielleicht ganz willkürliche Assumtionen, um deren Erfülltsein, Gültigkeit, Wahrheit in irgend einem Denkbereiche man sich absolut nicht kümmert, man sich enthält, im Geringsten etwas zu behaupten.
Die geometrischen Sätze werden alsdann blos relative Wahrheit beanspruchen dürfen, werden immer nur zuzugeben sein, soferne eben jene Voraussetzungen zutreffen.
Gemeinhin, und meines Erachtens mit Recht geschieht aber dergleichen nicht.
Die geometrischen Axiome werden vielmehr gelehrt, hingestellt und angenommen mit dem Anspruche auf reale Geltung, Wahrheit, sei es für unsre subjektive Raumanschauung sei es für das derselben objektiv zugrunde liegend gedachte Wirkliche.
Und diese Axiome sind keineswegs analytische oder nichtssagende Urteile; mögen sie auch zufolge der Beschaffenheit, Natur unsres räumlichen Anschauungsvermögens „psychologisch denknotwendig“ genannt werden, so kommt ihnen doch keine Denknotwendigkeit im logischen Sinne zu, und die Geometrie ist mehr als ein blosser Zweig der Logik; sie ist das elementarste Glied in der grossen Reihe der physikalischen Wissenschaften.
Anders die Arithmetik.
Ich habe mich darum schon in Bd. 1 enthalten für die bei dem dortigen Lehrgange benötigten „Prinzipien“ den Namen „Axiome“ zu gebrauchen.
Und jene „Prinzipien“ sind blos verkappte Definitionen — „are mere substitutes for definitions of the universal logical relations“.
Soweit die allgemeinen logischen Beziehungen definirt zu werden vermögen — sagt Peirce mit Recht — kann man ohne irgend welche „Prinzipien“ in der Logik auskommen (all axioms may be dispensed with).
Diese Auffassung wird denke ich in dem nachfolgenden Lehrgebäude noch weitre Bekräftigung finden.
Besonders wird die Thatsache der Führbarkeit des da geführten Beweises für das volle Distributionsgesetz in dieser Hinsicht lehrreich sein.
Um nun also nochmals auf unsre drei Evidenzen zurückzukommen, so darf in der Theorie an die beiden letzten nicht wesentlich appellirt werden und sind dieselben höchstens zur Illustration der Sätze heranzuziehen.
Während bei den einfachern Sätzen die zweite und dritte Evidenz leichtlich die erste überflügelt, ihr nur allzugerne vorauseilt, bleibt bei fast allen verwickelteren Untersuchungen namentlich die dritte Evidenz weit — nicht selten hoffnungslos — hinter der ersten zurück, sieht man sich schliesslich auf die Evidentmachung mittelst penibel deduktiven Beweises allein angewiesen oder erfordert wenigstens die Herbeiführung auch der beiden andern Evidenzen für den Ungeübten einen nicht geringen Aufwand von „Kopfzerbrechen“.
§ 5. Haushalt mit Klammern.
Bevor wir in die so mannigfaltigen Sätze oder Formeln der Theorie eintreten, haben wir endlich noch Vereinbarungen zu treffen, die auf einen möglichst sparsamen Haushalt mit Klammern abzielen.
Bei Verwirklichung solcher höchst begehrenswerten Ökonomie mit genanntem Element der Zeichensprache, mit den Parenthesen, wird eine gründliche Vertrautheit mit den darauf bezüglichen Vereinbarungen unerlässlich sein zum richtigen Verständniss der Ausdrücke, welche in verwickelteren Formeln auftreten.
Bereits haben wir die sechs Spezies in zwei „Hauptstufen“ eingeteilt, als deren erste die identische, als deren zweite die relative bezeichnet wurde.
Daneben und unabhängig davon empfiehlt es sich aber, noch gewisse Rangordnungsverhältnisse oder „Stufen“folgen zwischen diesen Spezies festzusetzen.
Was zunächst die vier knüpfenden von den sechs Spezies betrifft, so sollen die beiden Multiplikationen (in Analogie zur Arithmetik) für von höherer Stufe“ gelten als wie die beiden Additionen.
Von den „gleichnamigen“ Operationen aber, d. h. von den beiden Multiplikationen resp. von den beiden Additionen, soll immer die relative für von der höheren Stufe gelten (von höherer somit als wie die identische).
Darnach kommt der identischen Addition die erste, der relativen Addition die zweite, der identischen Multiplikation die dritte und der relativen Multiplikation die vierte „Stufe“ zu.
Das richtige Verstehen, die korrekte Deutung aller erdenklichen mittelst dieser Operationen aufzubauenden Ausdrücke wird alsdann garantirt sein durch durch die folgende(n beiden) aus der Arithmetik einfach herüberzunehmende(n) Konvention(en).
Erste Konvention.
Kommen Operationen derselben Stufe auf der Zeile zusammen ohne dass durch Klammern die Reihenfolge von deren Ausführung ausdrücklich vorgeschrieben wäre, so hat man sich dieselben successive oder „fortschreitend“ ausgeführt zu denken in der Reihenfolge, in der man beim Lesen von links nach rechts auf deren Knüpfungszeichen stösst.
Diese Konvention war zwar noch in § 23 des Bd. 1 von Belang, indem sie z. B. den Ausdruck a - b + c, = (a - b) + c gebührend schied von dem nicht damit zu verwechselnden a - (b + c), bei welchem darnach die Klammer nicht unterdrückt werden durfte.
Hier jedoch, in unsrer Theorie der Relative, wird diese Konvention zu einer schliesslich belanglosen zufolge der erweislichen Assoziativität unsrer sämtlichen knüpfenden Spezies, derzufolge a + b + c = (a + b) + c von a + (b + c), abc = (ab)c von a(bc) a ɟ b ɟ c = (a ɟ b) ɟ c von a ɟ (b ɟ c), a; b; c = (a; b); c von a; (b; c) ohnehin nicht unterschieden zu werden braucht — vergleiche auch Bd. 1 Anhang 2. Wesentlich bleibt nur die
Zweite Konvention.
Kommen Operationen verschiedener Stufe zusammen ohne dass durch Klammern die Reihenfolge von deren Ausführung ausdrücklich vorgeschrieben wäre, so hat man sich allemal die Operation der höheren Stufe zuerst ausgeführt zu denken.
Hienach wird zum Unterschied von — im Kontrast mit — dem rechts entgegengestellten Ausdrucke, bei welchem die Klammer niemals weggelassen werden darf, bedeuten:
a + bc = a + (bc) entgegen (a + b)c ab + c = (ab) + c entgegen a(b + c) a + b ɟ c = a + (b ɟ c)
„ (a + b) ɟ c a ɟ b + c = (a ɟ b) + c „ a ɟ (b + c) a + b; c = a + (b; c)
„ (a + b); c a; b + c = (a; b) + c „ a; (b + c) a ɟ bc = a ɟ (bc) „ (a ɟ b)c ab ɟ c = (ab) ɟ c „ a(b ɟ c) a ɟ b; c = a ɟ (b; c)
„ (a ɟ b); c a; b ɟ c = (a; b) ɟ c „ a; (b ɟ c) a · b; c = a(b; c)
„ (a · b); c a; b · c = (a; b)c „ a; (b · c).
Eine gewisse Härte zeigt die rigorose Durchführung dieses Prinzips (nur) da, wo die beiden Multiplikationen konkurriren, sofern von diesen die identische (wie zumeist üblich) ohne Knüpfungszeichen geschrieben ist:
In Fällen wie ab; c, a; bc, ab; cd wird man sich nämlich versucht fühlen, die näher beisammen stehenden Buchstaben für zunächst zusammengehörig zu halten, was zu einem Widerspruch mit obiger Übereinkunft führen würde.
Diesem Gefühle dürfte es ratsam sein auch Rechnung zu tragen, und wir thun dies zunächst, indem wir für den genannten Fall die Geltung der Konvention an die Bedingung knüpfen, dass für die identische Multiplikation der Punkt als Malzeichen ausdrücklich Verwendung gefunden habe.
Hiernach haben wir das vorstehende Tableau noch zu ergänzen durch den gleichsam eine „Ausnahme“ statuirenden Zusatz zu seiner letzten Zeile:
ab; c = (ab); c entgegen a(b; c) a; bc = a; (bc) entgegen (a; b) c.
Von der „Ausnahme“ aber wird man am besten die Konvention selbst entlasten, indem man sich etwa einprägt:
Nur wo sie des Malzeichens entbehrt, stellt die identische Multiplikation sich über die relative, geht ihr voran.
Beispielsweise noch wird also bedeuten:
[Formel] .
Ferner fügen wir als Interpretirübung an:
[Formel] .
Bei einiger Übung wird man bald wahrnehmen, dass jeder Ausdruck nur eine sparsamste Schreibung zulässt und dass man nicht etwa unter verschiedenen gleich einfachen „einfachsten“ Schreibungen eines solchen jemals die Wahl haben kann.
Durch unsre Konventionen erweist sich die beste Darstellung eines Ausdrucks als eine in jedem Falle unzweifelhaft bestimmte.
In dieser Hinsicht ist namentlich hervorzuheben, dass, weil der Punkt doch ein einfacheres Zeichen ist, wie die Klammer, für einen Ausdruck von der Form a(b; c), wenn derselbe für sich steht, besser gesagt wird: a · b; c.
Wenn dagegen dieser Ausdruck selber noch eingeklammert werden müsste, wie z. B. in (a · b; c); d, so würde besser wieder die vorige Schreibung für ihn eintreten, indem die Darstellung a(b; c); d sich als (um den Punkt) sparsamer erweist!
Unterdrückt darf hienach die Klammer welche einen Ausdruck einschliesst nur dann werden, wenn die „innere“ Operation, d. h. diejenige aus welcher der eingeklammerte Ausdruck zuletzt hervorgegangen ist, nicht von niedrigerer Stufe ist wie die „äussere“ Operation, d. h. die Spezies durch welche der Ausdruck mit einem andern Term (oder andern Termen) verbunden erscheint. —
Die nicht knüpfenden von unsern 6 Grundoperationen — die Negation nämlich beim Gebrauch des horizontal übergesetzten Negationsstriches, sowie die Konversion — brauchen in die Vereinbarung nicht einbezogen zu werden, weil das als Strich oder Ringelchen übergesetzte Zeichen als vinculum schon eine Klammer ersetzt.
Beim Gebrauch des vertikalen Negationsstriches aber brauchte man nur die Negation als „von der höchsten Stufe“ hinzustellen um unsre zweite Konversion auch auf sie mit auszudehnen — wonach denn (in erster Zeile wie vordem) gelten würde:
a + b1 = a + (b1) entgegen (a + b)1 ab1 = a(b1) entgegen (ab)1 a ɟ b1 = a ɟ (b1) „ (a ɟ b)1 a; b1 = a; (b1) „ (a; b)1.
Ähnliches wäre bezüglich der Suffixe 0, 00, 1, 11 zu sagen, durch deren Anhängung wir späterhin noch die Operation der „Ketten-“, „Bildketten-“ etc.
Bildung anzeigen.
Diese letztern müssen den knüpfenden Operationen gegenüber als von der höheren Stufe gelten, sodass wir beispielsweise haben werden: etc.
a + b0 = a + (b0) entgegen (a + b)0 ab00 = a(b00) entgegen (ab)00
Ihnen dagegen sollen die mit horizontal übergesetztem Striche resp. Hyphen angedeuteten Operationen der Negation und Konversion ihrerseits vorgehen, sodass uns gelten wird: ā0 = (ā)0 entgegen (a0͞), ă00 = (ă)00 entgegen (a00)͝, desgleichen ā̆0 = (ā̆)0 entgegen (a0)͞͝. Etc.
Dies motivirt sich später dadurch:
weil man die Operationen „strich“, konvers“ oder „strichkonvers“ an der a-Kette resp. a-Bildkette etc. ohnehin wird „ausführen“ können, sodass die hinter „entgegen“ angeführten unbequem zu druckenden Symbole gar nicht werden endgültig vorzukommen brauchen.
Endlich aber müssen wir uns noch über den Klammerngebrauch da, wo Π und Σ-zeichen mitspielen, verständigen.
Unmittelbar hinter jedem dieser Zeichen steht der „allgemeine Term (allgemeine Faktor resp. das allgemeine Glied), auf welchen das Zeichen Π resp. Σ sich beziehen, den es beherrschen, regiren soll.
Wo der Name dieses allgemeinen Terms anfängt, darüber kann hienach kein Zweifel bestehen, es frägt sich aber wo dieser Name jeweils aufhört, m. a. W. bis wie weit nach rechts hin die Herrschaft unsres Zeichens reichen, sich erstrecken soll?
Letzteres ist im Allgemeinen durch den Usus in der Mathematik (dem wir uns, wo er ausschlaggebend, anschliessen) bereits geregelt.
Gleichwohl müssen wir für unsre Disziplin (im Hinblick auf die ihr eigentümlichen Spezies und Schreibweisen) es nochmals und sorgfältiger resp. vollständiger statuiren.
Im allgemeinen Term selbst können — ebenso wie Relativ-Koeffizienten — hier auch Aussagen auftreten, welche z. B. als „spezifizirte eines Umfangsbeziehungszeichens, wie ⋹, =, ⊂, ≠, ∉, zu ihrer Darstellung benötigen und sich dessen bedienen.
In solchem Falle muss dies Beziehungszeichen stets von einer Klammer mittelbar umschlossen sein, welche hinter dem Π resp. Σ anhebt und schliesst.
Wir nennen solches Beziehungszeichen (hinsichtlich unsers Π oder Σ) ein „gebundenes“ — im Gegensatz zum „freien“ Zeichen einer Umfangsbeziehung.
Als „frei“ (ev. inbezug auf unser Π resp. Σ) wird (solch) ein (Beziehungs-)Zeichen zu bezeichnen sein, wenn es entweder überhaupt nicht von einer Klammer (mittelbar) umschlossen ist, oder doch nur von solchen Klammern, welche unser Π resp. Σ-zeichen selber mitenthalten, in sich fassen, mittelbar umschliessen.
Beispielsweise ist in den Ausdrücken: Π(a⋹b) = c, {Σ(a⋹b) = c}d das Einordnungszeichen ein gebundenes, das Gleichheitszeichen ein freies hinsichtlich des Π oder Σ, das linkerhand ein freies schlechtweg.
Keinesfalls soll nun die Herrschaft eines Π oder Σ-zeichens über das ihm als nächstes folgende freie Umfangsbeziehungszeichen (Vergleichungszeichen) hinüberreichen.
Was die gebundenen betrifft, so gehören diese jeweils entweder einem als Faktor, oder als Summand — wenn nicht als Negand — auftretenden „Aussagenterm“ an, und werden solche Aussagenterme mit den übrigen Operationsgliedern auf einer Linie stehen, sodass wir uns bei den ferneren Konventionen um die etwaigen Umfangsbeziehungszeichen als solche nicht weiter zu kümmern brauchen, und nur mehr noch die Frage zu erledigen bleibt, welche Operationen der Herrschaft unsres Π oder Σ Halt gebieten.
Letzteres wird im Grossen und Ganzen durch den Hinweis darauf zu erledigen sein, dass unser Π stets eine identische Multiplikation, das Σ eine identische Addition vorzuschreiben hatte, wonach die Rangordnung oder Stufenfolge, wie sie im Vorangegangenen zwischen den vier knüpfenden Operationen festgesetzt wurde, implicite auch schon mitgeordnet erscheint für die mittelst Π und Σ anzudeutenden Operationen.
Hienach muss in der That schon bedeuten:
[Formel] .
Ein Zweifel kann nur noch obwalten und wird darum eine Übereinkunft erforderlich in folgenden Fällen:
Erstens, wenn identisches Produktiren mittelst Π zusammentrifft mit relativer Multiplikation, und zwar aus dem Grunde, weil es (im Hinblick auf die oben statuirte „Ausnahme“) zunächst noch nicht ausgemacht ist, ob man das Πa ebenso wie ein a · b nach der allgemeinen Vorschrift, oder ob man es wie ein ab unter dem Gesichtspunkt der Ausnahme behandeln wolle.
Indem wir uns für ersteres entscheiden, so gilt uns: Πa; b = Π(a; b) entgegen (Πa); b.
Zweitens, wenn identisches Produktiren mit Π zusammentrifft mit identischem Multipliziren (ohne Π, also mit dem oder ohne das Malzeichen.).
Hier gelte: Πa · b = Π(a · b), Πab = Π(ab) entgegen (Πa) · b = (Πa)b.
Drittens, wenn identisches Summiren mit Σ zusammentrifft mit identischem Addiren (ohne Σ, also mit +).
Hier ist schon längst der Usus sanktionirt, zu verstehen: Σa + b = (Σa) + b entgegen Σ(a + b) in welch letzterm Ausdruck die Klammer allemal nicht unterdrückt werden darf.
Es geht also die Summation jeweils der Addition vor.
Im Hinblick auf diesen Gebrauch erscheint es bequemer auch die oben in eckige Klammer gesetzte Konsequenz unsrer allgemeinen Festsetzungen nicht zu adoptiren, sie vielmehr zu ersetzen durch die folgende Übereinkunft: Σa ɟ b = (Σa) ɟ b entgegen Σ(a ɟ b).
Wir können uns dann einfach merken:
Die Herrschaft der Π und Σ-zeichen reicht stets bis zum nächsten freien Plus- oder Piu-Zeichen.
Kommen Suffixe mit in Betracht, sei es einfache, wie i, wie 0 und 1, sei es doppelte wie hk, etc., so haben diese, sofern nicht durch Klammern das Gegenteil ausdrücklich vorgeschrieben ist, allemal den Vortritt vor allen übrigen Operationen.
So gilt in der ganzen Welt schon längst: abi = a(bi) entgegen (ab)i, a + bh k = a + (bh k) „ (a + b)h k, und wäre auch von vornherein zu verstehen: Πai j = Π(ai j) entgegen (Πa)i j, Σai j = Σ(ai j) entgegen (Σa)i j unbeschadet dessen, dass hier beides definitionsweise mit (15) für äquivalent erklärt worden.
Ein gleiches gilt ja auch für den Apostroph, sofern uns z. B. a1' = a · 1' = a(1') bedeutet, wogegen (a1)' = a' für ein von 0 und 1 verschiedenes a in unsrer Disziplin jeden Sinnes baar sein würde, für a = 0 aber einen andern Sinn gäbe.
Ein gleiches ist endlich auch für (Potenz-)Exponenten (als schon anderweitig üblich) zu statuiren, wonach denn bedeutet: abn = a(bn) entgegen (ab)n, a; bn = a; (bn) entgegen (a; b)n, a + bn = a + (bn) „ (a + b)n, a ɟ bn = a ɟ (bn) „ (a ɟ b)n, Σan = Σ(an) entgegen (Σa)n, Πan = Π(an) „ (Πa)n.
Die beiden letzten Ausdrücke würden miteinander und mit Πa selbst übereinstimmen, und ähnlich müssten auch die darüber einander entgegengestellten beiden Ausdrücke jeweils zusammenfallen, wenn die „Potenz“ als ein identisches Produkt aus gleichen Faktoren aufgefasst würde.
In unsrer Disziplin reserviren wir aber den Potenzbegriff für relative Produkte aus gleichen Faktoren — wo dann die entgegengestellten Ausdrücke verschiedenes bedeuten werden.
Da nun ani j als (ai j)n gedeutet auf ai j selbst hinauskommen müsste, so erklären wir ani j = (an)i j entgegen (ai j)n = ai j.
Weiter werden wir verstehen: a0n = (a0)n entgegen (an)0 und a1n = (a1)n entgegen (an)1.
Kommen — ein in unsrer Theorie ungemein häufiger Fall — mehrere Σ und Π-zeichen in bunter Folge unmittelbar nebeneinander zu stehen, so erstreckt sich die Wirkung eines jeden über alle folgenden und den allgemeinen Term des letzten hinweg bis zu dessen Ende hin, und bedarf es keiner weitern Übereinkunft um den Sinn des ganzen Ausdrucks klar zu stellen.
Man hat sich dann die Summationen und Produktationen in der umgekehrten Folge vollzogen zu denken von derjenigen, in welcher ihre Zeichen der Zeile entlang von links nach rechts gelesen werden — weil dem Ausführen einer solchen Operation die Bildung, Herstellung ihres allgemeinen Terms notwendig vorausgehen muss.
So bedeutet z. B.: ΣiΣjΠhΣkai j h k = Σi[Σj{Πh(Σkai j h k)}]. —
Dritte Vorlesung.
Die Sätze von allgemeinster Natur in der Algebra der binären Relative.
§ 6. Gesetze der Spezies, soweit nur allgemeine Relative in deren Ausdruck eingehen.
Dualismus und Konjugation.
Die wichtigsten Gesetze der 6 Grundrechnungsarten sind von Peirce schon mit ziemlicher Vollständigkeit aufgestellt.
Es werden uns die kleinen lateinischen Buchstaben nunmehr stets allgemeine binäre Relative vorstellen, zudem die in 3) S. 7 angeführten „Elemente“ bedeuten.
Natürlich werden die Knüpfungsgesetze, die schon bei den einfachsten Knüpfungen zutage treten, auch bei den komplizirteren Knüpfungen eine Rolle spielen, sie werden den verwickelteren auf solche bezüglichen Sätzen voraussichtlich mit zugrunde liegen.
Als einfachste Knüpfungen mag man diejenigen hinstellen, in welche nur 1, 2, 3 (oder höchstens 4)
Buchstaben als Symbole für ebensoviele von vornherein unabhängig beliebige Relative eingehen.
Auf diesem Wege lässt sich das Feld der für unsre Disziplin als fundamental zu bezeichnenden Folgesätze oder „Gesetze“ zunächst einmal roh umgrenzen.
Um sodann heuristisch gedachte fundamentale Gesetze zu entdecken, brauchte man blos mit kombinatorischer Vollständigkeit alle erdenklichen Ausdrücke hinzuschreiben, welche sich mittelst unsrer Spezies aus so geringer Buchstabenzahl aufbauen lassen.
Für jeden dieser Ausdrücke wäre gemäss den Festsetzungen (10) bis (13), S. 29, der allgemeine Koeffizient zu bilden — eine für Anfänger ohnehin empfehlenswerte Übung — und endlich wäre zuzusehen, welche Relationen (der Einordnung oder Gleichheit) sich zwischen diesen Koeffizienten aufgrund der Sätze des Aussagenkalkuls rechtfertigen lassen.
Auf solche Weise würde sich auch die Überzeugung von der Vollständigkeit unsrer Zusammenstellung der Sätze wol gewinnen lassen oder wenigstens die Erkenntniss, dass in ihr nichts Belangreicheres übersehen sein dürfte.
Diesen immerhin etwas mühsamen und zeitraubenden Weg will ich aber mit dem Leser nicht gehen; ich will vielmehr die Grundgesetze summarisch darlegen.
Dabei soll auf Erzielung einer guten Übersicht Bedacht genommen und zu dem Ende eine Einteilung der Gesetze in Gruppen herbeigeführt werden.
Die Beweise liefern uir zumeist erst am Ende einer grössern Gruppe — für die chiffrirten Formeln dieses Paragraphen sogar erst im nächsten.
Im gegenwärtigen haben wir vollauf damit zu thun, von den Formeln selbst Kenntniss zu nehmen, uns die Sätze, die sie darstellen, zum Bewusstsein zu bringen, die Namen, welche sie etwa zu führen berechtigt wären, ihre Stellung, Anwendungsweise und Tragweite in unsrer Wissenschaft zu beurteilen, dasjenige darzulegen, was zu beachten ist, um sie sich gut einprägen zu können, u. s. w. Da müsste denn die sofortige Einfügung der Beweise die Übersicht zu schwer beeinträchtigen.
Zu den Formeln pflege ich jedoch auch naheliegende Korollare — wie Ausdehnung auf noch mehr Operationsglieder, und anderes — immer sogleich mitanzuführen.
Bei der zumeist ganz kurz abzuthuenden Begründung solcher Korollare ist natürlich der Leser gebeten, die chiffrirten Formeln selbst, zu denen sie gegeben werden, vorläufig als schon erwiesene zu betrachten.
Ein grosser Teil der Grundgesetze — diejenigen die den Vortritt haben umfassend — ist dem Leser aus dem identischen Kalkul ohnehin bereits bekannt.
Der Beweis ebendieser aus den fundamentalen Festsetzungen des § 3 ist wie sich zeigen wird durchgängig äusserst leicht zu führen.
Es genügt dafür in § 7 ein paar Paradigmata anzuführen, unter denen das volle Distributionsgesetz nicht wird fehlen dürfen.
Direkt: mittelst Zurückgehens auf die Koeffizienten, brauchten — woferne man nicht den Inhalt unsres Bd. 1 ignoriren will — ohnehin nur die wenigen „Definitionen und Prinzipien (nun als „Theoreme“) aus § 3 „bewiesen“ zu werden, welche wir in Bd. 1 dem identischen Kalkul zugrunde gelegt hatten.
Dieses wenigstens geschieht auch im § 7.
Doch wird die Methode der Beweisführung, also die Herbeiführung der „Koeffizientenevidenz“, an den höhern, auf relative Operationen bezüglichen Sätzen so reichlich eingeübt und ist das Beweisverfahren ein so gleichmässiges, einheitliches, indem es durchweg auf demselben Grundgedanken beruht, dass auch bei keinem noch dem identischen Kalkul angehörenden Satze der direkte Beweis dem Leser irgend eine Schwierigkeit zu bereiten vermöchte und dass man die Theorie der Relative auch als eine selbständig begründete sich wird aneignen und von Bd. 1 und 2 ganz emanzipiren können.
Wenn nun gegenüber dem Bd. 1 die Grundlagen, auf die wir uns berufen müssen, hier auch als neue zu bezeichnen sind, so wollen wir aber doch mit der detaillirten Beweisführung der schon bekannten Sätze den Leser nicht ermüden, auch über deren Benennung, verbale Fassung und Anwendungsweise, ihre Ausdehnung auf noch mehr Operationsglieder etc. weiter keine Worte verlieren, dieserhalb ein für allemal auf Bd. 1 verweisend.
Dass (a ￼ b) = (b ⋹ a) bedeuten solle ist kein „Satz“, sondern eine Zusatzkonvention, die wir aber unter den fundamentalen Festsetzungen nicht mit aufgeführt haben, weil sie immer nur nebensächlich zur Anwendung gelangt und man ganz gut mit immer nur im Sinne von links nach rechts angesetzten Subsumtionen in der Theorie auskommen könnte.
Die Sätze: 0) a ⋹ a, a = a, (a = b) = (b = a), (a ⋹ b) (b ⋹ c) ⋹ (a ⋹ c) drücken kein Gesetz unsrer Spezies aus, müssen aber als ganz unentbehrliche und aus unsern Festsetzungen beweisbare Theoreme über Relative einmal Erwähnung gefunden haben.
Eine erste Gruppe von Gesetzen bezieht sich auf die knüpfenden Operationen.
Als ganz fundamental sei vorangestellt der Satz: 1) (a ⋹ b)(c ⋹ d) ⋹ (ac ⋹ bd)(a + c ⋹ b + d)(a; c ⋹ b; d)(a ɟ c ⋹ b ɟ d), der eigentlich, weil das Aussagenprodukt rechterhand einem jeden seiner Faktoren eingeordnet ist, also dessen Geltung nach sich zieht, die vier zumeist getrennt anzuwendenden Sätze in sich zusammenfasst:
Man merke hinzu:
Gleichstimmige Subsumtionen dürfen auch durch relative Multiplikation oder Addition überschiebend verknüpft werden.
(a ⋹ b)(c ⋹ d) ⋹ (a · c ⋹ b · d) (a ⋹ b)(c ⋹ d) ⋹ (a + c ⋹ b + d) (a ⋹ b)(c ⋹ d) ⋹ (a; c ⋹ b; d) (a ⋹ b)(c ⋹ d) ⋹ (a ɟ c ⋹ b ɟ d).
Die Konklusion, gefolgerte Subsumtion, ist aber hierbei eine ganz andre, wenn man die zweite Subsumtion hinter die erste schiebt, als wenn man das Umgekehrte thut.
Und beides ist zulässig, liefert richtige Konklusionen:
man hätte aus der Prämisse links auch schliessen können: c; a ⋹ d; b, sowie c ɟ a ⋹ d ɟ b — wie man denn relatives Vor- und Nachmultipliziren, resp. -addiren bei der Anwendung des Satzes noch zu unterscheiden hat.
Die Modifikationen zu formuliren, welche der Satz zulässt, wenn die eine oder die andre oder wenn beide Prämissensubsumtionen in Gleichungen ausarten — in Analogie zu den Theoremen 15) bis 19) des Bd. 1 (S. 263 ‥ 267 sowie Bd. 2, S. 31) — überlassen wir dem Leser:
Es können, relativ nicht minder wie identisch, auch Subsumtionen mit Gleichungen sowie Gleichungen mit Gleichungen überschiebend verknüpft werden.
Eine Subsumtion sowol wie eine Gleichung kann beiderseits mit Gleichem, mit einem beliebigen aber links und rechts demselben Relative, relativ (vor- resp. nach-)multiplizirt werden; ein solches kann beiderseits zu ihr relativ (vor- resp. nach-)addirt werden.
Z. B. es ist (a ⋹ b) ⋹ (a; c ⋹ b; c).
Dagegen wäre: links nach- und rechts vorzumultipliziren mit c, im Allgemeinen natürlich nicht gestattet.
Gleiches, auf gleiche Art geknüpft, gibt auch in unsrer Disziplin stets Gleiches.
Diese Bemerkungen sind, im Hinblick auf die Def. (1) der Gleichheit, so nahe liegende Korollare zu unserm Theoreme 1), dass sie mit diesem zugleich als erwiesen anzusehn sein werden.
Demnächst reihen sich an: die schon bekannten Sätze der ersten Hauptstufe: 2)
[Formel] von denen nur das erste Paar, das Kommutationsgesetz, kein Analogon auf der zweiten Hauptstufe finden wird.
Ausserdem sind aber noch als fundamentale Sätze des identischen Kalkuls, zu denen sich bei den relativen Operationen keine Analoga werden nachweisen lassen, erinnernd hervorzuheben diese: 3)
[Formel]
Als (mit) auf die relativen Operationen bezüglich kommen nunmehr neu hinzu die hochwichtigen Sätze: 4)
[Formel] 5)
[Formel] 6)
[Formel] 7)
[Formel] welche mit ihren höchst nahe liegenden Korollaren: A) [Formel] unsre erste Formelgruppe abschliessen.
Die Sätze 4) bis 7) und A) bilden augenscheinlich in gewissem Sinne Analoga — wonicht einen Kontrast — zu den Sätzen 2), in denen mehr als zwei Buchstaben vorkommen.
Man muss sich dieselben möglichst fest einprägen, und zwar die blos einseitig als Subsumtionen geltenden 5) und 7), etc., auch mit der zugehörigen Richtung des Subsumtionszeichens.
Vor allem merke man zu 4):
Auch die relative Multiplikation verhält sich distributiv zur identischen Addition, ebenso die relative Addition zur identischen Multiplikation.
Insbesondre kann man identische Summen auch relativ „ausmultipliziren“ und umgekehrt einen „gemeinsamen“ relativen (Vor- resp.
Nach-) Faktor bei den Gliedern einer identischen Summe als ebensolchen „ausscheiden“.
Etc.
Das Theorem 4) wollen wir das Distributionsgesetz der relativen Knüpfungen oder der zweiten Hauptstufe nennen — wobei wir fortfahren unter dem „Distributionsgesetze“ schlechtweg immer das bisherige, in 2) mit angeführte der ersten Hauptstufe angehörige Gesetz gleichen Namens zu verstehen.
Höchst beachtenswert ist der Satz 6) als das „Assoziationsgesetz der beiden relativen Knüpfungen.
Von den beiden Gleichheitszeichen einer jeden Doppelgleichung 6) soll nur das erste als „ein Theorem statuirend“ aufgefasst werden, das zweite dagegen als — konventionell — eine Zusatzdefinition zum Ausdruck bringend.
Das Theorem lautet:
Auch die relative Multiplikation ist (gleichwie die identische) eine assoziative Operation, desgleichen die relative Addition.
Die Zusatzdefinition erklärt hernach den Begriff des relativen Produktes von drei in bestimmter Ordnung gegebenen Faktoren mittelst Zurückführung dieses Begriffes auf den schon feststehenden eines relativen Produktes von nur zwei Faktoren — analog den Begriff der Summe aus drei relativen Summanden.
Die Zusatzkonvention setzt fest: Unter a; b; c soll der übereinstimmende Wert der beiden in 6) vorhergehenden relativen Produkte verstanden werden.
Etc.
Begriff und Sätze sind von dreien alsbald auf beliebig viele Terme ausgedehnt zu denken so, wie wir es in Anhang 3 des Bd. 1 für irgend eine Knüpfung nachgewiesen haben, wofern sie nur dem einfachsten Falle des Assoziationsgesetzes (dem „speziellen“ Assoziationsgesetz für drei Terme) unterworfen ist.
Dies empfiehlt sich wenigstens als praktisch für unsre Theorie im Allgemeinen, unbeschadet dessen, dass in der neunten Vorlesung zeitweilig davon abgesehen werden mag.
Auch bei der relativen Multiplikation von beliebig vielen Relativen (und eventuell noch relativen Produkten solcher) wird hienach die Klammerstellung gleichgültig sein: die Klammern können sämtlich unterdrückt oder auch nach Belieben angebracht werden.
Analog bei der relativen Addition von Relativen (selbst und eventuell noch relativen Summen).
Der Satz 5) — zunächst links vom Mittelstriche — lehrt: dass wenn man einen relativen Faktor als ebensolchen (nämlich Vor- resp. Nachfaktor) distributiv zugesellt den Faktoren eines identischen Produktes, man im Allgemeinen nicht das Gleiche, sondern Übergeordnetes erhalten wird.
Am leichtesten wird man sich diese Sätze wol einprägen mittelst Beachtung ihrer „rhetorischen Evidenz“, auf welche für den ersten derselben S. 66 schon hingewiesen wurde.
Die Achtsamkeit auf dieses Merkmal erleichtert überhaupt das Behalten der Sätze, namentlich derer links vom Mittelstriche.
Diejenigen rechts prägen sich hernach von selbst mit ein als solche, die den vorerwähnten dual entsprechen.
Wofern man sich nur die Herrschaft über die „Prinzipien des Dualismus und der Konjugation erwirbt, die wir baldigst aufstellen und begründen werden, fällt es überhaupt nur nötig, von jedem Quadrupel zusammengehöriger oder „verwandter“ Sätze einen einzigen — den ersten z. B. — zu merken.
Ebenso ist für den zweiten einleuchtend:
Ein Liebender und zugleich Wohlthäter von einem Dienenden ist Liebender eines Dienenden und auch Wohlthäter von einem Dienenden.
Aber nicht umgekehrt!
Wer Liebender ist von einem, und zugleich Wohlthäter ist von einem (vielleicht ganz andern) Dienenden, braucht nicht Liebender und zugleich Wohlthäter von einem (einem und demselben) Dienenden zu sein!
In der That:
Satz 6) erscheint rhetorisch geradezu als selbstverständlich, indem z. B. der „Liebende eines Wohlthäters“ von einem Dienenden als dasselbe sich darstellt wie: der Liebende eines „Wohlthäters von einem Dienenden“.
Ebenso auch 4):
Der Liebende von einem Wohlthäter von- oder Dienenden von- (jemand) ist entweder Liebender eines Wohlthäters von- oder Liebender eines Dienenden von- (diesem jemand), und umgekehrt.
Desgleichen: Wer Liebender oder Wohlthäter ist von einem Dienenden, der ist auch Liebender von einem Dienenden oder Wohlthäter von einem Dienenden, und umgekehrt.
Diese Wahrnehmungen dürfen aber, wie bereits betont, beileibe nicht als ein „Beweis“ der Sätze angesehen werden, welchen letzteren wir vielmehr noch schuldig sind. —
Von zwei Operationsgliedern (Faktoren, Summanden) der in ihnen vorkommenden identischen Produkte oder Summen sind auch die Sätze 4) und 5) alsbald auf beliebig viele Terme ausgedehnt zu denken in einer höchst nahe liegenden Weise, die vom speziellen Distributionsgesetze her aus Bd. 1 wohlbekannt ist (S. 311).
Ebenso ist namentlich die erste Formel A) fortan erweitert zu denken zu einer auf relative Multiplikation bezüglichen „Multiplikationsregel für Polynome“ (nämlich identische Summen).
Und somit wäre nun blos noch das Theorem 7) zu besprechen und zu merken.
Dasselbe nimmt eine Sonderstellung insofern ein als es einen Gegensatz, Kontrast bildet zum Distributionsgesetze der ersten Hauptstufe.
Es lässt zunächst vermuten, dass zwischen a; (b ɟ c) und a; b ɟ a; c allgemein keine Beziehung der Einordnung oder Gleichheit (überhaupt der Wertgemeinschaft) bestehn wird, indem es eine solche Beziehung vielmehr statuirt zwischen jenem ersten Ausdrucke und diesem: a; b ɟ c, der sich durch Unterdrückung der Klammer aus ihm ergibt — wenn man will auch: durch Abänderung der Klammerstellung, Verschiebung der Klammer, indem nach § 5 dieser letztre Ausdruck nichts andres wie (a; b) ɟ c bedeutet.
Dass in der That zwischen relativer Multiplikation und Addition ein distributiver Zusammenhang allgemein nicht besteht, würde sich mittelst Exemplifikation auf das Gegenteil unschwer beweisen lassen.
Wollten wir uns aber damit befassen von allen erdenklichen Sätzen, denen in unsrer Disziplin allgemeine Geltung nicht zukommt, auch dieses nachzuweisen, so würden wir allzusehr belastet und unser ohnehin voluminöses Buch übermächtig anschwellen.
Wir haben schon genug damit zu thun für alle in unsrer Theorie positiv hingestellten Behauptungen die erforderlichen Beweise zu erbringen.
Und die Pflicht der Beweisführung, das onus probandi, bliebe auf seite Desjenigen, der einen hier nicht aufgenommenen Satz anwenden wollte.
Die eingehende Beschäftigung mit der Disziplin von seiten des Herrn Peirce und von mir gibt eine gewisse Bürgschaft dafür, dass einfachre Sätze, falls sie allgemein Geltung hätten, hier schwerlich übersehen sein würden.
Wer den aufgeführten Sätzen neue hinzufügen will, sei hiermit herausgefordert.
Gelingt das, so wird eine Bereicherung der Theorie zu verzeichnen sein.
(Bei den Umkehrproblemen liefre ich selbst noch Einiges hinzu).
Verbal interpretirt besagt der erste Satz 7) z. B.: der Liebende eines „Wohlthäters von allen ausser Dienenden“ ist immer „Liebender eines Wohlthäters“ von allen ausser Dienenden, d. h. steht zu allen ausser Dienenden in der Beziehung des Liebenden eines Wohlthäters von ihnen.
Wenn man den Worttext (in seiner ersten Fassung) liest, so möchte man wohl meinen, dass der Satz auch umgekehrt gelten müsse, dass nämlich die durch die Kopula „ist“ verbundnen beiden Kategorieen von Personen in eine Kategorie zusammenfielen.
Dieses ist, wie wir noch genauer sehen werden, nun keineswegs der Fall:
unser Satz darf nicht umgekehrt werden.
Und es ist sehr bemerkenswert, dass die „rhetorische Evidenz“ — im Grunde (nur) weil die Wortsprache des Hülfsmittels (oder zur exakten Behandlung so unentbehrlichen Bezeichnungskapitals) der Klammern entbehrt — hier leichtlich irreführt, wonicht geradezu dazu verleitet einen Fehlschluss zu begehen.
Ähnlich besagt der zweite Satz 7):
Wer zu irgend einem Dienenden in der Beziehung steht eines Liebenden von allen ausser dessen Wohlthätern, der ist ein Liebender von allen ausser Wohlthätern von Dienenden.
Vor Fehlschlüssen gewährt hier jedenfalls der Kalkul Rettung, und so kann ich nur raten, dass der Leser sich die einfachen Formeln 7) so wie sie eben sind einpräge.
Was nun die Beweise der Formeln betrifft, so muss ich den Leser schon darum bitten, sich noch ein wenig zu gedulden bis zur Erledigung der nächsten Formelgruppe, weil bei Berücksichtigung der in dieser zu statuirenden Prinzipien der Konjugation und des Dualismus unsre Arbeit sich sehr verringern wird.
Eine zweite Formelgruppe zieht auch die Spezies der Negation und Konversion mit in Betracht.
Als die allereinfachsten verdienen vorangestellt zu werden die drei Sätze:
8) ā̄ = a, ă̄ = ā̆, ă̆ = a.
Der erste von diesen ist der schon aus dem identischen Kalkul bekannte „Satz der doppelten Verneinung (Negation)“.
Der zweite lehrt, dass die Reihenfolge, in welcher die beiden Operationen der Negation und der Konversion hintereinander ausgeführt werden, für das Ergebniss gleichgültig ist.
Dieser Satz hat bislang keinen Namen; vielleicht ist es genehm, denselben als den „Wechselsatz von Negation und Konversion“ zu bezeichnen.
Der dritte mag analog der „Satz der doppelten Konversion“ heissen.
Derselbe lehrt, dass — gleichwie durch doppelte Negation — so auch durch doppelte (zweimal hintereinander vollzogene) Konversion jedes Relativ ungeändert bleibt.
Auch doppelte Konversion „hebt sich auf oder: das Konverse vom Konversen eines Relativs ist dieses ursprüngliche Relativ selber.
In ihrer Gesamtheit legen unsre drei Sätze die Folgerung nahe, dass die vier Ausdrücke B) a, ā, ă, ā̆ in Hinsicht der beiden Operationen der Negation und Konversion eine „Gruppe“ bilden.
Dieselben sollen die vier mit a (oder irgend einem von ihnen) „verwandten“ Relative heissen.
In hinreichend vereinfachten (sog. reduzirten) Ausdrücken kann eine jede der beiden nichtknüpfenden Spezies niemals successive, in mehrfacher Wiederholung, auftreten, sondern es kann nur vorkommen: eine jede einzeln, oder gar nicht, oder beide in der Ordnung -̆ (strichkonvers) je einmal hintereinander.
Insbesondre wird auch stets sein müssen: ā̆̄̆ = a.
Hiernächst treten zu De Morgan’s schon bekannten Formeln: 9) als vollkommne Analoga auf der zweiten Hauptstufe hinzu: 10) [Formel] — zwei höchst bemerkenswerte Sätze, nach welchen auch für die relativen Knüpfungen der Wortlaut der vorigen aufrecht erhalten werden kann: das Negat des Produktes ist die Summe der Negate der Faktoren, das Negat einer Summe ist das Produkt der Negate ihrer Glieder.
a̅b̅ = ā + b̄ a̅ +̅ b̅ = āb̄
Setzt in 10) man ā, b̄ für a, b und wendet den — unter 8) mit registrirten — Satz der doppelten Verneinung an, so ergeben sich zu den aus Bd. 1 schon bekannten beiden ersten auch noch die beiden letzten von den folgenden vier Formeln: C)
[Formel] welche (die schon S. 3 aufgestellte Behauptung rechtfertigend) erkennen lassen: dass von den beiden knüpfenden Spezies einer jeden Hauptstufe die eine — gleichviel welche — zur Not auch durch die andre entbehrlich gemacht werden kann.
Solches aber auf Kosten der Einfachheit, Symmetrie und Eleganz des ganzen Lehrgebäudes wirklich zu thun, wäre mindestens ebenso thöricht, als wenn man z. B. in der Mathematik zugunsten des sinus die Namen cosinus, (tg, sec, etc.)
— oder umgekehrt — aus der Welt schaffen wollte.
Nach C) muss auch jeder mittelst knüpfender Spezies aus einfachen Relativsymbolen aufgebaute Ausdruck seinem Werte nach ungeändert bleiben, wenn man denselben folgendem Prozesse unterwirft, der sich aus drei Teiloperationen zusammensetzt, nämlich: wenn man erstens die sämtlichen einfachen Operationsglieder in ihre Negate verwandelt, zweitens die beiden knüpfenden Operationen einer jeden Hauptstufe, als da sind Multiplikation und Addition, miteinander vertauscht, drittens vom Ergebnisse die Negation nimmt.
Bei dem Austausch der Operationen dürfen jedoch die Konventionen über Erforderlichkeit oder Entbehrlichkeit von Klammern nicht ausser Acht gelassen werden.
Exempel: a; (b + c) ɟ d = (ā ɟ b̄c̄); d̄.͞
Diese Sätze 9), 10) — in Verbindung mit 8) — garantiren nunmehr, dass die Operationen der Negation und Konversion, welche in irgend einem mittelst der 6 Spezies aufgebauten Ausdrucke vorkommen, d. i. vorgeschrieben sein mögen, samt und sonders sich so weit ausführen lassen, dass sie an keinem noch irgendwie zusammengesetzten Ausdruckteile mehr zu vollziehen sein werden.
Vielmehr lässt durch „Ausführung“ der nichtknüpfenden Spezies hinfort jeder Ausdruck sich so weit reduziren, dass Negationsstrich sowie Konversionsringel oder auch das Zeichen Strichkonvers höchstens noch über den einfachsten Symbolen — wie Buchstaben — haften, aus welchen als aus seinen letzten Elementen der Ausdruck aufgebaut war.
Der allgemeinste Ausdruck also, der in unsrer Theorie ein binäres Relativ vorzustellen vermag, wird — solchergestalt reduzirt — ausschliesslich mittelst der vier knüpfenden von den 6 Spezies zusammengesetzt erscheinen aus lauter durch Buchstaben dargestellten und eventuell noch den mit ihnen „verwandten“ Relativen von der Form B).
Solche Symbole eben wollen wir hinfort „einfache“ nennen.
Die Buchstaben können auch durch Modul(name)n vertreten sein, und werden dann die durch die übergesetzten Zeichen -, ̆, -̆ angedeuteten Operationen, wie bald zu sehen, sich an ihnen noch vollends „ausführen lassen, sodass mit jenen Zeichen behaftete Moduln auch nirgends vorkommen werden.
Die Anwendung der Formeln 9), 10) im Sinne von links nach rechts nennen wir das „Ausführen“ der Negation an den unter dem Negationsstriche linkerhand stehenden Ausdrücken.
Analog — doch in gewissen Hinsichten damit kontrastirend — gelten für die „Ausführung“ der Konversion die folgenden ebenfalls ganz fundamentalen Sätze: oder auch im Hinblick auf das Kommutationsgesetz als hiermit äquivalent: 11) und dazu: 12)
ab͝ = ăb̆ a + b͝ = ă + b̆
ab͝ = b̆ă a + b͝ = b̆ + ă
a; b͝ = b̆; ă a ɟ b͝ = b̆ ɟ ă.
Im Gegensatz zur Negation lässt hiernach die Konversion bei ihrer Ausführung die Natur der Ausdrücke unverändert; sie kehrt aber, indem sie sich distributiv von denselben auf deren Operationsglieder, Terme überträgt, die Reihenfolge der letzteren um — ein Zusatz der blos bei den identischen Knüpfungsergebnissen irrelevant, belanglos ist, bei den relativen dagegen nicht missachtet werden darf.
Man merke:
Das Konverse eines identischen Produktes ist das identische Produkt der Konverse seiner Faktoren.
Das Konverse einer identischen Summe ist die identische Summe der Konverse ihrer Glieder.
Das Konverse eines relativen Produktes ist das relative Produkt der Das Konverse einer relativen Summe ist die relative Summe der Konverse seiner Faktoren, diese jedoch in der entgegengesetzten Reihenfolge genommen.
Konverse ihrer Glieder, diese ebenfalls in der umgekehrten Ordnung genommen.
Sowie umgekehrt.
Die Sätze 9) bis 12) sind von zweien alsbald auch wieder auf beliebig viele Terme ausgedehnt zu denken.
Ersetzt man in 11) und 12) a und b durch ă, b̆, und beachtet den Satz der doppelten Konversion aus 8), so ergeben sich noch die Darstellungen: D)
[Formel] welche zeigen, dass man in irgend einem vermittelst knüpfender Spezies aufgebauten Ausdrucke die umgekehrte Ordnung seiner sämtlichen Operationsglieder oder Terme herstellen könnte dadurch, dass man die letztern durch ihre Konverse ersetzte und alsdann den ganzen Ausdruck konvertirte.
Es sind jedoch die Teiloperationen des unter D) gleichwie des unter C) im vorigen Kontext geschilderten Prozesses blos in ihrer Gesamtheit allgemein gestattet.
Im allgemeinen wird dagegen bei einem für sich stehenden Ausdrucke es nicht zulässig sein, dass man die Teiloperationen der soeben genannten Prozesse einzeln an ihm vornehme, sintemal die letztern von Einfluss auf den Wert des Ausdrucks sich erweisen dürften.
Ebensowenig darf man die Terme des Ausdrucks durch ihre Negate ersetzen oder (eventuell in Verbindung damit) die Negation vom ganzen Ausdruck nehmen.
Denn wenn der Wert, die Bedeutung eines Ausdruckes geändert, derselbe in einen (nicht blos der Form nach) „andern“ Ausdruck verwandelt wird, so lässt sich, falls man vom ursprünglichen Ausdrucke irgend etwas wusste oder zu begründen vermochte, von dem geänderten Ausdrucke dies nicht mehr wissen oder behaupten.
Jedenfalls lässt sich das über den Ausdruck vorhandene Erkenntnisskapital nicht ohne weiteres auf diejenigen Transformationen desselben, die seinen Wert beeinflussen, übertragen.
Vielmehr geht man dieses gesamten Erkenntnisskapitals verlustig, gibt dasselbe preis, sobald man den Ausdruck durch einen solchen ersetzt, der einen vielleicht ganz andern Wert besitzen mag.
Es geht damit ähnlich wie in der Arithmetik: Stellt ein numerischer oder auch Buchstaben-Ausdruck z. B. die Geldsumme vor, die eine Person A einer Person B schuldet, so wird A gegen alle Transformationen des die Schuldsumme repräsentirenden Ausdrucks Protest erheben, welche denselben in einen solchen von höherem Werte verwandeln, B mindestens dagegen Verwahrung einlegen, dass der Ausdruck in einen andern von niedrerem Betrage umgewandelt werde.
Aus Gründen der angedeuteten Art nennt man bekanntlich „erlaubt oder „zulässig“ nur solche Umformungen eines Ausdruckes, von welchen garantirt werden kann, dass sie den Wert desselben ungeändert lassen.
Dies traf oben bei C) und D) für die Teiloperationen der Prozesse nur in ihrer angegebnen Verbindung miteinander zu.
Doch können (solche) Operationen — wie Negiren, Konvertiren, Ersetzen der Terme durch von ihnen verschiedene, z. B. ihre Negate oder ihre Konverse — welche am einzelnen Ausdrucke unzulässig sind, an Ausdrücken dennoch zulässig werden in einer hochwichtigen Kategorie von Fällen, nämlich wenn diese Ausdrücke in eine allgemeingültige Formel als deren beide Seiten eingehen, oder was auf dasselbe hinauskommt, wenn sie in allgemeinen Lehrsätzen figuriren.
Dass da die unbestimmten, durch Buchstaben als allgemeine Symbole repräsentirten Operationsglieder auch durch andre durchweg ersetzt werden dürfen ist a priori einleuchtend, liegt nämlich im Begriffe der Allgemeingültigkeit der Formel oder des Lehrsatzes.
Unter welchen Bedingungen aber, oder mit welchen Kautelen, die Operation des Negirens sowie die des Konvertirens beiderseitig vollzogen werden darf an einer Subsumtion oder Gleichung — dies lehren die nächstfolgenden Sätze: 13) (a ⋹ b) = (b̄ ⋹ ā) = (ă ⋹ b̆) = (b̄̆ ⋹ ā̆) mit den höchst nahe liegenden Korollaren: E) [Formel] — worin sämtliche Aussagen weniger einander als vielmehr der ersten von ihnen gleichgesetzt zu denken sind.
Die Verwandlung der ersten Subsumtion 13) in die zweite wird bekanntlich die Kontraposition von jener genannt; sie läuft hinaus auf beiderseitiges Negiren, welches jedoch nicht ohne gleichzeitige Umkehrung des Subsumtionszeichens gestattet ist (oder falls man letztres beibehalten will, zu verbinden ist mit einer Vertauschung von Subjekt und Prädikat der Subsumtion).
Die Verwandlung der ersten Subsumtion 13) in die dritte möge das beiderseitige Konvertiren derselben heissen.
Dasselbe ist hienach ohne weiteres gestattet, liefert wiederum eine mit der gegebenen äquivalente Subsumtion.
Die „Umkehrung der Subsumtion“ a ⋹ b selbst dagegen würde dieselbe in b ⋹ a verwandeln, welche letztere mit ihr zugleich gar nicht zu gelten braucht; ihre (legitime) Verwandlung in b ￼ a dagegen würde blos als ein „Rückwärtslesen“ der Subsumtion zu bezeichnen sein.
Ihre Verwandlung in die vierte mag konvertirende Kontraposition genannt werden.
Bei den Gleichungen muss alsdann kraft Def. oder Festsetzung (1) das beiderseitige Negiren (die Kontraposition) sowol als auch das beiderseitige Konvertiren, sowie endlich dieses in Verbindung mit jenem ohne weiteres gestattet sein.
Durch beiderseitiges Negiren (Kontraposition) der Aussagengleichungen (Äquivalenzen) in 13) und E) ergibt sich noch als ein weiteres Korollar dazu: dass es auch gestattet ist in ihnen die in den Klammern stehenden Zeichen ⋹ und = durch deren Negationen ⋹ und ≠ durchweg zu ersetzen.
Wir haben also ganz ähnliche Sätze auch für die Unsubsumtion und Ungleichung, nämlich als Korollar zu 13) und E):
[Formel] .
Aus den Sätzen 8) bis 13) lassen sich jetzt auch die hochwichtigen „Prinzipien des Dualismus und der Konjugation“ rechtfertigen, die uns in den Stand setzen, zu jeder als allgemeingültig erkannten „Formel“ sogleich noch drei zumeist neue Formeln hinzuschreiben, deren Gültigkeit mit ihr zugleich verbürgt sein wird.
Die in der Theorie zu leistende Beweisarbeit wird damit auf beinah ihren vierten Teil reduzirt!
Es verlohnt deshalb, hierauf sogleich näher einzugehen, indem man die chiffrirten Formeln vorderhand als erwiesen ansieht.
Die Formel habe die Gestalt einer Subsumtion oder aber einer Gleichung, oder auch der Verneinung von dieser oder jener.
Wie später zutage tritt, lässt sich dies bei jeder Formel hinbringen, sodass es unbeschadet der Allgemeinheit vorausgesetzt werden kann.
Zu beiden Seiten der Formel seien auch die Operationen der Negation und Konversion schon ausgeführt.
Alsdann dürfen (erster Prozess) sämtliche Buchstabenrelative durch ihre Konverse ersetzt werden, weil für diese letztern Relativwerte die Formel ebensogut Geltung beansprucht wie für jene ursprünglichen Relative.
Und ferner dürfen (zweiter Prozess) die Ausdrücke beiderseits nach 13) und E) konvertirt werden, wodurch nach 8) die Konversionsringel über den Buchstaben wieder aufgehoben werden, aber die Reihenfolge sämtlicher Operationsglieder in der Formel sich in die entgegengesetzte verwandelt.
Es muss dann also auch diejenige Formel gelten, welche man (mit einem Schlage) aus der gegebnen Formel erhält, indem man die Ausdrücke zu beiden Seiten derselben genau so hinschreibt, wie man sie rückwärts liest — während man jedoch etwa vorkommende spezielle Relative durch deren Konverse ersetzt.
Buchstaben natürlich, mit Einschluss der Π, Σ, ebenso aber auch die Modulsymbole 0, 1, 0', 1' und endlich die Knüpfungszeichen; und ɟ dürfen hierbei nicht umgedreht werden.
Und die Π, Σ müssen den Ausdrucksteilen, vor welchen sie standen, vorangestellt bleiben.
Dies ist zunächst klar, soferne in der Formel keine speziellen Relative (Moduln) vorkamen, dieselbe vielmehr lediglich auf allgemeine oder Buchstabenrelative Bezug nimmt.
In solchem Falle muss zur Rechtfertigung des Gesagten nur noch folgende Überlegung beigebracht werden.
Kam ein a, ā, ă oder ā̆ in der Formel vor, so verwandelt der erste Prozess dasselbe bezüglich in: ă, ă̄ = ā̆, ă̆ = a, ă̄̆ = ā̆̆ = ā.
Der zweite Prozess verwandelt dasselbe hernach in resp.: ă̆ = a, ā̆̆ = ā, ă, ā̆, das heisst: die beiden Prozesse hintereinander ausgeführt lassen, wie behauptet, die vier Symbole wirklich unverändert.
Auf spezielle Relative, nur, die etwa (neben allgemeinen) noch in der Formel vorkommen, ist der erste Prozess gar nicht anwendbar.
Gilt z. B. a + 1 = 1 als allgemeine Formel, so darf zwar a durch ā, ă, b, 0 und was man will ersetzt werden, nicht aber 1.
Bei solch speziellen Relativen hat daher der zweite Prozess die durch nichts kompensirte Wirkung, dieselben unter Umkehrung der Reihenfolge, in welcher sie mit andern Symbolen verknüpft sind, in ihre Konverse zu verwandeln.
Moduln allerdings — werden wir sehen — bleiben auch hierbei unverändert, sodass die vorstehend kursiv gedruckte Methode schon ohne den letzten Zusatz anwendbar ist, soferne — neben Buchstaben — als spezielle Relative höchstens Moduln in der Formel vorkommen.
Diese zweite mit der ersten zugleich verbürgte Formel möge die zu ihr „konjugirte“ heissen.
Aus ihr geht hinwiederum durch dieselben Prozesse auch ihrerseits die erste hervor, sodass die Beziehung zwischen konjugirten Formeln eine gegenseitige zu nennen ist.
Das aus den genannten beiden Prozessen zusammengesetzte Verfahren mag „Konjugiren“ (Konjugation) genannt werden.
Bei Gleichungen — natürlich „analytischen“, denn auf „synthetische Gleichungen, auf „Relationen“ ist das Konjugiren überhaupt nicht anwendbar — bei Gleichungen, in welchen keine andern speziellen Relative als höchstens Moduln vorkommen, könnte das Verfahren geradezu als ein buchstäbliches Rückwärtslesen derselben bezeichnet werden; bei Subsumtionen jedoch darum nicht, weil behufs Konjugirens Subjekt und Prädikat nicht vertauscht werden dürfen, vielmehr der Minor Minor bleiben muss.
Hier wäre es allenfalls angängig „beiderseitiges buchstäbliches Rückwärtslesen für „Konjugiren“ zu sagen.
Jedoch ist der verbale Ausdruck „Rückwärtslesen“ schlechtweg bei einer Gleichung, oder Subsumtion, Ungleichung etc. bereits in einem ganz andern Sinne gebräuchlich:
man pflegt darunter blos zu verstehen: die Verwandlung von a = b in b = a oder von a ⋹ b in b ￼ a, etc., unter gewöhnlichem oder Vorwärtslesen der beiderseitigen (vielleicht sehr komplizirten) Ausdrücke, welche uns die Buchstaben a und b bei dieser Betrachtung vertreten.
Ebendarum, sowie auch wegen der in der vorigen Fussnote hinsichtlich etwa vorkommender Π, Σ statuirten Einschränkung, empfiehlt es sich am besten, den Ausdruck „Konjugiren“ zu gebrauchen.
Die Konjugation also liefert uns zur ersten Formel eine zweite, die mit ihr zugleich gelten muss.
Es kann sein, dass diese zweite Formel doch nur den nämlichen Satz ausdrückt wie die erste — dass sie nämlich aus ihr auch hervorgeht durch blosse Buchstabenvertauschung —, in Verbindung, nötigenfalls, auch mit wirklichem Rückwärtslesen der ganzen Formel (sofern sie Gleichung oder Ungleichung gewesen).
Wie leicht zu sehen würde das z. B. bei irgend einem unsrer vier Assoziationsgesetze zutreffen.
In solchem Falle führen wir die zu einer aufgestellten konjugirte Formel nicht mit an.
Dergleichen findet verhältnissmässig selten statt.
In der grossen Mehrzahl der Fälle drückt die zu einer ersten konjugirte Formel einen ganz neuen Satz aus.
Wir pflegen sie dann unter die erste zu schreiben, und verfügen bis jetzt über (im allgemeinen) zwei Formeln.
Die zu einer gegebnen konjugirte Formel wird jedoch oftmals nicht rein als solche, sondern mit noch obendrein vertauschten Buchstaben angegeben, etwa damit diese wiederum alphabetische Ordnung aufweisen.
Zu jeder von diesen Formeln lässt sich nun ferner das duale Gegenstück derselben herstellen, sodass wir noch zwei eventuell abermals neue Formeln hinzu erhalten, die wir dann hinter einem „Mittelstrich“ gewöhnlich neben die vorigen stellen.
Den beiden letzten werden ihrerseits auch wieder die beiden ersten Formeln „dual entsprechen“.
Das duale Entsprechen, der „Dualismus“ zwischen den nebeneinander stehenden Formeln wird ein gegenseitiges sein, und ferner: wie die untereinander stehenden Formeln links vom Mittelstriche einander konjugirt waren, so werden auch die beiden Formeln rechts vom Mittelstrich zueinander konjugirt sein müssen, sodass mit den vier Formeln deren „Gruppe“ abschliesst.
Für die Operation der Bildung des dualen Gegenstücks ist noch kein Name in Gebrauch; es scheint dafür der Ausdruck „Dualisiren zur Verfügung zu stehen (minder gut, weil schon mit Nebendeutungen versehen, wol „Opponiren, Opposition, Entgegensetzung“ oder dergl.).
Also: durch Dualisiren gehen die nebeneinander, durch Konjugiren die untereinander stehenden von den vier Formeln in einander über, und weil jene beiden erlaubte Prozesse sein werden, so dürfen mit irgend einer von den vier Formeln zugleich alle viere Geltung beanspruchen.
Die vier Formeln, die sich nur auf zweie oder eine auch reduziren können, bilden eine Tetrade, ein Quadrupel, Viergespann von — wie wir sagen wollen — „verwandten“ Formeln oder Sätzen.
Beispiele dazu liefern schon die bisher aufgeführten Sätze.
Eine Reduktion der vier Formeln auf dreie, welche verschiedene Sätze zum Ausdruck brächten und dennoch in Hinsicht der Operationen des Konjugirens und Dualisirens eine (vollständige) Gruppe bildeten, ist unmöglich.
Dies würde sich leicht im Anschluss an unsre Ausführungen apagogisch beweisen, theoretisch begründen lassen.
Man mag sich jedoch auch an der aus der Praxis unsrer Disziplin zu schöpfenden Erfahrung genügen lassen, dass Triaden, Tripel, Dreigespanne von Formeln in dieser niemals auftreten.
In eine Dyade, ein Paar oder Zweigespann von Formeln kann das Viergespann auf zwei Arten ausarten.
Entweder könnten hiebei die einander konjugirten, oder die zueinander dualen Formeln jeweils in eine zusammenfallen — abgesehen natürlich von der Wahl der Buchstaben, mit denen die in die Formel als Terme eingehenden allgemeinen Relative gerade benannt erscheinen und wofür ja der Grundsatz massgebend ist: „der Name thut nichts zur Sache“.
Im erstern Falle sind die verbleibenden das Zweigespann bildenden Formeln, als duale, durch einen Mittelstrich getrennt nebeneinander gesetzt (oder wenigstens auf einer Zeile stehend zu denken).
Im letztern Falle — der jedoch nicht vorzukommen scheint — würden sie als konjugirte, untereinander stehen.
Dagegen kommt es — wie beim Zweigespann: 7)
[Formel] — vor, dass die dualen Formeln zugleich konjugirte sind, ohne dass doch diese oder jene unter sich zusammenfielen.
Dass die vier Formeln auch in eine zu einer „Monade“, einem Eingespann“ zusammenschrumpfen können, zeigt sich schon bei den Sätzen 0), 1) und 13).
Im Hinblick auf diese Möglichkeiten oder Degenerationsfälle werden wir allgemein am besten (ohne nähere Zahlbezeichnung) blos von einem „Gespann“ von Formeln oder Sätzen reden.
Der Ausdruck „Gruppe“ wird schon anderweitig und ohnehin in nur zu oft wechselndem Sinne gebraucht.
Ursprünglich setzt sich das „Dualisiren“ aus folgenden beiden Prozessen zusammen, mit deren Zulässigkeit das Verfahren auch gerechtfertigt erscheint.
(Erster Prozess:)
Man ersetze alle in der Formel vorkommenden Buchstaben, welche allgemeine Relative vorstellen, durch deren Negate für welche ja die Formel ebensogut gelten muss wie für die ursprünglichen Relative.
Hernach wende man (zweiter Prozess) das gemäss 13) und E) erlaubte Verfahren des beiderseitigen Negirens, der Kontraposition an, was nach den Schemata 13) bei einer Subsumtion oder Subsumtionsnegation die Umkehrung von deren Beziehungszeichen, wo nicht eine Vertauschung von Minor und Major involvirt, bei einer Gleichung solche Vertauschung ihrer beiden Seiten zwar nicht peremtorisch fordert aber wenigstens zulässt.
Durch diesen zweiten Prozess wird nach den Schemata 9) und 10) die Reihenfolge der Operationsglieder oder Terme nicht alterirt.
Es werden ferner wegen 8) die vorhin über die Buchstaben eingeführten Negationstriche wieder aufgehoben und bleibt als Nutzeffekt nur der: dass die knüpfenden Operationen einer nämlichen Hauptstufe sich durch einander ersetzen — während jedes in der Formel vorgekommene spezielle Relativ sich in sein Negat verwandelt.
Um die Restitution, Wiederherstellung der ursprünglichen Buchstaben zufolge des Sich-Aufhebens der doppelten Verneinung genauer einzusehen, hat man noch zu überlegen:
Kam ein a, ā, ă, ā̆ in der Formel vor, so wird es durch den ersten Prozess in ā, ā̄ = a, ā̆, ā̄̆ = ă verwandelt, darnach aber durch den zweiten Prozess in ā̄ = a, ā, ā̆̄ = ā̄̆ = ă, ă̄ = ā̆, d. h. man erhält die alten Symbole wieder.
Nur bei Symbolen für spezielle Relative — wie Moduln z. B. —, auf welche der erste Prozess nicht angewandt werden durfte, ansonst die Formel ihrer erwiesenen Gültigkeit verlustig ging, nur bei diesen tritt der zweite Prozess ungeschwächt in Wirksamkeit und verhilft ihnen zu einem Negationsstriche.
Bei Moduln — wird sich im § 8 zeigen — kann auch diese Negation sogleich „ausgeführt“ werden indem sie blos Vertauschung von 0 und 1, sowie von 0' und 1', mithin der beiden Moduln einer Hauptstufe, bewirkt.
Indem man also daneben blos die Zeichen · und + sowie; und ɟ event. auch Π und Σ vertauscht, wird sich die Operation des Dualisirens eines Ausdruckes auch mit einem Schlage ausführen lassen, soferne als spezielle Relative höchstens Moduln in dem Ausdrucke vorkommen — und dies ist praktisch weitaus der häufigste Fall.
Im Gegensatz aber zum Konjugiren, welches die Natur der Knüpfungszeichen und die Klammerstellung nicht weiter berührte als indem sie deren Reihenfolge in die entgegengesetzte verwandelte, wird nun bei der Herstellung des dualen Gegenstücks zu einem Ausdrucke sorgfältigst Bedacht zu nehmen sein auf korrekten Ansatz der Klammern.
Das zu dem Ende einzuhaltende Verfahren wird man sehr leicht im Hinblick auf die Konventionen des § 5 sich aneignen und einüben, doch ist es nicht ganz einfach zu beschreiben.
Man muss sich eben in dem gegebnen Ausdrucke sämtliche Klammern — auch die Ersparniss halber daselbst unterdrückten — ausdrücklich angesetzt denken, muss die fehlenden mental suppliren oder im Geiste herbeischaffen.
Blos innerhalb solcher Ausdruckteile, die wie a · b · c … (oder abc ‥), wie a + b + c ‥, a; b; c; ‥, a ɟ b ɟ c ɟ ‥ mittelst einer und derselben knüpfenden Spezies aufgebaut erscheinen, darf letztres — der Assoziationsgesetze halber — unterbleiben.
Unerlässlich ist es aber überall da, wo verschiedene knüpfende Spezies konkurriren, verschiedne Knüpfungszeichen (durch Buchstaben oder Ausdruckteile getrennt) aufeinander folgen.
Nach vollzogener Umwandlung der Knüpfungszeichen muss man alsdann die sich nach § 5 als entbehrlich zu erkennen gebenden von all den Klammern wieder fort lassen.
Es werden entbehrlich gerade diejenigen Klammern, die im gegebnen Ausdrucke ausdrücklich angesetzt waren und dort nicht unterdrückt werden durften.
Diese also wird man beim Dualisiren weglassen.
Und umgekehrt: diejenigen Klammern, die im gegebnen Ausdrucke fehlten, werden im allgemeinen in dessen dualem Gegenstücke ausdrücklich zu setzen sein — abgesehn nämlich von obenerwähnten Fällen der Assoziativität und noch einigen andern Fällen, wie a · b; c — wozu, auch wieder ohne Klammern, a + b ɟ c das duale Gegenstück sein wird — deren vollständige Aufzählung indessen kaum verlohnen dürfte.
Es versteht sich, dass beim Dualisiren sowol als beim Konjugiren die Reihenfolge der beiden Teilprozesse auch als die umgekehrte hätte genommen, der zweite Prozess als erster hätte angesetzt werden können.
Darin, dass beim Dualisiren die Reihenfolge der Terme ungeändert gelassen wird, und beim Konjugiren die Natur der Knüpfungszeichen, liegt die Rechtfertigung der obigen Angabe, dass die dualen zu zwei konjugirten Formeln (resp. Ausdrücken) ebenfalls einander konjugirt sein müssen, gleich- wie die konjugirten zu zwei einander dual entprechenden Formeln (resp. Ausdrücken) auch ihrerseits werden zu einander dual sein müssen.
Die beiden Prozesse „stören sich gegenseitig nicht“.
Es muss auch einerlei sein, in welcher Ordnung etwa diese beiden einander niemals störenden Operationen oder Prozesse hintereinander ausgeführt werden, als da sind:
Vertauschung gewisser Knüpfungszeichen, nämlich Verwandlung jedes Knüpfungszeichens in das andre von derselben Hauptstufe, und: Rückwärtslesen des Ausdrucks, oder Umkehrung der Reihenfolge von allen seinen Termen und den sie verbindenden Zeichen — worauf ja das Dualisiren und das Konjugiren wesentlich hinauslief.
Durch beide Operationen, gleichviel in welcher Folge sie ausgeführt werden, gelangt man — genau so wie in der Kinematik bei der Zusammensetzung, dem „Parallelogramm der Bewegungen“ — von irgend einer der vier Formeln unsres Quadrupels allemal zu der ihr diagonal gegenüberstehenden — das eine mal über die eine, das andre mal über die andre Ecke des Vierecks, d. h. eben vermittelst einer von den beiden Formeln, die mit ihr in derselben Flucht stehen (auf derselben Zeile oder aber in derselben Spalte).
So wichtig in praktischer Hinsicht diese Fingerzeige auch sein mögen indem sie uns beinah drei viertel aller Deduktionsarbeit ersparen werden, bilden sie doch kein wesentliches Moment im deduktiven Aufbaue unsrer Theorie selbst:
die durch sie gesparte Arbeit könnte ja in jedem Einzelfalle mit grösster Leichtigkeit geleistet werden!
Es ist darum kein grosses Gewicht darauf zu legen, ob etwa die vorstehend über Dualismus und Konjugation aufgestellten Behauptungen in ihrer ganzen Allgemeinheit durch die von mir dazu gegebnen Erläuterungen schon vollkommen strenge — als aus unsern 28 fundamentalen Festsetzungen formal folgende — begründet zu erachten seien.
Solche Begründung könnte pedantischer noch verlangt und beigebracht werden; bei wesentlichen Deduktionen werden wir ganz anders strenge — penibel formal — zuwerke gehen.
Bei jenen Überlegungen aber verlohnte wol solches nicht; ich messe denselben fast nur die erziehliche Wirkung bei, dass sie den Leser in den Stand setzen, sowol: die fehlenden drei viertel der Beweise, um deren Druckraum wir unser Buch entlasten müssen, gewünschtenfalles selbst beizubringen: als blosse Wiederholungen in der dualen oder konjugirten Umschreibung des Viertels der Beweise welches wir bringen, als auch: aus der von uns bewiesenen Formel eines jeden Quadrupels sich immer die drei andern direkt auf kürzestem Wege herzuleiten.
Immerhin hoffe ich die beiden Prinzipien einleuchtend gemacht zu haben und kann versichern, dass sie bei längerer Praxis immer intuitiver werden.
Das Prinzip des Dualismus — hier nur zufolge Hinzutretens der beiden relativen Knüpfungen und Moduln unwesentlich in nahe liegender Weise, zu erweitern gewesen — ist dem Leser schon aus dem identischen Kalkul bekannt.
Dass letzterm das Konjugationsprinzip fremd ist, liegt daran dass diese Disziplin keine nicht-kommutativen Spezies kennt.
Im identischen Kalkul fallen konjugirte Formeln im Hinblick auf die Kommutationsgesetze jeweils in einen Satz zusammen, und sie würden auch in der Algebra der Relative in eine Formel zusammenfallen, wenn hier alle knüpfenden Spezies kommutative wären; verschieden können beide hier nur ausfallen, wenn relative Knüpfungen in ihnen vorkommen.
Es drücken insbesondre bei den Distributionsgesetzen in 2) die vier Formeln blos zwei Theoreme aus; die untereinanderstehenden besagen das nämliche; getrennt wurden sie blos aufgeführt, damit ihre Analogie mit 4) etc. gut zutage trete.
Unschwer würde wol ein Bezeichnungssystem zur Darstellung der Operationen (sowie der Moduln) unsrer Disziplin sich aushecken lassen, welches die vier (eventuell auch nur zwei) Formeln eines jeden „Gespannes“ von Sätzen auf einen gemeinsamen Ausdruck zu bringen gestattete.
Zu solch genereller Zusammenfassung der Sätze jeden Quadrupels scheint mir aber gar kein Bedürfniss vorhanden.
Dem Anfänger ist die kleine Repetition der Beweisführung beim dual entsprechenden oder konjugirten eines einmal bewiesenen Satzes als eine heilsame Übung wohl zu gönnen, und angewendet werden die Sätze eines Gespannes, wenn nicht — wie in der Regel — blos einzeln, so doch zusammen immer nur in kollektiver Verbindung miteinander — als cuncti, nicht als omnes.
Um nunmehr mit unsrer zweiten Formelgruppe zu Ende zu kommen, haben wir anzuführen, dass noch diese allgemeinen Sätze bekannt sind: 14) [Formel] 15) [Formel] welche letztern noch von Peirce gegebnen man auch mit der Anwendung auf den andern Term, die sie nach den Kommutationsgesetzen zulassen, vereinigen könnte zu: F) [Formel]
Und ferner, dass die Peirce’schen Sätze identischen Kalkuls: 16) welche ein gewisses Gegenstück zu denen der letzten Zeile unter 3) bilden, auch für unsre Relative gelten und für deren Theorie hochwichtig sind.
(ab ⋹ c) = (a ⋹ c + b̄) = (b ⋹ ā + c) (c ⋹ a + b) = (cb̄ ⋹ a) = (āc ⋹ b)
Diese (rechts und links vom Mittelstriche im Grunde den nämlichen Satz darstellenden) Formeln 16) besitzen auf der zweiten Hauptstufe merkwürdige Analoga, auf die wir in § 17 eingehen werden.
Zudem würden sich noch andre gar nicht sehr zahlreiche Sätze als unter die Überschrift des Paragraphen fallende anreihen lassen, die wir für eine spätere Fortsetzung aufzusparen vorziehen.
Zu einer ersten Grundlegung kann das Bisherige genügen und wollen wir unsre Aufmerksamkeit demnächst dem Beweisverfahren für die aufgezählten Sätze zuwenden.
Diejenigen von den vorstehenden allgemeinen Sätzen, welche sich in der Form von Gleichungen präsentiren, sichern uns, falls die Gleichungen primäre im Boole’schen Sinne sind, die Mittel zur Umformung, Transformation von Ausdrücken: jeder nach dem Schema der einen Seite der Gleichung gestaltete Ausdruck kann durch einen nach dem Vorbild der andern Seite umgestalteten ersetzt werden.
Von solchen Mitteln lässt sich, mit dem Erfolge dass man zu neuen Erkenntnissen geführt wird, ein judiziöser Gebrauch machen.
Ebenso, wenn die Gleichungen sekundäre sind, verbürgen unsre Sätze uns die Erlaubniss zur äquivalenten Umformung von Behauptungen, Urteilen oder Aussagen, sobald solche nur die Form der einen Seite der Gleichung haben, gleichviel welcher von beiden Seiten.
Formeln, die wie z. B. 1) die Form von sekundären Subsumtionen haben, gestatten wenigstens das Ziehen von Schlüssen, als den Übergang von einer Prämisse der Form des Minor zu einer Konklusion von der Form des Major der Aussagensubsumtion — ein Übergang, der bei der Aussagenäquivalenz sogar vor- und rückwärts statthaft.
Aber auch diejenigen Sätze oder Formeln, welche wie 5, 7, 14, 15) blos als primäre Subsumtionen sich darstellen, ermöglichen — im Hinblick besonders auf Prinzip II sowie Th. 2) und 3) des Bd. 1 — noch in mannigfaltiger Weise das Ziehen von Schlüssen.
Dem Anfänger scheinen solche wenn auch allgemeingültige Subsumtionen vielleicht herzlich wenig Information zu liefern, nur wenig zu lehren, und erscheint der Rat am Platze sie, und ihresgleichen später, hinsichtlich ihrer Bedeutung ja nicht zu unterschätzen.
Nicht nur ist ja, nach dem Theorem von R. Grassmann (a ⋹ b) = (a = ab) = (a + b = b) z. B., jede Subsumtion ohnehin äquivalent einer Gleichung, die dann freilich von minder einfachem Ausdrucke und demgemäss von beschränkterer Anwendungsfähigkeit erscheint, sondern es wird auch ein jeder, der sich selbstthätig an Untersuchungen oder Forschungen, an die Lösung von Aufgaben in unsrer Disziplin wagt, unfehlbar folgende Erfahrung machen.
So unliebsam gross die Menge der Sätze, die wir aufzustellen haben, so überwältigend die Fülle der Formeln auf den ersten Blick erschienen sein mochte, sie scheint in solchem Falle noch lange nicht gross genug zu sein; man ist froh um eine jede derselben, auf die man sich zu berufen vermöchte, mag sie auch blos den dürftigen Inhalt einer Subsumtion aufweisen; man steht den gewichtigsten Problemen unsrer Disziplin oft noch beinahe ratlos gegenüber, und erkennt ihren wirklich grossen Reichtum an Ausdrucksformen als einen eben den Bedarf deckenden, das noch nicht so grosse Heer der Methoden aber, über die unsre Disziplin bislang verfügt, als ein zumeist noch recht unzulängliches.
So repräsentiren unsre Sätze zwar ein gewisses schon nicht zu verachtendes Kapital an Hülfsmitteln, oft machtvollen Instrumenten des Denkens, dem aber eine Ausgestaltung zu immer noch grösserer Fülle, eine Entwickelung zu noch viel grösserer Machtentfaltung dringend zu wünschen bleibt.
Schliesslich erübrigt es uns noch, die wichtigsten von den Sätzen oder Formeln zusammenzustellen welche für die (identischen) Produkt(ation)e(n) Π und Summ(ation)en Σ von binären Relativen Geltung haben, sei es dass man diese Symbole als selbständig definirt ansieht in der Art, wie wir es am Schlusse des § 3, S. 36 geschildert haben und wie es beispielsweise bei „kontinuirlichem“ Erstreckungsbereiche der Π und Σ unumgänglich ist, sei es dass man dieselben blos als Abkürzungen verwendet für die Ergebnisse binärer identischer Knüpfungsspezies zwischen irgendvielen Termen, welche nur unbequem sämtlich hinzuschreiben wären.
Dass für beide Deutungsweisen unsre Formeln die nämlichen sein müssen (indem eben die zweite Interpretation sich der ersten einordnet) wird streng genommen erst mit der neunten Vorlesung als gesichert anzusehen sein.
Überhaupt ist zu bemerken, dass die einschlägigen Sätze erst spät, in schon ziemlich vorgerückten Partieen unsrer Theorie zur Anwendung kommen werden, weshalb sie der Studirende auch bis dahin überschlagen mag.
Grösstenteils sind die Sätze schon im identischen Kalkul gültig und bekannt.
Sie bilden alsdann Gegenstücke, Pendants, eventuell aber auch stark modifizirte (nämlich abgeschwächte oder defekte) Analoga zu den Schemata des Aussagenkalkuls, welche wir unter α) bis ξ) am Schlusse des § 3 bereits zusammengestellt haben — und zwar Analoga, weil, mit Rücksicht auf Festsetzung (14), im Grunde Konsequenzen derselben!
Die Analogie ist aber keine durchgängige, vielmehr werden einzelne von jenen Aussagenschemata sogar ganz ohne Gegenstück (bei Relativen) bleiben, und wird sich dem formelreichern Aussagenkalkul gegenüber auch von unsern neufundirten Grundlagen aus der identische Kalkul wiederum als der weniger Schlüsse gestattende erweisen — wofür der letzte Grund in dem Umstande zu erblicken ist, dass zu der mit Πi j konstruirten fundamentalen Festsetzung (14) ein mit Σi j konstruirtes „aussagenduales“ Gegenstück fehlt, und daselbst (vgl. Bd. 2, S. 43 sqq.) auch definitiv unzulässig bleibt. —
Um die Formeln nicht mit Zeichen zu überladen, wollen wir da, wo nur ein allgemeines Relativ und Σ oder Π-zeichen in Betracht kommt, den laufenden Zeiger unerwähnt lassen.
Ist a konstant, so haben wir das Tautologiegesetz 17) Πa = a = Σa wie immer die Erstreckung des Π oder Σ auch gegeben sein möge — vgl. δ) des § 3, S. 39.
Ist a variabel, so haben wir doch: 18) Πa⋹a⋹Σa wenn das in der Mitte stehende (von Π und Σ) freie a nur irgend einen, einen beliebigen von den wechselnden Termen (a) vorstellt, über welche das Π und Σ sich übereinstimmend erstrecken soll — vergl. α) des § 3.
Ein solches Πa, = [Formel] , soll uns eigentlich einen in formaler Hinsicht als allgemeiner oder noch umfassender erscheinenden Ausdruck vertreten:
[Formel] .
Dieser Ausdruck umfasst zunächst in der That den vorigen, indem es uns, solange φ(a) von unbestimmter Allgemeinheit ist, jederzeit freistehn wird, dieses φ(a) = a selbst zu spezialisiren.
Anstatt jedoch als Erstreckung des Π den Bereich der Werte anzugeben, welche dem Argument a des allgemeinen Terms φ(a) in Gedanken beizulegen sind, m. a. W. welche a selbst „zu durchlaufen hat, und durch welche sich die zugehörigen Werte von φ(a) jeweils eindeutig bestimmt erweisen, kann man sich auch sogleich den Bereich der letzteren Werte angegeben denken.
Dieser bildet einen neuen, von dem des a im allgemeinen verschiedenen Erstreckungsbereich, und wenn wir ihn an Stelle des vorigen zugrunde legen, so wird unser Ausdruck [Formel] durch den [Formel] nunmehr zu ersetzen sein.
Förmlich einander gleich dürfen trotz ihrer Identität die beiden Ausdrücke aber nicht gesetzt werden, weil in solcher Gleichung wegen der Verschiedenheit der beiderseitigen Erstreckungsbereiche das Zeichen Π als ein „doppelsinniges“ gebraucht erschiene [das φ(a) hat ja nicht die Werte des a anzunehmen oder zu durchlaufen!] — also: weil mit dem Übergang über das Gleichheitszeichen ein Wechsel in den Bezeichnungsprinzipien, in der Terminologie oder Nomenklatur eingetreten wäre, was unerlaubt.
Jetzt steht aber nichts im Wege, für den umständlichern Namen φ(a) einen Buchstaben c als kürzern Namen einzuführen, φ(a) = c zu setzen, und so gelangen wir zu dem Ausdrucke:
[Formel] welcher von derselben Form ist wie der frühere [Formel] , in welchem nur der Erstreckungsbereich jetzt als ein anderer zu denken ist, nämlich statt aus den Werten von a aus denen von φ(a) bestehen wird.
Von vornherein, nämlich sofern es sich um eine neue oder selbständig in voller Allgemeinheit zu führende Untersuchung handelt, mögen wir aber auch statt des Buchstabens c den Namen a selbst verwenden, und gelangen so zu unserm frühern Ausdruck zurück als einem nur scheinbar weniger allgemeinen:
Durch geeignete Wahl, Abänderung des Erstreckungsbereiches lässt sich jeder Ausdruck von der Form [Formel] in einen einfacheren von der Form [Formel] umwandeln.
Ähnliches ist inbezug auf die Ausdrücke [Formel] , [Formel] , [Formel] gesagt zu denken, die wir durch die einfacheren [Formel] , [Formel] , [Formel] a priori ersetzen können, wie dann auch das Umgekehrte zulässig bleibt.
Jenes aber zu thun empfiehlt sich wegen der dadurch bewirkten Entlastung, des erzielten Gewinnes an Übersichtlichkeit der Formeln.
Dies vorausgesetzt werden wir haben, als Gegenstück zu γ) des § 3: 19) woneben sogleich gestellt sein möge: 20) [Formel] ferner als Gegenstück zu ε), ζ) des § 3: 21) [Formel] — was auch hinreichend ausdrucksvoll, nicht missverständlich, schon durch Π(a⋹b) = (Σa⋹Πb) dargestellt werden kann.
Π̅a̅ = Σā Σ̅a̅ = Πā
Die Schemata η), ϑ) des § 3 entbehren eines genauen Analogons in unsrer Theorie, ziehen keine Formel vom selben Schema für unsre Relative nach sich es sei denn die abgeschwächte: 22) Σ(a⋹b) ⋹ (Πa ⋹ Σb).
Den Schemata ι) ibid. entspricht: 23) 24) wobei die Formeln der zweiten Zeile gegen die dortigen Schemata abgeschwächt erscheinen.
Π(a = 1) = (Πa = 1) Π(a = 0) = (Σa = 0)
Σ(a = 0) ⋹ (Πa = 0) Σ(a = 1) ⋹ (Σa = 1)
Dem κ) des § 3 entspricht in seinem ersten Teile: 25) [Formel] wobei der letzte Teil oder das Ende jenes Schemas ohne Gegenstück bleibt.
Als Gegenstück zu λ), μ) des § 3 haben wir die Distributionsgesetze: 26) als solches zu ν) und ξ) des § 3 die Sätze: 27) , — wo bei letzterem, falls die Erstreckung beider Π resp. Σ die nämliche sein sollte, das Doppelprodukt (resp. die Doppelsumme) auch in ein einfaches (eine einfache) zusammenziehbar [vergl. 5) des § 7]: — endlich haben wir als Gegenstück zu ο) des § 3 den Satz: 28) ΣΠa⋹ΠΣa.
Für die relativen Knüpfungen treten nun hiezu blos noch die folgenden Erweiterungen der Sätze 5) und 6) des gegenwärtigen Paragraphen: 29) 30) .
Hierbei können stets die Zeichen 31) — nach Belieben — gelesen werden.
§ 7. Beweis jener Grundgesetze.
Nebst einigen Hülfsschemata des Aussagenkalkuls.
Die beiderseits oder „voll“ eingeklammerten Chiffren verweisen jeweils auf die „fundamentalen Festsetzungen“ des § 3, die blos einseitig, rechts mit einem Klammerhaken versehenen Chiffren aber auf die Formeln des laufenden — wonicht eines eigens citirten — Paragraphen.
Die linke Seite einer zu beweisenden Formel werden wir häufig mit L, die rechte mit R bezeichnen um die sonst oft nötig fallende Wiederholung der umständlichen Ausdrücke zu ersparen, welche hüben und drüben stehn mögen.
Wir haben zunächst nur mit dem Beweise von Formeln zu thun, welche die Form einer Subsumtion oder aber einer Gleichung haben, während Ungleichungen und Unsubsumtionen vorerst nicht in Betracht kommen.
Die Formeln sind entweder „primäre“, d. h. solche Propositionen L ⋹ R resp. L = R, deren beide Seiten (binäre) Relative vorstellen, oder sie sind „sekundäre“ (in Boole’scher Terminologie), indem ihre beiden Seiten L und R sich als Aussagen darstellen.
Letztre sind alsdann aus primären Propositionen der vorhin beschriebenen Art vermittelst der 3 Spezies des Aussagenkalkuls aufgebaut.
Der Beweis einer primären Formel und Proposition genannter Art (also einer Subsumtion oder Gleichung nicht aber einer Ungleichung etc.) wird im Hinblick auf die Festsetzungen (14) nebst Korollar und (1) zu leisten sein, indem man allgemein — für jedes ij — zeigt, dass zwischen Li j und Ri j ebendie Beziehung der Einordnung resp. Gleichheit besteht, welche der zu beweisende Satz, die Formel zwischen L und R behauptet.
Da Li j und Ri j als Relativkoeffizienten Aussagen repräsentiren, so können bei diesem Nachweise und den dazu erforderlichen Schlüssen die Gesetze und Schemata des Aussagenkalkuls frei oder nach Herzenslust angewendet werden, weil diese durch unsre Festsetzungen bereits gesichert worden.
Auf solchem Wege lässt jede primäre und mittelbar auch die Thesis jeder sekundären Formel (aus dem angedeuteten Propositionenkreise) sich, wie wir sagen wollen „direkt“ „unmittelbar“ (immediately) oder „aus der Koeffizientenevidenz“ beweisen.
Und falls man die unmittelbaren Beweise vorzieht, ist die Reihenfolge, in der man die Beweise durchnimmt, gleichgültig.
Falls jedoch eine Formel sich ohne Zurückgehen auf die Relativkoeffizienten aus andern auf diesem Wege schon bewiesenen Formeln und Sätzen ableiten lässt, so werden wir solch „mittelbaren“ (mediate) Beweis fast immer vorziehen — uns bestrebend, die Technik der Algebra der Relative selbst zur Entwickelung zu bringen und zur Geltung, zu ihrem Rechte kommen zu lassen.
In solchen Fällen verbleibt die Führung des „unmittelbaren“ Beweises dem Leser als eine jederzeit empfehlenswerte Übungsaufgabe.
„Indirekt“ darf aus bekannten Gründen hier nicht gesagt werden.
Beweis von 1) des § 6. Prämisse, Hypothesis (der sekundären Formel) ist L = (a ⋹ b)(c ⋹ d).
Nach (14) haben wir: (a ⋹ b) = Πi j(ai j ⋹ bi j) ⋹ (ai j ⋹ bi j), ebenso (c ⋹ d) ⋹ (ci j ⋹ di j), woraus nach bekannten Schemata des Aussagenkalkuls (für jedes ij) folgt: ai jci j⋹bi jdi j und ai j + ci j ⋹ bi j + di j, oder wegen (10): (ac)i j ⋹ (bd)i j und (a + c)i j ⋹ (b + d)i j.
Denkt man sich vor diese in Klammer { } zu stellenden Konklusionen das Zeichen Πi j gesetzt und wendet das Schema (14) rückwärts an, so erscheinen die beiden ersten Teil-Behauptungen: ac ⋹ bd und a + c ⋹ b + d der Behauptung, Thesis R von 1) erwiesen.
Ganz ebenso haben wir aber nach (14) auch: (a ⋹ b) = Πi h(ai h ⋹ bi h) ⋹ (ai h ⋹ bi h) und (c ⋹ d) = Πh j(ch j ⋹ dh j) ⋹ (ch j ⋹ dh j), woraus im Vereine zu schliessen ist: ai hch j⋹bi hdh j nebst ai h + ch j ⋹ bi h + dh j nicht nur, sondern auch: Σhai hch j⋹Σhbi hdh j nebst Πh(ai h + ch j) ⋹ Πh(bi h + dh j), das heisst wegen (12): (a; c)i j ⋹ (b; d)i j, (a ɟ c)i j ⋹ (b ɟ d)i j.
Weil es in unser Belieben gestellt, gleichgültig ist, welchen Namen wir für den laufenden Zeiger (die Summations- oder Produktationsvariable) wählen.
Mit andern Worten:
es dürfen die vorhin für jedes Suffix ij gezognen Folgerungen ai j ⋹ bi j, ci j ⋹ di j auch für Suffixe in Anspruch genommen werden, die man etwa ih und hj zu nennen beliebt, die man irgendwie anders zu nennen vorzieht.
Diese Folgerungen sind wiederum allgemein, für irgend ein Suffix ij gezogen.
Man kann sie auch für jedes Suffix ij in Anspruch nehmen, was durch Voranschreiben des Zeichens Πi j vor diese alsdann in { } zu setzenden Konklusionen anzudeuten wäre.
Alsdann ist im Hinblick auf (14) gerechtfertigt, dass a; c ⋹ b; d, a ɟ c ⋹ b ɟ d ist, und haben wir somit die Behauptung von 1): R = (ac ⋹ bd)(a + c ⋹ b + d)(a; c ⋹ b; d)(a ɟ c ⋹ b ɟ d) mit allen ihren Teil-Behauptungen erwiesen, q. e. d.
Von den Beweisen der schon dem identischen Kalkul angehörigen Sätze wollen wir als vornehmstes Paradigma jetzt den
Beweis des Distributionsgesetzes a(b + c) = ab + ac — siehe unter 2) des § 6 — geben.
Nach den beiden Festsetzungen (10) ist einerseits {a(b + c)}i j = ai j(b + c)i j = ai j(bi j + ci j) und andrerseits: (ab + ac)i j = (ab)i j + (ac)i j = ai jbi j + ai jci j.
Für Relativkoeffizienten, die — wie Aussagen — nur der beiden Werte 1 und 0 fähig sind, steht aber die Gültigkeit des Distributionsgesetzes kraft des Abacus längst fest, d. h. wir haben: ai j(bi j + ci j) = ai jbi j + ai jci j, und somit ist auch erkannt dass: {a(b + c)}i j = (ab + ac)i j für ein beliebiges Suffix ij ist.
Da diese Konklusion für jedes Suffix ij in Anspruch genommen werden darf, was auch durch Umhüllen, Hineinsetzen ihrer Aussage zwischen die Zeichen Πi j[, und], ausgedrückt werden könnte, so folgt nunmehr nach dem Korollar zu (14), dass a(b + c) = ab + ac sein muss, was zu beweisen gewesen.
Wenn hiernach nicht blos die erste Subsumtion desselben, sondern sogleich das volle Distributionsgesetz sich hat beweisen lassen, so wird der einsichtsvolle Leser doch sofort erkennen, dass dies unserm früher (Bd. 1) vermittelst des „Gruppenkalkuls“ geführten „Beweise seiner Unbeweisbarkeit“ keinen Eintrag thut.
Die formalen Grundlagen, aus welchen der Beweis zu führen war, sind eben hier und dort (ganz) andere gewesen.
Was die formalen Grundlagen des Bd. 1 betrifft, denen nur unsre Festsetzung (1) auch als Def. (1) der Gleichheit angehörte, so mussten wir dort neben zwei „Prinzipien“ I und II auch noch zu einem „Prinzip“ III unsre Zuflucht nehmen, welches als ein partikularer Fall in dem vollen Distributionsgesetze enthalten war.
Von diesem letzteren Prinzip ist zunächst zu betonen, dass es mit Vorstehendem nun ebenfalls aus den Festsetzungen des § 3 „bewiesen“ ist.
Nimmt man jetzt noch die nach dem Abacus identisch geltenden Formeln oder Schemata des Aussagenkalkuls:
[Formel] , — bei deren zweitem und letztem Paare noch Festsetzung (6) mit anzurufen war — für jedes Suffix ij in Anspruch, indem man bei den drei sekundären von ihnen aussagenrechnerisch die verschiedenen Individualisirungen in denen sich die Formel für alle Suffixe verkörpert, überschiebend multiplizirt, so erhält man kraft Festsetzung (14) dieselben Schemata oder Formeln als für die binären Relative a, b, c selbst gültige — wir brauchen sie so nicht herzusetzen, weil sie sich aus den vorstehenden Schemata leicht ablesen lassen, indem man die Suffixe durchgängig weglässt.
0i j ⋹ ai j ai j⋹ 1i j,
(ci j ⋹ ai jbi j) = (ci j ⋹ ai j)(ci j ⋹ bi j)
(ai j + bi j ⋹ ci j) = (ai j ⋹ ci j)(bi j ⋹ ci j)
1i j ⋹ ai j + āi j ai jāi j⋹ 0i j
Damit sind dann auch die „Prinzipien“ I und II des Bd. 1 nebst den dortigen Definitionen (2), (3) und (6) — kurz: die gesamten formalen Grundlagen, aus welchen wir seinerzeit den identischen Kalkul entwickelten, streng deduktiv ableiteten, nunmehr aus unsern Festsetzungen des § 3 „bewiesen“.
Fortan dürfen wir also auch den identischen Kalkul selbst, mit einem jeden seiner Sätze, für unsre binären Relative legitim in Anspruch nehmen.
Ohne mich der geringsten Lücke schuldig zu machen, kann ich darum den Beweis jedes einzelnen Satzes, den wir aus dem identischen Kalkul hier benötigen werden, getrost dem Leser überlassen.
Nur darauf muss ich hervorhebend hinweisen, dass für jeden Satz in der That auch solch ein selbständiger unmittelbarer Beweis leicht zu führen ist, welcher indessen ganz anders aussieht, sich so sehr verschieden gestaltet von den in Bd. 1 für denselben Satz gelieferten Beweisen.
Die letzteren werden hier als „mittelbare“ zu bezeichnen sein.
Nachdem wir so den „Anschluss“ unsrer Theorie an die der vorhergehenden Bände gewonnen haben, wenden wir uns blos noch dem Beweise derjenigen Formeln zu, die auf die relativen Spezies mit Bezug haben oder der zweiten Hauptstufe angehören.
Zu dem Quadrupel der Formeln 4) des § 6 gebe ich erstmals alle vier verwandten Beweise.
Sie lauten: {a; (b + c)}i j = Σhai h(b + c)h j = Σhai h(bh j + ch j) = Σh(ai hbh j + ai hch j) = = Σhai hbh j + Σhai hch j = (a; b)i j + (a; c)i j = (a; b + a; c)i j und zwar — den vorstehenden Gleichheitszeichen der Reihe nach entsprechend — nach (12), (10), dem Distributionsgesetz für Koeffizienten, wegen der distributiven Kraft des Summenzeichens (die aus der Umstellbarkeit der Glieder einer Aussagensumme bei kolonnenweisem Summiren der in Zeilen gesetzten Glieder hervorgeht) und wiederum nach (12) und (10) in rückwärtiger Anwendung dieser (oben vorwärts angewendeten) Festsetzungen, q. e. d.
Analog hat man: {(a + b); c}i j = Σh(a + b)i hch j = Σh(ai h + bi h)ch j = Σh(ai hch j + bi hch j), (a; c + b; c)i j = (a; c)i j + (b; c)i j = Σhai hch j + Σhbi hch j; aber die rechten Seiten sind gleich, und folglich auch die linken, q. e. d. Ferner: (a ɟ bc)i j = Πh{ai h + (bc)h j} = Πh(ai h + bh jch j) = Πh(ai h + bh j)(ai h + ch j), {(a ɟ b)(a ɟ c)}i j = (a ɟ b)i j(a ɟ c)i j = Πh(ai h + bh j) · Πh(ai h + ch j), wo wieder die beiden Ausdrücke rechts und folglich auch die links übereinstimmen, q. e. d. Endlich:
(ab ɟ c)i j = Πh{(ab)i h + ch j} = Πh(ai hbi h + ch j) = Πh(ai h + ch j)(bi h + ch j) = = Πh(ai h + ch j) · Πh(bi h + ch j) = (a ɟ c)i j(b ɟ c)i j = {(a ɟ c)(b ɟ c)}i j, q. e. d.
Beweis zu 5) des § 6. Erste Formel.
Es ist Li j = (a; bc)i j = Σhai h(bc)h j = Σhai hbh jch j = Σhai hbh j · ai hch j, Ri j = (a; b · a; c)i j = (a; b)i j(a; c)i j = Σhai hbh j · Σkai kck j.
Offenbar ist nun Li j ⋹ Ri j, weil unter den Gliedern des expandirten Produktes der beiden letzten Summen die Glieder der darüberstehenden Summe sämtlich enthalten sind — nämlich als die Partialprodukte aus deren gleichstelligen Gliedern, jedoch neben noch vielen andern Gliedern, womit die Subsumtion erwiesen ist — q. e. d.
Zur zweiten Formel hätten wir:
Li j = (a ɟ b + a ɟ c)i j = (a ɟ b)i j + (a ɟ c)i j = Πh(ai h + bh j) + Πk(ai k + ck j) = = Πh k(ai h + bh j + ai k + ck j), letztres nach dem dualen Gegenstück des Distributionsgesetzes.
Dazu: Ri j = {a ɟ (b + c)}i j = Πh{ai h + (b + c)h j} = Πh(ai h + bh j + ch j) = = Πh(ai h + bh j + ai h + ch j) unter Anwendung des Tautologiegesetzes.
Die Vergleichung beider Ergebnisse zeigt, dass alle Faktoren von Ri j sich unter denen von Li j vorfinden, wo sie bei k = h zutage treten.
Nach dem Aussagenschema ab ⋹ a ist nun das faktorenreichere Produkt im andern enthalten, d. h. Li j ⋹ Ri j, q. e. d.
Übrigens bedarf man zum Beweise dieses Satzes der Berufung auf die Koeffizientenevidenz gar nicht.
Wegen bc ⋹ b hat man vielmehr nach 1) des § 6: a; bc ⋹ a; b, und wegen bc ⋹ c ähnlich: a; bc ⋹ a; c, welche beiden Ergebnisse zusammengefasst unsern Satz a; bc ⋹ a; b · a; c liefern.
Etc. q. e. d.
Beweis zu 6) des § 6. Erste Formel.
Es ist: Li j = {a; (b; c)}i j = Σhai h(b; c)h j = Σhai hΣkbh kck j = Σh kai hbh kck j, Ri j = {(a; b); c}i j = Σk(a; b)i kck j = Σk(Σhai hbh k)ck j = Σk hai hbh kck j.
Weil nun Σh k = Σk h, so ist also Li j = Ri j, q. e. d.
Zweite Formel: Li j = {a ɟ (b ɟ c)}i j = Πh{ai h + (b ɟ c)h j} = Πh{ai h + Πk(bh k + ck j)} = = Πh k(ai h + bh k + ck j), Ri j = {(a ɟ b) ɟ c}i j = Πk{(a ɟ b)i kck j} = Πk{Πh(ai h + bh k) + ck j} = = Πk h(ai h + bh k + ck j).
Weil aber Πk h = Πh k, so ist also Li j = Ri j, q. e. d.
Beweis zu 7) des § 6. Erste Formel.
Es ist: Li j = {a; (b ɟ c)}i j = Σhai h(b ɟ c)h j = Σhai hΠk(bh k + ck j) = ΣhΠkai h(bh k + ck j), Ri j = (a; b ɟ c)i j = Πk{(a; b)i k + ck j} = Πk{Σhai hbh k + ck j} = ΠkΣh(ai hbh k + ck j).
Dass man im zweitletzten Ausdrucke der oberen Zeile das Zeichen Πk vor den bezüglich dessen Zeigers konstanten Faktor ai h schieben konnte, ebenso dass im zweitletzten Ausdruck der unteren Zeile das Zeichen Σh erstreckt werden konnte über alles folgende mit Einschluss des bezüglich h konstanten Termes ck j, beruht auf den Tautologiegesetzen (des Aussagenkalkuls).
Bei Li j und Ri j stimmen nun die allgemeinen Terme hinter den Σ- und Π-zeichen nicht überein, und ausserdem ist die Ordnung der Σ, Π in beiden Ergebnissen die entgegengesetzte.
Von dem allgemeinen Term bei L ist aber leicht zu zeigen, dass er eingeordnet ist demjenigen bei R, indem: ai h(bh k + ck j) = ai hbh k + ai hck j ⋹ ai hbh k + ck j wegen ai hck j ⋹ ck j sein muss.
Es muss hienach jedenfalls sein:
Li j⋹ΣhΠk(ai hbh k + ck j), wo nun rechts der allgemeine Term mit demjenigen bei Ri j sich deckt und der Unterschied nur noch in der Reihenfolge der Σ, Π besteht.
Nach jenem (minder geläufigen) Schema: ΣhΠk ⋹ ΠkΣh des Aussagenkalkuls, welches wir weiter unten S. 112 gesondert rechtfertigen, wird nun a fortiori erkannt sein, dass Li j ⋹ Ri j, q. e. d.
Ebenso haben wir zur zweiten Formel 7): Li j = {(a ɟ b); c}i j = ΣkΠh(ai h + bh k)ck j ⋹ ΣkΠh(ai h + bh kck j), Ri j = (a ɟ b; c)i j = ΠhΣk(ai h + bh kck j), also nach demselben Schema Li j ⋹ Ri j, q. e. d.
Behufs Beweises der drei Formeln 8) des § 6 S. 83 müssen wir uns auf die Festsetzungen (11) und (13) S. 29 berufen.
Erste Formel.
Macht man der Deutlichkeit zuliebe ausgiebigen Gebrauch von Klammern, so bedeutet: ā̄ = (ā)͞, somit ā̄i j = (ā̄)i j = [(ā)͞]i j.
Dies ist aber nach (11):
[Formel] .
Dass nun bei Koeffizienten oder Aussagen die doppelte Verneinung sich aufhebt, darauf dürfen wir uns schon längst berufen; es ist also (ai j)͞͞ = ai j und damit ist auch gezeigt, dass ā̄i j = ai j, das heisst ā̄ = a ist, in Anbetracht dass die Gleichheit der Relative auf die Übereinstimmung ihres allgemeinen Koeffizienten hinausläuft — q. e. d.
Bei der zweiten Formel 8) bedeutet: ă̄ = (ă)͞ und ā̆ = (ā)͝ Nach (11) und (13) wird aber: ă̄i j = [(ă)͞]i j = {(ă)i j}͞ = {aj i}͞ = (ā)j i = āj i und ā̆i j = [(ā)͝]i j = (ā)j i = āj i (wo der letzte Ausdruck nur eine Namensabkürzung des vorletzten ist), somit allgemein ă̄i j = ā̆i j und damit auch ă̄ = ā̆, wie zu beweisen war.
Die dritte Formel 8) betreffend ist zu bedenken, dass ă̆ = (ă)͝ bedeutet, somit: ă̆i j = [(ă)͝]i j = (ă)j i = ai j nach (13) sein muss, indem sich durch die zweimal hintereinander vollzogene Vertauschung der beiden Indizes im Suffixe deren ursprüngliche Ordnung wiederherstellt — q. e. d.
Wer das Bedürfniss empfindet, sich das Verständniss noch mehr zu erleichtern, der möge hier einfachere Namen, wie b für ā und c für ă, ad hoc — für den Augenblick — einführen.
Beweise von 9) des § 6: [Formel] , [Formel] nach den Festsetzungen und De Morgan’s für Aussagen und Koeffizienten bereits sicher gestellten Theoremen.
Beweise der Formeln 10) des § 6 — ebenso:
[Formel] , [Formel] .
Beweise von 11) des § 6 — S. 85: (ab͝)i j = (ab)j i = aj ibj i = bj iaj i = b̆i jăi j = (b̆ă)i j, (a + b͝)i j = (a + b)j i = aj i + bj i = bj i + aj i = b̆i j + ăi j = (b̆ + ă)i j.
Beweise von 12) des § 6: (a; b͝)i j = (a; b)j i = Σhaj hbh i = Σhbh iaj h = Σhb̆i hăh j = (b̆; ă)i j, (a ɟ b͝)i j = (a ɟ b)j i = Πh(aj h + bh i) = Πh(bh i + aj h) = Πh(b̆i h + ăh j) = (b̆ ɟ ă)i j.
Behufs Beweises der Formeln 13) des § 6 — S. 87 — ist unmittelbar nur zu zeigen dass: (a ⋹ b) = (b̄ ⋹ ā) sowie (a ⋹ b) = (ă ⋹ b̆) ist.
Ersteres folgt, weil wir die Kontraposition mit Aussagen- oder Koeffizientensubsumtionen vorzunehmen bereits berechtigt sind, im Hinblick auf (14) leicht so: (a ⋹ b) = Πi j(ai j ⋹ bi j) = Πi j[(bi j)͞ ⋹ (ai j)͞] = Πi j(b̄i j ⋹ āi j) = (b̄ ⋹ ā).
Letzteres, weil Vertauschung der Produktzeiger gestattet ist, so: (a ⋹ b) = Πi j(ai j ⋹ bi j) = Πj i(ai j ⋹ bi j) = Πi j(aj i ⋹ bj i) = = Πi j(ăi j ⋹ b̆i j) = (ă ⋹ b̆).
Aus den beiden hiermit bewiesenen Sätzen folgt nun die letzte oder dritte Formel 13): (a ⋹ b) = (b̄̆ ⋹ ā̆) bequemer mittelbar durch deren „kombinirte“ Anwendung — das soll hier heissen: durch deren successive Anwendung in irgend einer Folge.
Nachdem mit diesen Sätzen nunmehr die Prinzipien des Dualismus und der Konjugation, die wir im vorigen Paragraphen auseinandergesetzt haben, vollends erhärtet sind, werden wir künftig von jedem Quadrupel „verwandter“ Formeln nur mehr eine einzige — zumeist die erste — beweisen (auf deren linke und rechte Seite dann also die Symbole L und R bezugnehmen sollen) — es sei denn, dass bei dem Beweise ganz neue Schemata des Aussagenkalkuls in Betracht kämen, die wir insgesamt sichtbar zu machen wünschen.
Ebenso werden wir auch bei verwickelteren Untersuchungen von jeder Tetrade von „verwandten Problemen“ immer nur eines wirklich zu lösen brauchen, das wir den Repräsentanten des Quadrupels oder „Gespannes“ nennen mögen.
Zur Sicherung einer Priorität der Entdeckung eines Sätzequadrupels würde auch schon die Mitteilung eines einzigen von den vier Sätzen genügen und die Aufführung der übrigen als ein Luxus, eine Raumverschwendung erscheinen.
Die Drucklegung aller viere, wie sie hier meistens doch verwirklicht wird, rechtfertigt sich aber aus den Bedürfnissen der Anwendung der Sätze, des Nachschlagens, bei den Verweisungen auf dieselben, etc.
In Fällen des Zweifels, ob Anwendung aller schon hier erfolgen wird, thun wir auch lieber etwas zu viel als wie zu wenig.
Und ferner werden wir fortan den allgemeinen Koeffizienten eines (wenn auch noch so verwickelten) vermittelst der 6 Spezies aus lauter Relativen zusammengesetzten Ausdruckes zumeist fertig „entwickelt“ oder ausgerechnet“ hinsetzen ohne so, wie es im Vorstehenden noch vorbildlich geschah, die Schritte einzeln darzulegen, welche zu dessen Herstellung gemäss den Vorschriften (10) bis (13) auszuführen waren.
Der allgemeine Koeffizient eines Ausdrucks wäre zur Not schon ausgerechnet zu nennen, wenn er als eine „Aussagenfunktion“ („Funktion im Sinne des Aussagenkalkuls) dargestellt ist von den Koeffizienten der „einfachen“ Symbole (cf. S. 85) die (als Elemente oder Komponenten im weiteren Sinne, als Argumente, Operationsglieder, Terme) in den Ausdruck eingehen, das heisst also:
wenn er aus letzteren nur durch die drei identischen Spezies aufgebaut ist — während im Ausdrucke selbst ja alle 6 Spezies zur Verwendung kommen mochten.
Da aber die beiden nicht knüpfenden Spezies schon im Ausdrucke selbst sich stets „ausführen“ liessen, so werden wir an den „ausgerechneten“ Koeffizienten die fernere Anforderung stellen dürfen, dass er blos mittelst identischer Knüpfungen (der Multiplikation und Addition) aus den Koeffizienten seiner „einfachen“ Terme sich zusammensetze.
Und wo Moduln in Betracht kommen werden, behalten wir uns vor, diese Anforderungen noch weiter zu steigern.
Die Kunst, den allgemeinen Koeffizienten eines zusammengesetzten Relativs „auszurechnen“ muss der Studirende sich aneignen.
Man gelangt bei einiger Übung bald dahin, denselben schon mit dem ersten Ansatze fertig hinzustellen, indem man zugleich — wozu noch nähere Anleitung zu geben sein wird — die sämtlichen Σ und Π-zeichen mit den zugehörigen Zeigern in der gehörigen Reihenfolge nach links vor den verbleibenden (von allen Σ und Π befreiten) Koeffizientenausdruck schiebt.
Die entgegengesetzte Kunst, die umgekehrte Aufgabe: eine Aussagenfunktion von Koeffizienten „einfacher“ Relativsymbole als den allgemeinen Koeffizienten eines aus letztern Relativen zusammengesetzten Ausdruckes oder Relativs darzustellen, ist — sofern lösbar — im Allgemeinen etwas schwieriger zu lösen resp. zu erlernen.
Um nun auch noch von 14) des § 6 die erste Formel zu beweisen, bemerke man, dass: Li j = (ab)i j = ai jbi j, Ri j = (a; c + b; c̄)i j = Σh(ai hch j + bi hc̄h j).
Letztre Summe enthält den beim Werte h = j des Zeigers sich ergebenden Term: ai jcj j + bi jc̄j j und dass Li j schon diesem eingeordnet ist, um so mehr also der ganzen Summe Ri j, lässt sich nachweisen aus der dem identischen Kalkul angehörigen (somit nicht blos für Aussagen, sondern sogar für Klassen gültigen) Formel: ab⋹ab + ac + bc̄ = (a + ab)c + (b + ab)c̄ = ac + bc̄ wenn man darin dem a und b durchweg das Suffix ij, dem c und c̄ das Suffix jj zuteilt, q. e. d.
Beweis von 15) des § 6, erste Formel.
Es ist Li j = {a; b · (ā ɟ c)}i j = ΣhΠkai hbh j(āi k + ck j), Ri j = (a; bc)i j = Σhai hbh jch j.
Das Produkt Πk in Li j enthält den bei k = h sich ergebenden Faktor: ai hbh j(āi h + ch j) = ai hbh jch j.
Dasselbe ist demnach, weil zu letzterm noch mehr Faktoren hinzutreten — nach dem Schema ab ⋹ a des Aussagenkalkuls — eingeordnet diesem Faktor, womit erkannt ist, dass das allgemeine Glied der Σh welche Li j vorstellt, eingeordnet ist dem allgemeinen Gliede der Σh welche Ri j vorstellt.
Diese Beziehung überträgt sich von den allgemeinen Gliedern auf die Summen derselben, d. h. es ist Li j ⋹ Ri j, q. e. d.
Da wir fortan äusserst viel werden zu thun haben mit Summen und Produkten, in symbolischer Abkürzung dargestellt vermittest der Σ und Π-zeichen, wobei der allgemeine Term ein Aussagensymbol ist, das einen doppelten Index führt, so verlohnt es, auf die wichtigsten Gesichtspunkte nochmals zurückzukommen, nach denen hiebei mit den Zeichen Σ, Π zu operiren ist, obwol sich das meiste schon im § 3, aus Bd. 2 rekapitulirt und durch weitre Hülfssätze ergänzt, findet.
Hierbei wollen wir (was nicht unumgänglich und vergl. S. 38 streng genommen zu vermeiden wäre) — aus didaktischen Gründen — auch auf die gewöhnliche Schreibung des Π und Σ als eines „expliziten“ vieltermigen Produkts oder Aggregates (ohne Π und Σ-zeichen), vorwiegend Rücksicht nehmen.
Nennen wir ah k gedachten allgemeinen Term! Lässt man in ihm die laufenden Zeiger (Summations- oder Produktationsvariablen) h und k je eine aparte Reihe, eventuell Sequenz, von Werten durchlaufen und schreibt die Werte des gedachten Terms geordnet hin, so erhält man ein jetzt nicht notwendig quadratisches, vielmehr mit Sicherheit nur rechteckiges Schema, eine Matrix, und zwar: a11, a12, a13, a14, … a21, a22, a23, a24, … a31, a32, a33, a34, … . . . . . . . . falls wir etwa hier jene Wertreihen durch Ziffern repräsentiren.
Dass nun hierbei sowohl Summenzeichen unter sich als auch Produktzeichen unter sich beliebig umgestellt werden dürfen, und dass ihrer mehrere in ein einziges derselben Art zusammengezogen, resp. aus letzterem (wieder) abgesondert werden mögen, dies sprechen für den einfachsten Fall (den wo nur zwei Zeichen in Betracht kommen) die Schemata aus: 1) .
Das ist aber in der That durch den kommutativen und assoziativen Charakter der identischen Multiplikation resp. Addition garantirt.
Für die selbständig definirten Aussagen Π und Σ folgt es ohne weitres nach dem „dictum de omni, et“ — möchten wir hinzufügen — de aliquo“ oder „ullo“.
Was von jedem Paare h, k gilt, das gilt bei jedem h für jedes k und gilt auch bei jedem k für jedes h — und umgekehrt.
Desgleichen:
Was für ein gewisses Paar h, k gilt, das gilt auch bei einem gewissen h für ein gewisses k, und bei einem gewissen k für ein gewissen h, sowie umgekehrt.
[Nämlich: was bei einem gewissen h für gewisses k gilt, das gilt auch für ein gewisses Paar h, k. Etc.]
Lassen wir z. B. h die Werte von 1 bis n, k die von 1 bis m durchlaufen, so stellt das erste der drei vorstehenden „Doppel“-Produkte vor: das Ergebniss einer multiplikativen Verknüpfung, bei welcher zuerst die Elemente einer jeden Zeile unsrer Matrix (bis zum mten einschliesslich) zu einem Teilprodukte vereinigt, hernach diese Produkte aus den n ersten Zeilen miteinander multiplizirt werden, wogegen das zweite Doppelprodukt bedeutet: das Knüpfungsergebniss, wenn zuerst die Elemente einer jeden Kolonne (bis inclusive zum nten) zu einem Teilprodukte vereinigt, sodann diese Produkte aus den m ersten Kolonnen miteinander multiplizirt werden.
Das erste Doppelprodukt also fordert „zeilenweises“, das zweite „kolonnenweises“ Multipliziren.
Dass dies so und nicht umgekehrt der Fall ist, liegt daran, dass die Π oder Σ-zeichen jeweils in der entgegengesetzten Ordnung „evaluirt“, ausgewertet (in die ausführliche Schreibung umgedeutet) werden müssen, als die ist, in der sie dem von links nach rechts lesenden Auge sich darbieten.
Das zweite oder innere Zeichen muss allemal zuerst interpretirt werden; denn der mit ihm gebildete Ausdruck bildet den allgemeinen Term zu dem vorhergehenden, ersten oder äusseren Zeichen, und (nach dem Grundsatze:
Die Nürnberger hängen keinen, sie hätten ihn denn zuvor) muss man diesen Term erst haben, bevor man ihn produktiren oder summiren kann.
So ist in der That:
[Formel] Etc.
Die Umstellung der beiden Π-zeichen bewirkt also weiter nichts als eine Vertauschung von Zeilen und Kolonnen (Horizontal- und Vertikalreihen) in unsrer Matrix.
In dem dritten Produkte 1), welches wegen der unter das Π geschriebenen beiden laufenden Buchstaben h, k erst recht ein Doppelprodukt zu nennen ist (obwol man nur ein Π-zeichen in ihm erblickt) darf man diesen Buchstaben die ihnen bezüglich zukommenden Werte in beliebiger Zusammenstellung und Reihenfolge beigelegt denken, so jedoch, dass ausschliesslich jeder von den vorgeschriebenen Werten des h mit jedem von den gegebenen Werten des k (mindestens) einmal kombinirt wird (Wiederholungen sind als überflüssig im allgemeinen zu vermeiden, schaden jedoch der Tautologiegesetze halber — im identischen Kalkul wenigstens — nichts); es hat also — kann man sagen — das Indizespaar h, k ein bestimmtes System von Wertepaaren zu durchlaufen.
Von den Summen gilt mutatis mutandis dasselbe, was wir soeben bei den Produkten zur Sprache brachten.
Was nun aber die Verbindung von Summen- mit Produktenzeichen betrifft, so ist höchst bemerkenswert, dass hier nur die beiden im Grunde auf einen hinauslaufenden Sätze gelten: 2)
[Formel] — vergl. ο) des § 3 — deren zweiter aus dem ersten hervorgeht, indem man die Namen der beiden Variabeln h und k mit einander vertauscht, nachdem man den Namen ah k durch den ak h ersetzt hatte.
(Peirce8 p. 197.)
Es genügt demnach, die erste von diesen Formeln zu beweisen.
(Dieselbe gilt schon im identischen Kalkul, was auch immer für Klassen die Symbole ah k vorstellen mögen.)
Interpretirt man beide Seiten dieser Subsumtion, so stellt sich dieselbe dar als: a11a12a13a14 ‥ + a21a22a23a24 ‥ + a31a32a33a34 ‥ + … ⋹ ⋹ (a11 + a21 + a31 ‥) (a12 + a22 + a32 ‥) (a13 + a23 + a33 ‥)(a14 + a24 + a34 ‥) … und versteht sich nach Th. 6+) des Bd. 1 daraus von selbst:
weil die Glieder des Subjektes links sämtlich unter denen der ausmultiplizirten Summen rechterhand im Prädikate vorkommen werden, und zwar als die Partialprodukte aus deren gleichstelligen Gliedern — allerdings aber neben noch sehr viel anderweiten Gliedern, weshalb im Allgemeinen Unterordnung und nicht Gleichheit stattfinden wird.
Noch etwas einfacher, vielleicht, kann man den Satz so darstellen: aa'a'' ‥ + bb'b'' ‥ + … ⋹ (a + b + …)(a' + b' + …)(a'' + b'' + …) ‥
Derselbe mit ￼ statt ⋹ würde auch für positive Zahlen bezüglich arithmetischer Produkte und Summen gelten.
Man merkt sich den Satz am besten durch den Kontrast: während für sich Π ⋹ Σ ist, gilt sozusagen verkehrt: ΣΠ ⋹ ΠΣ. —
Zwei besonders wichtige Fälle verdienen aber noch Hervorhebung, in welchen die Subsumtionen in unserm Satze in Gleichungen übergehen, und auf deren einen schon Peirce aufmerksam gemacht.
Es sind das die Fälle, in welchen der allgemeine Term ah k (additiv oder multiplikativ) zerfällt in zwei Terme, welche die Indizes h und k einzeln — somit getrennt, voneinander isolirt — tragen; die Fälle ah k = ahbk und ah k = ah + bk.
Hier gelten die Sätze: 3)
[Formel] das ist ausführlich hingeschrieben: a1b1a1b2a1b3 ‥ + a2b1a2b2a2b3 ‥ + … = = (a1b1 + a2b1 + a3b1 + …)(a1b2 + a2b2 + a3b2 + …) ‥ = = (a1 + a2 + …)b1b2b3 …, (a1 + b1)(a1 + b2)(a1 + b3) ‥ + (a2 + b1)(a2 + b2)(a2 + b3) ‥ + … = = (a1 + b1 + a2 + b1 + …)(a1 + b2 + a2 + b2 + …)(a1 + b3 + a2 + b3 + …) ‥ = = a1 + a2 + … + b1b2b3 ‥, wie ersichtlich.
Der Beweis kann aber auch ganz in Summen- und Produktzeichen geführt werden auf Grund der Tautologiegesetze und des Distributionsgesetzes nebst dualem Gegenstück, wie folgt: Wir haben:
[Formel] weil sich konstante Faktoren vorschieben lassen.
Ebenso: [Formel] , q. e d.
Das andre dual entsprechend.
Hier bietet sich als ein interessantes Problem die Frage dar: welches ist die allgemeinste Funktion identischen Kalkuls: ah k = f(ah, bk) derart, dass die Subsumtionen 2) als Gleichungen bestehen?
Dieselbe muss Produkt und Summe unter sich begreifen.
Unter denselben Annahmen bezüglich ah k verdient auch noch Beachtung, dass die vorhergehenden Formeln 1) der Zusätze fähig sind: 4)
[Formel] die sich der Leser leicht aus den Tautologiegesetzen (erster und vierter) resp. aus der Multiplikationsregel für Polynome (zweiter) und deren dualem Gegenstück (dritter) beweisen wird.
Von diesen Formeln gestattet aber die erste und die letzte noch eine weitere Vereinfachung sobald h und k die nämliche Erstreckung haben:
dann lässt sich auch der eine der beiden Zeigerbuchstaben — gleichviel welcher — mitsamt dem zugehörigen Σ oder Π-zeichen noch obendrein ersparen, indem wir haben: 5) — in der That z. B. rechts vom Striche:
[Formel] .
Unter derselben Voraussetzung gilt dagegen zu 3) blos als Einordnung: 6) nämlich in extenso z. B.: a1a2a3 … (b1 + b2 + b3 + …) ⋹ a1b1 + a2b2 + a3b3 + … (a1 + b1)(a2 + b2)(a3 + b3) … ⋹ a1 + a2 + a3 + … + b1b2b3 … wie unschwer zu sehen (Peirce9c p. 202). —
Ebenso müssten die Schemata 1) bis 6) sämtlich ihre Gültigkeit behalten, wenn unter dem allgemeinen Terme ah k statt eines Relativkoeffizienten oder einer Aussage, vielmehr ein System (Gebiet) oder eine Klasse, ja selbst ein Relativ verstanden würde.
Mit dem in dieser Vorlesung gesicherten Erkenntnisskapital von Sätzen lässt sich, wie wir sehen werden, schon ziemlich viel in der Theorie erreichen. —
Sollten die Variabeln h, k anstatt der Ziffern 1, 2, 3, … irgend welche Buchstabenwerte A, B, C, … zu durchlaufen haben, so ändert das nichts an der Gültigkeit der Sätze und der Triftigkeit der für sie gegebenen Beweise.
Was schliesslich den Beweis für die noch eine Weile entbehrlichen Sätze 17) bis 31) des § 6 betrifft, welche von den Π und Σ binärer Relative handeln, so wollen wir nur ein paar Paradigmata als Vorbilder bringen, wonach der vorgerücktere Leser, wenn die Sätze endlich zur Verwendung kommen, sich deren etwa noch ausständige Beweise leicht selbst konstruiren wird.
Zunächst ist zu erinnern, dass wie immer der Erstreckungsbereich gegeben sein mag, nach Festsetzung (15) die Ausdrücke Πa und Σa als binäre Relative definirt zu denken sind durch die für jedes ij ihre Koeffizienten erklärenden Ansätze: (15)
(Πa)i j = Πai j (Σa)i j = Σai j.
Da nun nach dem Aussagenschema α) des § 3: Πai j ⋹ ai j ist, so folgt auch allgemein (Πa)i j ⋹ ai j und haben wir im Hinblick auf (14) damit den Beweis von 18) Πa ⋹ a.
Ebenso geben die Überlegungen:
[Formel] , [Formel] — unter Berufung auf (11) vorwärts, (15) links, γ) des § 3, (11) rückwärts und (15) rechts, resp. auf (13) vorwärts, (15) links, (13) rückwärts und (15) links — den Beweis zu 19) und 20) des § 6 (links vom Mittelstriche).
Beweis zu 21).
Nach (14), 1) des § 7, ζ) des § 3, 1) des § 7, δ) des § 3, (15) und (14) ist:
[Formel] .
Beweis zu 29) erste Formel:
[Formel] , nach (12), (15), λ) des § 3, 1) des § 7, (12) und (15).
Beweis zu 30) erste Formel:
[Formel] nach (12), (15), ν) des § 3, ο) des § 3, (12) und (15).
Diese Beispiele von Beweisführung werden ohne Zweifel mehr als ausreichend sein.
Vierte Vorlesung.
Einfachste Sätze von speziellerem Charakter in der Algebra der binären Relative. Modulknüpfungen.
§ 8.
Noch einige weitre Grundformeln.
Die reduziblen primären Modulknüpfungen.
Der Abacus vervollständigt.
Produktdarstellung der Relative.
Als spezielle Relative traten in unsrer Algebra die vier Moduln 1, 0, 1', 0' in erster Linie hervor.
An Formeln und Sätzen, in welche neben allgemeinen binären Relativen auch Relative von spezieller Natur — wie Moduln — eingehen, ist unsre Disziplin ganz unvergleichlich viel reicher, wie an nur Buchstaben führenden Gesetzen.
Man kann kaum irgend eine Untersuchung anstellen ohne jener eine Menge zu entdecken, und es hält schwer auch nur die wichtigsten derselben in der Theorie einigermassen unterzubringen.
Bei Versuchen, die schwierigen Aufgaben zur Lösung zu bringen, welche die Theorie stellen wird, ist man jedoch (wie bereits erwähnt) gelegentlich froh um eine jede Formel die es gelungen ist sicher zu stellen.
Trotz ihrer ungeheuren Fülle müssen wir darum eine gewisse Vollständigkeit der Formelaufstellungen zu erreichen wenigstens bestrebt sein.
Vorangestellt seien die schon dem identischen Kalkul angehörigen Sätze: 1) mit welchen zugleich auch gegeben ist: — was jedoch keinen neuen Satz vorstellt, sondern weiter nichts als die Anwendung des vorigen auf das Relativ ă (statt a) ist.
1 ⋹ a + ā aā⋹ 0
1 ⋹ ă + ā̆ ăā̆⋹ 0
Zu diesen altbekannten Sätzen treten nun für die relativen Moduln — in entfernter Analogie — noch auf der ersten Hauptstufe diese beiden hinzu: 2) womit begreiflich auch gegeben ist.
1' ⋹ a + ā̆ aā̆⋹ 0'
1' ⋹ ā + ă āă⋹ 0'
Die beiden untereinanderstehenden Formen des Satzes 2) lassen nebenbei sich auch zusammenfassen zu: oder: Korollar zu 2):
1' ⋹ (a + ā̆)(ā + ă) aā̆ + āă ⋹ 0',
1' ⋹ aă + āā̆ (a + ă)(ā + ā̆) ⋹ 0'.
Merkwürdiger Weise aber besitzen die Sätze 1) auf der zweiten Hauptstufe auch folgende strikte Analoga, welche schon Peirce entdeckte: 3) — womit zugleich auch gegeben ist: wie man durch Vertauschung von a mit einem seiner drei verwandten Relative, welche der Allgemeingültigkeit von 3) halber gestattet sein muss, unschwer erkennt.
1' ⋹ a ɟ ā̆ a; ā̆ ⋹ 0'
1' ⋹ ā̆ ɟ a ā̆; a ⋹ 0'
1' ⋹ ā ɟ ă ā; ă ⋹ 0'
1' ⋹ ă ɟ ā ă; ā ⋹ 0'
Bei Beachtung aller erwähnten nähern und fernern Analogien werden die Formeln insgesamt leicht zu behalten sein.
Natürlich kann man auch die verschiednen Formen des Satzes 3) zusammenfassen zu dem Theorme:
Korollar zu 3): worin von den Termen (Faktoren, Summanden) irgendwelche unterdrückbar.
Auch wäre hievon mit den beiden Formen von Satz 2) noch weitere Zusammenfassung thunlich.
1' ⋹ (a ɟ ā̆)(ā̆ ɟ a)(ā ɟ ă)(ă ɟ ā) a; ā̆ + ā̆; a + ā; ă + ă; ā ⋹ 0'
Behufs Beweises von 2) ist blos die Gültigkeit der Koeffizientensubsumtionen: allgemein — für jedes Suffix ij darzuthun.
1'i j ⋹ ai j + āj i ai jāj i⋹ 0'i j
Ist nun i ≠ j, so ist in der ersten Subsumtion das Subjekt = 0, in der zweiten das Prädikat = 1, mithin dieselbe allemal ohnehin erfüllt.
Ist dagegen i = j, so kommen unsre Behauptungen auf diese hinaus: welche nach den den Sätzen 1) entsprechenden Schemata des Aussagenkalkuls gelten müssen, q. e. d.
1'i i = 1 ⋹ ai i + āi i ai iāi i⋹ 0 = 0'i i,
Behufs Beweises von 3) ist blos erforderlich, dass man sich von der Gültigkeit der Koeffizientensubsumtionen: für jedes Suffix ij überzeuge.
Hierbei sind wieder die Fälle i = j und i ≠ j zu unterscheiden.
1'i j ⋹ Πh(ai h + āj h) Σhai hāj h⋹ 0'i j
Im ersten Falle ist 1'i j = 1'i i = 1 und 0'i j = 0'i i = 0 und haben wir in der That: weil jeder Faktor des Produkts = 1 und jedes Glied der Summe = 0 ist.
1 = Πh(ai h + āi h) Σhai hāi h = 0,
Im zweiten Falle ist 1'i j = 0 und 0'i j = 1 und müssen die Subsumtionen als solche die das Subjekt 0 oder das Prädikat 1 haben, ohnehin gelten — q. e. d.
Wegen des Dualismus zwischen den beiden Formeln 2), 3) war eigentlich nur je die eine derselben zu beweisen nötig.
Während nun aber mit Rücksicht auf die Schemata identischen Kalkuls: 4) die beiden Subsumtionen 1) auch als Gleichungen angesetzt werden dürfen, wird zu merken sein, dass bei den Subsumtionen 2) und 3) solches nicht der Fall ist — weil eben die Schemata 4) kein Analogon auf der zweiten Hauptstufe besitzen.
(1 ⋹ a) = (1 = a) (a ⋹ 0) = (a = 0)
Ebensowenig gibt es auch zu diesen Sätzen des identischen Kalkuls: 5) ein Analogon bei den relativen Operationen, wogegen wir zu den hochwichtigen und schon bekannten Sätzen: 6)
(1 ⋹ ā + b) = (a ⋹ b) = (ab̄ ⋹ 0) entsprechende auf der höhern Hauptstufe noch am Schlusse dieses Paragraphen kennen lernen werden.
Endlich zu diesen Formeln: 7)
[Formel] dürfte es Analoga auf der höhern Stufe schwerlich geben.
(1 = ab) = (1 = a)(1 = b) (a + b = 0) = (a = 0)(b = 0)
Die aufgeworfene Frage nach etwaigen Analogieen der Sätze erster Hauptstufe auf der zweiten mag eventuell als Anregung zu weitern Forschungen dienen.
Es war uns dabei weniger um deren endgültige Beantwortung zu thun als vielmehr darum, die Sätze 1) bis 7), die noch zu den Grundformeln der Theorie zu zählen sind, an gegenwärtiger Stelle, wo sie hingehören, wenigstens einmal aufgezählt zu haben, sodann das Behalten neu hinzukommender Sätze zu erleichtern.
Wer die Sätze, soweit sie der ersten Hauptstufe, dem identischen Kalkul angehören, in Zusammenhang mit der früheren Gestaltung von dessen Theorie gebracht sehen will, wird keine Schwierigkeit finden, die vormaligen Chiffren dieser Sätze aus unsrer in Bd. 2, S. 28 ‥ 34 gegebnen Übersicht derselben beizubringen.
Ungemein wichtig sind nun noch die Sätze, welche die Ergebnisse der Verknüpfung eines allgemeinen Relativs a mit Moduln vermittelst der vier knüpfenden unter den sechs Spezies betreffen.
Ich will solche kurz als „Modulknüpfungen“ bezeichnen.
Ein Relativ a kann successive mit eventuell verschiedenen Moduln verknüpft werden, und je nach der Zahl der Knüpfungen unterscheiden wir primäre, sekundäre, tertiäre, quartäre, quintäre etc.
Modulknüpfungen von a.
Durch eine von den 4 knüpfenden Spezies mit einem von den 4 Moduln in einer der beiden möglichen Reihenfolgen a verknüpfend erhalten wir 4 × 4 × 2 = 32 primäre Modulknüpfungen von a, und zwar 16 identische und 16 relative je nachdem die knüpfende Spezies der ersten oder der zweiten Hauptstufe angehört.
Ein Teil — gerade die Hälfte — von diesen 32 primären Modulknüpfungen ist „reduzibel“, vereinfacht sich nämlich sei es zu a selbst, sei es zu einem Modulwerte.
Die übrigen von den Modulknüpfungen des a sind „irreduzibel“ zu nennen und stellen eigenartige Relative vor, die zu a in gewissen Beziehungen stehen oder aus a in bestimmt gesetzmässiger Weise sich ableiten.
Über jene, die 16 reduzibeln primären Modulknüpfungen, geben die Formeln Aufschluss und Übersicht — für die erste Hauptstufe: 8) 9) und analog für die zweite Hauptstufe: 10) 11)
0 · a = 0 = a · 0 1 + a = 1 = a + 1
a · 1 = a = 1 · a a + 0 = a = 0 + a
0; a = 0 = a; 0 1 ɟ a = 1 = a ɟ 1
a; 1' = a = 1'; a a ɟ 0' = a = 0' ɟ a.
Den irreduziblen werden wir einen besondern Abschnitt widmen.
Von vorstehenden Formeln, deren acht erste 8), 9) schon aus dem identischen Kalkul bekannt sind, rechtfertigen es die 9) und 11), zu nennen: insofern in jedem Falle die angeführte Operation mit dem zugehörigen Modul nichts ändert.
Dies ist gewiss leicht zu merken und man muss es sich fest einprägen.
1 den Modul der identischen Multiplikation 0 den Modul der identischen Addition
1' den Modul der relativen Multiplikation 0' den Modul der relativen Addition
Wenn man sich jetzt noch hinzu merkt, dass auch ein relatives Produkt verschwindet, sobald ein Faktor desselben 0 ist, und auch eine relative Summe gleich 1 wird, sobald ein Term diesen Wert annimmt, so wird man — was unerlässlich — die vorstehenden Sätze bald fest inne haben.
Der Zusammenziehung zuliebe haben wir in 8) bis 11) die konjugirten Gleichungen neben statt untereinander geschrieben.
An Beweisen ist zu liefern zu 10): (0; a)i j = Σh0i hah j = Σh0 ah j = Σh0 = 0 = 0i j.
Zu 11): (a; 1')i j = Σhai h1'h j = ah j, (a ɟ 0')i j = Πh(ai h + 0'h j) = ai j, (1'; a)i j = Σh1'i hah j = ai j, (0' ɟ a)i j = Πh(0'i h + ah j) = ai j.
Der letzte Beweis legt uns eine sehr wichtige allgemeine Bemerkung nahe.
Man merke, dass eine Summe 12×) Σh1'h kf(h) = f(k) = Σhf(h)1'k h in deren allgemeinem Gliede ein Koeffizient des Moduls 1' als (veränderlicher) Faktor auftritt, sich immer nach dem vorstehenden Schema reduzirt zu einem einzigen ihrer Glieder nämlich demjenigen, welches man erhält, indem man im allgemeinen Gliede die Summationsvariable ersetzt durch den Ko-Index, andern Zeiger, welcher mit ihr zusammen das Suffix von 1' ausmacht.
Dualentsprechend reduzirt sich auch ein Produkt, in dessen allgemeinem Faktor ein Koeffizient von 0' als variabler Summand enthalten ist, nach dem Schema: 12+) Πh{0'h k + f(h)} = f(k) = Πh{f(h) + 0'k h} zu einem einzigen und zwar demjenigen seiner Faktoren, in welchem die Produktationsvariable ihren Mitzeiger im Suffix von 0' zum Werte hat.
Der Beweis dieser Bemerkungen liegt darin, dass nach (7): [Formel] ist.
Es verschwinden mithin alle Glieder unsrer Summe ausser demjenigen in welchem h = k ist. Ebenso werden alle Faktoren unsres Produktes gleich 1, kommen mithin nicht zur Geltung oder sind zu unterdrücken, ausser demjenigen, wo h den Wert k annimmt.
Solche Faktoren eines Produktes, welche notwendig den Wert 1 haben, werden wir häufig nichtssagende, belanglose, unwirksame oder ineffektive nennen im Gegensatz zu den andern als den wirksamen oder effektiven Faktoren.
Es ist hier der Ort, die einfachsten Formeln der Algebra der Relative anzureihen — welche die Ergebnisse der 6 Spezies an Moduln betreffen.
Inbezug auf diese Operationen bilden die vier Moduln 1, 0, 1', 0' eine „Gruppe“.
Zunächst ist 13) [Formel] Es lassen hiernach die beiden nichtknüpfenden Spezies der Negation und Konversion an jedem Modul sich sofort „ausführen“; sie müssen in jedem hinreichend reduzirten Ausdrucke, sofern sie sich auf Moduln miterstrecken, an diesen ausgeführt sein und bleiben fürderhin ausser Betracht.
Man merke besonders: dass die Konversion jeden Modul ungeändert lässt, die Negation einen Modul in sein duales Gegenstück verwandelt.
Was die vier knüpfenden Spezies anbelangt, so haben wir zu unterscheiden: identische und relative Knüpfungen zwischen den absoluten desgleichen zwischen den relativen Moduln unter sich und wechselseitig (miteinander) — wir erhalten also ziemlich viele Formeln.
Zunächst überträgt sich der „Abacus“ wie er mit Festsetzung (3) in § 3 für Relativ-Koeffizienten oder -Aussagen 1, 0 ausgemacht wurde als genau der gleiche auch auf die Relative oder absoluten Moduln 1, 0 in deren identischen Knüpfungen: 14) [Formel]
Ebendarum, überhaupt wegen Fortbestehens von (2), (3), (4), ist es unverfänglich als Namen für die absoluten Moduln die „Wahrheitswerte“ der Aussagen zu verwenden.
Und diesen Formeln wiederum entspricht bei den relativen Knüpfungen aber absoluten Moduln genau: 15) [Formel]
Beide Formelgruppen sind als partikulare Fälle schon in 8), 9), 10) enthalten und mit diesen Sätzen zugleich zu behalten.
Die identischen Knüpfungen zwischen absoluten und relativen Moduln erledigen sich durch die ganz bekannten und geläufigen Ansätze: 16) [Formel] welche ebenso mit 8), 9) schon gegeben sind.
Die identischen Knüpfungen zwischen den relativen Moduln durch: 17) [Formel] wovon die Formeln der ersten Zeile aus den Tautologiegesetzen sich verstehen, die der zweiten Zeile aus den in 13) mitenthaltenen Sätzen zu merken sein werden, wonach: gleichwie die beiden absoluten, so auch die beiden relativen Moduln Negate von einander sind, mithin disjunkt sein und einander zur Gesamtheit, dem Totum 1 ergänzen müssen.
Weiter die relativen Knüpfungen zwischen absoluten und relativen Moduln erledigen sich durch: 18) [Formel] von welchen Formeln die der ersten Zeile schon mit 9) und 10) gegeben und damit zu merken sind.
Die der zweiten Zeile, hälftig aus 11), werden sich mit einer spätern Bemerkung über die Bedeutung der Modulknüpfungen 1; a, a; 1, 0 ɟ a, a ɟ 0 von selbst einprägen, wofern man nur beachtet, dass die beiden relativen Moduln 1' und 0' lauter besetzte Zeilen aber keine Vollzeilen — und analog Kolonnen — haben.
Es bleiben hienach nur noch die relativen Knüpfungen zwischen den relativen Moduln zu studiren.
Für diese gelten die Formeln: 19) [Formel] wovon sich die der beiden letzten Zeilen aus 11) verstehen, die der ersten Zeile aber besonders zu merken sind mit dem Zusatze — auf welchen cf. S. 5 der Stern hinweisen soll — dass zu ihrer Geltung erforderlich ist, dass der Denkbereich 11 mehr als zwei Elemente enthalte.
Das System der Formeln 13) bis 19) nennen wir den „Abacus“ der binären Relative.
Derselbe erscheint zugleich als eine Erweiterung, die Vervollständigung, des schon in § 3 für die Koeffizientenwerte 1 und 0 aufgestellten „Abacus“.
An Beweisen ist für die Sätze des Abacus nur mehr ganz weniges beizubringen.
Zu 13) hat man blos zu bemerken, dass wegen der allgemein für jedes Suffix ij getroffenen Festsetzungen (6) und (7) des § 3 — S. 25 — auch gelten muss 1j i = 1 = 1i j, 0j i = 0 = 0i j, 1'j i = (j = i) = (i = j) = 1'i j, 0'j i = (j ≠ i) = (i ≠ j) = 0'i j, wonach denn in der That die Konverse der Moduln diese selbst sind.
Dass die Negation des einen relativen Moduls der andre ist, wird aus (7) unmittelbar ersichtlich, und haben wir auch zur zweiten Zeile von 17):
Die zweite Zeile von 18) beweist sich mit: (1; 0')i j = Σh1i h0'h j = Σh0'h j = 1, (1'; 1)i j = Σh1'i h1h j = Σh1'i h = 1'i i = 1 — also = 1i j — wo zu ersterm zu bemerken ist, dass, weil der Denkbereich 11 mindestens zwei Elemente enthält, in der Σh der Zeiger h auch mindestens einen von j verschiedenen Wert durchlaufen wird, für welchen somit 0'h j = 1 sein muss.
0'i j1'i j = (i ≠ j)(i = j) = 0 = 0i j 1'i j + 0'i j = (i = j) + (i ≠ j) = 1 = 1i j.
Endlich haben wir behufs Beweises der ersten Zeile von 19) den Ansatz: zu dessen Rechtfertigung bemerkt werden muss:
(0'; 0')i j = Σh0'i h0'h j = 1 = 1i j (1' ɟ 1')i j = Πh(1'i h + 1'h j) = 0 = 0i j
(Links).
Ist i ≠ j und gibt es ein von i und j verschiedenes h, so wird für jedes solche 0'i h0'h j = 1 · 1 = 1 sein.
Diese Voraussetzung trifft aber nur dann sicher zu, wenn der Denkbereich 11 mindestens drei Elemente enthält.
Bei i = j würde schon die Annahme h ≠ i genügen um den Term 0'i h0'h i = 1 werden zu lassen.
Ebenso (rechts) wird bei der gleichen Annahme mindestens ein Faktor 1'i h + 1'h j des Produktes = 0 und verschwindet auch dieses.
Unter jener Voraussetzung, auf welche der Stern hinweisen soll, haben wir also — mag i gleich oder ungleich j sein — für beide Fälle (0'; 0')i j = 1, etc. und sind die obersten Formeln 19) bewiesen.
Enthält dagegen der Denkbereich 11 blos zwei Elemente, so ist zwar noch — wie vorhin bemerkt — (0'; 0')i i = 1, dagegen für i ≠ j (0'; 0')i j = 0, weil in 0'i h0'h j der Zeiger h nur die beiden Werte i und j durchlaufen kann, für deren jeden einer der beiden Faktoren verschwindet.
Hier wird dann (0'; 0')i j = 1'i j. Mithin gälte: 0'; 0' = 1', 1' ɟ 1' = 0' beim Denkbereich aus gerade zwei Elementen.
Im „Ausnahmefall“ endlich, wo der Denkbereich auf ein einziges Element zusammenschrumpfte, hätten wir ohnehin keine Möglichkeit, relative Moduln von den absoluten zu unterscheiden; hier wäre überhaupt:
1' = 1, 0' = 0 also auch: 0'; 0' = 0 und 1' ɟ 1' = 1 — gerade umgekehrt wie in 19).
Bei völlig leerem Denkbereiche hätten wir auch noch 1 = 0 und wäre „alles egal“; buchstäblich gälte: „es ist alles nichts“.
Dass sobald der Denkbereich mehr als ein Element umfasst, die vier Moduln von einander verschieden sein müssen, erhellt bereits aus dem Anblick ihrer Matrizes.
Dasselbe kann natürlich auch leicht ganz strenge — formal aus den Festsetzungen — bewiesen werden.
Denn aus dem Korollar zu Festsetzung (14) folgt durch Kontraposition: (a ≠ b) = Σi j(ai j ≠ bi j), wonach es behufs Nachweises der Ungleichheit zweier Relative erforderlich und hinreichend ist, ihre Nichtübereinstimmung an einer einzigen Matrixstelle darzuthun, d. h. für ein einziges Suffix ij zu zeigen, dass der Koeffizient des einen Relativs gleich 1 während der des andern gleich 0 ist.
Dies aber gelingt sofort für irgend zweie von den vier Moduln unter der angegebnen Voraussetzung.
Kraft des Abacus können wir nun sagen, dass in dem „(hinreichend) reduzirten“ Ausdrucke eines Relativs Moduln nicht mehr miteinander verknüpft vorkommen können.
Käme z. B. irgendwo der Ausdruck a; 1; 0' vor, so müsste derselbe sofort zu a; (1; 0') = a; 1 reduzirt werden.
Moduln können zwar immer noch äusserlich als successive Terme in Ausdrücken auftreten — aber nur, wenn sie durch eine Klammer getrennt oder getrennt zu denken sind.
So würde sich a; 0' ɟ 0 nicht reduziren lassen, weil es = (a; 0') ɟ 0 nach unsern Konventionen über Klammern bedeutet.
Dagegen dürfte a; (1 ɟ 0') nicht vorkommen, sondern müsste zu a; 1 reduzirt sein.
Ebenso a; (0' ɟ 0) zu a; 0, das ist vollends zu 0. Etc.
Nach dem längst bekannten Theoreme 6) lässt sich im identischen Kalkul jede Subsumtion a ⋹ b nach Belieben bringen auf den absoluten Modul 1 als Subjekt, oder auf den 0 als Prädikat.
Peirce9 p. 194 hat sich nun die Frage vorgelegt, ob Ähnliches auch bezüglich der relativen Moduln 1' resp. 0' zutrifft, und erkannt, dass dieselbe merkwürdiger Weise zu bejahen ist.
Mit der Angabe und dem Beweise der hierauf bezüglichen Sätze wollen wir den gegenwärtigen Paragraph zum Ende führen.
Es gelten auch die folgenden Aussagenäquivalenzen: 20) [Formel] aufgrund deren, wie man sieht, die Mannigfaltigkeit der verfügbaren Schreibweisen oder Darstellungsmöglichkeiten einer Subsumtion, die schon im identischen Kalkul eine grosse gewesen, für unsre Disziplin noch ausserordentlich viel grösser wird, ja fast in’s Ungeheuerliche anwächst.
Beweis von 20).
Gilt a ⋹ b, so können wir nach Satz 1) des § 6 — zum Beispiel: beiderseits ā̆ relativ voraddiren und erhalten: ā̆ ɟ a ⋹ ā̆ ɟ b.
Nach 3) ist aber 1' ⋹ ā̆ ɟ a und somit folgt a fortiori: 1' ⋹ ā̆ ɟ b, d. h. es ist der Satz erwiesen: (a ⋹ b) ⋹ (1' ⋹ ā̆ ɟ b).
Um auch die umgekehrte Subsumtion zu erweisen, erheben wir die rechte Seite zur Voraussetzung und multipliziren beiderseits mit a relativ vor; dadurch entsteht: a; 1' ⋹ a; (ā̆ ɟ b), wo die linke Seite sich nach 11) zu a reduzirt.
Die rechte Seite ist aber nach Satz 7) des § 6: a; (ā̆ ɟ b) ⋹ a; ā̆ ɟ b ⋹ 0' ɟ b = b wegen 3), sowie 1) des § 6, und 11); mithin ist a ⋹ b erwiesen, q. e. d.
Die Formeln des Gespannes: 21) [Formel] deren erste wir mit der letzten Beweiszeile erwiesen haben, sind auch an sich bemerkenswert und würden sich den Sätzen des § 6 anreihen.
Nachdem nun die erste von den Äquivalenzen 20) bewiesen ist, ergeben sich die drei übrigen Formen der Aussage links von der Zeilenmitte leicht, indem man den in jener enthaltenen Satz anwendet auf die drei andern Subsumtionen, mit denen nach 13) des § 6, S. 87 die vorgelegte a ⋹ b äquivalent ist — wonach denn in der That auch: (b̄ ⋹ ā) = (1' ⋹ b̆ ɟ ā), (ă ⋹ b̆) = (1' ⋹ ā ɟ b̆), (b̄̆ ⋹ ā̆) = (1' ⋹ b ɟ ā̆) wird sein müssen.
Aus den linksseitigen vier Formen der als äquivalent mit a ⋹ b hingestellten acht Subsumtionen (20) fliessen endlich die vier rechtseitigen (als die jenen dual entsprechenden) durch Kontraposition, sodass sie nunmehr alle bewiesen sind.
Nimmt man b = a in 20) an, indem man demgemäss b durch a ersetzt, so kommt man, weil a ⋹ a selbstverständlich gilt, auf die Sätze 3) zurück, von welchen also gesagt werden kann, dass sie in denen 20) als besondre Fälle mit enthalten seien.
Umgekehrt werden wir die Sätze 20) als partikulare Anwendungen eines noch allgemeinern Satzes, des von mir sogenannten ersten Inversionstheoremes, in § 16 erkennen.
Vertauscht man in 20) a mit ā̆, oder b mit b unter Berücksichtigung auch von 13) des § 6, sowie von 6), so ergeben sich noch folgende Formen der bisherigen, Äquivalenz von Subsumtionen statuirenden Sätze: 22) [Formel] , in welchen sie zur Anwendung, nämlich als Schemata für die Umformung von Subsumtionen bequem hergerichtet erscheinen. Peirce l. c.:
Ist hienach das Prädikat zum Subjekte 1' eine relative Summe, so werden wir (deren) beide Terme sowol umstellen als auch zusammen konvertiren dürfen, mithin unter vier Schreibweisen zum Ausdruck jener Thatsache die Wahl haben.
Ebenso, wenn zum Prädikate 0' das Subjekt ein relatives Produkt ist.
Liegt dagegen der umgekehrte Fall vor (d. h. ist zum Subjekte 1' das Prädikat ein relatives Produkt, etc.), so sind wir blos berechtigt, den Ausdruck zu konvertiren — nicht aber, auch die Terme umzustellen — und verfügen wir blos über zwei Schreibweisen, indem:
(1' ⋹ a; b) = (1' ⋹ b̆; ă) (a ɟ b ⋹ 0') = (b̆ ɟ ă ⋹ 0').
Nachdem im gegenwärtigen Paragraphen mit 13) die Operationen der Negation und Konversion auch an den Moduln zu vollziehen gelehrt worden, haben die in § 6 über die Prozesse des Dualisirens und Konjugirens gemachten Angaben ihre Ergänzung dahin gefunden, dass man diese Prozesse praktisch nun auch an solchen Formeln, die neben allgemeinen Buchstabenrelativen auch Moduln führen, vollständig ausführen kann.
Wenn nun mit jeder allgemeinen Formel zugleich auch deren konjugirte, sowie deren duale nebst der konjugirtdualen, mithin ein Viergespann von Formeln, Geltung beansprucht, so wird die Frage unabweislich, welche andern Formeln denn vor allem die fundamentalen Festsetzungen des § 3 so noch nach sich ziehen? M. a. W. es drängt sich der Gedanke auf, die Prinzipien des Dualismus und der Konjugation (nachdem sie eben ihre volle Gebrauchsfähigkeit erlangten) zunächst auf jene fundamentalen Formeln anzuwenden, und damit sozusagen noch eine Fortsetzung, Ergänzung zum § 3 zu gewinnen.
Lassen wir zu dem Ende jene Festsetzungen Revue passiren, so wird das Ergebniss sein: dass die Konjugation nichts Neues liefert, wohl aber — bei den Festsetzungen (5) bis (13) — das Prinzip des Dualismus.
Wegen 0̆ = 0, 1̆ = 1 lässt die Konversion zugleich mit deren Wahrheitswerte auch jede Aussage ungeändert.
Darnach kann der Abacus (2) bis (4) durch Konjugation nur in sich selbst übergehen, desgleichen die (im Boole’schen Sinne) sekundären Aussagenformeln (1) und (14).
Die letzteren sind ausserdem zu sich selbst („gebiets“-)dual und der Abacus trägt bereits den Dualismus in sich zur Schau.
Es können daher nur mehr die Festsetzungen (5) bis (13) in Betracht kommen, für welche (5) das Prototyp bildet.
Diese Formel (5) a = Σi jai j(i : j) ginge nun durch beiderseitiges Konvertiren über in: ă = Σi jai j(j : i), indem nach dem Gesagten das Konverse von ai j nicht aj i sondern ai j selbst ist.
Ersetzte man in dem Ergebnisse dann a durch ă, so entstünde a = Σi jaj i(j : i) = Σj iaj i(j : i). D. h. man erhält durch Konjugation die ursprüngliche Formel wieder, mit dem einzigen Unterschiede, dass die beiden laufenden Zeiger blos ihre Namen ausgetauscht haben.
[Streng genommen war hiezu eine Bemerkung vonnöten:
Wir sind zwar verbal schon in § 2 übereingekommen j : i das „zu i : j konverse“ Elementepaar zu nennen; dass aber dieser Begriff aufgrund der später gegebnen Definition der „Konversion“ zusammenfällt mit deren Ergebnisse i : j͝ musste erst bewiesen werden.
Der Beweis, durch den erst jene verbale Ausdrucksweise ihre Rechtfertigung nachträglich findet, ist äusserst leicht zu erbringen und sei — da die ganze Betrachtung einen nebensächlichen Charakter hat — hier dem Leser überlassen.
Wir werden systematisch denselben erst in § 24 liefern.]
Konjugation also lieferte uns nichts Neues.
Anders das Dualisiren.
Kontraposition, beiderseitiges Negiren der Formel ā = Σi jāi j(i : j) gibt als das duale Gegenstück zu 5) die für jedes Relativ a gültige Darstellung: 23) a = Πi j(ai j + i : j͞).
Um zunächst den Schluss ganz überzeugend zu finden, mag man bedenken, dass in der vorhergehenden, der für ā in Anspruch genommenen Formel (5) alle Koeffizienten āi j den Wahrheitswert 0 oder 1 haben.
Wegen völligen Zusammenfallens der Knüpfungsgesetze muss es aber erlaubt sein, diese Wahrheitswerte 0 und 1 auch als Relative, nämlich als die absoluten Moduln anzusehen.
Bei dieser letztern Auffassung wird die Gleichung in der That absolut das nämliche besagen und dieselbe Determination für ā geben, wie bei der vorhergehenden Koeffizientendeutung.
Dann aber haben wir rechts eine Summe Σi j von identischen Produkten aus binären Relativen: āi j (= Modul 0 oder aber 1) das eine, und i : j das andre.
Und dieses Aggregat von Relativen kann nach den(selben) Regeln negirt werden, welche für solche bereits gesichert sind — wodurch nun eben 23) entsteht.
Sehen wir uns jetzt die Darstellung näher an.
Sooft (d. h. für jedes ij wofür) ai j = 1 ist, wird auch der zugehörige Faktor des Πi j gleich 1 mithin belanglos, unterdrückbar, unwirksam.
Sooft dagegen ai j = 0 ist, erscheint (weiter nichts wie)
i : j͞ selbst als Faktor unsres Produktes angesetzt.
Gleichwie das binäre Relativ a die identische Summe ist der in ihm enthaltenen, vorhandenen Elementepaare, so ist es also auch das identische Produkt der Negate von sämtlichen Elementepaaren die in ihm fehlen oder unvertreten sind!
Dergleichen Negate von individuellen (binären) Relativen nennt Peirce (bekanntlich) „simples“.
Das Relativ ist die Summe seiner „Individuen (im Denkbereiche 12) und das Produkt der Negate seiner „Nichtindividuen“ (seiner Simpla).
Jene, die Elementepaare, mit Peirce die „Aggreganten“ von a zu nennen ist angängig, diese, die Simpla, dagegen als die „Komponenten von a zu bezeichnen schafft einen Doppelsinn im Hinblick auf die „Komposition“ als relative Multiplikation der Relative.
Ich würde — wie dort den Ausdruck „Konstituenten“ — so hier den „Produzenten“ (Poretzki’s) vorziehn.
Dual ergänzt hätte also unsre Festsetzung (5) zu lauten: 24) Σi jai j(i : j) = a = Πi j(ai j + i : j͞), indessen kann doch nur die eine Hälfte dieser Formel als „Festsetzung gelten; die andre ist dann eine Konsequenz — aus den wirklichen Festsetzungen.
Wegen des Korollars zu Festsetzung (14) ist die („additive“) Darstellung eines binären Relativs als Summe von Elementepaaren nur auf eine Weise möglich, und ebendies muss auch von seiner („multiplikativen“) Darstellung als Produkt von Simplen gelten — die ja durch Kontraposition aus jener folgte.
Wenn nun so der einen Darstellung der Relative, die wir als die fundamentale zugrunde gelegt, noch eine zweite völlig gleichberechtigt gegenübersteht, so wollen wir uns doch mit dieser theoretischen Einsicht begnügen und von der letztern thunlichst keinen Gebrauch machen.
Wir werden auch sehr wohl imstande sein, alle Schlüsse nur auf die erstere zu bauen.
Und unsre Disziplin ist ohnehin schon vielförmig genug.
Ich will darum auch hier darauf verzichten, unter dem Gesichtspunkt dieser zweiten Darstellungsweise auch die mit Festsetzung (6) bis (9) definirten speziellern Relative, sowie die mit (10) bis (13) erklärten Erzeugnisse unsrer 6 Spezies noch weiter zu verfolgen. —
§ 9.
Die 12 irreduzibeln primären Modulknüpfungen und die 64 Diagonalabwandlungen eines allgemeinen Relativs.
Nicht vertreten in den Formeln 8) bis 11) des vorigen Paragraphen sind folgende 16 Modulknüpfungen: 1)
[Formel] 2)
[Formel] von denen wir wieder die konjugirten neben- statt untereinander geschrieben haben.
Diese sind die irreduziblen unter den primären Knüpfungen.
Im Allgemeinen fallen sie weder mit einem der Moduln noch mit dem Relativ a selber oder einem von dessen Verwandten zusammen.
Dagegen bestehen zwischen ihnen und a, sowie auch unter sich, gewisse Beziehungen der Einordnung, Subsumtionen, mit denen wir noch zu thun haben werden.
Die ersten 8 derselben, welche auf nur vier im Allgemeinen verschiedene hinauskommen, sind identische Knüpfungen, gehören der ersten Hauptstufe an — doch gehn in sie nur relative Moduln ein.
Die letzten 8 sind relative Knüpfungen.
Den Gruppen 1) und 2) entsprechend haben wir also nur 4 + 8 = 12 sage zwölf verschiedene Relative als irreduzible primäre Modulknüpfungen eines gegebnen Relativs a zu studiren.
Vertrautheit mit diesen ist für unsre Disziplin fundamental.
Wir betrachten zuerst die vier Knüpfungen 1).
Das Relativ 1'a hebt aus dem Relativ a dessen individuelle Selbstrelative sämtlich hervor, schneidet sie gleichsam aus ihm heraus, und vereinigt ausschliesslich sie zu einem neuen Relative.
Das duale Gegenstück hiezu, 0' + a, vereinigt die individuellen Selbstrelative von a mit allen erdenklichen individuellen Aliorelativen.
Das Relativ 0'a vereinigt in sich alle individuellen Aliorelative von a und nur diese.
Das duale Gegenstück hiezu 1' + a fasst diese individuellen Aliorelative von a mit allen erdenklichen Selbstrelativen zusammen (zu einem neuen Relative).
Die Subsumtionen, welche über diese Relative ausgesagt werden können, sind die aus dem identischen Kalkul selbstverständlichen.
Es ist natürlich.
1'a ⋹ a ⋹ 0' + a und auch 1'a ⋹ 1', 0' ⋹ 0' + a, und so weiter.
Der allgemeine Koeffizient ist für ein jedes dieser Relative 1) leicht anzugeben.
Es wird z. B. nach den einschlägigen Festsetzungen (7) und (10) des § 3: (1'a)i j = 0 für i ≠ j, dagegen (1'a)i i = ai i, (0'a)i j = ai j für i ≠ j, und (0'a)i i = 0.
Die Formel: 3) a = 1'a + 0'a gibt die Zerfällung jedes Relativs in seine individuellen Selbst- und Aliorelative.
Dieselbe folgt mit Leichtigkeit aus der in 16) des Abacus enthaltenen Gleichung 1' + 0' = 1.
In seiner älteren Schrift2 hebt Peirce hervor die Analogie von 1'a mit dem „Skalar-“, und von 0'a mit dem „Vektor“-Teil von Quaternionen, dieselben — worauf er nicht mehr zurückkommt — mit Sa und Va zu bezeichnen vorschlagend.
Auf das Vorhandensein oder Fehlen in a der einen oder andern Art von individuellen Relativen oder Elementepaaren kann man eine Einteilung der Relative gründen, welche auch dazu führt, den Begriff des „Selbst“- und „Aliorelativs“ von den individuellen auf beliebige oder allgemeine binäre Relative auszudehnen.
Überhaupt drängen sich hier vier begriffliche Unterscheidungen auf.
Ich will zunächst die Peirce’sche Nomenklatur, der ich mich anschliesse, übersichtlich einführen.
Wir definiren:
[Formel] [Formel]
Missachtet man die Anforderungen des Dualismus, so könnte man, nachdem die Definition der ersten Zeile adoptirt ist, sich versucht fühlen, die Benennungen für „Selbstrelativ“ und „Konkurrent“ auszutauschen.
Ich habe mich erst nach Überwindung dieses Befremdlichen mit Peirce’s Terminologie zu befreunden vermocht, dieselbe jedoch bald als die zweckmässigste und eleganteste erkennen müssen.
Von diesen vier Paaren von Ansätzen sind nur die des ersten und dritten Paares selbständige Festsetzungen, die beiden andern Paare dann durch Kontraposition von selbst gegeben.
Die untereinander stehenden Begriffe jeden Paares schliessen sich gegenseitig aus und teilen alle binären Relative zwischen sich.
Es wird also „Aliorelativ“ ein Relativ zu nennen sein, welches kein Elementepaar der Form i : i enthält, dagegen „Selbstrelativ“ ein solches, dem Elementepaare von dieser Form i : i (daneben vielleicht auch noch andre der Form i : j, wo j ≠ i) angehören.
Ein Relativ, dem kein Elementepaar der Form i : j (wo j ≠ i) angehört, heisst ein „Konkurrent“; ein solcher besteht also höchstens aus Elementepaaren der Form i : i (sofern er nämlich nicht 0 ist), und ein Relativ, dem Elementepaare der Form i : j (wo j ≠ i) angehören, heisst „Opponent“.
[Die beiden Formen hätten wir auch kürzer als die von A : A und A : B bezeichnen können].
„Konkurrenten“ — bemerkt Peirce 2 p. 52 — drücken eine blosse Übereinstimmung zwischen Objekten aus (a mere agreement among things), wie z. B. „Mensch, welcher … ist“ („man, that is-“); demnach also drücken Opponenten“ einen Gegensatz (opposition) aus (set one thing over against another, ἀντιϰεῖσϑαι).
Dass ein Elementepaar der Form A : A nun wirklich als ein Selbstrelativ, eines der Form A : B als Aliorelativ anzuerkennen ist, ist ersichtlich.
Jenes ist zugleich auch Konkurrent, dieses auch Opponent. —
Was die Moduln betrifft, so ist: und zwar gibt es allemal nur ein einziges Relativ (nämlich der angegebne Modul), welches die beiden Charaktere in sich vereinigt — wie leicht zu zeigen.
0 zugleich Aliorelativ und Konkurrent
1 Aliorelativnegat und Konkurrentnegat
0' Aliorelativ und Konkurrentnegat
1' Aliorelativnegat und Konkurrent,
Im übrigen — bei Ausschluss je eines gewissen von den beiden Moduln 0 und 1 — bestehn zwischen den 8 verschiedenen Klassen folgende Beziehungen:
Jedes Aliorelativ sowie jedes Konkurrentennegat ist zugleich Opponent und Selbstrelativnegat.
Jeder Konkurrent sowie jedes Aliorelativnegat ist zugleich Selbstrelativ und Negat eines Opponenten.
Dies beruht auf den folgenden Aussagensubsumtionen: (a ⋹ 0')(a ≠ 0) + (0' ⋹ a)(a ≠ 1) ⋹ (a ⋹ 1')(1' ⋹ a) (a ⋹ 1')(a ≠ 0) + (1' ⋹ a)(a ≠ 1) ⋹ (a ⋹ 0')(0' ⋹ a) die mit ihren Teilvoraussetzungen und Teilbehauptungen der Leser sich zur Übung leicht selber beweisen wird.
Nebenbei bemerke man: 1' ist die „Gemeinheit“ (Π, der least common part) aller Aliorelativnegate und das Universum (Σ) aller Konkurrenten, 0' ist das Universum aller Aliorelative und die Gemeinheit aller Konkurrentnegate.
Ebenso wie a selbst kann man aber auch dessen Verwandte ā, ă, ā̆ mit den Moduln verknüpfen.
Um dem Studirenden eine Ahnung von dem ungeheuren Reichtum unsrer Disziplin zu verschaffen, will ich hier überhaupt — im Anschluss an die Besprechung von 1) — die Frage erledigen, wievielerlei und welche Relative sich aus einem gegebnen Relativ a nebst dem Modul 1' ableiten lassen durch die Operationen der Negation und Konversion in Verbindung mit den beiden identischen Knüpfungen.
Wir wollen also die genannten zwei Relative in Hinsicht der genannten vier Spezies zu einer „Gruppe“ ergänzen.
Der Ausschluss der beiden relativen Knüpfungen motivirt sich aus der Erwägung, dass bei deren Zulassung die Menge der fraglichen Relative — wie schon aus der Reihe a; a, a; a; a, a; a; a; a, … zu ersehen ist — eine unbegrenzte werden müsste.
Mit 1' wird als dessen Negation auch 0' zugelassen sein, und brauchte also neben 1' nicht extra gegeben zu werden.
Ebensowenig die beiden absoluten Moduln, sintemal 1 = a + ā, 0 = aā ohnehin aus a ableitbar sind.
Dagegen ist es nicht möglich mittelst genannter 4 Spezies einen relativen Modul aus a abzuleiten, zu dessen Bestimmung ja seine Stellung als Subjekt resp. Prädikat in 2) des § 8 jedenfalls nicht ausreichend wäre.
Zunächst liefern die vier verwandten Relative 4) a, ā, ă, ā̆, durch identische Multiplikation und Addition verknüpft, uns die 8 reduzibeln Knüpfungen: aā = āa = ăā̆ = ā̆ă = 0, a + ā = ā + a = ă + ā̆ = ā̆ + ă = 1, dazu 16 nämlich achterlei irreduzible Ausdrücke.
Die 8 kraft der Tautologiegesetze reduzibeln Knüpfungen aa = a, āā = ā, etc. a + a = a, etc. haben wir nicht mitgerechnet, ansonst wir auch 16 reduzible und zusammen 2 × 4 × 4 = 32 Knüpfungen hätten.
Mit Rücksicht auf jene aber sieht man leicht auch a priori, dass die Zahl der Ergebnisse einmaliger Knüpfung zwischen den 4 Verwandten 2 × 4 × 3 = 24 sein muss.
Man könnte auch hiervon nur die Hälfte rechnen, wenn man ebenso (wie die Tautologie-) auch die Kommutationsgesetze berücksichtigen wollte.
Jene achterlei irreduziblen Knüpfungen sind: 5)
[Formel] 6)
[Formel]
Aus ihnen sind noch die beiden irreduziblen Ausdrücke ableitbar: 7) und überzeugt man sich unschwer, dass zusammen mit den 2 Moduln 0, 1 die 4 verwandten Relative 4) nebst den 8 abgeleiteten 5), 6) und den 2 letzten 7) eine „Gruppe“ in Hinsicht unsrer vier Spezies bilden — eine Gruppe, die also 16 im Allgemeinen unter sich verschiedene Relative umfasst.
1' ⋹ aă + āā̆ = (a + ā̆)(ā + ă) aā̆ + āă = (a + ă)(ā + ā̆) ⋹ 0'
Werden alle diese jetzt auch noch mit den beiden relativen Moduln 1', 0' nach dem Vorbild von 1) identisch verknüpft, so treten als eventuell neue Relative erstlich hinzu die 12erlei Ausdrücke: 8)
[Formel] 9)
[Formel] welche die verschiednen irreduziblen primären identischen Modulknüpfungen des Verwandtenquadrupels 4) von a vorstellen, sodann die 14erlei Ausdrücke aus den Modulknüpfungen der zusammengesetzten Relative 5) bis 7): 10) [Formel] 11) [Formel] 12) [Formel] 13) [Formel] endlich die 20erlei Ausdrücke, welche noch durch identische Knüpfungen zwischen den bisherigen erhältlich sind: 14) [Formel] 15) [Formel] 16) [Formel] 17)
[Formel]
Nehmen wir hierzu noch die 2 Moduln 1' und 0' selbst, so ist mit den aufgezählten (2 + 14) + 12 + 14 + 20 + 2 = 64 Relativen die gesuchte Gruppe abgeschlossen.
Rechnet man zum selben „Typus“ immer diejenigen Ausdrücke welche durch blosse Buchstabenvertauschung — also hier: durch Vertauschungen zwischen den vier verwandten Relativen 4) — in einander übergeführt werden können, so müsste man allerdings die vier Moduln auch zu vier verschiedenen Typen rechnen und ebenso im Allgemeinen die vier resp. zwei Ausdrücke, welche jeweils (nach den Prinzipien des Dualismus und der Konjugation) eine Tetrade resp. Dyade, ein Gespann ausmachen.
Es interessirt uns aber weniger die Typenzahl der Ausdrücke selber als vielmehr vorwiegend die Typenzahl ihrer Gespanne.
Da zerfallen denn die beiden Modulnpaare auch nur in zwei Typen — den beiden Hauptstufen entsprechend.
Im übrigen sind die Typen der Ausdrucksgespanne durch unsre Chiffrirung kenntlich gemacht, sodass wir insgesamt 2 + 14 = 16 Gespann-Typen unsrer 64 Relative vorfinden und zu unterscheiden haben.
Dass die 64 Relative sämtlich von einander verschieden sein können, lässt sich schon durch das einfache Beispiel nachweisen: .
Wir empfehlen dem Studirenden als eine leichte und erspriessliche Übung in vorstehender Weise auch noch die 60 (oder von den Moduln abgesehen 56) übrigen Relative durch ihre Matrix mittelst Augen und Leerstellen sich darzustellen und sich zu überzeugen, dass wirklich keine zwei von allen 64 einander gleich ausfallen.
Verfügt man über karrirtes Papier, so brauchen blos die Augen eingetragen, die Leerstellen nicht markirt zu werden.
Dass freilich die Gruppe unsrer 64 Relative vollständig, ist nicht so bequem erweisbar und müssen wir, nachdem die Methoden zu solchem Nachweise in Anhang 6 des Bd. 1 auseinandergesetzt sind, denselben zu führen dem Leser überlassen.
Was die Sätze betrifft, die im Vorstehenden mitenthalten sind, so erscheinen die in 6) nebenher mit angeführten Subsumtionen als einerlei mit den Sätzen 2) des § 8.
Aus ihnen ergibt sich durch überschiebendes Multipliziren derer rechts vom Mittelstriche alsbald die Subsumtion links in 7) und dual entsprechend die rechts — vergleiche auch das Korollar zu 2) des § 8.
Ausserdem dürfte der in 8) mitenthaltene Satz am bemerkenswertesten sein: dessen Beweis gegeben ist durch die Bemerkung, dass die Gleichung 1'i jai j = 1'i jaj i für i ≠ j auf 0 = 0, für i = j aber auf ai i = ai i hinausläuft.
1'a = 1'ă 0' + a = 0' + ă
Im übrigen erheischt es schon einiges analytische Geschick in der Handhabung des identischen Kalkuls, unter Verwertung der Sätze 2) des § 8 und ihrer Korollare in 7) des gegenwärtigen, nachzuweisen, dass irgend ein durch die genannten 4 Spezies aus den Verwandten von a und Moduln gebildeter Ausdruck notwendig auf eines der 64 Relative der Gruppe hinausläuft — und damit den Ausdruck jeweils auf seine typische oder einfachste Form zu bringen.
Auf den ersten Blick nämlich scheinen sich noch viel mehr als die angeführten 64 Ausdrücke bilden zu lassen.
Beispielsweise wird man leicht erkennen, dass die folgenden Ausdrücke mit Fug und Recht in unsrer Zusammenstellung ausgelassen sind (ungeachtet ihres anscheinend analogen Baues mit andern darin angeführten), weil sie sich eben reduziren: und so weiter.
Hätte man beispielsweise den Ausdruck 1'(ā + ā̆) + aā̆ + āă, so wäre, indem man den Faktor von 1' in ā + aā̆ umformt, die Unterdrückbarkeit des Termes 1'ā̆ in unserm Ausdruck nachzuweisen und dürfte solche nicht übersehen werden.
Dergleichen Vereinfachungen sind beim Nachweis der Vollständigkeit der Gruppe in grosser Menge auszuführen.
1'aā̆ = 0, 1'(a + ā̆) = 1' 0' + a + ā̆ = 1, 0' + aā̆ = 0' 1'āă = 0, 1'(ā + ă) = 1' 0' + ā + ă = 1, 0' + āă = 0'
1'(aă + āā̆) = 1' 0' + aā̆ + āă = 0' 1'(aā̆ + āă) = 1' 0' + aă + āā̆ = 1
Quintessenz der vorstehenden Untersuchung ist also: dass sich schon bei Ausschluss der beiden relativen Knüpfungen aus einem gegebnen binären Relativ a nicht weniger als —
es selbst und die vier Moduln eingerechnet — sechzig vier Relative ableiten lassen.
Die Entstehungsweise eines jeden dieser Relative aus dem ursprünglichen a wird — eine empfehlenswerte Übung — der Leser sich unschwer mit Worten beschreiben.
Es müssen in jedem Falle von den Elementepaaren — oder besser Matrix-Augen — des a gewisse hervorgehoben (ausgeschnitten oder beibehalten), andre vielleicht unterdrückt werden, es müssen eventuell sei es auf, sei es ausserhalb der Hauptdiagonale die fehlenden ergänzt, oder auch die Konversen zu den daselbst fehlenden oder vorhandenen Augen hinzugefügt oder aber ausgemerzt werden.
Die Beschreibung wird in vielen Fällen erleichtert und vereinfacht, wenn man sich des folgenden Ausdrucks bedient, den wir, mit einem modifizirenden Epitheton versehen, aus der mathematischen „Substitutionentheorie“ herübernehmen müssen und hiermit einführen.
Ein Relativ von der Form: i : j + j : i wo i ≠ j soll eine nackte Transposition (oder ein „Cyklus zweiter Ordnung“) heissen.
Die Matrix desselben besteht also aus gerade zwei Augen, welche symmetrisch zur Hauptdiagonale und seitlich von derselben stehen.
Ein solches Relativ entsteht, indem man zu irgend einem individuellen Aliorelativ das konverse desselben hinzufügt.
Von der „Transposition“ schlechtweg (im Sinne der Substitutionentheorie), muss wie wir sehn werden, die „nackte Transposition“ wohl unterschieden werden.
Jene hat — beiläufig bemerkt — viel mehr Augen, trägt nämlich Augen auch noch an all den Stellen der Hauptdiagonale, welche nicht in der Flucht von i oder j liegen.
Darnach wird man beispielsweise sagen können:
Das Relativ aă besteht aus den individuellen Selbstrelativen von a in Verbindung mit allen nackten Transpositionen, welche a enthält.
Das Relativ a + ă dagegen aus den vorgenannten Elementepaaren nebst all den nackten Transpositionen, zu welchen sich die „nur einseitig vorhandenen“ individuellen Aliorelative von a ergänzen lassen.
Ein Elementepaar, Auge, ist in a „nur einseitig vorhanden“ zu nennen, wenn (es zwar vorhanden ist aber) das zu ihm konverse fehlt.
Weil ein Selbstrelativ das konverse von sich selber ist, kann solcher Fall nur bei individuellen Aliorelativen eintreten.
Es ist doch wohl wünschenswert, und das Bedürfniss wird mit dem Fortschreiten unsrer Disziplin immer stärker hervortreten, dass zur Behandlung der einschlägigen Materie und zur Beschreibung der dabei in Frage kommenden Verhältnisse eine geeignete präzise und knappe Terminologie ausgebildet werde und allgemein in Übung komme.
Die vorstehenden Vorschläge scheinen noch nicht allen Anforderungen zu genügen.
Ich will mir daher gestatten, noch einige weitere Ausdrucksmöglichkeiten der Erwägung des Lesers zu unterbreiten.
Wie von Symmetrie (inbezug auf die Hauptdiagonale) kann man auch von Spiegelung, Spiegelbildern reden, wobei immer zu unterstellen sein wird, dass die Hauptdiagonale als spiegelnde Linie gedacht wird.
Die Operationen der oben betrachteten Gruppe gestatten, aus einem irgendwie gegebnen Relativ a abzuleiten 64 eventuell andre Relative, und diese wollen wir insgesamt — im Gegensatz zu später zu studirenden Zeilen- oder Kolonnenabwandlungen — als die „diagonal flektirten“ Relative zu a bezeichnen, jene Operationen auch die „diagonalen“ (oder „spiegelnden“) Abwandlungen (Flexionen) des Relativs a nennen.
Zwei Stellen der Matrix eines Relativs a, die in der Tafel 12 von zu einander konversen Elementepaaren, genauer individuellen Aliorelativen i : j und j : i, eingenommen, okkupirt werden, sollen symmetrisch gelegene Stellen heissen; sie bilden ein „symmetrisches Stellenpaar“, bestehend aus einer Stelle und ihrem Spiegelbilde.
Sind sie bei a alle beide mit Augen besetzt, so mögen wir, einem Vorgang der Botanik folgend, diese Augen „parige“ nennen; dieselben bilden dann ein „symmetrisches Augenpaar“, bestehend aus einem Auge und seinem Spiegelbilde.
Ebenso, wenn ein symmetrisches Stellenpaar in a unbesetzt ist, nennen wir die Leerstellen desselben parige.
Wenn dagegen in einem symmetrischen Stellenpaar blos die eine Stelle bei a ein Auge trägt, während die andre unbesetzt ist, so soll dies Auge ein „unpariges“ heissen; mit demselben Rechte ist dann also auch die Leerstelle eine unparige zu nennen.
Die Operationen der diagonalen Gruppe gestatten uns nun bei einem Relativ a ganz unabhängig von einander die folgenden 12 = 2 × 6 Prozesse einzeln auszuführen (oder zu unterlassen):
Die auf der Diagonale stehenden Augen, desgleichen Leerstellen, die (seitlich derselben stehenden) parigen Augen, desgleichen Leerstellen, sowie die unparigen Augen, desgleichen Leerstellen aus a hervorzuheben oder aber zu tilgen — wobei das „Tilgen von Leerstellen“ als ein Besetzen derselben mit je einem Auge zu verstehen ist.
Im folgenden Schema ist zur Anschauung gebracht, in welcher Weise bei a eine Stelle auf der Hauptdiagonale, sowie ein symmetrisches Stellenpaar überhaupt besetzt (oder unbesetzt) sein kann, und wie alsdann bei den mit a verwandten Relativen ebendiese Stellen besetzt sein müssen.
Es kommen bei a sechs Möglichkeiten in Betracht, von denen die zwei mittleren der Art nach nicht verschieden sind, und zwar zeigt 0) ein Auge, 4) eine Leerstelle auf der Diagonale, 1) zeigt parige Augen also ein symmetrisches Augenpaar, 3) parige Leerstellen, 2) zeigt mit den zwei Besetzungsmöglichkeiten ein unpariges Auge.
Fig. 19.
Wir erhalten hierzu leicht die folgenden sechs Schemata: und kann man darnach z. B. sagen:
Fig. 20.
Das Relativ aă hebt aus a dessen parige nebst den auf der Diagonale stehenden Augen hervor; das aā̆ blos dessen unparige Augen.
Das Relativ aā̆ + āă gibt die unparig besetzten Stellenpaare von a als vollbesetzte, indem es die übrigen Augen von a abwirft.
Und dergleichen mehr. a + ă dagegen ergänzt die unparigen Augen von a zu parigen, indem es alle übrigen Augen von a ungeändert beibehält.
Und so weiter.
Man wird nunmehr keine Schwierigkeit finden, irgend eine von den 64 diagonalen Abwandlungen nach ihrer Wirkung kurz und treffend zu beschreiben. —
Von noch fundamentalerer Wichtigkeit — wo möglich — als wie die identischen 1) sind die relativen irreduziblen Modulknüpfungen 2) zu deren Betrachtung wir uns jetzt wenden.
In diejenigen der ersten Zeile von 2) gehn die absoluten, in die der zweiten Zeile die relativen Moduln ein.
Wir stellen zuerst für jene den allgemeinen Koeffizienten auf.
Es wird nach den einschlägigen Festsetzungen: 18) [Formel] .
Hiernach ist für ein bestimmt festgehaltenes i das (a; 1)i j gleich 1 für jedes j, wenn es auch nur für einen einzigen Werth von j gleich 1 ist — andernfalles gleich 0; das heisst das Relativ a; 1 kann nur aus ganz voll besetzten und gänzlich leeren Zeilen bestehen, ebenso das a ɟ 0.
Dagegen können die Relative 1; a und 0 ɟ a nur bestehen aus vollen und leeren Kolonnen; denn ist bei bestimmt festgehaltenem j das (1; a)i j gleich 1 (resp. 0) für irgend ein i, so ist es auch gleich 1 (resp. 0) für jedes i, d. h. an allen den Stellen, die in der durch j bestimmten Vertikalflucht liegen.
Eine Reihe (der Matrix), deren jede Stelle mit einem Auge besetzt ist, nennen wir eine Vollreihe.
Trägt dagegen keine Stelle der Reihe ein Auge, enthält die Reihe lauter Leerstellen, so nennen wir sie eine Leerreihe.
Eine Reihe, von der mindestens eine Stelle mit einem Auge besetzt ist, welche also überhaupt Auge(n) trägt — einerlei ob eines, mehrere oder auch lauter Augen — heisse eine besetzte Reihe.
Im gewöhnlichen Leben wird „besetzt“ oft synonym mit „voll besetzt gebraucht.
Wir nehmen es hier blos als Gegensatz zu „unbesetzt“ — im Sinne von „irgendwie besetzt“.
Eine Reihe dagegen, von der mindestens eine Stelle unbesetzt ist, heisse eine lückenhafte, lückige oder Lückreihe.
Dies ist der Anfang einer Terminologie, welche wir, um in unsrer Theorie eine präzise und knappe Ausdrucksweise zu ermöglichen, noch weiter auszubilden haben werden.
Es müssen hienach einerseits: Vollreihe und Lückreihe andrerseits: Leerreihe und besetzte Reihe kontradiktorische Gegensätze sein.
Dagegen sind Vollreihe und Leerreihe blos konträre Gegensätze.
Die Vollreihe gehört zu den besetzten Reihen, und die Leerreihe ordnet sich den Lückreihen ein, ist auch eine „Lückreihe“ zu nennen, obwol bei ihr der Begriff der Lücke ausartet in etwas die ganze Breite einnehmendes, dem das Substrat, welches die „Lücke“ einfassen sollte, fehlt.
Es war also erkannt: dass die Relative a; 1 und a ɟ 0 blos aus Voll- und Leerzeilen, die 1; a und 0 ɟ a blos aus Voll- und Leerkolonnen bestehen können.
Welche Zeilen — müssen wir nun weiter fragen — werden aber Vollzeilen und welche Leerzeilen von a; 1 sein?
Die Antwort ergibt sich aus der Diskussion des Ausdruckes Σhai h = ai A + ai B + ai C + … welcher den allgemeinen Koeffizienten (a; 1)i j darstellt.
Diese Summe wird nur dann verschwinden, wenn alle Glieder derselben = 0 sind.
Sobald dagegen auch nur eines der Glieder gleich 1 ist, m. a. W. sobald mindestens eines der ai h die sich bei festgehaltnem i und seine Bedeutung wechselndem h ergeben, nicht = 0 (mithin = 1) ist, wird auch unsre Summe den Wert 1 erhalten.
Es muss also a; 1 eine Vollzeile überall da (für alle jene i) aufweisen, wo a eine (irgendwie) besetzte Zeile besitzt, und eine Leerzeile nur da, wo auch a eine Leerzeile hat.
Andrerseits wird Πhai h = ai Aai Bai C … gleich 1 nur dann sein können, wenn sämtliche ai h gleich 1 sind, dagegen verschwinden, sobald auch nur einer der Faktoren ai h verschwindet.
Diese Faktoren sind die Koeffizienten der mit i markirten Zeile („iten Zeile“) von a.
Sonach ist (a ɟ 0)i j = 1, hat das Relativ a ɟ 0 eine Vollzeile nur da, wo auch a eine Vollzeile besitzt, und jeder Lückzeile von a entspricht eine Leerzeile von a ɟ 0.
Führt man ebenso die Diskussion für die beiden andern Relative, so gelangt man zu folgenden fundamentalen Sätzen (welche leicht zu merken):
Das Relativ a; 1 wird erhalten, indem man alle (irgendwie) besetzten Zeilen von a in Vollzeilen verwandelt und die Leerzeilen von a als ebensolche beibehält.
Um das Relativ a ɟ 0 zu bilden, behalte man die Vollzeilen von a ausschliesslich bei — indem man alle übrigen Zeilen von a „abwirft“, d. h. alle Lückzeilen von a in Leerzeilen verwandelt.
Bei solcher „Verwandlung“ in Leerzeilen bleiben natürlich die etwa schon vorhandenen Leerzeilen ungeändert; auch heisst „Leerzeilen“ (mitnebst noch andern) „abwerfen“ dasselbe wie: „sie beibehalten“.
Um das Relativ 1; a zu bilden, verwandle man alle besetzten Kolonnen von a in Vollkolonnen und behalte dessen Leerkolonnen bei.
Das Relativ 0 ɟ a wird erhalten, indem man die Vollkolonnen von a ausschliesslich beibehält, die übrigen Kolonnen abwirft, d. h. dessen Lückkolonnen in Leerkolonnen verwandelt
Für die Relative der zweiten Zeile von 2) sind die allgemeinen Koeffizienten: 19) [Formel]
Lässt man in der That — im letzten Produkt z. B. — den laufenden Zeiger (die Produktationsvariable) h den Wert i annehmen, so erweist sich der zugehörige Produktfaktor 1'i i + ai j = 1 + ai j = 1 als belanglos, ineffektiv, wogegen in jedem Falle h ≠ i derselbe sich zu 1'i h + ah j = 0 + ah j = ah j zusammenzieht.
Etc.
Bei der Diskussion der Möglichkeiten, unter denen diese Koeffizienten = 1 oder = 0 werden, ergibt sich nun die Nötigung, noch weitre Unterscheidungen hinsichtlich der Reihen eines Relativs zu machen, entsprechend den arithmetischen Unterscheidungen zwischen Einzahl und Mehrzahl, den sprachlichen zwischen Singular und Plural:
Trägt eine Reihe, die sonst lauter Leerstellen hat, gerade nur ein Auge, so soll sie eine einbesetzte Reihe heissen; trägt sie mehr als ein Auge, so heisse sie eine mehrbesetzte Reihe.
Hiernach zerfallen also die besetzten Reihen in einbesetzte und mehrbesetzte, und die Vollreihen gehören zu den letztern.
Ich hatte zuerst die Audsrücke „einfach besetzte“ und „mehrfach besetzte Reihe“ bei meinen Vorträgen im Mathematischen Kränzchen Karlsruhe’s gebraucht, wurde jedoch von Kollegen auf deren Missverständlichkeit aufmerksam gemacht.
Obwohl ich diese letztern Ausdrücke noch jetzt für die buchstäblich zutreffendsten halte, weil es sich hier wirklich um Besetzung von einem oder mehrern „Fächern“ (Stellen) handelt — wogegen, wenn von einem „mehrfachen Punkte“ einer „mehrfachen Wurzel“ einer Gleichung und dergleichen gesprochen wird, das Wort „mehrfach“ bereits metaphorisch — im übertragenen Sinne — steht für das genauere „mehrwiegend, mehrwichtig“, und trotzdem auch eine derartige Deutung in unsrer Theorie kaum zulässig erscheinen dürfte, weil eine Stelle doch immer nur als besetzt (und dann als „einfach besetzt“) oder als unbesetzt gedacht werden kann — trotzalledem bequeme ich mich gerne dem Verbesserungsvorschlage an, nicht nur weil die erwähnte übertragene Bedeutung des „mehrfach“ so wichtig für die Mathematik geworden und so verbreitet ist, dass sie die buchstäbliche Bedeutung fast verdrängt zu haben scheint, sondern vor allem auch wegen der grössern Kürze der dafür adoptirten Benennungen.
Eine Reihe, die gerade eine Leerstelle hat, sonst aber lauter Augen trägt, soll ebenso eine einlückige oder Einlück-Reihe genannt werden.
Weist eine Reihe mehr als eine Leerstelle auf, so heisse sie eine Mehrlückreihe.
Es zerfallen also auch die Lückreihen in einlückige und mehrlückige, und die Leerreihen gehören zu den letztern.
Eine Reihe kann auch mehrbesetzt und mehrlückig zugleich sein.
Sobald der Denkbereich mehr wie zwei Elemente umfasst, werden aber die Einlückreihen zu den mehrbesetzten zählen und die einbesetzten Reihen auch mehrlückige sein müssen.
Unter Benützung dieser Terminologie können wir nun die Ergebnisse der Koeffizientendiskussion kurz dahin statuiren:
Das Relativ a; 0' wird aus a erhalten, indem man alle mehrbesetzten Zeilen von a in Vollzeilen verwandelt, alle einbesetzten Zeilen von a in deren Negation (somit in Einlückzeilen) verkehrt und dessen Leerzeilen beibehält.
Um das Relativ 0'; a aus a abzuleiten, verwandle man alle mehrbesetzten Kolonnen von a in Vollkolonnen, die einbesetzten Kolonnen in deren Negation (mithin in Einlückkolonnen) und behalte die Leerkolonnen von a unverändert bei.
Es bleiben bei dem Prozesse auch hier die Vollkolonnen, oben die Vollzeilen von a unverändert.
Um a ɟ 1' zu bilden, behalte man die Vollzeilen von a unverändert bei, verwandle dessen Einlückzeilen in ihre Negation (also in einbesetzte Zeilen) und werfe die Mehrlückzeilen ab.
Das Relativ 1' ɟ a wird erhalten, indem man die Vollkolonnen von a beibehält, dessen Einlückkolonnen in ihre Negation (also in einbesetzte Kolonnen) verkehrt und alle Mehrlückkolonnen von a abwirft.
Hierbei werden auch die Leerkolonnen von a — gleichwie vorhin dessen Leerzeilen — ungeändert bleiben.
Auch diese Resultate sind zu merken, und werden wir zur Erleichterung dessen in § 15 noch weitre Unterstützung beibringen.
Um sich aufgrund von 19) von der Richtigkeit vorstehender hochwichtigen Angaben zu überzeugen, hat man — ich will es blos für die erste und für die letzte (vierte) Angabe durchsprechen — folgendes zu bedenken.
Es war (a; 0')i j = ai A + ai B + ai C + … (ohne ai j).
Für ein bestimmtes i, d. h. in einer bestimmten Zeile, ist dies gleich 1 bei jedem j, sobald mindestens zwei von den ai h gleich 1 sind.
Denn ist dann auch ai j vielleicht eines von diesen beiden, so wird wenigstens noch das andre als Glied der Summe rechts (ausserhalb und vor der letzten Klammer) auftreten.
a; 0' muss also eine Vollzeile haben überall da, wo a eine mehrbesetzte Zeile hat.
Ist dagegen die ite Zeile von a eine einbesetzte, gibt es also gerade ein j(= k), für welches ai j gleich 1 wird, sodass wir haben ai k = 1, während alle übrigen ai h gleich 0 sind, so wird unsre Summe den Term ai k der 1 ist aufweisen, somit selbst = 1 sein, für jedes von k verschiedene j. Und nur für j = k, wo das in der Klammer erwähnte, in der Summe fehlende ai j das einzige nicht verschwindende ai h ist, werden alle Glieder unsrer Summe und diese selbst = 0 sein.
Der einbesetzten Zeile von a entspricht hienach eine Einlückzeile des a; 0', welche erhalten wird, indem man das einzige Auge der Zeile von a in eine Leerstelle, alle Leerstellen dieser Zeile aber in Augen verwandelt.
Ist die mit i markirte Zeile von a eine Leerzeile, so sind alle ai h gleich 0, und — einerlei welches von diesen in unsrer Summe fehlt — wird die Summe stets = 0 sein; dann hat also auch a; 0' eine Leerzeile.
Ähnlich war (1' ɟ a)i j = aA jaB jaC j … (ohne ai j).
Dies Produkt ist bei bestimmtem j gleich 0 für jedes i, sobald mindestens zweie der ah j gleich 0 sind, d. h. also: wenn a eine Mehrlückkolonne bei j aufweist, erhält 1' ɟ a eine Leerkolonne.
Das Produkt ist gleich 1 bei jedem i, falls alle ah j gleich 1 sind, d. h. also:
wenn die jte Kolonne von a eine Vollkolonne war, erhält auch 1' ɟ a eine solche.
Blos wenn a bei j eine Einlückkolonne besitzt, mithin blos ein bestimmtes (es heisse ak j) von allen ah j verschwindet, während alle übrigen ah j gleich 1 sind, kommt es darauf an, ob jenes allein verschwindende ak j eben das als Faktor in unserm Produkte einzig fehlende ai j ist oder nicht.
Im letztern Falle ist das Produkt = 1, in allen andern Fällen = 0. D. h. der Einlückkolonne von a entspricht bei 1' ɟ a eine einbesetzte Kolonne, die gerade nur an der Stelle der einen Lücke von jener ein Auge trägt, sonst völlig leer ist, und die wir daher als die Negation jener Einlückkolonne am bequemsten charakterisiren. —
Ebenso wie a selbst können auch die mit a verwandten Relative ā, ă, ā̆ nach den Schemata 2) mit den Moduln relativ verknüpft werden.
Die Knüpfungsergebnisse sind im Allgemeinen sowol unter sich als von den bisherigen durchweg verschieden.
Und es ist eine namentlich bei dem Negat ā verlohnende Übung für den Anfänger, sich die Entstehungsweise von dessen irreduzibeln Modulknüpfungen aus a selber zum Bewusstsein zu bringen und mit Worten zu formuliren.
Dass übrigens die aus den Verwandtenknüpfungen hinzutretenden Relative nichts andres sein werden als Negate, Konverse und Strichkonverse von den bisher besprochenen Modulknüpfungen, geht aus der Anwendung der Sätze 9) bis 12) des § 6 auf die Fälle wo a oder aber b einen Modul vorstellt, in Verbindung mit 13) des Abacus in § 8 hervor — wonach wir haben: 20) [Formel] 21)
[Formel]
Hiermit ist nun auch Dasjenige erhärtet, was wir inbezug auf das Dualisiren und Konvertiren für den Fall des Auftretens von Moduln als Termen in § 6 vorgreifend angemerkt haben (S. 89 u. 92).
Von den zahlreichen Sätzen über unsre irreduzibeln Modulknüpfungen seien hiernächst nur diese noch angeführt: 22) [Formel] wo die der zweiten Zeile durch Kontraposition aus denen der ersten folgen.
Ersetzte man auf der einen Seite vom Mittelstrich das a durch ā, so könnte auch der Mittelstrich in ein Gleichheitszeichen verwandelt werden.
Beweis.
Ist jedes ai j = 0, so ist auch Σhai h = 0 und jedes (a; 1)i j = 0, also (a = 0) ⋹ (a; 1 = 0).
Ist umgekehrt jedes (a; 1)i j = 0, so muss nach 5) des § 8 zugleich mit der Summe Σhai h auch jeder Term ai h verschwinden, d. h. es muss auch jedes ai j gleich 0 sein, womit erkannt ist, dass auch (a; 1 = 0) ⋹ (a = 0), q. e. d.
Ebendies leuchtet aus der geometrischen Evidenz ohne weitres ein: soll ein Relativ a ≠ 0 sein, so wird seine Matrix mindestens ein Auge haben; dann hat aber a auch wenigstens eine besetzte Zeile sowol als Kolonne, und a; 1 mindestens eine Vollzeile, 1; a eine Vollkolonne, etc.
Soll das aus den Vollzeilen von a gebildete Relativ a ɟ 0 gleich 1 sein, so kann a nur lauter Vollzeilen haben und muss selber gleich 1 sein.
Etc.
Mit Rücksicht auf diese ihre Selbstverständlichkeit werden die Sätze 22) auch leicht zu merken sein.
§ 10. Erste 6 „ausgezeichnete“ Relative.
Sekundäre und höhere Modulknüpfungen eines allgemeinen Relativs a werden wir noch systematisch in’s Auge fassen.
Von jenen, den sekundären und zwar relativen Knüpfungen, nehmen wir hier aber eine kleine schon von Peirce entdeckte Gruppe voraus, weil dieselbe sich von bestimmendem Einfluss erweist auf die Gestaltung der beiden Hauptprobleme (der Elimination und Auflösung) in unsrer Algebra, von der es ratsam ist möglichst bald Kenntniss zu erlangen.
„Ausgezeichnet“ nenne ich solche Modulknüpfungen eines allgemeinen binären Relativs a, welche sich zwar nicht reduziren, vielmehr jederzeit von der Natur oder Annahme, Wahl, Bestimmung des a abhängig erweisen, welche indessen die merkwürdige Eigenschaft besitzen lediglich die beiden Werte 1 und 0 annehmen zu können — geradeso als ob sie selber Aussagen wären!
nur mit dem Unterschiede natürlich, dass 1 und 0 hier nicht als Aussagen, sondern als binäre Relative (die absoluten Moduln) zu deuten sein werden.
Von solcher Art sind von den sekundären Modulknüpfungen (nur) folgende sechse, die zwei Gespanne bilden, ein dyadisches und ein tetradisches: 1) 2)
[Formel]
1; a; 1 0 ɟ a ɟ 0
Der allgemeine Koeffizient zum Suffix ij ist hiefür nach den Festsetzungen:
3) 4)
[Formel] augenscheinlich unabhängig sowol von i als von j. Der Wert 1 oder 0, welcher einem solchen Koeffizienten für ein Wertepaar ij zukommt, wird demselben sonach für jedes Suffixum zukommen, und ist das zugehörige Relativ im ersten Falle gleich 1, im zweiten gleich 0, d. h. das Relativ ist, wie behauptet, ein „ausgezeichnetes“.
(1; a; 1)i j = Σh kah k (0 ɟ a ɟ 0)i j = Πh kah k
Die an den Koeffizientenausdruck zu knüpfende Diskussion nun, wann das Relativ den einen und wann den andern Wert annimmt, liefert leicht die folgenden höchst merkwürdigen Ergebnisse, deren Übersicht wir auch sogleich diejenigen einverleiben, die sich durch Kontraposition daraus ergeben und die ausgezeichneten Modulknüpfungen des Negates ā betreffen:
5) 6)
[Formel] .
(1; a; 1 = 1) = (a ≠ 0) = (0 ɟ ā ɟ 0 = 0)
(0 ɟ a ɟ 0 = 0) = (a ≠ 1) = (1; ā; 1 = 1)
(1; a; 1 = 0) = (a = 0) = (0 ɟ ā ɟ 0 = 1)
(0 ɟ a ɟ 0 = 1) = (a = 1) = (1; ā; 1 = 0)
Zu 5) haben wir die schon am Schlusse des vorigen Paragraphen unter 22) aufgeführten äquivalenten Formen der Aussagen nicht wieder hinzugefügt.
Stellt für den Augenblick r irgend ein „ausgezeichnetes“ Relativ vor, so ist nach dem Begriffe desselben: (r = 1) + (r = 0) = 1, (r = 1)(r = 0) = 0, somit 7)
(r = 1) = (r ≠ 0), (r = 0) = (r ≠ 1).
Bedenkt man dies, so kann der Beweis der Sätze 5), 6) schon ohne Zuhülfenahme der Koeffizientenevidenz aus 22) des § 9 mittelbar geführt werden wie folgt.
Es ist (1; a; 1 = 1) = (1; a; 1 ≠ 0) = (a; 1 ≠ 0) = (a ≠ 0), {1; (a ɟ 0) = 1} = {1; (a ɟ 0) ≠ 0} = (a ɟ 0 ≠ 0), was unmittelbar besagt, dass a Vollzeilen habe, indem die Gesamtheit der letztern eben das Relativ a ɟ 0 ausmacht — q. e. d.
Sehr zu empfehlen ist aber, dass der Studirende die gleichen Überzeugungen auch aus der Diskussion der Koeffizientenausdrücke 3), 4) schöpfe und dieselben mit der geometrischen Evidenz kontrolire.
Z. B.
Es stellt (1; a; 1)i j die Summe der sämtlichen Koeffizienten des Relativs a vor.
Diese ist dann und nur dann = 0, wenn alle Koeffizienten von a gleich 0 sind, d. h. wenn a = 0 ist.
Sobald dagegen auch nur einer von diesen Koeffizienten von 0 verschieden, = 1 ist, wird auch unsre Summe = 1 werden; geometrisch: sobald a auch nur ein Auge besitzt, verwandelt die Operation 1; a die Kolonne in welcher gedachtes Auge sich befindet, in eine Vollkolonne; dadurch sind im Relative 1; a sämtliche Zeilen zu besetzten Zeilen geworden, indem eine jede von ihnen mindestens in der vorerwähnten Kolonne ein Auge aufweist.
Die Operation (1; a); 1 verwandelt nunmehr die besetzten Zeilen des Relativs 1; a — mithin sämtliche Zeilen — in Vollzeilen, wodurch notwendig 1 herauskommt.
Den Rest überlassen wir dem Leser.
Die 6 ausgezeichneten Modulknüpfungen von ā erscheinen in 5) und 6) bereits untergebracht.
Da die Operation der Negation, auf die Werte 1 und 0 angewendet, nur ebendiese vertauscht, die Konversion sie ungeändert lässt, so muss auch Negat und Konverses von einem ausgezeichneten Relative wiederum ein ausgezeichnetes Relativ sein — und zwar ist gemäss 13) des § 8: 8) r = r̆.
In der That folgt aus 7) noch weiter hinzu: (r̄ = 0) = (r̄ ≠ 1), (r̄ = 1) = (r̄ ≠ 0)
(r̆ = 1) = (r̆ ≠ 0), (r̆ = 0) = (r̆ ≠ 1).
Durch die genannten beiden Operationen gewinnt man die ausgezeichneten Modulknüpfungen der Verwandten von a hinzu.
Diese können aber in ihrer Gesamtheit nur mit denen von a selber zusammenfallen — wie wir bezüglich des ā bereits gesehen haben.
Bezüglich des ă statuiren es die Formeln:
9) 10) [Formel] die sich mit Rücksicht auf 8) leicht aus 21) des § 9 ergeben.
1; a; 1 = 1; ă; 1 0 ɟ ă ɟ 0 = 0 ɟ a ɟ 0
Für später ist auch noch diese Bemerkung von Nutzen.
Für a = 0 nehmen alle sechs ausgezeichneten Relative 1), 2) nach dem Abacus den Wert 0, für a = 1 nehmen sie den Wert 1 an.
Ersetzt man also in irgend einem der 6 Relative 1), 2) das a durch ein ausgezeichnetes Relativ, z. B. durch eines von diesen 6 Relativen selber, so erhält man unfehlbar dieses wieder, oder:
Jedes der sechs ausgezeichneten Relative, genommen von einem ausgezeichneten Relative, erzeugt nur das letztere wieder, lässt ebendieses unverändert.
Z. B. es reduzirt sich: 1; 1; a; 1; 1 = 1; a; 1, 0 ɟ 0 ɟ a ɟ 0 ɟ 0 = 0 ɟ a ɟ 0, 0 ɟ 1; a; 1 ɟ 0 = 1; a; 1, 1; (0 ɟ a ɟ 0); 1 = 0 ɟ a ɟ 0, 0 ɟ 1; (0 ɟ a ɟ 0) = 0 ɟ a ɟ 0, 0 ɟ (1; a ɟ 0); 1 = 1; a ɟ 0, etc.
Es liegt die Frage nahe, ob alle „ausgezeichneten“ Relative aus Modulknüpfungen von der Form eines der sechs Peirce’schen sein müssen?
Obwol dies für deren grosse Mehrzahl zutrifft, werden doch unsre Forschungen über höhere Modulknüpfungen (in einer späteren Vorlesung) diese Frage verneinend entscheiden, und will ich vorgreifend erwähnen, dass auch diese vier tertiären Modulknüpfungen: sich als „ausgezeichnete“ Relative erweisen, welche ich demnach berechtigt bin als die meinigen zu bezeichnen.
0 ɟ 0'; (a ɟ 0)
1; (1' ɟ a; 1)
(0 ɟ a); 0' ɟ 0 (1; a ɟ 1'); 1
Ein ausgezeichnetes Relativ r muss nach Festsetzung (6) des § 3 mit jedem seiner Koeffizienten übereinstimmen, sonach gilt also auch:
Ein ausgezeichnetes Relativ ist gleich seinem allgemeinen Koeffizienten: 11) rh k = r.
Umgekehrt steht auch nichts im Wege die Koeffizienten ai j eines beliebigen Relativs a so anzusehen und bei allen Rechnungen geradeso zu behandeln als ob sie ebenfalls binäre Relative, nämlich unbestimmte ausgezeichnete Relative wären.
Bei solcher Auffassung bewegen wir uns dann mit unsern Überlegungen durchaus im Denkbereiche 12, zu dem die beiden Wahrheitswerte 1 und 0 selbst als die absoluten Moduln gehören.
Und dabei hätte uns einfach: 12) (ai j)h k = ai j zu gelten.
Nur inbezug auf die Konversion dürfte ein Umstand, der zur Vorsicht mahnt, nicht übersehen werden.
Während mit Festsetzung (13) des § 3 das Symbol ăi j, als gleichbedeutend mit (ă)i j, gleich aj i erklärt ist, kann die Operation der Konversion an dem [als binäres (ausgezeichnetes) Relativ betrachteten] Koeffizienten (r =)ai j nach 8) nichts ändern, d. h. es ist: 13) (ai j)͝ = ai j — weil eben 1̆ = 1 und 0̆ = 0 zu gelten hat.
Sonach muss (ai j)͝ von (ă)i j im Allgemeinen unterschieden werden.
Diese Auffassungen werden am Schlusse des § 25 noch weiter entwickelt und gefestigt.
Fünfte Vorlesung.
Das Auflösungsproblem in der Algebra der binären Relative.
§ 11. Gesamtaussage der Data eines Problems und allgemeinste Aufgabe.
Das Bemerkenswerteste unter den Ergebnissen des vorigen Paragraphen dürfte die in den Formeln 5) desselben sich offenbarende Thatsache sein, dass in unsrer Algebra jede Ungleichung mit der rechten Seite 0 oder 1 sich umformen lässt in eine Gleichung (von ähnlichem Charakter).
Die Schemata hiefür wollen wir nochmals hersetzen, aber nicht die dual entsprechenden nebeneinander, sondern diejenigen obenan, die man befolgen muss, wenn man die rechte Seite 0 bevorzugt; darunter setzen wir die Schemata, die zu befolgen sind, falls man vorziehen sollte mit Gleichungen der rechten (besser eigentlich linken) Seite 1 zu operiren: 1)
[Formel]
Diese Thatsache ist von grosser Tragweite und begründet einen Vorzug der Algebra der Relative vor dem identischen Kalkul, in welchem, wie wir früher gesehen haben (Bd. 2, S. 91 sq. und 180 sq.), Ungleichungen niemals in die Form von Gleichungen umgesetzt werden können und die Scheidung der Urteilsformen in „partikulare“ und universale“ eine endgültige ist.
Wie wir Bd. 2 in § 40 nachgewiesen haben, ist die allgemeinste Aussage als eine im Boole’schen Sinne „sekundäre“ aussagenrechnerisch aus lauter „primären“ Propositionen aufgebaut.
Eine primäre Proposition hat entweder die Form einer Subsumtion oder einer Gleichung — was auf dasselbe hinauskommt, indem die eine Form stets in die andre umgesetzt werden kann — oder aber der Negation einer solchen, das ist einer Unsubsumtion oder einer Ungleichung — welche wiederum in einander umsetzbar.
Im identischen Kalkul waren die Gleichungen resp. Ungleichungen anzusehen als statuirt zwischen Klassen oder Gebieten (Systemen) — hier: in unsrer Algebra, sind sie statuirt zu denken zwischen (binären) Relativen.
Gleichwie jede Gleichung (und Subsumtion), kann nun aber — schon im identischen Kalkul — auch jede Ungleichung (und Unsubsumtion) einerseits auf 0 oder 1 gebracht werden, und da letztere Propositionen nach solcher Vorbereitung gemäss 1) ebenfalls in Gleichungen umschreibbar sind, so ist klar dass in unsrer Algebra ohne jede Einschränkung Ungleichungen und Unsubsumtionen überhaupt in Gleichungen umgesetzt werden können.
Unbeschadet der Allgemeinheit können wir hier hinfort annehmen, dass die Gesamtaussage der Data eines Problems sich aussagenrechnerisch aus lauter (primären) Gleichungen aufbaue.
Nachdem die Negationen, die in einer Aussagenfunktion vorgeschrieben sein mögen, „ausgeführt“ (und die etwa dadurch eingeführten Ungleichungen auch ihrerseits in Gleichungen umgesetzt) sind, können nur noch (identische) Produkte und Summen solcher Gleichungen in Betracht kommen.
Im identischen Kalkul konnten zwar jene zu einer einzigen Gleichung vereinigt, diese aber nicht weiter zusammengezogen werden (ausgenommen natürlich da, wo alle vorkommenden Buchstaben „Aussagen“ vorstellten, also auf den Wertbereich 0, 1 beschränkt waren).
Einen weitern Vorzug unsrer Algebra begründet nun der Umstand: dass hier nicht blos Produkte, sondern auch Summen also Alternativen von Gleichungen sich jeweils in eine einzige Gleichung zusammenziehen lassen — ebenso nicht blos Summen, sondern auch Produkte von Ungleichungen (auch dann, wenn ihre Polynome oder beiden Seiten beliebige Relative vorstellen).
Dies beruht nächst den vorstehenden oder überhaupt den Formeln 5) des § 10 und den längst bekannten: 2)
[Formel] noch auf folgenden Sätzen:
3) 4) welche insgesamt von zweien leicht auf beliebig viele Terme auszudehnen und sofort dergestalt ausgedehnt zu denken sind.
0 ɟ a ɟ 0 + 0 ɟ b ɟ 0 = 0 ɟ a ɟ 0 ɟ b ɟ 0 1; a; 1 · 1; b; 1 = 1; a; 1; b; 1
(0 ɟ a ɟ 0)(0 ɟ b ɟ 0) = 0 ɟ ab ɟ 0 1; a; 1 + 1; b; 1 = 1; (a + b); 1
Nach 3) müssen wegen der Kommutativität identischer Knüpfungen die zwischen lauter relative Summanden 0 sowie die zwischen lauter relative Faktoren 1 eingestreuten Terme jeweils permutabel, muss deren Reihenfolge belanglos sein.
Was zunächst den Beweis dieser Sätze betrifft, so sind die Formeln 3) weiter nichts als die Anwendung eines allgemeinern Satzes, welcher lautet: 5)
a; 1 · 1; b = a; 1; b a ɟ 0 + 0 ɟ b = a ɟ 0 ɟ b.
Beweis der erstern Formel direkt:
Li j = (a; 1)i j(1; b)i j = Σhai h · Σkbk j = Σh kai hbk j = Ri j, q. e. d. Wegen der Assoziativität der relativen Knüpfungen ist nunmehr 1; a; 1 · 1; b; 1 = (1; a); 1 · 1; (b; 1) = (1; a); 1; (b; 1) = 1; a; 1; b; 1 und damit auch 3) gewonnen, q. e. d.
Die Sätze 4), bereits von Peirce gegeben, sind am bequemsten mittelbar aus 4) des § 6 zu beweisen, z. B. der rechts vom Mittelstriche wie folgt: L = (1; a); 1 + (1; b); 1 = (1; a + 1; b); 1 = {1; (a + b)}; 1 = R.
Nach diesen Sätzen 1) bis 4) erhalten wir nun zu obigem Zwecke der Zusammenziehung von Gleichungen (desgleichen Ungleichungen) unschwer die folgenden Schemata. 6)
[Formel] 7)
[Formel] 8)
[Formel] 9)
[Formel] .
Zur Begründung dieser Schemata ist bei 6) und 7) — welch letzteres durch Kontraposition aus 6) hervorgeht — keine weitre Bemerkung vonnöten.
Das Schema 8) wird man am bequemsten durch Kontraposition aus 9) ableiten, und um letzteres zu rechtfertigen, hat man z. B. links vom Mittelstriche: L = (0 ɟ ā ɟ 0 = 0)(0 ɟ b̄ ɟ 0 = 0) ‥ = (0 ɟ ā ɟ 0 + 0 ɟ b̄ ɟ 0 + ‥ = 0) = R nach 1), 6) und 3), q. e. d.
Wenn nun also in der Aussagenfunktion, welche die Gesamtaussage der Data eines Problemes vorstellt, gemäss dem Schema 8) alle Alternativen oder Summen von Gleichungen — mittelst Zusammenziehung in eine einzige Gleichung — sich beseitigen liessen, so können wir schliesslich nur mehr ein Produkt, das ist ein „System“ von koexistirenden oder simultanen Gleichungen vor uns haben.
Ein solches aber zieht sich nach längst bekannten Boole’schen Sätzen — vgl. 6) — vollends zusammen in, ist ersetzbar durch eine einzige Gleichung, die wir die vereinigte Gleichung des Systems genannt haben.
Damit ist der wichtige Satz gewonnen:
In der Algebra der binären Relative lässt jeder Komplex von Aussagen — so namentlich also auch die Gesamtheit der Data irgend eines Problems — sich zusammenziehn in eine einzige Gleichung, in welcher neben oder ausser ihrem einen Gleichheitszeichen andre Zeichen von „Umfangsbeziehungen (wie =, ⋹, ≠ etc.) nicht mehr vorkommen.
Auch die „sekundären Aussagen (im Boole’schen Sinne) sind hier reduzirbar auf eine „primäre“.
Die Gleichung kann nach Belieben mit der rechten Seite 0 oder 1 angesetzt werden, und wird ihr „Polynom“ alsdann sein: eine „Funktion im Sinne unsrer Algebra der Relative“ von all den Relativen, auf die sich die Teilaussagen bezogen, das heisst: ein Ausdruck, welcher aus ebendiesen Relativen und eventuell auch noch den Moduln unsrer Theorie lediglich vermittelst der sechs Spezies derselben aufgebaut erscheint.
Ist die Gleichung nicht auf 0 oder 1 gebracht, so gilt das nämliche von ihren beiden Seiten: jede von diesen muss eine „Funktion“ sein im genannten Sinne von den vorkommenden Argumenten.
Gedachte „Funktion“ ist selbst ein binäres Relativ und mag für den Augenblick f genannt werden.
Dann stellt sich also eine Gleichung von der Form f = 0 dar als die Einkleidung der Data des allgemeinsten in unsrer Theorie erdenklichen Problemes.
Ich werde diese als die „vereinigte Gleichung“ oder „Gesamtaussage der Data“ auch hier bezeichnen und wie in Bd. 1 bei den allgemeinen Betrachtungen, zu denen wir nachher überzugehen haben, den Ansatz mit der rechten Seite 0 bevorzugen.
Wenn man will, kann die Gleichung jeden Augenblick auch als eine Subsumtion mit dem Prädikate 0: f⋹ 0 hingestellt werden.
Des dem Gesagten dual Entsprechenden, dass man mit f̄ = 1 oder 1 ⋹ f̄ alles auch auf das Subjekt 1 hinausspielen könne, thun wir künftighin als einer selbstverständlich mitgegebnen Sache zumeist nicht mehr Erwähnung.
Das Polynom f unsrer vereinigten Gleichung kann aus lauter bereits (anderweitig) völlig bestimmten, etwa spezifizirt von vornherein gegebenen oder kurzweg „bekannten“ Relativen — zu derengleichen auch die vier Moduln unsrer Theorie zu zählen sind — aufgebaut sein, oder es kann auch unbestimmte (oder Buchstaben-) Relative als Terme (Operationsglieder, Argumente) enthalten.
Im ersten Falle ist die Gleichung f = 0 einfach entweder wahr (richtig) oder unwahr (falsch).
Dann kann man nämlich das Relativ f — wegen der eindeutigen Ausführbarkeit sämtlicher in seinem Ausdruck vorgeschriebenen Operationen — wirklich „ausrechnen“ (indem man alle seine Koeffizienten, womöglich mit einem Schlage seinen allgemeinen Koeffizienten, ermittelt).
Stellt sich als Wert von f (mithin von jedem seiner Koeffizienten) in der That 0 heraus, dann war die Gleichung f = 0 richtig indem sie auf 0 = 0 hinausläuft; dieselbe vorauszusetzen oder zu behaupten bleibt dann zulässig, wenn auch die Voraussetzung eine inhaltsleere oder nichtssagende (selbstverständliche) genannt werden mag (ihre Selbstverständlichkeit oder Gültigkeit nachzuweisen kann indess recht mühsam sein).
Erweist sich dagegen der Wert von f als von 0 verschieden (indem sich mindestens ein Koeffizient von f als = 1 herausstellt), so war die Gleichung f = 0 falsch und bleibt sie als Annahme wie als Behauptung unzulässig.
Als Annahme oder Voraussetzung kann sie höchstens provisorisch zugelassen werden zu dem Zwecke, um durch etwa aus ihr zu ziehende absurde Folgerungen „apagogisch“ gerade ihre endgültige Verwerflichkeit nachzuweisen.
Wir mögen die Gleichung f = 0 dann auch selbst eine „absurde oder widersinnige nennen, und als das Urbild, ja den Repräsentanten aller absurden Gleichungen das aus dem identischen Kalkul bekannte Schema 1 = 0 auch für unsre umfassendere Disziplin (der Theorie der Relative) beibehalten.
Letzteres trifft in der That in einem dreifachen Sinne zu.
Mit der Behauptung f = 0 ist erstlich 1 = 0 gefordert für die erwähnten von 0 verschiedenen Koeffizienten des f. Zweitens indem sich bei der „Ausrechnung“ f ≠ 0 herausstellte, ist die Geltung von (f ≠ 0) = 1 und damit die von (f = 0) = 0 gesichert.
Die Behauptung f = 0, d. h. also (f = 0) = 1 müsste somit zu dem Widerspruche 1 = 0 (als Aussagenäquivalenz verstanden) führen.
Endlich aber drittens kann, falls f ≠ 0 ist, aus der Gleichung f = 0 sofort auch die Gleichung 1 = 0, gedeutet als solche zwischen binären Relativen, nämlich als Gleichsetzung der absoluten Moduln 1 und 0, mit Leichtigkeit abgeleitet werden und zwar indem man beiderseits mit 1 relativ vor- und nachmultiplizirt, also aus f = 0 auf 1; f; 1 = 1; 0; 1 — das gibt nach 1) dann eben: 1 = 0 — schliesst.
Um z. B. sei es aus der Behauptung 1' = 0, sei es aus der 0' = 0 auf die Form 1 = 0 zu kommen, genügt es schon, mit 1 beiderseits relativ nachzumultipliziren.
Es kann somit 1' = 0 oder 0' = 0 in 1 = 0 transformirt werden, gleichwie auch umgekehrt wegen 1 = 1' + 0' mit 1 = 0 auch 1' = 0 und 0' = 0 gegeben wäre.
Die Gleichungen 1' = 0 (z. B.) und 1 = 0 sind damit als äquivalent erwiesen und wird jene ebenso wie diese „absurd“ zu nennen sein.
Ein Problem (sei es der Auflösung, sei es der Elimination) kann uns in dem bis jetzt betrachteten „ersten“ Falle nicht erwachsen.
Anders im „zweiten“ Falle, dem, wo unbestimmte Relative in dem Ausdrucke des Polynoms f der Gleichung f = 0 vorkommen.
Durch den blossen Ansatz der Gleichung, indem man ebendiese „f = 0“ auch nur ausspricht oder hinstellt, sei es als eine (bedingte oder unbedingte) Behauptung, sei es um sie zur Voraussetzung einer Untersuchung zu erheben, mutet man dem Leser zu und verpflichtet sich selbst: unter den Buchstaben, welche als Namen von unbestimmten Relativen in der Gleichung vorkommen, sich ein solches System von Werten zu denken oder vorzustellen, für welches die Gleichung wahr ist.
Jedes System von spezifizirten Relativen, welches für jene unbestimmten Relativsymbole in die Gleichung eingesetzt derselben „genügt“, sie „erfüllt“, d. h. eben wahr macht, heisst bekanntlich ein System von „Wurzeln“ der Gleichung, und sofern es sich um die Entdeckung eines Systems von Wurzeln handelt, werden jene unbestimmten Relative auch „Unbekannte“ genannt, als „die Unbekannten“ bezeichnet.
Die Ermittelung eines Systems von Wurzeln heisst „eine Auflösung der Gleichung, und die Ermittelung (zuweilen auch blos die Angabe) aller möglichen Systeme von Wurzeln derselben wird die allgemeine (oder vollständige Auf-) Lösung der Gleichung zu nennen sein.
Also: mit der Gleichung ist von selbst schon die Anforderung aufgestellt und die Verpflichtung erwachsen, dieselbe nach den in ihr vorkommenden unbestimmten Relativen als „Unbekannten“ „aufzulösen“; die Gleichung involvirt, statuirt uns ein Problem.
Hierbei können zwei extreme oder Grenz-Fälle vorkommen:
Einerseits der Fall, wo es gar kein System von Wurzeln gibt.
In diesem Falle ist durch die Gleichung eine Anforderung gestellt, welche unmöglich zu erfüllen ist, die Aufgabe bleibt unlösbar und die Gleichung unzulässig (ihre „Wurzeln“ — falls man noch von solchen sprechen will hier, wo es gar keine gibt, während sie allerdings doch bereits in Gestalt von x, ‥ Namen besitzen, sozusagen voreilig erhalten haben — wären im Gebiet der Relative „undeutig“, d. i. eben deutungsunfähig, zu nennen).
Wir sagen in solchem Falle: „die Resultante der Elimination“ sämtlicher Unbekannten aus der Gleichung, oder auch irgendwelcher von ihnen, sei die „absurde“ 0, nämlich die Gleichung 1 = 0, und wir dürfen auch die Gleichung f = 0 selber „absurd“ nennen, desgleichen sie als eine „Inkonsistenz“ (im weiteren Sinne des Worts) bezeichnen.
Andrerseits kann der Fall vorkommen, wo jedes System von (ebensoviel) Relativen (als wieviel Unbekannte vorhanden sind) auch ein System von Wurzeln ist, nämlich die Gleichung f = 0 erfüllt.
In diesem Falle nennen wir die Gleichung eine „allgemeingültige“, „analytische“, „selbstverständliche“, auch eine „Identität“, oder eine Formel [— in jedem andern Fall dagegen eine „synthetische“], ihre Wurzeln bleiben unbestimmt, resp. willkürlich, beliebig, arbiträr.
Auch sagen wir: die „Resultante“ der Elimination sämtlicher Unbekannten (oder auch irgend welcher von ihnen) aus der Gleichung sei 1, sive 0 = 0, oder auch: die Gleichung f = 0 liefere „keine Resultante“.
Und von der Gleichung f = 0 selber sagen wir, sie sei „nichtssagend“, laufe auf ebendiese Behauptung 0 = 0 hinaus; sie liefert dann in der That keine Bestimmung, gewährt keinerlei Information über die in ihr vorkommenden unbestimmten Relative.
Für die beiden hiernach auf die Resultante 1 = 0 resp. 0 = 0 führenden Grenzfälle kann man sagen, dass bei jeder Elimination sämtliche Unbekannte „aus der Gleichung f = 0 herausfielen“.
Auch in diesen beiden Grenzfällen, welche es (ungeachtet des Epithetons der Selbstverständlichkeit beim einen) oft gar nicht leicht ist als solche zu erkennen und nachzuweisen, liegt noch kein wirkliches Auflösungsproblem vor.
Dagegen tritt ein solches in jedem andern Falle in Kraft, und mit seinesgleichen wollen wir uns nunmehr eingehend beschäftigen.
Darnach ist den fernern Betrachtungen jetzt die Voraussetzung zugrunde zu legen:
es gebe im Bereich der binären Relative zwar mindestens ein System (eventuell auch viele Systeme) von Werten, welche unter den in der Gleichung vorkommenden „Unbekannten“ x, y, z, ‥, a, b, … bezüglich verstanden, die Gleichung wahr machen, aber die Werte dieser Buchstaben dürfen, wofern die Gleichung erfüllt sein soll, doch auch nicht allesamt ganz nach Belieben angenommen werden — m. a. W. die Gleichung sei weder absurd, noch eine Formel, indem sie vielmehr eine wirkliche Beziehung, „Relation“, zwischen den sämtlichen Unbekannten statuirt resp. zu erfüllen fordert.
„Relation zwischen -“ hier im weitesten Sinne verstanden.
Die Relation kann auch „zerfallen“ in zumeist wol einfachere und schliesslich nicht mehr zerfallende Relationen (Relationen im engeren Sinne) zwischen denjenigen Unbekannten blos, welche dann noch in sie eingehen.
Geht aber in eine solche „Relation“ nur mehr eine Unbekannte ein — wie z. B. wenn sich x ⋹ 0' ergeben hätte —, so erscheint allerdings der Ausdruck „Relation zwischen x, y, z, ‥“ deplacirt und wäre durch den Ausdruck Relation für x“ ersetzt zu denken.
Die damit statuirte Beziehung wäre dann eben eine uninäre.
Es wäre aber wol zu umständlich, wollten wir allgemein immerfort von „Relationen zwischen den und eventuell für die Unbekannten“ reden.
Obendrein erscheint die Distinktion für unsre Theorie unwesentlich, weil sich in ihr gerade mittelst der Gesamtaussage die Ausartungsfälle wenigstens äusserlich dem allgemeinen Falle einordnen, nämlich auch die Systeme und Alternativen von „zerfallenden“ Relationen sich formal als eine Relation zwischen sämtlichen Unbekannten darstellen lassen.
Heben wir alsdann unter den Unbekannten irgend eine — x möge sie heissen — hervor, so kann in Hinsicht der übrigen Unbekannten y, z, ‥ a, b, … nur einer von diesen zwei Fällen vorliegen:
Entweder diese letzteren können samt und sonders nach Belieben angenommen werden, indem es zu jedem System von Werten, welches denselben beigelegt werden mag, einen Wert oder Werte von x gibt, welche mit ihm zusammen ein „System von Wurzeln“ der Gleichung f = 0 bilden.
Oder solches trifft nicht zu.
Im ersten (Unter-)Falle sagen wir, die Elimination der Unbekannten x aus der Gleichung f = 0 liefere „keine“ Resultante, oder „die Resultante dieser Elimination“ sei die Gleichung 0 = 0, aus der Gleichung seien mit x zugleich die sämtlichen Unbekannten „herausgefallen“ und zwischen jenen übrigen Unbekannten bestehe keinerlei Relation, dieselben seien unbeschränkt allgemeine Relative („Parameter“).
In der That mögen wir dann diesen letztern ein willkürliches Wertsystem beilegen und wird es nur noch darauf ankommen die zugehörigen Werte von x zu ermitteln, welche mit ihm zusammen ein System von Wurzeln bilden, m. a. W. die Unbekannte x durch die übrigen Unbekannten auszudrücken.
Soferne solcher Fall sich als zutreffend hat nachweisen lassen liegt alsdann ein „reines“ Auflösungsproblem vor, und zwar dasjenige der Auflösung der Gleichung f = 0 nach der einen Unbekannten x; dann ist diese Gleichung als eine „unbedingt auflösbare“ erkannt und mögen wir alsbald zu ihrer Auflösung schreiten.
Im zweiten (Unter-)Falle gibt es gewisse Wertsysteme (mindestens eines), welche den Unbekannten y, z, ‥, a, b, … nicht beigelegt werden dürfen weil es zu denselben keinen Wert von x gibt, mit dem zusammen sie ein System von Wurzeln vorstellen würden.
Jede Aussage, die wahrheitsgemäss ein Wertsystem von y, z, ‥, a, b, … als unzulässig hinstellt, „ausschliesst“, lässt sich alsdann als eine „Relation zwischen diesen übrigen Unbekannten ansehen, wenn man will auch wieder in Form einer Gleichung darstellen, und darf dieselbe, weil sie durch die Gleichung f = 0 bedingt wird (zur Erfüllung ebendieser unerlässlich ist), in ihr aber der Name der Unbekannten x nicht vorkommt, als „eine Resultante der Elimination von x aus der Gleichung f = 0“ bezeichnet werden.
Die vereinigte Gleichung, Gesamtaussage aller Resultanten (der Elimination von x aus f = 0) aber muss nicht nur eine notwendige sondern auch hinreichende Bedingung sein für die Auflösbarkeit der Gleichung f = 0 nach der Unbekannten x; wir nennen sie „die“ vollständige oder „volle Resultante“ gedachter Elimination.
Dieselbe schliesst alle unzulässigen Wertsysteme der übrigen Unbekannten y, z, ‥, a, b, … aus.
Jedes ihr genügende Wertsystem dieser Unbekannten ist ein „zulässiges“, welches mit gewissen Werten von x zusammen ein System von Wurzeln der Gleichung f = 0 liefert, und sie kann auch charakterisirt werden als eine solche Relation zwischen den Unbekannten ohne x, welche von der Gleichung f = 0 bedingt wird und deren Erfülltsein die Auflösbarkeit „nach x“ der Gleichung f = 0 garantirt, d. h. uns die Existenz von mindestens einem dieser Gleichung genügenden Wurzelwerte x verbürgt; sie statuirt die „Valenzbedingung“ für x.
Da wir uns die Auflösung der Gleichung f = 0 nach der Unbekannten x natürlich blos vornehmen können für solche Fälle, wo die Gleichung auflösbar ist, wo es Werte von x geben kann, die ihr genügen, so muss ihrer Auflösung nach x diesmal voraufgehen: die Ermittelung und die Erfüllung ihrer (vollen) Resultante (der Elimination von x).
Jene ist als ein Eliminationsproblem zu bezeichnen.
Diese, die Aufgabe erst einmal unsre Resultante zu erfüllen, stellt sich wiederum als ein Auflösungsproblem dar, bei welchem es sich aber um (allermindestens) eine Unbekannte (x) weniger handelt.
Es hat sich unser ursprüngliches Auflösungsproblem verschoben und ist an seine Stelle zunächst ein einfacheres getreten.
Für letzteres treten dieselben Grundsätze in Kraft, die wir für das ursprüngliche Problem aufgestellt haben und noch aufstellen werden.
Man wird der Resultante etwa durch geeignete Bestimmung irgend einer von den noch in ihr verbliebenen (bei der Elimination des x aus f = 0 nicht mit x zugleich herausgefallenen) Unbekannten zu genügen suchen, indem man strebt, sie als Funktion der andern darzustellen.
Dabei kann sich jedoch abermals eine Resultante ihrer Elimination ergeben, welche dann erst ebenso weiter zu behandeln sein wird.
Etc.
Das Ergebniss, zu welchem wir in dem betrachteten zweiten Unterfalle gelangt sind, lässt sich nun folgendermassen formuliren und zugleich auch auf den ersten Unterfall sowie auf die beiden vorher betrachteten Grenzfälle mitausdehnen, mithin als ein ganz allgemein zutreffendes hinstellen:
In der Algebra der Relative ist (gleichwie schon im identischen Kalkul) jedes Auflösungsproblem untrennbar verbunden mit einem Eliminationsprobleme; die Auflösung einer Gleichung nach einer (oder auch einem System von) Unbekannten kann vernünftigerweise nicht in Angriff genommen werden bevor die volle Resultante der Elimination ebendieser Unbekannten ermittelt und ihrerseits nach allen übrigen (resp. den noch in ihr vorkommenden) Unbekannten aufgelöst ist; sie erheischt zunächst den Vollzug jener Elimination als eine vorgängige oder präliminare Aufgabe.
Unter diese letztere subsumiren sich in der That auch unsre Ergebnisse bei den übrigen Fällen, insofern der Nachweis für das Fehlen einer Resultante sich auch hinstellen liess und von uns hingestellt wurde als die Herleitung einer Resultante 0 = 0 (d. h. die Erbringung des Beweises, dass „die Resultante“ blos auf 0 = 0 hinausläuft), und ferner der Nachweis für die Unmöglichkeit der Auflösung, oder die Absurdität der Gleichung f = 0, auch angesehen werden mochte als ein Nachweis, dass die Resultante auf 1 = 0 hinausläuft.
Auch die vorerwähnten schon als zuweilen schwierige gekennzeichneten Probleme werden sich demnach unter dem Titel des Eliminationsproblemes mit zu erledigen haben.
Setzen wir vorderhand die Menge der in der Gleichung f = 0 vorkommenden unbestimmten Relative oder „Unbekannten“ als eine begrenzte (ihre Anzahl als eine „endliche“) voraus, so verbleiben uns diese beiden Hauptaufgaben:
Erstens aus einer Gleichung eine Unbekannte zu eliminiren.
Zweitens sofern „die“ Resultante ihrer Elimination erfüllt ist, eine Unbekannte aus der Gleichung „zu berechnen“, d. h. die Gleichung allgemein nach ihr aufzulösen.
Gesetzt diese beiden Probleme der Elimination von einer und der Auflösung nach einer Unbekannten vermöchten wir in jedem Falle zu bewältigen, so werden wir auch jeder Forderung f = 0, die nicht absurd ist, allgemein zu genügen imstande sein:
Man eliminire in beliebiger Folge eine Unbekannte nach der andern bis sie alle „herausgefallen“ sind und man zur Resultante 0 = 0 gelangt ist.
Dies wird spätestens bei der Elimination der letzten Unbekannten eintreten.
Mit der Elimination von einer bestimmten Unbekannten können nämlich auch noch verschiedene andre Unbekannte (die man vielleicht gar nicht zu eliminiren beabsichtigte) zugleich herausfallen — wie wir es bereits in den beiden „Grenzfällen“ wahrnehmen konnten, wo sie ja sämtlich herausfielen.
„Die“ Resultante der Elimination eines x „führt“, „enthält“ als Term, Operationsglied oder Argument, zuverlässig diesen Eliminanden nicht; es können aber auch noch irgend welche andre von den Unbekannten in ihr unvertreten sein oder fehlen, welche in der zum Ausgangspunkt der Elimination genommenen Gleichung vertreten waren.
Man erhält dadurch eine Reihe von Resultanten, deren jede sicher eine oder vielleicht mehrere Unbekannte weniger als ihre Vorgängerin enthält.
Die ursprüngliche Gleichung f = 0 selber mag dabei als „nullte Resultante“ bezeichnet werden, während wie gesagt die Identität 0 = 0 als deren „letzte“ hinzustellen ist.
Das Erfülltsein irgend einer R' von diesen Resultanten ist notwendige und hinreichende Bedingung dafür, dass ihre unmittelbare Vorgängerin R auflösbar sei nach irgend einer von den Unbekannten, die bei der Elimination aus ihr herausgefallen sind, welche also in R' nicht mehr, wohl aber noch in R vorkommen.
Während die übrigen von diesen „überschüssigen“ Unbekannten beliebig angenommen werden können, braucht man behufs Erfüllung von R, sobald R' erfüllt ist, immer nur nach einer von jenen die R aufzulösen, m. a. W. eine von diesen überschüssigen Unbekannten durch die andern (und die bereits aus R' bestimmten) Unbekannten auszudrücken, welche erstern ihrerseits dann unbestimmt bleiben werden.
Daraus ergibt sich die Vorschrift, den Resultanten fortschreitend zu genügen in der umgekehrten Reihenfolge von derjenigen in welcher sie durch die successiven Eliminationen gewonnen worden sind.
Man genüge also zuerst der vorletzten Resultante mittelst Auflösung derselben nach irgend einer von den in ihr verbliebenen Unbekannten, indem man wie gesagt die übrigen von diesen, und die etwa sonst noch aus ihrer Vorgängerin herausgefallenen Unbekannten unbestimmt lässt; sie muss unbedingt auflösbar sein, weil die letzte Resultante 0 = 0 ja sicher erfüllt ist.
Man setze das so gewonnene System von Wurzelwerten für die in Betracht gekommenen Unbekannten in alle vorhergehenden Resultanten (mithin bis einschliesslich zur Gleichung f = 0) ein, um alsdann ebenso mit der nächstvorhergehenden Resultante zu verfahren und so weiter, bis man die Gleichung f = 0 selber nach der zuerst eliminirten Unbekannten aufgelöst hat. —
Durch die vorstehenden Betrachtungen erscheint es gerechtfertigt, dass wir uns im folgenden immer nur mit den anscheinend so sehr viel spezielleren Problemen der Elimination und Auflösung beschäftigen bei denen sich alles nur um ein Relativ als Eliminanden oder Unbekannte dreht.
Zum Schlusse noch ein paar Bemerkungen.
Beispiele wird die Theorie genugsam bringen.
Es möge entschuldigt werden, dass wir vorstehend einige Betrachtungen dem Wesen nach wiederholten, die wir analog schon in Bd. 1, § 22 für den identischen Kalkul mit seiner soviel geringeren Tragweite angestellt resp. nur gestreift haben.
Man sieht, dass zwischen den als allgemeine „gegeben“ zu denkenden und den gesuchten Relativen kein prinzipieller Unterschied besteht.
Auch jene, die „Parameter“ (z. B. Polynomkoeffizienten a, b, c …, etc.) des Problems, sofern sie nicht etwa „spezifizirt“ (d. h. als spezielle Relative) gegeben sind, müssen von vornherein als „Unbekannte“ betrachtet und ganz ebenso wie diese x, y, … behandelt werden.
Woran es liegt, dass in dieser Hinsicht unsre Disziplin in einem Gegensatz zur arithmetischen Analysis steht, wird sich der denkende Leser leicht klar zu machen vermögen.
§ 12. Allgemeine und rigorose Lösungen.
Es möge 1) F(x) = 0 eine nach einer Unbekannten x aufzulösende Gleichung sein, welche „auf lösbar“ ist, d. h. also mindestens eine Wurzel x besitzt.
Kommen ausser x noch andre unbestimmte Relative in der Gleichung vor, und involvirt die Gleichung eine Relation zwischen den letztern (welche als „die Resultante“ der Elimination von x aus ihr zu bezeichnen wäre), so stellen wir uns etwa vor, dass diese Relation durch geeignete Bestimmung jener übrigen Buchstabenrelative erfüllt worden sei und ebendadurch unsre Gleichung zu einer auflösbaren gemacht ist.
Die Gleichung 1) soll also als eine unbedingt auflösbare gedacht werden; ihre Auflösbarkeit nach x darf nicht mehr an die Bedingung des Erfülltseins einer (von x freien) Resultante geknüpft sein, oder: die Elimination von x aus ihr darf keine Resultante mehr liefern.
Unter der „vollständigen“ Auflösung nach x der Gleichung 1) verstehen wir (S. 156) die Angabe aller Relative, welche, für x eingesetzt, die Gleichung kraft der Gesetze der relativen Algebra erfüllen, gesondert von allen Relativen, die sie nicht erfüllen.
Jene Relative — das sind die „Wurzeln“ der Gleichung — kann man theoretisch sowol als praktisch stets in einen einheitlichen Ausdruck zusammenfassen, welcher sie alle und nur sie unter sich begreift und darum „die allgemeine Wurzel (oder Lösung)“ der Gleichung zu nennen sein wird.
Über diese letztere beabsichtigen wir nunmehr, ein paar fundamentale Sätze aufzustellen und zu begründen, welche unsrer ganzen Disziplin zum einen Teile ihren eigentümlichen Charakter aufprägen.
Ich behaupte erstens:
Die allgemeine Wurzel der Gleichung 1) lässt sich stets in der Form angeben: 2) x = f(u), worin u ein unbestimmtes Relativ vorstellt, welches als willkürlich oder arbiträr zu bezeichnen ist soferne über die Unbekannte x keine andern Bestimmungen vorliegen als die, dass sie die Gleichung 1) zu erfüllen habe, worin ferner f eine gewisse „Funktion im Sinne der Algebra der binären Relative“ bedeutet.
Diese Funktion f ist — sei es gleich von vornherein gesagt — durch die gegebene F, welche das Polynom der aufzulösenden Gleichung bildet, mehr oder weniger bestimmt, genauer gesagt: im Allgemeinen „nicht völlig oder „nur unvollkommen“ bestimmt, so zwar, dass man bei unbegrenztem Denkbereiche in der Regel noch unter unendlich vielen Funktionen f die Wahl hat, welche nicht etwa blos „formell“ nach der äusserlichen Gestaltung ihres Ausdrucks verschieden erscheinen, sondern „wesentlich“ verschieden sind insoferne sie oft für den gleichen Wert von u ganz verschiedene Wurzeln x der Gleichung 1) „liefern“, d. h. mit ihrem Funktionswerte darstellen.
Man wird also noch in vielerlei Sinne von einem Ausdrucke für die allgemeine Wurzel — oder von „der“ allgemeinen Lösung — der Gleichung 1) sprechen können, und erst die Gesamtheit aller Bedeutungen von f(u), diese Funktion gebildet, berechnet gedacht für alle erdenklichen Werte von u, wird in allen diesen Fällen die nämliche sein, sich nämlich decken mit der Klasse aller, dem Inbegriff sämtlicher Wurzeln x, welehe die Gleichung 1) zulässt.
Ich behaupte zweitens: dass jede allgemeine Lösung f(u) der Gleichung 1) ausreichend charakterisirt ist durch die Aussagenäquivalenz: 3)
[Formel] , worin die Summe rechts sich zu erstrecken hat über alle erdenklichen Relative u innerhalb 12.
Und drittens behaupte ich: dass man einer Funktion f, welche gemäss 3)
[und zum Überfluss auch 2)] „eine allgemeine Lösung“ — d. h. ausschliesslich sämtliche Wurzeln — der Gleichung 1) darzustellen fähig und bestimmt ist, auch noch gewisse andre Anforderungen auferlegen kann, die ich als „adventive“ bezeichnen werde, weil sie keineswegs schon im Begriffe der allgemeinen Lösung liegen.
Namentlich aber: dass man theoretisch sowol als praktisch die allgemeine Lösung f stets in einer solchen Form aufstellen könne, dass sie die nachstehende „(erste) Adventivforderung“ erfüllt: 4)
{F(x) = 0} = {f(x) = x}, die sich in praktischer Hinsicht vorzugsweise empfiehlt, ja als eine eminent zweckmässige aufdrängt.
Die Begründung dieser Behauptungen wollen wir damit beginnen zu zeigen, dass die Äquivalenz 3) den Begriff von f(u) als der allgemeinen Wurzel der Gleichung 1) ausdrückt.
Soll ein Ausdruck 2) diese allgemeine Wurzel darstellen, so muss er in der That zwei Eigenschaften besitzen.
Erstens muss er für jeden Wert von u eine richtige Wurzel x unsrer Gleichung F(x) = 0 liefern, sodass also identisch: 5) F{f(u)} = 0 ist, m. a. W. diese Gleichung für ein beliebig gelassenes Relativ u als eine allgemeine Formel gilt.
Das heisst auch:
unser Ausdruck 2) darf nur Wurzeln unsrer Gleichung 1) liefern.
Den Nachweis, dass solches bei einer bestimmten Funktion f(u) zutrifft, nennen wir „die Probe 1“ dafür, dass ebendiese Funktion die allgemeine Lösung der Gleichung 1) darstelle.
Vollständiger als durch 5) wird diese Forderung regelrecht durch den Ansatz auszudrücken sein 6)
[Formel] , was in der That besagt: für jedes u muss, wenn der Wert von f(u) mit x bezeichnet wird, F(x) = 0 sein.
Wird in 6) für x durchweg der Name f(u) gebraucht, den die Voraussetzung, Hypothesis, der Bedingungssatz der in [ ] stehenden Aussagensubsumtion dafür einführt, so erfüllt sich jene als eine Identität, erhält mithin den Aussagenwert {f(u) = f(u)} = 1.
Nach dem „spezifischen Prinzip des Aussagenkalkuls (1 ⋹ A) = A, wie wir es in Bd. 2 genannt haben, wird damit die Behauptung, Thesis, der Folgesatz ebendieser Aussagensubsumtion zu einer schlechthin gültigen, d. h. die Formel 6) zieht sich zusammen in: 7)
[Formel] , was nichts andres ist als die ausdrucksvoller geschriebene Formel 3) — diese nämlich in Verbindung mit dem ihr oben beigefügten verbalen Zusatze zum Ausdruck gebracht.
Umgekehrt folgt aus 7), indem man für f(u) den Namen x einführt, auch wiederum 6), sodass diese beiden Aussagen 6) und 7) [d. h. auch 5) als allgemeingültige Formel verstanden] als äquivalent und äquipollent zu erachten sind.
Weil nun aber in 6) das Prädikat der Aussagensubsumtion in der eckigen Klammer [] unabhängig von, konstant in Hinsicht der Produktationsvariabeln u ist, so lässt sich nach bekanntem Satze [nämlich gemäss Th. 3+) des Bd. 1] diese 6) äquipollent umschreiben in: 8)
[Formel] .
Ist diese Forderung allein erfüllt, ohne die sogleich zu erwähnende folgende, so werden wir sagen: x = f(u) stelle eine „partikulare“ Lösung der Gleichung F(x) = 0 vor, auch dann, wenn diese Lösung noch von grosser Allgemeinheit ist und vielleicht unendlich viel verschiedene Wurzeln liefert.
Zweitens aber muss unser Ausdruck f(u) auch imstande sein, jede Wurzel x unsrer Gleichung 1) zu liefern, d. h. wenn x irgendwie ein gegebenes Relativ vorstellt, derart jedoch, dass es die Gleichung F(x) = 0 erfüllt, so muss es auch ein Relativ u geben, für welches unser f(u) gerade gleich diesem x wird.
Diese Forderung drückt regelrecht der Ansatz aus: 9)
[Formel] .
Den Nachweis bei einer bestimmten Funktion f(u), dass sie diese Forderung 9) erfülle, nennen wir „die Probe 2“ dafür, dass dieses f(u) die allgemeine Lösung der Gleichung 1) vorstelle.
Die beiden Forderungen 8) und 9) besagend, dass der Ausdruck f(u) nur Wurzeln aber auch jede Wurzel der Gleichung 1) „liefere oder unter sich begreife, sind nun aber notwendige und hinreichende Bedingung dafür, dass man f(u) die allgemeine Lösung der Gleichung 1) zu nennen berechtigt sei, sie charakterisiren ein f(u) als „die allgemeine Wurzel“ von 1).
Diese beiden Aussagensubsumtionen 8), 9) ziehen sich jedoch als vor- und rückwärtige äquipollent zusammen zu der Aussagengleichung 3), welche hienach, wie (unter „zweitens“) behauptet worden, weiter nichts als wie den Begriff von 2) als der „allgemeinen Lösung“ von 1) formulirt, q. e. d.
Um in der Begründung unsrer Behauptungen fortzufahren, so besteht deren Hauptstück nunmehr in folgendem:
Wir setzten die Gleichung 1) als auflösbar voraus; demnach hat sie mindestens eine Wurzel.
Eine solche sei das Relativ a, so wird also — nicht blos als eine erst noch zu erfüllende Vorschrift, sondern von vornherein wirklich — 10) F(a) = 0 sein — wogegen für ein auf’s Gerathewohl angenommenes x im Allgemeinen F(x) ≠ 0 sein wird, und die Gleichung F(x) = 0 nicht als erfüllt, sondern als „eine Vorschrift“ anzusehen ist, welche erst durch geeignete Bestimmung des x erfüllt werden müsste.
Bildet man nun den Ausdruck 11) f(u) = a · 1; F(u); 1 + u · {0 ɟ F̅(u)̅ ɟ 0}, so muss in der That: x = f(u) eine der Anforderung 3) genügende Form der allgemeinen Lösung von 1) sein.
Beweis.
In Anbetracht, dass nach 1) des § 11 das Relativ [Formel] und dass umgekehrt das Relativ [Formel] , sieht man sofort, dass f(u) = a · 1 + u · 0 = a wird, sobald u keine Wurzel der Gleichung F(x) = 0 ist, dass dagegen f(u) = a · 0 + u · 1 = u selbst wird, sobald u der Gleichung F(u) = 0 genügt, mithin als eine Wurzel x derselben angenommen wird.
Insbesondre für die Annahme u = a decken sich beide Ergebnisse.
Nimmt man das Relativ u aufs Gerathewohl an, so ist es entweder keine Wurzel der Gleichung 1) oder es ist eine solche: u = x.
In beiden Fällen — haben wir soeben gesehen — liefert f(u) eine Wurzel, und zwar im erstern immer die schon bekannte, laut Voraussetzung existirende Wurzel a, im letztern aber die glücklich erratene Wurzel x. Jedenfalls also liefert der obige Ausdruck f(u) blos Wurzeln der Gleichung F(x) = 0, und er liefert alle Wurzeln dieser Gleichung, weil er irgend eine gewünschte x von diesen Wurzeln schon bei der Annahme u = x reproduzirt.
Unser f(u) genügt mithin nicht nur den Anforderungen, die im Begriff der allgemeinen Wurzel von 1) liegen, sondern obendrein auch noch der ersten Adventivforderung 4) — vergl. S. 171.
Drücken wir — behufs Erleichterung des Druckes — die Negation von F(u), bequemer wie durch F̅(u)̅, durch F̄(u) aus, so haben wir nach alledem das Theorem: 12) [Formel] — welchem noch, als einem für jedes a gültigen, das Symbol [Formel] vorangestellt werden dürfte.
Zur Erläuterung diene:
Ist a keine Wurzel, mithin {F(a) = 0} = 0, so ist 12) als eine Aussagensubsumtion von der Form 0 ⋹ R selbstverständlich gültig, wennschon nichtssagend.
Die Voraussetzung, dass die Gleichung F(x) = 0 auflösbar sei, kann aber in der Form ausgedrückt werden:
[Formel] und garantirt uns, dass es gewisse a gebe, für welche die Prämisse unsres Theorems {F(a) = 0} erfüllt, = 1 ist.
Für jedes solche a muss dann auch wegen (1 ⋹ R) = (R = 1) = R die rechte Seite R des Theorems 12) Geltung haben, und diese drückt gemäss dem Schema 3) regelrecht aus, dass der oben für f(u) angegebene Ausdruck 11) die allgemeine Wurzel sei, was ja vorhin nachgewiesen worden.
Anmerkungsweise sei noch gesagt, dass die mit 11) gefundene und in 12) angegebene allgemeine Lösung x = f(u) nach den Prinzipien des Dualismus (aus Kontraposition) sich selbst entspricht.
Der dual entsprechend gebildete Ausdruck zu unserm x = f(u) aus 11) wäre nämlich: x = (a + 0 ɟ F̄ ɟ 0)(u + 1; F; 1), was durch Ausmultipliziren auf x = au + f(u) hinausläuft, und wo nun, weil f(u) entweder = a oder = u ist, der Term au allemal absorbirt wird, sich also nur x = f(u) wiedererzeugt.
Jene Lösung ist demnach — nachdem a unter den bekannten Wurzeln oder partikularen Lösungen von 1) einmal ausgewählt ist — auch der Form nach eine vollkommen bestimmte.
Nur von der Wahl des a bleibt ihr Ausdruck abhängig.
Wir nennen sie aus bald zutage tretenden Gründen die (zur Wurzel a gehörige) „rigorose Lösung“ der Gleichung F(x) = 0.
Die „rigorose“ ist eine von den Formen der „allgemeinen“ Lösung.
Durch den mit ihrer Aufstellung geleisteten Nachweis ihrer Existenz haben wir jetzt auch die noch ausständig gewesene Begründung dessen geliefert, was wir unter „erstens“ und „drittens“ behauptet haben — wenigstens soweit prätendirt worden: dass es „theoretisch“ möglich sei, die allgemeine Wurzel x von 1) stets in der Form 2) darzustellen in welcher u arbiträr ist und f auch die Adventivforderung 4) erfüllt.
Aber noch mehr als das.
Nicht nur theoretisch dürfen wir von der Existenz einer allgemeinen Lösung solchen Charakters überzeugt sein, sondern wir vermögen auch praktisch — als eine „rigorose Lösung wenigstens — sie immer aufzustellen.
Das Problem der vollständigen Auflösung einer auflösbaren Gleichung 1) nach einer Unbekannten ist nämlich durch das bisherige zurückgeführt auf die Entdeckung einer einzigen Partikularlösung, oder ganz speziellen Wurzel a, ebendieser Gleichung.
Und eine solche wird sich immer entdecken lassen — so namentlich bei allen Problemen mit denen sich unsre Theorie zu beschäftigen hat.
Den Nachweis für diese auf das „Praktische“ bezügliche Behauptung allgemein zu erbringen, darauf muss ich freilich hier verzichten.
Doch mögen wenigstens einige Fingerzeige darüber im Kontext folgen.
Nicht selten genügt es schon, die vier Moduln als problematische Lösungen oder fragliche Wurzeln für x probeweise in F(x) einzusetzen, um einen oder mehrere derselben als wirkliche Lösung, Wurzel zu erkennen.
Wenn es sich z. B. um die Auflösung nach x der Gleichung x; x = x handelte, so verfügten wir augenblicklich über 0, 1 und 1' als von vornherein bekannte Partikularlösungen.
Ebenso ist 1' a priori bekannt als Wurzel derjenigen Gleichung, welche ein Relativ x als eine gegenseitig eindeutige Abbildung zu definiren haben wird.
In andern Fällen bieten sich vorkommende Parameterwerte oder gewisse einfach gestaltete Funktionsausdrücke aus solchen gebildet leicht als Partikularlösungen dar.
So, wenn wir die Gleichung a; x = x; a aufzulösen hätten, verfügten wir sofort ausser 0 und 1' auch über die Partikularlösung x = a.
Die zumeist, vorgängig der Auflösung nach x, von den übrigen Unbekannten allgemein zu erfüllende Resultante (der Elimination des x) verschafft diesen Bemerkungen eine noch grössere Tragweite.
Handelt es sich z. B. um die Auflösung der Gleichung x; b = a, so wird (siehe übernächste Vorlesung) die Resultante fordern, dass a selber von der Form c; b sei und damit wird von vornherein eine Partikularlösung x = c(= a ɟ b̄̆) bekannt sein.
Und dergleichen mehr.
So sehr wir demnach über unsre Errungenschaft der so allgemein ermittelten allgemeinen Lösung 12) erfreut sein könnten, so wird doch die Freude sehr herabgestimmt, ja wir werden kleinlaut, wenn wir uns diese Errungenschaft näher ansehen, indem wir uns über die Natur solch „rigoroser“ Lösung genauer unterrichten.
Dieselbe gewährt nicht etwa für eine Reihe von auf’s Gerathewohl angenommenen Werten ihres unbestimmten Argumentes u uns alsbald eine Fülle von erwünschten Partikularlösungen oder Wurzeln, sondern, sofern wir nicht geradezu das Glück haben, als angenommenen Wert von u eine Wurzel der Gleichung 1) selbst zu treffen, verweist sie uns nur immer wieder auf die schon längst bekannte und darum uninteressante — um nicht zu sagen „langweilige“ — Wurzel a.
Mit Hülfe des Ausdruckes 11) der rigorosen Lösung die sämtlichen Wurzeln der Gleichung 1) entdecken zu wollen das liefe geradezu darauf hinaus, bei allen erdenklichen Relativen u durchzuprobiren, ob sie diese Gleichung wol erfüllen!
Die „rigorose Lösung“ ist demnach noch keine befriedigende Form der allgemeinen Lösung; sie löst die Aufgabe nur zur Not — à la rigueur — und ist dies der Grund, weshalb ich ihr den angeführten Namen beigelegt habe, in Anbetracht, dass es nötig fiel, sie von andern vorteilhafteren Formen der allgemeinen Lösung unterscheidend zu benennen.
Immerhin gab ihre Aufstellung einen Fingerzeig, in welcher Form überhaupt wir auf die allgemeine Lösung einer Gleichung zu fahnden haben werden, lehrte sie uns vor allem, dass die vollständige Lösung der Gleichung 1) F(x) = 0 existirt in der Form 2) x = f(u).
Und sie bleibt eine letzte Zuflucht auf die man zurückgreifen kann so oft es nicht gelingt, eine „bessere“ Form der allgemeinen Wurzel für eine gegebene Gleichung zu finden, in allen den Fällen, wo man dennoch eines Ausdruckes für diese Wurzel zur Fortsetzung der Untersuchungen benötigt.
Der Begriff dessen, was nun aber „eine befriedigende“ und was eventuell „die beste“ Form der allgemeinen Lösung zu nennen wäre, dürfte nicht leicht festzustellen sein und wird sich voraussichtlich erst allmälig aus der Praxis unsrer Wissenschaft selbst heraus entwickeln.
Immerhin können wir wenigstens die stets an die allgemeine Lösung zu stellende „erste Adventivanforderung“ jetzt schon und allgemein rechtfertigen oder motiviren.
In Analogie zu einer schon in der arithmetischen Analysis vorhandenen Übung kann das „unbestimmte Argument“ u der allgemeinen Lösung f(u) in 2) wol auch deren (unabhängiger) „Parameter“ genannt werden.
Damit scheint allerdings ein gewisser Doppelsinn geschaffen und ist der Begriff und Ausdruck nicht zu verwechseln mit dem gleichnamigen in dem S. 158 erläuterten Sinne, in welchem wir von den „Parametern“ der Gleichung 1) F(x) = 0 oder des Polynoms F(x) derselben sprachen.
Als gemeinsames Merkmal beider Arten von Parametern kann — zur Rechtfertigung — allerdings deren durch nichts eingeschränkte Willkürlichkeit hingestellt werden.
Betont wurde bereits, dass u als arbiträres Relativ nur anzusehen ist sofern die Unbekannte x lediglich durch die Forderung bestimmt ist, dass sie die Gleichung F(x) = 0 erfülle, dass aber natürlich, sollten über x noch anderweite Angaben vorliegen oder sollte x gar völlig bestimmt, gegeben sein, die vorhin noch vollkommene Unbestimmtheit des Parameters u alsbald gewissen Einschränkungen unterliegen wird und derselbe sich sogar als vollkommen bestimmt im Einzelfalle erweisen kann, es z. B. vorkommen mag, dass u = 0 genommen werden muss, um eine Wurzel x = 0 zu liefern — wie dies schon unsre Erfahrungen im identischen Kalkul lehrten und manchfache Beispiele zeigen.
Da wir uns jedoch mit der Auflösung einer Gleichung nach einer Unbekannten zu beschäftigen haben und nicht nach einer Bekannten, so verschlägt es nichts, wenn wir den Parameter u im Allgemeinen und ungeachtet der zuletzt angedeuteten Möglichkeit als einen unbestimmten Parameter, und ebensowenig, wenn wir ihn als einen willkürlichen — als „den arbiträren Parameter“ der Lösung — hinstellen.
Obzwar die theoretischen Anforderungen an f(u), die im Begriff der Allgemeinen Lösung liegen, mit 3) erschöpft sind, so ist nun aber inbezug auf diesen Parameter u noch eine Anforderung — 4) — an die allgemeine Lösung zu stellen praktisch geboten.
Wie sollen wir nämlich dasjenige u oder ein solches u erfahren, welches uns eine bestimmte, etwa schon bekannte, eine gegebene oder gewünschte Wurzel x liefert?
Systematisch wäre ein solches u ja durch Auflösung der Gleichung 2): f(u) = x nach der Unbekannten u zu gewinnen.
Indessen dürfte dieses Auflösungsproblem sich nicht selten als ein noch viel schwierigeres darstellen, als dasjenige 1) gewesen, dessen Lösung uns die Gleichung 2) ausdrückte.
Es ist ein berechtigtes Desideratum, zu jedem vorbekannten x, das die Gleichung F(x) = 0 erfüllt, sogleich ein u — zum wenigsten — zu wissen, welches in f(u) eingesetzt gerade jenes x liefert.
Und diesem Verlangen kann nicht einfacher und besser — auch mnemonischer — allgemein genügt werden, als wenn die allgemeine Lösung so eingerichtet wird, dass sie für u = x selber jenes x liefert!
Diese Anforderung an die allgemeine Lösung zu stellen rechtfertigt sich noch unter einem zweiten und einem dritten Gesichtspunkte.
Ein zweiter ist der der Kontrole oder Probe für die Richtigkeit einer gefundenen Lösung (oder auch nur Wurzel) der Gleichung 1).
Die „allgemeine Lösung“ soll diese Kontrole auch für jeden speziellen oder Partikularwert der allgemeinen Wurzel selbst übernehmen; sie soll die Probe der Einsetzung des als x = f(u) gefundenen x in das Polynom F(x) der aufzulösenden Gleichung ersparen, gewisse Garantieen für dessen Richtigkeit schon in sich selbst bieten und zur Schau tragen:
Um verschiedene oder gar alle Wurzeln von 1) zu gewinnen, haben wir in dem Ausdruck f(u) andre und andre, prinzipiell alle erdenklichen Relative für den unbestimmten Parameter u einzusetzen resp. eingesetzt zu denken.
Ohne dem Begriff 3) der allgemeinen Lösung von 1) zu widersprechen kann nun f(u) so beschaffen sein, dass wenn man für u eine Wurzel x1 selbst einsetzt, irgend eine andre Wurzel x2 = f(x1) herauskommt, und falls man x2 einsetzt wieder eine andre Wurzel x3 = f(x2) und so weiter.
Ob ein für u genommener Wert nicht vielleicht selbst eine Wurzel der Gleichung F(x) = 0 schon ist, kann man bei solcher Sachlage nicht merken ohne mit ihm direkt die Probe zu machen: seiner Einsetzung in das Polynom F(x) unsrer Gleichung 1) behufs Nachsehens, ob dasselbe für ihn verschwinde.
Ein Hauptzweck der allgemeinen Lösung, uns diese Probe einfürallemal zu ersparen, wird damit hinfällig.
Dann könnten wir beinah ebensogut auf die allgemeine Lösung verzichten und uns begnügen, die Relative blos empirisch in zwei Klassen zu sondern, indem wir sie sämtlich einzeln durchgehen:
in solche u für welche F(u) ≠ 0 sich erweist, und in solche u, die dann x zu nennen, für welche sich F(u) = 0 herausstellt.
Ein Gleichniss macht die Sache am deutlichsten.
Wenig würde die Beförderung auf der Eisenbahn uns frommen, wenn der Zug die wünschenswerten Aussteigestellen ohne anzuhalten durchführe, oder wenn auf der Fahrt die Stationen sich durch nichts uns verrieten.
Haben wir eine Wurzel x, die vielleicht von besonderem Interesse für uns ist, richtig vermutet oder erraten, sie vielleicht durch Überlegungen von noch zweifelhafter Bündigkeit gewonnen, so muss die allgemeine Lösung uns kund geben, dass dies eine richtige Wurzel ist; wir sind alsdann bei der gewünschten Endstation angelangt, und dass wir uns schon da befinden, muss uns kund werden; der Zug darf nicht weiter fahren zu einer andern Wurzel.
Zu den in ihrem Begriff liegenden primären oder Minimal-Anforderungen der allgemeinen Lösung tritt also als eine sekundäre oder Adventiv-Anforderung aus den erwähnten beiden Gründen noch die hinzu, dass die allgemeine Lösung uns jede glücklich vermutete Wurzel als solche dadurch verrate, dass ihr Ausdruck bei deren Einsetzung für das u in f(u) uns diese Wurzel selbst wiedergibt, sie reproduzirt.
Das heisst: f(u) muss so beschaffen sein, wenn anders es eine befriedigende allgemeine Lösung soll heissen dürfen, dass 13)
{F(x) = 0} ⋹ {f(x) = x}.
Und da die umgekehrte Aussagensubsumtion — nach 3) für u = x in Anspruch genommen — schon ohnehin gilt, so mögen wir dieser Subsumtion auch die Form geben der Gleichung 4).
Diese zusätzliche oder adventive Anforderung 4) an die allgemeine Lösung genügt ihrerseits, wenn für eine gewisse Funktion f erfüllt, noch nicht, um diese Funktion als zur Darstellung der allgemeinen Lösung von 1) geeignet zu legitimiren; vielmehr garantirt sie blos, dass die Funktion f(u) alle Wurzeln x umfasse, es offen lassend, ob sie nicht auch noch andre als wie Wurzelwerte anzunehmen oder zu liefern fähig wäre; sie verbürgt uns blos, dass „die Probe 2“ stimmen muss.
Andrerseits sahen wir auch, dass 4) keineswegs logische Folge von 3) ist — wie zum.
Überfluss weiter unten streng bewiesen wird.
Zur Charakterisirung einer „nicht vorweg unbefriedigenden“ allgemeinen Lösung müssten wir also eigentlich das Produkt der Aussagen 3) und 4) oder auch deren Vereinigung zur Doppelgleichung 14) [Formel] jeweils hinschreiben.
Bei allen Lösungen von speziellen Problemen, die wir künftig aufstellen, werden wir Sorge tragen, dass jene Adventivforderung miterfüllt ist, und unsre Angaben von Lösungen werden allemal (wonicht anders bemerkt) deren Erfüllung thatsächlich leisten und sie zu erfüllen beanspruchen.
Es wäre aber zu umständlich, diesem Umstande mittelst ausdrücklicher Beifügung des Ansatzes f(x) = x — zumal, wo f(u) einen verwickelten Ausdruck besitzt — jeweils Rechnung zu tragen, und so werden wir uns mit der Angabe der Lösungen in Gestalt von 3) begnügen.
Man merkt sich leicht hinzu: dass u = x immer einen zulässigen Wert des u bildet, fähig die Wurzel x zu liefern.
Dem Anfänger erscheint es vielleicht als befremdend, dass ungeachtet der Äquivalenz der beiden Aussagen [Formel] und f(x) = x, wie sie 14) konstatirt, die erste zur Charakterisirung des f(u) als der allgemeinen Wurzel von 1) hinreicht, die letztere nicht.
Für das gedachte f, welches der Forderung 3) mitsamt der adventiven 4) genügt, treffen in der That beide Aussagen immer gleichzeitig zu, sobald x eine Wurzel der Gleichung 1) ist, und sie treffen alle beide nicht zu falls x ein andres Relativ (keine Wurzel) vorstellt.
Sie sind äquivalent.
Darum sind sie aber noch nicht äquipollent.
Die Sätze, dass 2 × 2 = 4 ist und dass Materie unzerstörbar sei, sind ebenfalls äquivalent.
Darum kann aber der erstere doch nicht zur Charakterisirung, Definition der Materie mitverwendet werden, obwol vielleicht der zweite.
Dass der adventiven Forderung 4) neben 3) immer genügt werden kann durch Aufstellung einer geeigneten Funktion f(u) haben wir an der „rigorosen“ Lösung gesehen.
Es wird aber der Forderung 3) — ja beiden Forderungen zugleich — sich noch in unbegrenzt mannigfaltiger Weise genügen lassen.
Und dieser Umstand lässt als einen dritten Gesichtspunkt, welcher die Zuziehung der adventiven Forderung motivirt, den hervortreten: dass wir darauf ausgehen müssen unser Problem zu einem bestimmteren zu gestalten, den Begriff „einer“ allgemeinen Lösung so zu präzisiren, dass für ein bestimmtes Problem gesprochen werden könne von „der“ allgemeinen Lösung desselben, von „seiner“ Lösung schlechtweg in einem feststehenden Sinne.
Schon im identischen Kalkul sind Funktionen angebbar, die aller Werte fähig sind.
Z. B. cu + c̄ū ist eine solche, irgendwie gelegen zwischen cc̄ = 0 und c + c̄ = 1 — vergl. Bd. 1, S. 427.
Und lassen wir c unbestimmt, so haben wir deren eine unbegrenzte Menge.
Umsomehr wird zuzugeben sein, dass es auch in der Algebra der Relative Funktionen gebe, die, wenn mit φ(u) bezeichnet, je nach dem Werte den man u beilegt fähig sind, den Wert jedes gewünschten Relativs zwischen 0 und 1 (inclusive) anzunehmen.
Funktionen φ(u) von dieser Eigenschaft gibt es in der That in unendlicher Fülle: φ(u) = ū oder ŭ oder ū̆ sind weitere (die einfachsten) Beispiele von solchen …
Ist φ(u) dergestalt aller Werte fähig („unbeschränkt variabel“) und zwar x = f(u) eine allgemeine Lösung von 1) im früheren, zunächst noch „weiteren“, blos durch 3) limitirten Sinne, so wird offenbar auch 15) x = f{φ(u)} wieder „eine allgemeine Lösung“ in diesem weitern Sinne sein.
Denn wenn ein bestimmter Wert v von u eine bestimmte Wurzel x mit x = f(u) lieferte, so wird f{φ(u)} ebendiese Wurzel x liefern, sobald man u so annimmt, dass φ(u) = v ist — was eben nach der über φ gemachten Voraussetzung allemal möglich ist; und dass jedes u mit 15) eine richtige Wurzel liefere versteht sich daraus von selbst, weil jedes w mit f(w) solches thut. —
So gut wie f(u) selbst stellen also beispielsweise auch f(bu + b̄ū), f(ū), f(ŭ), f(ū̆), f(cu + c̄ū), f(dŭ + d̄ū̆), und so weiter richtig die allgemeine Wurzel von 1) dar. —
Genügte etwa f(u) obendrein der Adventivbedingung 4), so wird f(ū), wenn mit F(u) bezeichnet, derselben aber nicht genügen, vielmehr nicht F(x) = x sondern sicher nur F(x̄) = x sein — analog blos F(x̆) = x falls wir F(u) als f(ŭ) deuteten, etc.
Dergleichen Überlegungen, wenn vollends exemplifizirt durch spezielle Funktionen f, verhelfen leicht zu dem (oben angekündigten) strengen Beweise, dass 4) nicht aus 3) folgen könne, indem wir darnach imstande sind Funktionen f anzugeben, die die Forderung 3) ohne 4) erfüllen. —
Schon aus dem ersten der obigen Beispiele, nämlich mit dem Ausdrucke f(bu + b̄ū), erhält man bei unbegrenztem Denkbereiche mittelst Variirens von b unendlich viele Funktionen f(u) als richtige, dem Begriffe 3) entsprechende allgemeine Wurzeln von 1).
Hiemit ist nachgewiesen, dass es im Allgemeinen unbegrenzt viele Funktionen f(u) gibt, welche gemäss 3) die allgemeine Wurzel x von 1) darstellen können.
Dieser Unbestimmtheit des Begriffes der allgemeinen Lösung von 1) wird durch die Adventivforderung 4) schon einigermassen gesteuert — durch welche in der That die oben als Beispiele angeführten Lösungen, im Allgemeinen wenigstens, sämtlich ausgeschlossen werden.
Jene bleiben zwar richtige, sind aber unpraktische wonicht fast unbrauchbare Formen einer allgemeinen Lösung, und demgemäss zu verwerfen.
Dass auch diese Forderung 4), wenn der im Begriffe liegenden 3) adjungirt, noch nicht hinreicht um eine Funktion f(u) als die allgemeine Wurzel von 1) vollkommen zu bestimmen, dass es vielmehr noch viele die Bedingungen 3) und 4) zugleich erfüllende und doch wesentlich verschiedene Funktionen f(u) geben kann, dies wird sich in der Theorie an speziellen Auflösungsproblemen zur Genüge offenbaren. —
Für die Anwendungen der Formel 12) behufs Aufstellung der rigorosen Lösungen zu speziellen Problemen ist es nützlich einfürallemal zu beachten, dass deren Ausdruck sich ungemein vereinfacht in den Fällen wo etwa a = 0 oder a = 1 eine Wurzel der aufzulösenden Gleichung F(x) = 0 sein sollte.
Wir erhalten leicht die beiden Unterfälle des dortigen allgemeinen Satzes: 16) [Formel] 17) [Formel] .
Soviel über das Auflösungsproblem im Allgemeinen.
Das mit jedem solchen unweigerlich verbundene Eliminationsproblem gipfelte in der Forderung aus jeder Gleichung 1) oder Subsumtion F(x) ⋹ 0 ein Relativ x zu eliminiren.
Kann man irgendein, jedes gewünschte Relativ eliminiren, so vermag man auch deren mehrere in irgend welcher Folge und damit auch irgend ein System von Relativen — dem Effekt nach simultan — zu eliminiren (so wenigstens gewiss bei endlich begrenzter Anzahl von Eliminanden).
Ändern wir die Bezeichnungen ein wenig ab, so kommt es also darauf an: aus irgend einer Gleichung f(u) = 0 ein Relativ u eliminiren zu lernen.
Zweckmässig mag es erscheinen, dies Problem in der blos formell etwas allgemeineren Fassung in Angriff zu nehmen, dass man sogleich die Resultante der Elimination eines u zu bilden fordert aus einer Gleichung von der Form f(u) = x.
Denn wie sich einerseits die letztere ja leicht auf das Prädikat 0 bringen liesse, so ist andrerseits klar, dass sobald wir bei ihr (für ein irgendwie gegeben gedachtes x) die Resultante der Elimination von u in Gestalt einer Subsumtion F(x) ⋹ 0 ermittelt haben, dann auch in Gestalt von F(0) ⋹ 0 die Resultante des vorhergehenden (der Form nach etwas spezielleren) Eliminationsproblems gefunden sein wird.
In dieser weiteren Fassung erscheint aber unser Eliminationsproblem als die unmittelbare Umkehrung, Inversion eines reinen Auflösungsproblems, und erlangen wir durch sie den Vorteil, zu sehen, dass mit jedem reinen Auflösungsprobleme zugleich auch ein gewisses Eliminationsproblem seine Lösung findet, und vice versa.
Bei jenem kam es darauf an, von der Gleichung F(x) = 0 zu ihrer allgemeinen Lösung x = f(u) fortzuschreiten; bei diesem aber wird nun verlangt den umgekehrten Weg zurückzulegen.
Ist mit 3) die Lösung von 1) gefunden, so stellt uns auch die — aus 8) a fortiori folgende —
Subsumtion: 18) {f(u) = x} ⋹ {F(x) = 0} die Lösung vor des Problemes der Elimination von u aus der linkseitigen Gleichung, nämlich aus 2); und zwar ist die rechte Seite, d. i. die Gleichung 1) — wegen 9) — auch die volle Resultante.
Dass beim Auflösungsprobleme — wie bereits erhärtet — so viele wesentlich verschiedene Formen der allgemeinen Wurzel existiren, wird uns nun nicht mehr Wunder nehmen, denn dieser Umstand stellt sich jetzt dar als ein Ausfluss der von vornherein plausibeln Thatsache, dass sehr verschiedene Ausgangsgleichungen doch die nämliche Resultante liefern können, wie bekanntlich zuweilen ganz verschiedene Prämissen doch dieselbe Konklusion liefern.
Die letztere zu gewinnen ist das Ziel des Eliminationsproblemes.
Und umgekehrt könnte man die Ermittelung aller allgemeinen Lösungen zu einer gegebenen Gleichung 1)
[als der Gesamtaussage eines Propositionensystems] hinstellen als die Beantwortung der Frage: welche Prämissen eine gegebene Konklusion liefern („what premises yield a given conclusion“)?
Dass die Beantwortung dieser letztern Frage kaum minder wichtig sei als die Lösung der erstern Aufgabe, also die Beantwortung der Frage, welche Konklusion aus gegebnen Prämissen folgt, dies hat schon Peirce8 p. 196 betont — ohne indessen dem Auflösungsprobleme als solchem irgend eine Behandlung zuteil werden zu lassen. —
Wir hatten bei den Betrachtungen dieses Paragraphen eingangs vorausgesetzt (was theoretisch immer hinzubringen gewesen), dass die aufzulösende Gleichung F(x) = 0, wenn überhaupt, so bedingungslos auflösbar sei, mithin durch Elimination von x keine „Resultante“ liefere.
Praktisch liegt zumeist der gegenteilige Fall vor.
Und wenn wir nun für jenen Fall das allgemeine Schema gefunden haben, nach welchem die Lösung immer anzusetzen ist, so müssen wir doch auch diesen Fall noch erledigen.
Wir müssen die Aufmerksamkeit des Lesers noch für die Frage in Anspruch nehmen: wie unser Schema dann zu modifiziren sein wird, wenn die aufzulösende Gleichung 1) eine (von x freie)
Resultante R = 0 liefert?
Unter R haben wir uns dabei irgend eine Funktion φ(b, c, …, y, z, …) von als gegeben zu denkenden Parametern, wie Polynomkoeffizienten z. B., eventuell auch von noch andern Unbekannten, vorzustellen.
Die Antwort auf die Frage ist einfach dahin zu geben: dass alsdann die Resultante als ein Aussagenfaktor der [Formel] rechterhand beizufügen oder vorzusetzen ist, sodass das allgemeine Schema für die Auflösung lautet: 19) [Formel] .
In der That ist die Resultante von den in 1) noch ausser x vorkommenden unbestimmten Relativen entweder nicht erfüllt, oder sie ist erfüllt.
Im ersten Falle haben wir (R = 0) = 0, und die rechte Seite unsres Schema’s wird den Wahrheitswert 0 haben.
Alsdann ist aber auch die Gleichung links nicht auflösbar, ist {F(x) = 0} = 0, oder die Gleichung F(x) = 0 für jede Bedeutung, die man dem x beilegen mag, absurd.
Unser Schema bewährt sich alsdann als die Aussagenäquivalenz 0 = 0.
Im zweiten Falle haben wir (R = 0) = 1.
Dann ist die Voraussetzung erfüllt, unter welcher wir das Schema 3) gerechtfertigt haben, dass nämlich die Gleichung 1) schlechthin auflösbar sei.
In ebendieses Schema 3) geht alsdann aber auch unser Schema 19) über.
Somit bewahrheitet es sich für alle Fälle.
Nennt man zur Abkürzung:
[Formel] so steht nach dem Frühern bereits fest, dass: Α ⋹ Β und Β ⋹ (Α = Γ), und ist es aussagenrechnerisch ein Leichtes, als mit diesem Subsumtionenpaar äquivalent die Gleichung nachzuweisen: Α = ΒΓ.
Zum Schlusse noch ein Wort über die Methoden zur Lösung beider Probleme.
Diese Probleme die an die Gleichung 1) sich anknüpfen vermögen wir ja als die analogen Probleme für die Koeffizienten der Unbekannten resp. des Eliminanden x darzustellen, indem wir in der für jedes Suffix ij zu erfüllenden Forderung: 20) {F(x)}i j = 0 die linke Seite regelrecht gemäss den Festsetzungen des § 3 ausrechnen, expandiren oder entwickeln.
Zunächst kommt es dann nur darauf an, den allgemeinen Koeffizienten xh k — besser gesagt:
die sämtlichen xh k — als Unbekannte aus der Gleichung zu berechnen, resp. sie zu eliminiren, und stellt das Problem sich dar als ein solches des reinen Aussagenkalkuls.
Schon im identischen, um so mehr für diesen Kalkul wurden die Methoden der Auflösung und der Elimination zu einer gewissen Stufe der Vollkommenheit gebracht; sie wurden in extenso entwickelt und zu befriedigend zu handhabenden ausgebildet.
Es wäre gleichwohl eine Täuschung daraufhin zu wähnen, dass man nun also in unsrer Disziplin jedes Problem zu lösen vermöchte — und zwar aus dem Grunde weil … bislang immer nur bestimmte und begrenzte Mengen von Unbekannten resp. Eliminanden in’s Auge gefasst worden und weil in der That nur zur Berechnung sowie Elimination einer solchen jene Methoden zureichend oder leidlich ausgebildet erscheinen!
Bei dem in der Regel als unbegrenzt vorauszusetzenden Denkbereiche aber werden wir es hier fast immer mit unendlichen oder wenigstens unbestimmten Mengen von Unbekannten und Eliminanden zu thun haben, und selbst wenn der Denkbereich 11 nur aus wenigen — sagen wir einmal: drei oder mehr — Elementen als Individuen besteht, erweisen sich die nach jenen bekannten Methoden auszuführenden Rechnungen bei der im Quadrate vergrösserten Zahl der Unbekannten als praktisch kaum mehr durchführbare.
Endlich aber, selbst wenn für die Koeffizienten die Aufgabe gelöst sein sollte, ist der Rückschluss von da auf die Relative selbst, nach denen resp. deren Relation gefragt worden, kein so ganz einfach zu vollziehender.
So leicht es ist, sich die Herrschaft über die Grundlagen unsrer Disziplin anzueignen, müssen doch ihre beiden Fundamentalprobleme als schwierige bezeichnet werden.
Es fehlt bislang an einer Methode, dieselben allgemein zu lösen.
Für eine Gruppe von 512 Problemen geben wir solche in der nächsten Vorlesung.
Elimination betreffend liegt (§ 28) blos eine Studie von Peirce vor in der sich etwas wie eine „Methode“ von noch einiger Allgemeinheit der Anwendung kund gibt, und Auflösung betreffend thut eine Ausdehnung meines Verfahrens bei den „symmetrisch allgemeinen Lösungen (Bd. 1, S. 498, 503 und Bd. 2, § 51) bei gewissen Klassen von Aufgaben gute Dienste — wie sogleich zu sehen sein wird.
Im übrigen sind wir bei den zahlreichen Problemen unsrer Theorie auf die Vertiefung in deren spezielle Natur, besondre Kunstgriffe und Glückeszufälle angewiesen.
Bei andern kann die Lösung vielleicht erst von der vereinten Arbeit vieler Forscher für eine fernere Zukunft erhofft werden.
Unter solchen Umständen erscheint es von Wert, gewisse noch sehr umfassende Klassen von Problemen zu kennen, in welchen sich die Auflösung nach einheitlichem Schema bewerkstelligen lässt, und will ich darum ein Paar von solchen noch namhaft machen.
§ 13. Fortsetzung.
Iterationen.
Grenzwerte und Konvergenz. Potenz.
Von ziemlicher Allgemeinheit sind die beiden Klassen von Auflösungsproblemen, wo die nach x aufzulösende Proposition sich äquivalent darstellen lässt in der einen oder andern der beiden Formen: x⋹φ(x), ψ(x) ⋹x.
Es sind die Fälle, wo das Polynom F(x) unsrer Gleichung F(x) ⋹ 0 den Faktor x, oder x̄, aufweist — dessen Kofaktor, resp. der selber, alsdann negirt auf die andre Seite geworfen werden kann (als Addend zur 0).
Eine „befriedigende“ allgemeine Lösung des Problems lässt in diesen beiden Fällen sich immer angeben in Gestalt der unbegrenzt oft iterirten Funktion eines arbiträren Relativs u, nämlich als x = f∞(u), wo f(u) einen gewissen Ausdruck vorstellt.
Und zwar gelten die beiden Theoreme: 1) bedeutet.
Die Erläuterung und Begründung dieser beiden Sätze veranlasst uns noch zu mehrern wichtigen Bemerkungen.
Zuvörderst werden für eine irgendwie gegebene Funktion f(u) (Relativfunktion oder „Funktion“ im bisherigen Sinne der Algebra der binären Relative verstanden) die „Iterationen“ fr(u) zu definiren sein — zunächst für alle „Exponenten“ r, die (endliche) natürliche Zahlen sind.
Diese Definition hat in der üblichen Weise „durch Induktion zu erfolgen, indem man nämlich ausmacht, dass: 2)
[Formel] bedeuten solle — wozu nur zu bemerken ist, dass die als „Exponenten 0, 1, 2, ‥ r, r + 1, … auftretenden Symbole in unsrer Theorie niemals als Relative, sondern immer nur als natürliche Zahlen aufgefasst werden müssen.
Nun ist ja allerdings einer der vornehmsten Zwecke unsrer Theorie der: die logische Grundlage der Zahlenlehre zu liefern, sozusagen dem Anzahlbegriffe auf den Grund zu kommen, namentlich auch die sogenannte „Definition durch Induktion“ als eine Definition zu rechtfertigen, ihre Wirksamkeit als eine das zu definirende Objekt wirklich bestimmende darzuthun, desgleichen den Schluss der vollständigen Induktion als einen berechtigten zu beweisen, und dergleichen mehr.
Beim unmittelbaren Verfolgen dieser Ziele werden wir darum von alledem nichts voraussetzen dürfen und dessen auch in den besondern Abschnitten unsres Buches, die genannten Zielen gewidmet sind, eingedenk sein.
Dies hindert aber nicht, dass wir einstweilen, in andern von jenen Zielen entlegenen Kapiteln desselben — wenn man will: etwas vorgreifend — ganz ungenirt vom Zahlbegriffe sowol, als von den genannten induktorischen Definitions- und Schlussarten Gebrauch machen — in gleicher Weise, wie es auch in den vorhergehenden Bänden schon öfters gelegentlich geschah und auch sonst in der ganzen mathematischen und wissenschaftlichen Welt längst üblich ist.
Um so mehr werden wir so zuwerke gehn dürfen, als ja die Berechtigung dazu gerade in unserm Buche geeigneten Ortes sich nachgewiesen findet in einer Weise, genügend den strengsten Anforderungen, die vom logischen Standpunkte aus zu stellen.
Freilich dokumentirt sich in solchem Vorgreifen eine gewisse Unvollkommenheit unsres Lehrgangs, der das Euklid’sche Ideal eines absolut streng stufenmässigen Aufbaues noch nicht verwirklicht — wie es klassisch z. B. Herrn Dedekind’s Schrift in ihrer Art thut.
Allein die eigentümliche — ich möchte sagen: harte — Schönheit solchen streng stufenmässigen Aufbaues wird bekanntlich auch durch gewisse Nachteile erkauft die namentlich auf dem didaktischen oder pädagogischen Felde zutage treten; sie scheint nur auf Kosten der Übersicht des Ganzen und des gebührenden Hervortretens von allgemeineren Gesichtspunkten zu verwirklichen.
Ich glaube demnach einen gewissen Mittelweg einhalten zu sollen, und mir einen Leser vorstellen zu dürfen, der einigermassen eklektisch, mit Auswahl (und gelegentlichem Überschlagen), zu lesen versteht (um auf Einzelnes später wieder zurückzukommen), einen Leser, der es auch über sich vermag, bei Untersuchungen die zu gewissen fundamentalen Erkenntnisszwecken geführt werden, wieder einige Stufen herabzusteigen und von dem vielleicht anderwärts schon gewonnenen Erkenntnisskapital zeitweilig ein Bestimmtes ungenutzt zu lassen, ja zu ignoriren.
Und so wollen wir denn hier „kurzen Prozess machen“, und die Iterationen der Funktion f(u) für alle Iterationsexponenten anerkennen als „definirt“ durch die „Rekursion“ in 2), welche Sinn und Bedeutung von fr + 1(u) festlegt, sobald dieselben für fr(u) feststehn — nachdem mit 2) auch f1(u), als f(u), oder wenn man will schon f0(u), als u, seine Erklärung gefunden hat.
Desgleichen wollen wir hier — worauf an anderm Orte ebenfalls zurückzukommen sein wird — als evidentermaassen aus der Definition folgend die Sätze gelten lassen: 3) fr + 1(u) = fr{f(u)} sowie überhaupt:
4) fm{fn(u)} = fm + n(u) = fn{fm(u)} — und wenn man will noch obendrein: 5)
(fm)n(u) = fm × n(u) = (fn)m(u) — wie sie in der That Demjenigen, der den Zahlbegriff schon hat, auch unmittelbar einleuchten werden, indem z. B. bei 4) die drei als gleich hingestellten Ausdrücke übereinstimmend weiter nichts bedeuten, als die von u m + n mal hintereinander genommene Funktion f — u. s. w.
Dies vorausgesetzt ist ferner „die unbegrenzte Iteration“ f∞(u) zu definiren, sofern der Name fähig ist einer Erklärung, die auf den Begriff von fλ(u) sich gründet und aus dem Verhalten dieses Relativs für alle und namentlich für unbegrenzt wachsende Iterationsexponenten λ motivirbar ist.
Die Bedingung für letzteres wird die Konvergenzbedingung für fλ(u), scilicet bei unbegrenzt wachsendem λ, zu nennen sein.
Ist überhaupt für die unbegrenzte Reihe von natürlichen Zahlen λ = 0, 1, 2, 3, … der Wert eines Relativs uλ bestimmt, z. B. für beliebig viele Relative der „Reihe u0, u1, u2, u3, … aktuell gegeben, für den Rest durch ein Gesetz oder Prinzip begrifflich festgesetzt, so werden wir bei (als natürliche Zahl) unbegrenzt wachsendem Zeiger λ zwar im Allgemeinen zu sagen haben, uλ „divergire und das Symbol u∞ habe keinen Sinn, doch wird es auch eine Klasse von Fällen geben, wo man sagen kann, das allgemeine Glied uλ unsrer Reihe „konvergire“, indem es einem bestimmten, festen, alsdann mit u∞ zu bezeichnenden Relativ als „Grenze“ „zustrebt“.
Letzteres ist der Fall, dann und nur dann, wenn für jede durch ein Suffix ij markirte Stelle der Tafel 12 — oder m. a. W. der Matrix von uλ — ein Zahlwert n angebbar ist oder existirt derart, dass in uλ die Stelle entweder für jedes λ > n ein Auge trägt, besetzt ist, oder aber für jedes λ > n leer, unbesetzt bleibt.
Eine Stelle ij der Matrix des mit λ veränderlichen Relativs uλ soll eine endgültig, „definitiv“ besetzte Stelle dieses variabeln Relativs heissen, wenn es solchen Wert n von λ gibt, dass für alle λ welche > n sind die Stelle in uλ sich als besetzt erweist; sie soll eine endgültig unbesetzte oder definitive Leerstelle heissen, falls es eine solche Zahl n gibt, dass für alle λ > n die Stelle in uλ unbesetzt bleibt.
Unter Benutzung dieser Ausdrucksweisen können wir kürzer sagen:
uλ soll bei wachsendem λ konvergent genannt werden, wenn für jede Stelle seiner Matrix entschieden oder entscheidbar ist, ob sie definitiv zur besetzten oder definitiv zur Leer-Stelle werde.
Unter dem Grenzwert (limes) von uλ (für lim. λ = ∞) verstehen wir alsdann dasjenige Relativ, welches an den „definitiv besetzten Stellen von uλ Augen trägt, die „definitiv unbesetzten“ Stellen von uλ aber zu Leerstellen hat.
Und diesen Grenzwert werden wir kurz mit u∞ bezeichnen.
Im Allgemeinen wird es aber Stellen ij geben, die weder zu den definitiv besetzten noch zu den definitiv unbesetzten Stellen des von λ abhängigen uλ gehören, bei welchen es vielmehr zu jedem noch so grossen Zeiger n stets Zahlwerte m > n gibt derart, dass wenn in un die Stelle besetzt war, sie in um wieder unbesetzt erscheint, und umgekehrt.
Solche in uλ bei wachsendem λ schwankend (wenn auch nicht notwendig in regelmässigem Wechsel) bald besetzte, bald auch einmal wieder unbesetzte Stellen mögen „oszillatorisch besetzte“ (und ebenso unbesetzte) oder (endgültig) oszillatorische Stellen von uλ heissen.
Nicht: „oszillirende“; die Stelle selbst schwankt nicht, nur ihre Besetzung, das Auge, schwankt (blinkt, szintillirt) zwischen Vorhandensein und Nichtsein.
Ist auch nur eine solche Stelle oder sind ihrer gar mehrere vorhanden, so lässt sich mit dem Zeichen u∞ kein bestimmter Begriff (als eines Relativs) verbinden, weil hier jeglicher Beweggrund fehlt der dafür den Ausschlag zu geben vermöchte, ob solche Stelle darin als besetzte oder als unbesetzte figuriren solle.
Das Symbol u∞ bleibt alsdann sinnlos, und uλ divergirt.
Divergenz kann in unsrer Disziplin immer nur „oszillatorisch“ stattfinden.
Ungeachtet solcher Sinnlosigkeit dieses Symbols kann man doch — worauf ich indessen zur Zeit kein grosses Gewicht lege — mit Subsumtionen, in welchen dasselbe als Subjekt oder als Prädikat auftritt, einen ganz bestimmten Sinn verbinden.
Man mag nämlich schreiben: a⋹u∞⋹b um damit auszudrücken, dass
a Augen hat nur oder höchstens an solchen Stellen, die zu den definitiv besetzten irgend eines uλ von hinreichend grossem Zeiger λ gehören, wogegen also a alle die bei den uλ immerfort oszillatorisch besetzten und die definitiv unbesetzten Stellen zu Leerstellen haben muss,
desgleichen, dass b Leerstellen hat nur oder höchstens an solchen Stellen, die zu den definitiv unbesetzten eines hinreichend hohen uλ gehören, wogegen also b alle die bei den uλ definitiv besetzten, sowie auch die immerfort oszillatorisch besetzten Stellen der uλ, zum mindesten, mit Augen besetzt zeigen muss.
In solchem Falle wird es auch einen umfassendsten oder Maximalwert des a, der noch der Forderung a ⋹ u∞ genügt (eventuell freilich = 0 sein mag) geben, den man als die „untere Grenze“ (limes inferior) dieses nicht völlig bestimmbaren Relativsymbols u∞ bezeichnen kann; desgleichen einen mindest umfassenden oder Minimalwert des b, welcher noch der Forderung u∞ ⋹ b genügt (der eventuell freilich = 1 sein kann) und demnach die „obere Grenze“ (limes superior) für u∞ heisse.
Und man wird nicht selten sagen können, dass uλ von einem hinreichend grossen λ ab beständig zwischen diesen beiden Grenzen schwanke, nur „Zwischenwerte“ zwischen denselben durchlaufend oder annehmend.
[Mit dem letztern Zusatze indessen, obwohl er häufig zutreffen wird — insbesondre stets bei endlicher Elementezahl des Denkbereiches mithin auch endlicher Stellenzahl der Matrix — dürfte für manche Fälle doch zuviel gesagt sein.
Gibt es z. B. für jede „definitiv besetzte“ Stelle ij eine Zahl n, nach deren Überschreitung durch λ die Stelle nicht mehr als eine Leerstelle in uλ auftreten wird, so gibt es allerdings auch für jede endliche Menge von solchen Stellen ij eine Zahl — in Gestalt des grössten der den Stellen der Menge einzeln zugeordneten Werten — von der Eigenschaft, dass, nachdem λ sie überschritten hat, alle genannten Stellen ihre endgültige Besetzung gefunden haben müssen und nie mehr in uλ zu Leerstellen werden können.
Allein wenn die Menge der in Betracht zu ziehenden Stellen unbegrenzt zunimmt, bleibt es fraglich und künftigen subtilern Untersuchungen vorbehalten zu entscheiden, ob nicht dieser grösste unter allen (kleinsten) Werten n (die zu jeder Stelle gehören) dann in der Zahlenreihe immer weiter hinausrückt und die Reihe der Werte n, als eine selbst unbegrenzt wachsende, keinen Wert als grössten einschliesst.
Dann würde zwar für jede einzelne Stelle eine Zahl λ = n angebbar, von der ab die Stelle in uλ ihre endgültige Besetzung gefunden hat, für die Gesamtheit aller definitiv zu besetzenden Stellen aber gleichwohl nicht.
Etc.]
Von der Frage der Konvergenz oder Divergenz des allgemeinen Gliedes (Terms) uλ unsrer Reihe ist wohl zu unterscheiden die Frage nach Konvergenz oder Divergenz der Reihe selber, wenn deren Terme durch eine knüpfende Operation (z. B. Spezies) verbunden gedacht werden.
Werden die Terme der Reihe durch eine identische Spezies mit einander verknüpft, so erhalten wir ein „unendliches Produkt“ oder eine „unendliche Summe“ schlechtweg (oder „Reihe“ im engern Sinne).
Dann ist das Knüpfungsergebniss aus den λ + 1 ersten 6)
d. i. „der produktatorische Faktor“ resp. das sogenannte „summatorische Glied“ der Reihe derjenige allgemeine Term, um dessen Konvergenz es sich im letztern Falle handelt.
Uλ = u0u1u2 … uλ Uλ = u0 + u1 + u2 + … + uλ
Hier gilt der bemerkenswerte Doppelsatz:
Jedes identische unendliche Produkt und jede identische unendliche Summe ist konvergent.
Und zwar selbst dann, wenn auch der allgemeine Term uλ divergiren sollte:
wir haben in unsrer Disziplin konvergente Produkte aus divergenten Faktoren und konvergente Summen (Reihen) mit divergenten Gliedern — dergleichen in der arithmetischen Analysis für Paradoxieen zu erklären wären!
Allemal hat 7) unbedingt einen Sinn und völlig bestimmten Wert im Gebiet der binären Relative.
U∞ = u0u1u2u3 … U∞ = u0 + u1 + u2 + u3 + … (in infinitum)
Dies ist verhältnissmässig leicht hier einzusehen.
Es beruht darauf, dass in dem Uλ links jede Leerstelle definitiv eine solche bleibt, wie viele Faktoren uλ bei wachsendem λ auch noch zum Produkt der bisherigen hinzutreten mögen, bei dem Uλ rechts aber jede besetzte Stelle ihr Auge permanent, untilgbar beibehalten muss, wie viele Glieder uλ zur Summe der bereits vereinigten auch noch hinzutreten mögen.
Genauer gesagt:
weil [Formel] definirt ist — für jede Auswahl, z. B. Reihe, von Werten u als Erstreckung des Π, der Σ — so wird es für eine bestimmte Stelle ij nur zwei Möglichkeiten geben und zwar:
Links: entweder gibt es eine Zahl n für welche uλ bei ij eine Leerstelle hat, (un)i j = 0 ist, oder nicht.
Im erstern Falle hat auch Uλ für jedes λ > n bei ij eine Leerstelle und wird diese zur definitiv unbesetzten.
Im letztern Falle muss nach λ jedes (uλ)i j gleich 1 sein und bleibt die Stelle eine definitiv besetzte.
Rechts: entweder gibt es ein n für welches uλ bei ij ein Auge trägt, (un)i j = 1 ist, oder solches trifft nicht zu.
Im erstern Falle hat auch Uλ für jedes λ > n an der Stelle ij ein Auge und diese wird zur definitiv besetzten.
Im letztern Falle sind nach λ alle (uλ)i j gleich 0 und bleibt die Stelle endgültig leer.
Zu links wie rechts (vom Mittelstriche) erweisen also sämtliche Stellen der Matrix von Uλ sich als entweder definitiv besetzte oder definitiv unbesetzte und kann es ein Drittes, kann es oszillatorische Stellen überhaupt nicht geben — q. e. d.
Dass bei vorstehender Überlegung das numerische Moment der Zahlenzeiger nur eine nebensächliche Rolle spielt, wird der einsichtsvolle Leser sogleich übersehen.
Die Überlegungen bleiben auch stichhaltig, falls etwa in Πλuλ der Zeiger λ ein „Kontinuum“ von Zahlenwerten zu durchlaufen hätte.
Satz und Beweis gelten wesentlich auch für [Formel] und [Formel] , wie immer der Erstreckungsbereich beschaffen sein möge.
Denn was z. B. das Πu betrifft, so muss es zu irgend einem Suffix ij im Erstreckungsbereiche entweder ein u geben, für welches ui j = 0 ist, oder nicht.
Im erstern Falle hat Πu bei ij definitiv eine Leerstelle, im letztern, wo also „nach u alle“ ui j = 1 sind, wird Πu bei ij eine definitiv besetzte Stelle haben, und ein Drittes (eine oszillatorisch besetzte Stelle) bleibt undenkbar.
Etc. (d. h. analog für [Formel] ).
Für relative unendliche Produkte und Summen gilt ein ähnlicher Satz in gleicher Allgemeinheit nicht.
Man thut dies leicht durch Beispiele dar, z. B. beim relativen Produkt schon für den Fall durchweg gleicher Faktoren.
Ein relatives Produkt von lauter gleichen Faktoren nennen wir „Potenz“.
Wir definiren, wenn λ eine natürliche Zahl vorstellt, die Potenz (u;)λ sive (; u)λ, einfacher: uλ (u hoch λ), entweder „durch Induktion“ („rekurrirend“) mittelst der Festsetzung:
8) u1 = u, u2 = u; u, …, uλ + 1 = uλ; u, oder auch „independent“ als: 9)
[Formel] .
Es folgen die bekannten Sätze wie für die Potenzen der Arithmetik: 10) uλ + 1 = u; uλ, uϰ; uλ = uϰ + λ = uλ; uϰ, (uϰ)λ = uϰ × λ = (uλ)ϰ.
Durch ein zugefügtes Adjektiv die „Potenz“ als eine „relative“ zu charakterisiren ist überflüssig, weil durch das Tautologiegesetz uu = u jeder Möglichkeit vorgebeugt, es vorweg ausgeschlossen, präkludirt ist, die „Potenz als ein identisches Produkt (aus gleichen Faktoren) misszuverstehen.
Auch hier spielen mit den Exponenten wieder Zahlen vorzeitig eine Rolle.
Wen das genirt der möge uλ nur wie einen „stenographischen Schlüssel“, ein konventionelles Zeichen zur Vereinfachung der Schrift, bequemlichkeitshalber dulden.
Das duale Gegenstück zur Potenz ist die relative Summe aus lauter gleichen Summanden: 11) [Formel] .
Ich will sie „iterirte“ oder „iterative Summe“ gelegentlich nennen.
Wollte man die Analogie mit den arithmetischen Gebilden in der Bezeichnung noch weiter treiben, so hätte an Stelle der vorstehend dafür eingeführten Abkürzung — die mit der Schreibung (u;)λ für uλ parallel geht — eine andre gewählt werden müssen, bei der der Iterationsexponent λ wie ein „Multiplikator“ hinter das u zu treten hätte.
Wir würden dann aber dreierlei — und die arithmetische eingerechnet — viererlei Multiplikationen und ebensoviele Malzeichen zu unterscheiden bekommen, was entschieden zu viel ist (“Aller guten Dinge sind drei“).
Die dualen Gegenstücke zu den obigen Potenzgesetzen mag der Leser nun selbst sich zu Papier oder zum Bewusstsein bringen.
Also es ist behauptet: schon die Potenz uλ divergirt im Allgemeinen.
Dies zeigt schon ein so einfaches Beispiel, wie beim Denkbereich 1 ⅓ von nur drei Elementen die Annahme:
[Formel] gehört und nun u; u, = u2 = ū, u2; u, = u3 = u sich herausstellt; es oszillirt, schwankt daher hier regelmässig uλ ohne Ende fort vom einen zum andern der beiden Werte u und ū, indem u2ϰ = ū, u2ϰ + 1 = u ist, und uλ ist divergent, das Symbol u∞ hier sinnlos.
Man könnte freilich diesem sinnlosen Namen einen ganz beliebig zu wählenden Sinn willkürlich unterlegen.
Wie man diese Wahl aber auch treffen möge, für die sich rationelle Beweggründe nicht auffinden lassen, so wird die Einführung solchen Namens nicht nur keinen Vorteil gewähren sondern geradezu schaden; dieser Name wird in kein rationelles Bezeichnungsystem passen, insbesondre nicht in das in diesem Buche geschaffene, ja er wird die Gesetzmässigkeiten jedes solchen stören, wonicht über den Haufen werfen, wird künstlich Hindernisse bereiten und zur Quelle von Verlegenheiten werden, indem er zu lästiger Berücksichtigung von allerhand Ausnahmen nötigen wird, die ohne ihn gar nicht erwachsen konnten, gar nicht vorhanden waren.
Sinnlose Namen, die eine Disziplin hervorbringt, sind gleichsam Neben- oder Abfallprodukte einer bestimmten (Bezeichnungs-) Industrie.
Zuweilen stellen diese ein wertvolles Rohmaterial vor, das es in einer andern Industrie zu verarbeiten gelingt und das damit im gesamten Haushalt der Wissenschaft eine unschätzbare Verwendung findet — so die im Gebiet der natürlichen Zahlen sinnlosen Namen der negativen Zahlen, so der als Maasszahl unbrauchbare (im reellen Zahlengebiet sinnlose) Name [Formel] , etc. auf dem erweiterten Zahlengebiete.
Nicht immer aber liegen die Umstände so günstig, vielmehr muss manches Abwasser auch einfach fortgeschüttet werden.
Nunmehr ist etwa [Formel] eine nahe liegende Exemplifikation für eine konvergente Reihe mit divergentem Allgemeingliede.
Dieselbe hat für unser obiges u die Summe u + ū = 1.
Für die Konvergenz der Potenz uλ eines Relativs u — bei ohne Ende wachsendem Exponenten λ — sind die notwendigen und hinreichenden Bedingungen noch nicht bekannt.
Doch lassen sich einige Umstände als dazu hinreichende Bedingungen nachweisen.
So muss xλ mit λ = ∞ konvergiren sowol wenn x die Eigenschaft hat, dass x; x ⋹ x ist, als auch wenn es der Eigenschaft x ⋹ x; x teilhaftig ist.
Im ersteren Falle ist leicht zu folgern, dass xλ + 1 ⋹ xλ, im letzteren, dass xλ ⋹ xλ + 1 für jedes (noch so grosse) λ sein muss.
In jenem werden sich also bei fortgesetztem relativen Multipliziren mit x die Leerstellen als endgültige konserviren, indem, wo xλ eine Leerstelle hat, auch xλ + ϰ eine solche aufweisen muss; die Potenz konvergirt alsdann „abnehmend“ gegen eine feste Grenze.
In diesem gilt ein gleiches für die Augen und konvergirt die Potenz „zunehmend“ gegen eine Grenze.
Ist insbesondre x von der Form 1' + a, so ist x; x = 1' + a + a; a, mithin in der That x ⋹ x; x und folglich hat das Symbol (1' + a)∞ für jede Bedeutung von a einen Sinn.
Ebenso, wenn die Basis x einer Potenz xλ von der Form a; ă (mithin, ă für a gesagt, zugleich auch von der Form ă; a) ist, muss diese Potenz konvergiren — und zwar aufgrund des Satzes: den wir später als speziellen Fall (für b = ă) eines allgemeineren Satzes — 21) des § 18 — erkennen werden, und einstweilen durch die Koeffizientenevidenz mittelst des Hinweises darauf beweisen mögen, dass die Glieder von Li j = Σhai haj h sich unter denen von Ri j = Σh k lai hak hak laj l bei k = i, l = h sämtlich vorfinden.
a; ă ⋹ a; ă; a; ă a ɟ ă ɟ a ɟ ă ⋹ a ɟ ă
Nach diesen Zwischenbetrachtungen kehren wir zur Iteration der Funktionen und damit zu unserm Theorem 1) zurück.
Es gibt Fälle, wo „die rfache (rte) Iteration einer Funktion f(u)“, nämlich fr(u) für lim r = ∞ konvergirt, und zwar „allgemein“ für jedes Argument u.
Dies vermag schon ein Beispiel aus dem identischen Kalkul zu erhärten, wie etwa die Annahme f(u) = au + b, wofür f2(u) = a(au + b) + b = au + b, also f2(u) = f(u), und folglich auch f3(u) = f{f2(u)} = f{f(u)} = f2(u) = f(u), allgemein: fr(u) = f(u) und somit f∞(u) = f(u) wird.
Eine Funktion f von der Eigenschaft, dass allgemein, für jedes Argument, schon ihre zweite Iteration der ersten (oder der Funktion selber) gleich ist, mag „invariant“ genannt werden.
Alle Iterationen einer solchen Funktion, von der nullten ab, sind dann, wie leicht zu sehn, ihr selber gleich: jede invariante Funktion bleibt beim Iteriren ungeändert, und auch die unbegrenzt oft iterirte Funktion ist dann keine andre als sie selber.
u selbst ist ebenfalls eine invariante Funktion von u.
Im Allgemeinen aber, bei einer irgendwie gegebnen Funktion f(u), muss man darauf gefasst sein, dass die rte Iteration derselben mit wachsendem r divergire.
Auch dieses vermag bereits der identische Kalkul zu erhärten.
Die allgemeinste Funktion von u welche mit den Spezies dieser Diszplin gebildet werden kann ist bekanntlich: f(u) = au + bū.
Dafür wird f{f(u)} = a(au + bū) + b(āu + b̄ū) also f2(u) = (a + b)u + abū = (a + b)u + ab.
Dies ist im Allgemeinen von f(u) verschieden — wie leicht z. B. die Annahme b = ā zeigt, wo für f(u) = au + āū nun f2(u) = u = f0(u) wird, etc.
Dagegen wird im obigen allgemeinen Falle wieder: f3(u) = f(u), f4(u) = f2(u), etc., allgemein: f2ϰ + 1(u) = f(u), f2ϰ + 2(u) = f2(u), mithin ist fr(u) divergent und f∞(u) sinnlos, ausgenommen in dem oben angeführten Sonderfalle, wo schon f2(u) = f(u) und diese Funktion invariant ist.
Gibt es ein Zahlenpaar m, n derart, dass bei einer bestimmten Funktion f(u) für jedes u ist: fm + n(u) = fm(u), so nennen wir die Funktion eine „periodisch (oder oszillirend) iterirende mit einer Iterationsperiode n“, oder schlechtweg „mit der Iterationsperiode n“, falls n zugleich die kleinste Zahl von der genannten Eigenschaft sein sollte (die in ein solches Zahlenpaar m, n eingeht).
Darnach subsumirt sich der Begriff einer invarianten Funktion unter denjenigen einer periodisch iterirenden Funktion von der Periode 1.
Während die Iterationen einer solchen konvergent sind, wird dagegen jede periodisch iterirende Funktion, deren Periode n > 1 ist, eine divergent iterirende sein müssen.
Kürzehalber mag dies nur ein Beispiel erläutern.
Sei etwa allgemein — wenn wir das stets hinzuzudenkende Argument (u) unterdrücken — f8 = f5, so wird auch f9 = f6, f10 = f7, f11 = f5, f12 = f6, f13 = f7, f14 = f5, u. s. w. Die Iterationen von f, deren Periode gleich 3 ist, werden also ewig fort von einem der drei (als verschieden vorauszusetzen gewesenen) Werte f5, f6, f7 zum andern im Ring herum (vom letzten wieder zum ersten) oszilliren und f∞ ist keiner bestimmten Deutung fähig.
Solches gilt auch, wenn etwa m = 0, also fn(u) = u selbst sein sollte; hier wiederholen sich dann beim unbegrenzt fortgesetzten Iteriren in stetiger Folge die Werte f0, f, f2, f3, …, fn — 1, [f0 (oder u), f, etc.].
Für die allgemeine Funktion im identischen Kalkul hat sich oben gezeigt, dass sie, sofern sie nicht invariant ist, eine periodisch iterirende mit der Periode 2 sein muss.
Dass auch die relativen Operationen zur Bildung von Funktionen mit divergenten Iterationen führen können (und im Allgemeinen führen werden) zeigt schon das Beispiel f(u) = a; u, in welchem fr(u) = ar; u, gleichwie die Potenz ar selbst, im Allgemeinen oszilliren wird.
Für die beiden in unserm Theorem 1) angegebnen Bedeutungen von f(u) haben wir nun: 12)
fr + 1(u) = fr(u)φ{fr(u)} fr + 1(u) = fr(u) + ψ{fr(u)}.
Beim successiven Berechnen der Iterationen von f tritt also zu dem schon vorhandnen Ausdrucke von fr(u) immer nur ein Faktor:
„φ von allem Bisherigen“, resp. ein Summand:
„ψ von allem Bisherigen“ hinzu und ist das Bildungsgesetz der iterirten Funktionen leicht zu überschauen, wennschon die Ausdrücke für dieselben bei wachsendem Exponenten rasch immer verwickelter werden.
Wir haben z. B. links: f(u) = uφ(u), f2(u) = uφ(u)φ{uφ(u)}, f3(u) = uφ(u)φ{uφ(u)}φ[uφ(u)φ{uφ(u)}], … und rechts: f(u) = u + ψ(u), f2(u) = u + ψ(u) + ψ{u + ψ(u)}, f3(u) = u + ψ(u) + ψ{u + ψ(u)} + ψ[u + ψ(u) + ψ{u + ψ(u)}] ….
Obschon die Namen für „das Bisherige“ immer länger werden, steigern sich indessen keineswegs auch die Berechnungsschwierigkeiten oder Mühen.
Die Bildung von fr + 1(u) zu schon gewonnenem fr(u) bleibt ebensoleicht und erfordert wesentlich nicht mehr Arbeit, wie die Berechnung der Funktion φ resp. ψ selbst für ein irgendwie gegebnes Argument.
Die unbegrenzt fortgesetzten Iterationen der Funktion f(u) präsentiren sich also hier in der Form eines identischen unendlichen Produktes, resp. einer identischen unendlichen Summenreihe, und folglich sind sie (nach oben bewiesenem allgemeinern Satze) konvergent; es hat f∞(u) einen ganz bestimmten Wert.
Die „Probe 1“ für unser Th. 1) verlangt zu zeigen, dass dieses eine Wurzel der aufzulösenden Subsumtion angibt, wie immer der Wert des arbiträren Parameters u auch gewählt sein mochte.
Die „Probe 2“ verlangt zu zeigen, dass wenn von vornherein ist, dann auch f∞(x) = x selbst sein müsse.
x⋹φ(x) ψ(x) ⋹x
Letzteres ist leicht, in Anbetracht, dass die Voraussetzungen sich auch äquivalent umschreiben lassen in: mithin in: f(x) = x.
x = xφ(x)
x + ψ(x) = x
[Diese Wahrnehmung hat auch zur Entdeckung des iterirt die Lösung liefernden f(u) naheliegend geführt.]
Ist aber für irgend eine Funktion f(u) und einen bestimmten Argumentwert x von u wie vorstehend f(x) = x, so muss auch sein f2(x) = f{f(x)} = f(x) = x, etc., allgemein: fr(x) = x und f∞(x) = x.
Es hat nämlich wegen {fr(x)}i j = xi j nicht nur von einem bestimmten Werte des r an, sondern überhaupt, der linkseitige Koeffizient den Wert des rechtseitigen, somit trägt fr(x) die Augen des x als definitive Besetzung seiner Matrixstellen und hat die Leerstellen des x zu definitiv unbesetzten Stellen.
Hiedurch eben war aber das Relativ f∞(x) zu bestimmen, sodass von letzterem das nämliche gilt.
Mithin stimmt die Probe 2 und erscheint es sichergestellt, dass unsre Lösung 1) sämtliche Wurzeln des betreffenden Problemes liefert.
Nicht ganz so einfach ist jedoch Ersteres, nämlich die „Probe 1 oder der Nachweis zu leisten, dass unsre Lösung 1) auch (für jedes u) immer nur Wurzeln des Problemes liefere.
Gibt man freilich den jedem Mathematiker schon geläufigen Satz zu, dass wenn f∞(u) einen Sinn hat, nämlich fr(u) bei unbegrenzt wachsendem r konvergirt, dann f∞ + 1(u), aufgefasst als f{f∞(u)}, = f∞(u) selbst sein müsse, so ist der Beweis leicht zu führen, indem wir haben: f∞(u) = f{f∞(u)} = f∞(u)φ{f∞(u)} ⋹ φ{f∞(u)}, somit f∞(u) ⋹ φ{f∞(u)} | | ψ{f∞(u)} ⋹ f∞(u) + ψ{f∞(u)} = f{f∞(u)} = f∞(u), somit ψ{f∞(u)} ⋹ f∞(u), womit also für x = f∞(u) in der That die Probe 1 stimmt, nämlich für jedes u sich x ⋹ φ(x) resp. ψ(x) ⋹ x erweist.
Allein jener „Satz“ selbst ist für unsre Disziplin nicht so ganz einfach zu erhärten.
Bevor ich ihn in seiner Allgemeinheit bespreche, will ich auf den vorliegenden Anwendungsfall mich beschränkend — z. B. links vom Mittelstriche — sagen:
Nach linkseitigem Schema 12), für unbegrenzt wachsende Iterationsexponenten r in Anspruch genommen, hat f∞(u) zum Faktor: φ{fr(u)} für jedes noch so grosse r gebildet, mithin hat es auch φ{f∞(u)} selbst zum Faktor und muss diesem eingeordnet sein. M. a. W. bei der Bildung des unbegrenzten Produktes, als welches wir f∞(u) zu gewinnen hatten, tritt zu der Folge der schon angesetzten Faktoren ohne Ende fort immer φ von allem Bisherigen als weitrer Faktor hinzu; unter „allem Bisherigen“ figurirt („schliesslich“?) auch das Ganze f∞(u) selbst — q. e. d.(?).
Diese Überlegung ist jedenfalls unanfechtbar, sobald unser Denkbereich ein endlich begrenzter sein sollte.
Denn alsdann ist auch die Menge der überhaupt denkbaren Relative eine endlich begrenzte; es können die Faktoren unsrer Faktorenfolge nicht ohne Ende fort verschieden ausfallen und muss schliesslich das Produkt konstant werden, nämlich sich beim Hinzutritt der weitern Faktoren tautologisch wiedererzeugen.
In diesem f∞(u) kommt dann φ{f∞(u)} als Faktor wirklich vor.
Das Schema 1) nach welchem wir befriedigende allgemeine Lösungen für zahlreiche Einzelprobleme konstruiren werden, ist demnach als korrektes Schema der Auflösung allermindestens für jeden endlichen Denkbereich gerechtfertigt — und damit ist schon viel gewonnen!
Ich erhalte dasselbe jedoch ganz allgemein aufrecht — auch für die unbegrenzten Denkbereiche, obwohl ich gestehen muss, dass mich Dasjenige was ich an dieser Stelle zur Begründung dafür vorbringen kann, noch nicht vollkommen befriedigt.
Wer das Bedenken teilt, braucht den speziellern auf das Schema späterhin gegründeten Problemlösungen bis auf weiteres blos mit der angegebenen Beschränkung Vertrauen zu schenken.
Doch will ich nicht versäumen, schon hier den Kernpunkt der Frage thunlichst klar zu legen, und zu dem Ende dem Leser die Betrachtungen des folgenden Kontextes nahe legen.
Es liess sich u∞ als [Formel] ur überhaupt nur erklären, falls für jedes Suffix ij ein Zahlwert n angebbar ist oder existirt, derart, dass (ur)i j von r = n an mit wachsendem r konstant bleibt, mithin den Wert (un)i j = 0 oder aber 1 „endgültig“ beibehält für jedes r > n.
Darnach ist evident, dass 13) [Formel] sein muss, indem das oben Gesagte, was bei ur von r = n an zutrifft, bei ur + 1 von r = n - 1 an zutreffen wird und umgekehrt.
Zweifellos gilt darum auch: 14) [Formel] .
Nach dem Prinzipe, gemäss welchem, wie eingangs gesagt, für einen allfällig existirenden Grenzwert von ur der Name u∞ eingeführt worden, nach demselben Prinzipe hätten wir nun auch als Namen für den zweiten Ausdruck der vorstehenden Zeile 14) diesen: f{f∞(u)}, und darnach schiene unser Satz erwiesen.
Als Gleichheitsbehauptung zwischen f∞(u) und f∞ + 1(u) ist dies auch thatsächlich der Fall, wobei das letztre Symbol durch den ersten oder zweiten Ausdruck 14) erklärt zu denken ist.
Dagegen ist zu sagen, dass auf letztern Ausdruck jenes Prinzip unsrer Namengebung nicht anwendbar ist, indem es durch Einführung eines Doppelsinnes hier verfänglich wird.
Nachdem f∞(u) nämlich als existirend erkannt und erklärt worden, steht auch die Bedeutung von f{f∞(u)} als die des Wertes von f(x) für x = f∞(u) schon fest, ist dieser Name bereits vergeben und nicht mehr verfügbar um andrerseits auch den [Formel] f{fr(u)} ohne weitres damit zu taufen.
Vielmehr würde durch die Identifizirung beider implicite von einem ausdrücklich zu statuirenden und erst zu erweisenden Satze Gebrauch gemacht: 15) [Formel] , der nebenbei sich als Sonderfall eines allgemeineren Satzes darstellt: 16) [Formel] .
An der Gültigkeit dieses Satzes 16) zu zweifeln ist schon durch das Präzedenz der arithmetischen Analysis nahe gelegt, wo derselbe dann wenn die Funktion f(x) bei x = u∞ „unstetig“ ist, bekanntlich nicht gilt, vielmehr der „Grenzwert“ der Funktion von ihrem „Endwert“ (oder „Wert schlechtweg) verschieden ist.
Um sogleich den Satz 16) — als den allgemeineren — für unsre Disziplin mit ihrer Beschränkung des Begriffs von f(u) auf einen durch die sechs Spezies aus u und andern (von u unabhängigen) Relativen abgeleiteten Ausdruck zu beweisen kann man versuchen, die Gültigkeit desselben zunächst für jene Elementaroperationen mittelst deren f(u) sich aufbaut, darzuthun in Gestalt der Sätze: 17) 18) worin auch [Formel] als existirend, vr gleichwie ur als konvergent vorauszusetzen ist, und falls z. B. vr = a eine Konstante bezüglich r vorstellen sollte, auch v∞ = a zu denken wäre.
Von diesen Sätzen gelingt es sehr leicht die vier ersten zu beweisen.
Z. B. diese Überlegung beweist den ersten von ihnen: Ist für irgend ein ij und jedes r > n der Koeffizient (ur)i j endgültig = 0 oder 1, so ist auch ebendafür (ur̅)i j endgültig = 1 oder 0. Ebenso leuchten auch bei endlichem Denkbereiche die beiden letzten Sätze ein; dann wird es nämlich ein r geben — das grösste unter den n, die den (ur)i h und (vr)h j einzeln entsprechen — von welchem an, in der Σh des Produktes beider, diese Terme ihre endgültigen von r unabhängigen Werte erlangt haben, und dann wird das gleiche auch mit der Summe, d. h. mit (ur; vr)i j, der Fall sein.
Und ebenso wie die endgültigen Werte der (ur; vr)i j sich aus den Koeffizienten (ur)i h und (vr)h j zusammensetzen, ebenso muss sich auch (u∞; v∞)i j aus den Koeffizienten von u∞ und v∞ zusammensetzen, weil diese eben als jene erklärt worden.
Dagegen stösst bei unbegrenztem Denkbereiche der Beweisversuch [sofern Satz 18) dann überhaupt noch gilt!] auf Schwierigkeiten, die wir im Kontext der S. 182 in der eckigen Klammer schon angedeutet haben.
Hievon abgesehn würde von den Teilsätzen 17), 18) über die beim Aufbau von f(u) verwendeten Operationen die Behauptung sich offenbar leicht auf den aus ihnen aufgebauten Ausdruck f(u) selbst übertragen und wäre damit auch unser Satz 18) erwiesen.
§ 14. Beispiele einfachster Art.
Zur Illustration der allgemeinen Ergebnisse des vorvorigen Paragraphen wollen wir nun einmal die sämtlichen Propositionen auflösen, welche aus den Forderungen x ≠ 1 und x ≠ 0 nebst deren Verneinungen aufgebaut werden können.
Die letzteren x = 1 und x = 0 stellen schon ihre eignen Lösungen vor.
In Anbetracht, dass Inkonsistenzen sind: (x = 1)(x ≠ 1) = (x = 0)(x ≠ 0) = (x = 1)(x = 0) = 0, dass ferner als allgemeine Formel gilt: (x = 1) + (x ≠ 1) = (x = 0) + (x ≠ 0) = 1, endlich dass sich reduzirt: sieht man leicht, dass nur die folgenden vier Probleme in Betracht kommen können: den Forderungen x ≠ 1, x ≠ 0, (x ≠ 1)(x ≠ 0), (x = 1) + (x = 0) je für sich zu genügen.
(x = 1)(x ≠ 0) = (x = 1) (x = 1) + (x ≠ 0) = (x ≠ 0) (x ≠ 1)(x = 0) = (x = 0) (x ≠ 1) + (x = 0) = (x ≠ 1),
Aufgabe 1 und 2.
Die Ungleichung aufzulösen: d. h. vermittelst eines arbiträren Relativs u das allgemeinste Relativ x zu konstruiren, welches nicht = 1 resp. nicht = 0 ist.
x ≠ 1 x ≠ 0,
Auflösung.
Unsre Ungleichung ist bekanntlich äquivalent der Gleichung:
Für die Koeffizienten des gesuchten x muss also nach 3) des § 10 gelten:
Diese Gleichung vermögen wir aber — links nach Bd. 1, S. 501 sowie Bd. 2, § 51, Aufg. 16 — symmetrisch allgemein zu lösen und zwar vermöge des Ansatzes:
0 ɟ x ɟ 0 = 0 1; x; 1 = 1.
Πh kxh k = 0 Σh kxh k = 1.
xi j = ui jΣh kūh k xi j = ui j + Πh kūh k.
Darnach ist gefunden: und drückt unser Ergebniss der Satz aus: 1) .
x = u · 1; ū; 1 x = u + 0 ɟ ū ɟ 0
In der That ist:
[Formel]
Aufgabe 3. Die Proposition aufzulösen: 2) (x ≠ 1)(x ≠ 0), d. h. den Ausdruck für das allgemeinste Relativ zu finden, welches eo ipso weder null noch eins ist (ausserdem aber jedes Wertes fähig).
Auflösung.
Auf 0 oder 1 rechterhand gebracht stellt sich unsre Proposition bezüglich dar als die vereinigte Gleichung: und fordert für die Koeffizienten, dass 3) gemacht werde.
0 ɟ x̄ ɟ 0 + 0 ɟ x ɟ 0 = 0 1; x̄; 1 · 1; x; 1 = 1
Πh kxh k + Πh kx̄h k = 0 Σh kxh k · Σh kx̄h k = 1
[Nebenbei gesagt könnte die vereinigte Gleichung auch in die einfachere Gestalt zusammengezogen werden: oder auch x und x̄ vertauscht.
Denn letztere Relation gibt für die Koeffizienten die Forderung: in deren Übereinstimmung mit der obigen der „Beweis ad hoc“ für die behauptete Vereinfachungsmöglichkeit zu erblicken ist.
Man könnte dafür auch das allgemeinere Schema 5) des § 11 anziehen.]
0 ɟ x̄ ɟ 0 ɟ x ɟ 0 = 0 1; x̄; 1; x; 1 = 1
Πh k l m(x̄h k + xl m) = Πh kx̄h k + Πl mxl m = 0 Σh k l mx̄h kxl m = Σh kx̄h k · Σl mxl m = 1,
Die Forderung — links z. B. — zerfällt nun in die beiden: Πi jxi j = 0 und Πi jx̄i j = 0, deren jede für sich allein wir nach den Schemata in der vorigen Aufgabe symmetrisch allgemein aufzulösen vermögen.
Versucht man jedoch die arbiträren Parameter uh k der einen Lösung so zu bestimmen, dass sie auch der andern Forderung genügen, so gelangt man allemal für diese Unbekannten uh k zu Gleichungen von genau derselben Form wie die von den xh k zu erfüllen gewesenen Gleichungen 3); man bewegt sich also in einem Zirkel.
Die Lösung des zusammengesetzten Problemes zeigt sich hier durch die vorgängige Lösung seiner (beiden) Teilprobleme in keiner Weise gefördert — eine Wahrnehmung, die in unsrer Disziplin sehr häufig (obzwar nicht immer) zu machen ist!
Jene dürfte dann am besten a priori, ganz unabhängig von den Teilproblemen, in Angriff genommen werden.
Es kommt wesentlich darauf an, die Gleichung links in 3) nach den unbekannten Koeffizienten xh k „symmetrisch allgemein“ aufzulösen.
Die Forderung der Symmetrie ist darin begründet oder läuft darauf hinaus, dass eben ein einheitlicher Ausdruck für jedes unbekannte xi j gefunden werden muss, der sich dann allgemein als Koeffizient des unbekannten Relativs x darstellen lasse; m. a. W. es muss der allgemeine Wurzelwert für xi j aus dem für xh k durch Vertauschung von h mit i und k mit j hervorgehn.
Für Klassen xi j war zwar schon die symmetrisch allgemeine Lösung der Gleichung x1x2x3 + x̄1x̄2x̄3 = 0 nach Bd. 1, S. 699 unmöglich (in ebensoviel Parametern, wie Unbekannten, zum mindesten, wenn nicht überhaupt).
Für auf den Wertbereich 0, 1 beschränkte Koeffizienten (resp. Aussagen) xi j kann sie gleichwol möglich sein und ist sie möglich wenigstens für jede Quadratzahl von Unbekannten.
Denn sie wird für solche durch die nachher gegebene allgemeine Lösung unsrer Aufgabe 2 implizite geleistet.
Die Lösung gelingt, wenn wir auch noch die beiden relativen Moduln 0' und 1' herbeiziehen, welche beide ja ≠ 0 und ≠ 1 sind.
Beachtet man nun, dass das Relativ , so sieht man dass der Ausdruck sein muss, und konstruirt man leicht in Gestalt von 4)
[Formel] das gesuchte allgemeinste Relativ, welches weder 0 noch 1 ist.
Wir haben nämlich in der That f(1) = 1' ≠ 0 und 1, desgleichen f(0) = 0' ≠ 0 und 1, in jedem andern Falle aber, d. h. in jedem Falle wo u ungleich 0 und 1 ist, f(u) = u selbst.
Der Ausdruck f(u) umfasst also von vornherein jedes irgendwie von 0 und 1 verschieden gegebene Relativ, und nur solche Relative, q. e. d.
Für f(u) könnte auch der dazu duale Ausdruck genommen werden.
Schon die blosse Negation des obigen Ausdruckes 4) von f(u) würde (gleich x gesetzt) zwar dem Begriff der allgemeinen Lösung von 2) entsprechen, aber nicht die Adventivforderung erfüllen.
Ausserdem leuchtet im Hinblick auf die Begründung ein, dass die Faktoren 1' und 0' in 4) auch durch irgendwelche spezifizirte, nur eben von 0 und 1 verschieden gewählte Relative ersetzt werden dürften; insbesondre kann man dieselben auch vertauschen, oder auch: diese beiden relativen Moduln durch blos einen von ihnen vertreten lassen — z. B. 0' durch 1' ersetzen — immer wird man so zwar wesentlich verschiedene aber gleichberechtigte und gleichermassen brauchbare Formen der allgemeinen Lösung erhalten, deren Vielgestaltigkeit ersichtlich ist.
Aufgabe 4. Die Proposition aufzulösen: 5) (x = 1) + (x = 0), d. h. das allgemeinste Relativ aufzustellen, welches entweder = 1 oder = 0 ist.
Auflösung.
Die vereinigte Gleichung, rechts auf 0 oder 1 gebracht, ist bezüglich: — gerade umgekehrt, wie über 3).
1; x̄; 1; x; 1 = 0 0 ɟ x̄ ɟ 0 ɟ x ɟ 0 = 1
Als allgemeine Wurzel vermögen wir sofort anzugeben: x = f(u), wo f(u) irgend ein „ausgezeichnetes“ Relativ in u vorstellt.
Solcher gibt es wol unendlich viele.
Indem wir aber die uns zunächst bekannten sechs Peirce’schen benutzen, mit denen sich obendrein die Adventivforderung als erfüllt erweist, mögen wir den Satz notiren: 6)
[Formel] .
In jedem der sechs Fälle erhalten wir für u = 1 auch x = 1 und für u = 0 auch x = 0; dagegen für (u ≠ 1)(u ≠ 0) wird x zwar ebenfalls entweder = 1 oder = 0, jedoch unter ganz andern Bedingungen bei einem jeden der sechs Ausdrücke — wie solche in § 10 nachgesehen werden können.
Auch die Annahmen x = f(u) = 1; u; 1; ū; 1 resp. 0 ɟ u ɟ 0 ɟ ū ɟ 0 z. B. würden zwar dem Begriffe der allgemeinen Wurzel von 5) noch entsprechen, aber nicht mehr der Adventivanforderung genügen, indem der erstere Ausdruck nicht nur für u = 0 sondern auch für u = 1 gleich 0 wird, der letztere in beiden Fällen gleich 1, sonach mit ihm die Wurzel 0 sich nicht reproduzirt.
Für u ≠ 0 und 1 wird dann umgekehrt der erstere = 1, der letztere = 0.
Zur Vergleichung wollen wir für die vier hiermit eigenartig gelösten Aufgaben auch noch „rigorose“ Lösungen in’s Auge fassen.
Zu dem Ende haben wir die Schemata 12), 16) und 17) des § 12 — S. 166, 174 — anzuwenden, wobei die dem F(u) jeweils beizulegende Bedeutung aus der von uns angegebnen vereinigten Nullgleichung der Aufgabe ersichtlich ist.
Die rigorose Lösung wird hienach völlig bestimmt sein durch den Hinweis auf eine partikulare Lösung a des Problemes, welche, als a priori erkannt, ihr zugrunde zu legen wäre.
Als solche bietet sich eventuell 0 oder 1, eventuell ein relativer Modul als die zweckmässigste dar, um einen möglichst einfachen Ausdruck der allgemeinen Lösung zu erzielen.
Für die linkseitige Aufgabe 1, also die Ungleichung x ≠ 1 ist x = a = 0 die zweckmässigste Partikularlösung.
Wir erhalten dann nach dem Schema 16) des § 12 die rigorose Lösung zunächst in der Form: x = u{0 ɟ 1; ū; 1 ɟ 0}, was sich aber nach der Bemerkung am Schlusse des § 10 zu x = u · 1; ū; 1, d. h. zu 1) selber vereinfacht.
Also:
Für die beiden Aufgaben 1, 2 ist die gefundene Lösung 1) zugleich rigorose Lösung.
Hier liegt ein Grenzfall vor, wo die rigorose Lösung ausnahmsweise auch das Epitheton einer befriedigenden allgemeinen Lösung verdient und es keinen Sinn hätte nach einer andern zu fahnden — wie man leicht sieht aus dem Grunde, weil es hier eben nur ein Relativ (1 resp. 0) gibt, welches der Forderung der Aufgabe nicht genügt.
Zu Aufgabe 3, wo (x ≠ 1)(x ≠ 0) sein soll, können wir a nach Belieben = 1' oder = 0' nehmen.
Wir erhalten, indem wir das F(u) dem F(x) links vom Mittelstriche nachgebildet nehmen, als rigorose Lösung gemäss Schema 12) des § 12 nach leichtester Reduktion: 7)
[Formel] , worin sich auch 0' für 1' setzen lässt.
Auch mit dieser Form 7) der rigorosen Lösung kommt die — formell nur etwas allgemeinere — Lösungsform 4) zur Deckung, falls man in letztrer, 1' beibehaltend, auch 0' durch 1' ersetzt.
Mit Rücksicht auf 3) des § 11 kann man nämlich bemerken, dass sich wegen u · 1; u; 1 = u auch in 7) der letzte Term noch in u · 1; ū; 1 vereinfachen lässt, sodass wir als wol konzisesten Ausdruck unsrer Lösung haben: 8)
[Formel] .
Zu Aufgabe 4, (x = 0) + (x = 1), haben wir x = a = 0 als die eine, und x = a = 1 als die andre verfügbare Partikularlösung, und erhalten demnach gemäss Schema 16) resp. 17) des § 12 die beiden ebenbürtigen Formen der rigorosen Lösung: 9)
[Formel] , welche ebensogute Dienste als wie die Lösungen 6) zu leisten vermögen und als die Lösungen „katexochen“ der Aufgabe zu bezeichnen wären.
Auch in diesen Fällen tritt das „Unbefriedigende“, welches sonst den rigorosen Lösungen anhaftet, noch nicht zutage.
Als eine interessante Gruppe von 12 Aufgaben schliesst sich den vorhin gelösten das Problem an: das allgemeinste Relativ x zu bestimmen, für welches ein gegebenes von den sechs ausgezeichneten Relativen verschwindet, resp. den Wert 1 annimmt.
Die Lösungen für diese zwölf Aufgaben sind in folgender Zusammenstellung angegeben: 10) 11) 12) 13) .
(0 ɟ x ɟ 0 = 1) = (x = 1)
(1; x; 1 = 0) = (x = 0)
Hievon ist 10) bereits mit 5) des § 10 gegeben, und 12) fällt mit der Lösung 1) unsrer obigen Aufgabe 1 zusammen.
Die Lösungen 11) werden systematisch von uns erst abgeleitet in § 16 unter 14) als „Aufg. 9“ und 21) als „Aufg. 17“, und sind hier vorgreifend angeführt; doch bietet ihre schon hier unschwer zu bewältigende Verifikation vermittelst beider Proben eine gute Übung für Anfänger.
Diese Lösungen 11) sind wesentlich verschieden von den „rigorosen Lösungen derselben Aufgaben, wie sie sich im Hinblick auf die partikulare Lösung x = 1 resp. 0 nach den Schemata 16) und 17) des § 12 mit Leichtigtigkeit ergeben, und sie sind weit befriedigender als diese letztern.
Für das Problem rechts oben in 11) würde man z. B. als die rigorose Lösung x = u(0 ɟ ū; 1) — anstatt ū; 1 · u — erhalten.
Etc.
Dagegen gewinnt man die Lösungen 13) am bequemsten aufgrund der ersichtlichen Partikularlösung oder speziellen Wurzel x = 0 resp. 1 gerade als die rigorose Lösung der betreffenden Aufgabe — nach soeben genannten Schemata.
Man scheint sich hier wohl oder übel mit der rigorosen Lösung zufrieden geben zu müssen.
Während 11) uns in den Stand setzt, das allgemeinste Relativ anzugeben, welches lauter besetzte Zeile(n) (d. i. keine Leerzeile) resp. keine Vollzeile hat, vermögen wir nach 13) auch das allgemeinste Relativ anzugeben, welches unbesetzte (oder Leer-)Zeile(n) hat, resp. welches Vollzeile(n) besitzt — und ähnlich für Kolonnen.
Jenes erste erhalten wir aus u, indem wir die etwaigen Leerzeilen des u, in Vollzeilen verwandelt, ihm zufügen.
Um dagegen dieses (drittgenannte) Relativ aus einem u von lauter besetzten Zeilen zu erhalten, müsste man deren irgendwelche abwerfen, und da kein Grund erfindlich ist, der allgemein den Ausschlag dafür geben könnte, welche Zeilen in dieser Hinsicht vor den andern zu bevorzugen wären, so verlangt es die Formel alsdann gleichmässig für alle Zeilen und verweist so auf die völlig bestimmte Partikularlösung 0 zurück — womit sich der oben bemerkte auffallende Gegensatz wohl einigermassen erklärt.
In methodologischer Hinsicht verdient es vielleicht Beachtung, dass die Lösungen 13) sich aufgrund derer 11) auch systematisch finden lassen ohne dass man in einen Zirkel gerät.
Um dies zu zeigen, muss ich freilich noch weiter vorgreifen.
Soll etwa 1; x ɟ 0 = 0 oder y ɟ 0 = 0 sein, so muss man nach dem Schema von 11) oben rechts haben: y, das ist 1; x = v̄; 1 · v.
Der Adventivforderung gemäss wird dabei v dem y als wesentlicher Parameter zugeordnet sein, und da y = 1; x bedeuten sollte, so wird derselben Adventivforderung zuliebe auch v durch 1; u zu ersetzen sein, damit schliesslich u dem x als wesentlicher willkürlicher Parameter entspreche.
In § 19 werden wir aber lernen, eine Gleichung von der Form 1; x = a in der Gestalt: x = a(u + 0 ɟ u;̄) aufzulösen und zugleich sehn, dass dabei als Resultante: a = 1; a zutreffen muss.
Mit dem oben motivirten Werte v = 1; u, also v̄ = 0 ɟ ū wird nun unser a = (0 ɟ ū); 1 · 1; u = (0 ɟ ū); 1; u und zeigt sich die Forderung der Resultante als 1; a = 1; (0 ɟ ū); 1; u = (0 ɟ ū); 1; u = a von selbst erfüllt.
Darnach haben wir sofort: x = (u + 0 ɟ ū) · (0 ɟ ū); 1 · 1; u = u · (0 ɟ ū); 1, weil u · 1; u = u und (0 ɟ ū) · 1; u = 0 ist — d. h. es ist die dritte von den Lösungen 13) gewonnen.
Auf diesem Wege hatte ich sie erstmals gefunden.
Dass jedes System von universalen Propositionen (also blos Gleichungen und Subsumtionen) sich, sofern es lösbar (d. h. nicht absurd) ist, in der Form x = f(u) auflösen lasse, dies hatte sich schon im identischen Kalkul herausgestellt und war das Fortbestehen dieser Thatsache auch in der Algebra der Relative wol weniger überraschend.
In § 12 haben wir aber gezeigt, dass hier ein Gleiches auch für Systeme mit partikularen Propositionen (Ungleichungen oder Unsubsumtionen) gelten muss — und nicht blos für Systeme mit simultanen sondern auch für solche mit alternativen Forderungen.
Die obigen Beispiele habe ich darum mit Vorliebe aus dem letzteren, dem ganz neu hinzugekommenen Anwendungsgebiete gewählt.
Dies um so mehr, als wir demnächst unsre Aufmerksamkeit für längere Zeit wieder vorwiegend den Problemen von universalem Charakter zuzuwenden haben werden.
Ebendarum seien nun auch noch folgende Probleme mit ihren Lösungen hiernächst angeführt: 14) [Formel] , 15) [Formel] . 16) [Formel] , wozu noch x̄ = 1; (pu + qū); 1 · ū + (p̄ + q){0 ɟ (p̄u + q̄ū) ɟ 0} gehört und zu bemerken ist, dass der Faktor pq̄ auch durch p + q̄ (sowie durch p oder q̄ allein) ersetzbar wäre.
Die Verifikation von 14) und 15) dem Leser überlassend, beweisen wir 16) wie folgt.
Entweder ist pu + qū ≠ 0, also p̄u + q̄ū ≠ 1 und 1; (pu + qū); 1 = 1, 0 ɟ (p̄u + q̄ū) ɟ 0 = 0; dann wird x = u, mithin px + qx̄ ≠ 0 und stimmen beide Proben.
Oder es ist pu + qū = 0 (was auch pq = 0 involvirt); alsdann wird 1; (pu + qū); 1 = 0, 0 ɟ (p̄u + q̄ū) ɟ 0 = 1, x = pq̄, x̄ = p̄ + q, px = pq̄ = pq̄ + pq = p, qx̄ = q, px + qx̄ = p + q ≠ 0, und stimmt abermals die Probe 1, während die Probe 2 gar nicht in Frage kommen kann, q. e. d.
NB.
Dass bei dem regelrecht gebildeten x̄ das Glied ū(p̄ + q) unterdrückbar war beruhte auf dem Satze Bd. 1, S. 376: ra + ab + br̄ = ra + br̄, wobei r das ausgezeichnete Relativ im ersten Gliede von x oder x̄ vertrat.
Hervorhebung verdient der Unterfall von 16) (āx + ax̄ ≠ 0), in welchem die Resultante p + q ≠ 0 der Elimination des x im allgemeinern Probleme — als in der Gestalt ā + a = 1 ≠ 0 von selbst erfüllt — entfällt.
Wir haben also: 17) [Formel] und wird hier in der That x = u sobald u ≠ a, dagegen x = ā sobald u = a angenommen ist; unbedingt also wird stets x ≠ a.
Als eine Nutzanwendung der Formel 14) wollen wir auch noch das allgemeinste Relativ angeben, welches bezüglich Selbst- resp. Aliorelativ, Konkurrent oder Opponent ist — vergl. (α) bis (δ) des § 9, S. 131 sq.
Während darnach 18) [Formel] ohne weitres einleuchtet, ist Berufung (für p = 1', 0') auf 14) erforderlich, um in Gestalt von 19) [Formel] auch die beiden letzten Relative zu gewinnen.
Ebendamit wird in vorstehender Ordnung bezüglich auch 1' + u, 0' + u, u · 1; 1'ū; 1, u · 1; 0'ū; 1 als allgemeinste Darstellung eines Relativs von der Kategorie des Negates von einem der vier vorigen ermittelt sein.
Wir haben nun also auch die allgemeinste Ungleichung, welche der identische Kalkul kennt, in der Form x = f(u) aufgelöst.
In bedeutend erweiterter Gestalt werden wir das Problem später wieder aufnehmen.
Zum Schlusse noch eine Bemerkung (Miscelle).
Gelegentlich vergeblicher Versuche, die Aufgabe 3 heuristisch, mittelst systematischer Erfüllung der Koeffizientenforderung 3), zu lösen, bin ich auf eine beachtenswerte Funktion geführt worden:
Wird: 20) f(u) = u · 1; ū; 1 + ū(0 ɟ ū ɟ 0) gesetzt, so stellt sich heraus dass f(1) = 0, f(0) = 1, jedoch ausserdem stets f(u) = u ist.
Das Relativ f(u) ist hienach insofern ein merkwürdiges Relativ, als es — alles Andre ungeändert lassend — blos die Werte 0 und 1 in einander verkehrt!
Sechste Vorlesung.
Die Parallelreihentransformationen und -Probleme.
§ 15.
Die 256 Zeilenabwandlungen eines allgemeinen Relativs.
Ebensoviele Kolonnenabwandlungen.
Einschlägige Sätze.
Wir haben in § 9 begonnen uns mit den sich nicht reduzirenden Modulknüpfungen der Relative zu beschäftigen.
Wie schon die Erforschung eines kleinen Teilgebietes dortselbst ahnen liess, wird es gar keine leichte Sache sein, einen Überblick über die Mannigfaltigkeit alles dessen zu gewinnen, was sich mittelst solcher Modulknüpfungen überhaupt leisten, hinbringen lässt, all der Veränderungen die damit an gegebenen Relativen bewirkt werden können sowie der Probleme die dadurch der Lösung zugänglich werden.
Und doch muss, wer Schlachten schlagen will, sich einen Überblick über die ihm zugebote stehenden Mittel und Heeresmassen verschaffen.
Um uns nach und nach zum Bewusstsein zu bringen, was auch nur mit Hülfe der acht relativen von den primären irreduziblen Modulknüpfungen sich alles erreichen lässt, d. h. welche etwa gewünschten oder verlangten Relative sich damit aus einem irgendwie gegebnen Relativ a ableiten lassen, studiren wir das Relativ zunächst blos hinsichtlich seiner Zeilen.
Dann kommen von den 8 Knüpfungen 2) des § 9 blos die viere in Betracht in denen das Argument dem Modul vorangeht:
weil die vier andern immer Umwandlungen an den Kolonnen von a bewirkten.
Wir unterscheiden jene von diesen als die „Zeilen-“ gegenüber den „Kolonnen-Knüpfungen“.
a; 1 a ɟ 0
a; 0' a ɟ 1',
Die vier Knüpfungen veranlassten uns fünferlei Arten von Zeilen in a zu unterscheiden und sie gestatten uns im Allgemeinen, aus a solche gesondert hervorzuheben und sie auch unabhängig von einander gewissen noch genauer zu statuirenden Umwandlungen zu unterwerfen.
Diese Arten sind:
erstens die Vollzeilen, zweitens die einlückigen Zeilen, drittens die mehrlückigen aber auch mehrbesetzten Zeilen, viertens die einbesetzten (d. i. nur ein Auge als sogenannten „Reiter“ tragenden) Zeilen und fünftens die Leerzeilen — — entsprechend den Unterscheidungen von Nullzahl, Einzahl und Mehrzahl als fehlend oder vorhanden.
Dabei müssen wir freilich annehmen, dass der Denkbereich 11 hinreichend viele — mindestens vier — Elemente umspanne, damit die angeführten Zeilenkategorieen sämtlich möglich sind und einander gegenseitig ausschliessen.
Ich will diese fünf Zeilenkategorien durch eine Figur, oder besser ein Schema, veranschaulichen und zwar die mittlere Kategorie doppelt in Gestalt ihrer beiden möglichen Extreme: wo die Anzahl der vorhandnen Lücken resp. der Augen blos 2 beträgt.
Zeilenschema.
Die kräftig ausgezognen Linien repräsentiren hier überall dichte Augenreihen, die hohlen Ringe Punktlücken, die fetten Punkte Augen und die feinst punktirten Linien überall dichte Leerstellen entlang der Zeile.
Um sich die geometrische Evidenz zu sichern, mag der Leser nun zu einem etwa durch das Zeilenschema dargestellt gedachten Relative a sich irgendwelche abgeleitete Relative, wie beispielsweise a; 1, ā ɟ 0, ā; 0' · ā, a; 1 · (ā ɟ 1' + ā) etc. in der gleichen Schematisirung hinzeichnen.
Es wird z. B. ā ɟ 0 als unterste eine Vollzeile und darüber lauter Leerzeilen haben.
Doch wird man solches Verfahren bald als zu mühsam und umständlich empfinden.
Wie wenig man auch die geometrische Evidenz, die Anschauung von der Beschaffenheit der abgeleiteten Relative (im Vergleiche mit dem ursprünglichen a) missen möchte, wird solche Anschaulichkeit auf diesem Wege doch wol zu teuer erkauft erscheinen.
Um den Vorteil der Anschaulichkeit mit dem der knappsten Darstellung, mit analytischer Kürze, zu verbinden, wollen wir das Relativ a „schematisch“ in folgender Weise darstellen: 1) a = 1αβγ0.
Hierin soll bedeuten: 1 das System aller Vollzeilen, α das System der Einlückzeilen, β das System der mehrlückigen mehrbesetzten Zeilen, γ das System der einbesetzten Zeilen und 0 das System der Leerzeilen von a — so, wie wir es auch schon in die Figur des Schemas eingetragen haben.
In Wirklichkeit stehen die Zeilen dieser fünferlei Systeme nicht neben-, sondern untereinander.
Es stehen auch die Zeilen eines bestimmten Systems nicht notwendig beisammen, sondern finden sich irgendwie zwischen die Zeilen der übrigen Systeme eingeschaltet, sodass also von einer bestimmten Reihenfolge zwischen den fünferlei Systemen „innerhalb a“ ganz und gar nicht gesprochen werden kann.
Demungeachtet empfiehlt es sich, weil die zu studirenden Umwandlungen allemal sämtliche Zeilen einer Kategorie gleichmässig betreffen, dieselben jeweils im Geiste zu einem Systeme zusammenzufassen, und ferner auch, die fünf Systeme bei dem ursprünglichen Relativ a jeweils in der oben festgesetzten Reihenfolge durchzugehen.
Wir wollen die Repräsentanten der 5 Zeilenkategorien 1, α, β, γ, 0 geradezu als die (symbolischen) „Ziffern“ der zeilenschematischen Darstellung von a — kurz als die (Zeilen-)Ziffern von a — hinstellen.
Es werden dann grössere Klassen von Problemen in elegantem fünfziffrigen Rechnen sich lösen lassen.
Von den 5 Zeilenkategorien können in dem Relativ a von vornherein irgendwelche, nur nicht alle, unvertreten sein.
Das a braucht z. B. nicht gerade Leerzeilen zu besitzen.
In solchen Fällen kann man, damit die Stelle der übrigen Ziffern gewahrt bleibe, die Ziffer der fehlenden Kategorie durch einen Horizontalstrich im Schema 1) ersetzen, für unser Beispiel also a = 1αβγ- schreiben.
Und darnach würde z. B. auch sein: 1 = 1----, 0 = ----0, dagegen ---γ- ein Relativ vorstellen, welches lediglich aus Zeilenreitern (einbesetzten Zeilen) zusammengesetzt ist (und späterhin als „Argument von-“ zu bezeichnen sein würde).
Indessen für gewisse Untersuchungen werden wir gar nicht nötig haben, das Unvertretensein von Elementegruppen ausdrücklich zu markiren oder von demselben überhaupt Notiz zu nehmen.
Behufs Studiums der Zeilentransformationen mögen wir jede Zeilenkategorie resp. „Ziffer“ als blos eventuell vertreten ansehen.
Denn wenn z. B. eine Operation vorschreibt, das Relativ a dadurch zu transformiren, dass man die Vollzeilen desselben abwirft, d. h. dieselben in Leerzeilen verwandelt, so wird diese Operation in dem Falle, wo a gar keine Vollzeilen besitzt, dasselbe einfach ungeändert lassen.
Im entgegengesetzten Falle aber wird sie das Relativ a ändern, nämlich dasselbe in 0αβγ0 verwandeln.
Und wenn wir nun diesen Ausdruck als das Ergebniss der Operation ganz allgemein hinstellen, so ist dies unbedenklich, nämlich ebendadurch keineswegs ausgeschlossen, dass dieses Resultat für besondre Werte von a mit a selbst an Wert übereinstimme.
Dass solche Übereinstimmung wirklich eintreten muss, sobald — vorstehend sowie in 1) — die erste Ziffer durch einen Horizontalstrich ersetzt wird (damit das Unvertretensein der ersten Zeilenkategorie zum Ausdruck gebracht werde), ist vielmehr auch der vorstehenden Darstellung des Transformationsergebnisses augenblicklich anzusehen.
Die Umwandlungen, die wir lernen müssen mit unsern fünferlei Kategorieen von Zeilen ganz nach Wunsch auszuführen, bestehen darin, dass wir sie entweder einzeln oder in irgendwelchen Kombinationen aus a hervorheben (dieselben ausschliesslich beibehaltend) oder sie in ihm löschen (abwerfen), dass wir ferner auf Verlangen sie verwandeln können in ihre Negationen, oder auch in Vollzeilen sowie in Leerzeilen (welches letztere mit dem schon erwähnten Abwerfen natürlich zusammenfällt).
Die Verwandlung der Zeilen einer bestimmten Kategorie in lauter Vollzeilen drücken wir dadurch aus, dass wir im Schema 1) eine 1 an die Stelle der betreffenden Ziffer setzen; ihre Verwandlung in Leerzeilen dadurch, dass wir eine 0 für die Ziffer einspringen lassen.
Die Verwandlung der Zeilen einer Kategorie in „ihre Negationen“ (somit die Umwandlung von den Leerstellen derselben in Augen und von den ursprünglichen Augen derselben in Leerstellen), diese deuten wir dadurch an, dass wir im Schema 1) über die Ziffer der Kategorie einen Negationsstrich setzen — wobei jedoch 1̄ sogleich in 0, 0̄ in 1 umzusetzen sein wird.
Es ist leicht zu sehen, dass die Anzahl der so aus a erhältlichen Relative (bei Einrechnung der beiden 1 und 0) 256 beträgt, nämlich = 2 × 4 × 4 × 4 × 2 = 28 sein muss — entsprechend den folgenden Möglichkeiten wie die Stelle jeder Ziffer besetzt werden kann:
1 1 1 1 α β γ 0 0 ᾱ β̄ γ̄ 1. 0 0 0
Es handelt sich nun für uns darum, ein jedes dieser 28 = 256 aus einem gegebnen a durch blosse „Zeilenflexion“ ableitbaren Relative vermittelst der Moduln und unsrer 6 Spezies durch a auch ausdrücken zu lernen, sowie umgekehrt für einen jeden dieser Ausdrücke — die man etwa als die „Zeilenrelative von a“ kurz kennzeichnen könnte — augenblicklich ermitteln zu lernen, durch welche Abwandlungen seine Zeilen aus denen von a hervorgehn.
Bei so grosser Zahl von Problemen ist es beinah unthunlich, die Formeln welche sie einzeln lösen thatsächlich hinzuschreiben, und werden wir uns mit einer Methode vertraut zu machen haben, nach welcher eine jede von den Forderungen sich erfüllen lässt.
Schematisch ist natürlich: 2) 1 = 11111, 0 = 00000, d. h. wenn man die Zeilen aller fünf Kategorieen in Vollzeilen verwandelt, erhält man den Modul 1, falls man sie abwirft (in Leerzeilen verwandelt) den Modul 0.
Mit Letzterem ist von vornherein die Isolirung der fünften Zeilenkategorie in a gewährleistet.
Die Ableitung aus a von 1 = a + ā und 0 = aā ist längst bekannt.
Wir wenden nunmehr die schematische Darstellung an, um die Ergebnisse der zweiten Hälfte des § 9, soweit sie Zeilenprobleme betreffen, übersichtlichst zu rekapituliren.
Für unser durch 1) schematisirtes a = 1αβγ0 stellen sich die vier relativen (primären irreduziblen) Modul-Zeilenknüpfungen wie folgt schematisch dar: 3) a; 1 = 11110, a ɟ 0 = 10000, a; 0' = 111γ̄0, a ɟ 1' = 1ᾱ000 — was man sich in dieser Form schliesslich leichter einprägen wird als wie die umständliche Beschreibung mit Worten, wie sie in § 9 S. 141 ‥ 143 gegeben.
In Gestalt von a ɟ 0 vermögen wir also bereits auch die Vollzeilen aus a hervorzuheben, die Lückzeilen abwerfend jene zu isoliren.
Dieselben Modulknüpfungen auf das Relativ 4) ā = 0ᾱβ̄γ̄1 angewendet, lassen uns verfügen über die Relative:
5) ā; 1 = 01111, ā ɟ 0 = 00001, ā; 0' = 0α111, ā ɟ 1' = 000γ1.
Um dieses im Hinblick auf die Konstitution 4) des Negates ā nach den vorhergehenden vier fundamentalen Schemata 3) mechanisch zu gewinnen, braucht man blos zu beachten und sich einfürallemal zu merken: dass β und β̄ von derselben Kategorie sind, dass dagegen α von der Kategorie von γ̄ und γ von der Kategorie des ᾱ sein muss.
Verwandelt also z. B. der relative Multiplikator (Nachfaktor) 0' die Kategorie γ (von a) in γ̄, so muss ebendieser auch die Kategorie ᾱ von ā in α verwandeln, während er β̄ und γ̄ bei ā, geradeso wie β und α bei a, in 1 umsetzt.
Etc.
Wir erledigen nun zuerst die Vor-Aufgabe, diese 12 primären Zeilenrelative — als da sind: die 4 übersichtlich wie folgt zusammengestellten 1), 2), 4): 1 = 11111, a = 1αβγ0 0 = 00000, ā = 0ᾱβ̄γ̄1 nebst den 8 noch einmal untereinander hingesetzt zu denkenden 3) und 5) — diese 12 Relative zu einer „Gruppe“ in Hinsicht der drei identischen Spezies zu ergänzen.
Die Lösung dieser Aufgabe wird für den Forscher ein gewisses Interesse bieten, wenngleich sie zur Erreichung unsres oben gekennzeichneten Zieles nicht unerlässlich ist.
Dieselbe möge daher hier im Kontext summarisch erfolgen.
Wir gehen mit den 12 Relativen zuerst intermultiplizirend vor, ergänzen jedoch neu hinzutretende Gebilde allemal sogleich dual.
Zuweilen ergeben sich für ein dabei neu hinzutretendes Relativ mehrere gleich einfache „einfachste“ Ausdrücke.
Es tritt hinzu: 6)
Dies — bis jetzt zusammen 32 — ist der Gewinn aus den zwölfen.
Jetzt müssen noch die 20 hinzugekommenen Relative mit den zwölfen, dann unter sich, zusammengehalten werden.
Damit erhalten wir noch weiter: 7)
Total: 64 Relative, womit die „Gruppe“ abschliesst.
Was die drei mittleren Stellen betrifft, so kommen ausschliesslich vor die 16 Triaden: von welchen unschwer nachzusehen, dass sie in Hinsicht der drei identischen Spezies eine Gruppe bilden.
Diese aber kommen vor mit auf jede mögliche Weise vorangestellter und hintangehängter 1 oder 0.
111 000 α11 ᾱ00 αβγ ᾱβ̄γ̄ 00γ 11γ̄ αβ0 ᾱβ̄1 α1γ̄ ᾱ0γ 1βγ 0β̄γ̄ 1β0 0β̄1
Wie ein Blick auf die Ergebnisse des Kontextes zeigt — cf. drittes Zeilenpaar links sub 6) — ist nun auch die Isolirung der Zeilenkategorie γ aus a (sowie der ᾱ aus ā) gelungen.
Dazu hat sich offenbart, dass hingegen die Isolirung der Kategorieen α sowie β (oder von deren Negaten) vermittelst identischer Knüpfungen zwischen unsern zwölf primären Zeilenrelativen nicht bewirkt werden kann.
Um sie, die allein noch aussteht, ebenfalls zu erreichen, wird es unumgänglich sein, auch die sekundären irreduziblen relativen Modulknüpfungen von a mit heranzuziehen.
Bevor dies geschieht, soll aber den zahlreichen Sätzen, welche schon unsre primären Relative und deren identische Verknüpfungen beherrschen, einige Beachtung geschenkt werden.
Viele von diesen Sätzen haben bereits sub 6) und 7) des Kontextes sich uns aufgedrängt als solche, welche Gleichheit allgemein statuiren zwischen den dort einander gleich gesetzten Ausdrücken, die sich in „ebenbürtigen“, vollkommen oder nahe gleich einfachen Ausdrucksformen uns darboten.
An sie werden hernach noch weitre auch auf sekundäre und höhere Modulknüpfungen (mit) bezügliche Sätze sich anreihen.
In ihrer Gesamtheit sind diese Sätze äusserst zahlreich und ihre vollständige Aufzählung unthunlich.
Nach Vollständigkeit der letztern zu streben wäre aber auch ebenso zwecklos, wie wenn jemand — nachdem das arithmetische Einmaleins nebst Adam Riese’s Multiplikationsregel bekannt ist — nun alle erdenklichen Produkte von natürlichen Zahlen einzeln ausgerechnet vorführen wollte.
In der That wird jeder von unsern Sätzen durch (noch bequemeres!) fünfziffriges Rechnen nach folgenden Regeln auf das leichteste zu gewinnen und zu verifiziren oder zu beweisen sein:
(Identische)
Multiplikation und Addition von zwei oder mehreren schematisch dargestellten (wohlgemerkt aber immer nur aus dem nämlichen Relativ a abgeleiteten) Zeilenrelativen wird einfach vollzogen, indem man „überschiebend“ deren gleichstellige Ziffern ebenso verknüpft, wobei, wenn δ irgend eine von den fünf Ziffern vorstellt, bekanntermassen gilt: 0 · δ = 0, 1 + δ = 1, 1 · δ = δ, 0 + δ = δ, δ · δ̄ = 0, δ + δ̄ = 1, δ · δ = δ, δ + δ = δ.
Hiezu kommt dann die schon S. 204 angeführte Regel für die Operation des Negirens, welches zifferweise auszuführen ist.
Und was endlich die (etwaigen sekundären oder höhern) relativen Zeilenoperationen betrifft, so wird für solche wiederum das Schema 3) maassgebend sein.
Eingeordnet wird ein solches Zeilenrelativ einem andern stets und nur dann sein, wenn im gleichen Sinne Einordnung zwischen den gleichstelligen Ziffern der beiden durchgängig besteht, wobei 0 ⋹ δ, δ ⋹ δ und δ ⋹ 1 maassgebend ist.
Und gleich sind zwei solche Zeilenrelative immer und nur dann, wenn sie in den gleichstelligen Ziffern durchaus übereinstimmen.
Als Beispiele mag der Leser die Äquivalenzen sub 6) und 7) nachrechnen.
Weitre, auch detaillirte, Rechnungsbeispiele folgen noch.
Wir können darnach jeden nur Zeilenoperationen betreffenden Satz künftighin als bekannt voraussetzen, eine jede, nur solche oder nur Kolonnenoperationen involvirende Formel — mag sie besonders registrirt worden sein oder nicht — ohne jegliche Erläuterung anziehen (citiren).
Gleichwie jedoch — um im obigen Bilde aus der Arithmetik zu bleiben — neben dem Einmaleins und der allgemeinen Multiplikationsregel, doch noch gewisse Sätze (wie für die Multiplikation einer Zahl mit 0, 1, 10, 100, ‥, 11 oder 25 etc.) besonders vom Rechner angeeignet werden müssen, so verdienen auch hier gewisse von den mit obigen Regeln implicite schon gegebenen Sätzen besonders hervorgehoben zu werden.
Ohne, wie gesagt, erschöpfend zu sein, hoffen wir doch die einfachsten und wichtigsten derselben zu treffen — viele, die sozusagen alle Augenblicke in Betracht kommen.
Bei der Vorlegung einer ungezwungenen Auswahl von derartigen Formeln wollen wir indess die Gespanne jeweils vollständig angeben, also auch die Kolonnenoperationen mit einbeziehen, da solche ebensooft Berücksichtigung heischen.
Zwischen a und seinen irreduziblen 8 primären relativen Modulknüpfungen gelten folgende Einordnungen: 8)
[Formel] Nach den Theoremen [Formel] liefert aber jede Subsumtion uns auch zwei Paar Gleichungen — so die obigen hier diese: 9)
[Formel] — desgleichen a und ā vertauscht; dazu: 10) [Formel] 11) [Formel] — Formeln, welche in succum et sanguinem des Studirenden übergehen müssen.
Weiter gelten auch noch die Einordnungen zwischen den primären relativen Modulknüpfungen selber: 12) [Formel] und damit ist wiederum eine Menge von Gleichungen gegeben, von denen im Bedarfsfalle ungenirt Gebrauch zu machen ist, ohne dass sie allesamt chiffrirt und registrirt zu sein brauchten.
Wir heben hervor: 0 = (a ɟ 0)(ā ɟ 0) = (a ɟ 0) · ā; 0' = (a ɟ 0)(ā ɟ 1') = (a ɟ 1')(ā ɟ 1') | | 1 = a; 1 + ā; 1 = a; 1 + ā ɟ 1' = a; 1 + ā; 0' = a; 0' + ā; 0'.
Sehr bemerkenswert sind weiterhin die Sätze: 13) [Formel] 14) [Formel] 15) [Formel] welche in 6) und 7) schon mit vorgekommen.
Man kann z. B. den oberen Satz 13) rechts auch so beweisen: a; 1 = a; (1' + 0') = a; 1' + a; 0' = a + a; 0', und dergleichen mehr.
In allen bisherigen finden sich die primären Modulknüpfungen höchstens durch identische Operationen verknüpft.
Gehen wir jetzt aber zu den Sätzen höherer Stufe über, nämlich zu solchen, worin Ergebnisse der eben charakterisirten Art selbst wieder in relative Modulknüpfungen eingehen, so sind in erster Linie anzuführen die beiden Formelgespanne: 16) [Formel] 17) [Formel] indem dieselben diejenigen von den sekundären relativen Modulknüpfungen aufweisen, welche sich kraft der vorstehenden besondern Sätze und nicht schon kraft des Abacus (auf den ersten Blick) reduziren.
Irreduzibel sind dagegen von den sekundären relativen Modulknüpfungen, welche sich lediglich als Zeilen- resp. Parallelreihen-relative darstellen, die beiden folgenden Quadrupel, die wir mit ihren nach den Schemata 3) und 5) ziffermässig ausgerechneten Werten angeben: 18) [Formel] 19) [Formel]
Von diesen werden wir wenigstens die der tiefern Stufe 18) zur Isolirung der noch ausständigen Ziffern α und β heranzuziehen haben, und werden ebendiese in Verbindung mit den primären Modulknüpfungen sich sogar als ausreichend erweisen um alle 256 Zeilenrelative vermittelst blos identischer Operationen darzustellen.
In der That lassen zunächst die irreduziblen Knüpfungen 19) durch die 18) in doppelter Weise sich ausdrücken wie folgt: 20) [Formel] etc. — dasselbe auch rückwärts gelesen, desgl. a und ā vertauscht.
Als Paradigma der Ausrechnung von Zeilenrelativen wollen wir die Verifikation der beiden linkseitigen Formeln L = M = R hersetzen: a = 1αβγ0, a ɟ 1' = 1ᾱ000, L = (a ɟ 1'); 0' = 1α000, (a ɟ 1'); 1 = 11000, ā = 0ᾱβ̄γ̄1, ā; 0' = 0α111, ā; 0' + a = 0α111 + 1αβγ0 = 1α111, M = 11000 · 1α111 = 1α000, (a ɟ 1'); 1 · ā; 0' = 0α000, a ɟ 0 = 10000, R = 10000 + 0α000 = 1α000, q. e. d.
Dass unter den Zeilenrelativen höhere irreduzible relative Modulknüpfungen als die sekundären 18) und 19) überhaupt nicht vorkommen, könnte — sofern es nicht aus dem weiter folgenden ohnehin und leichter hervorgeht — auch gerechtfertigt werden aufgrund der beiden folgenden Sätze, welche jedenfalls verdienen unter den auf Zeilenrelative bezüglichen mitangeführt zu werden: 21) [Formel] 22) [Formel] Dieselben sind äusserst leicht nachzurechnen.
Die höheren irreduziblen relativen Modulknüpfungen werden demnach das a nicht „am Rande“, als ersten oder letzten Term, aufweisen können, folglich sowol Zeilen- als Kolonnenoperationen involviren.
Inbezug auf Beweismethoden gestatte ich mir hier eine Bemerkung anzuknüpfen auf die noch einigemal zurückzukommen sein wird.
Natürlich kann der Beweis aller unsrer Formeln auch mittelst Zurückführung auf die „Koeffizientenevidenz“ geleistet werden.
Jede Formel liefert uns — falls sie etwa eine Gleichung L = R ist, in Gestalt von Li j = Ri j — ein richtiges Schema des Aussagenkalkuls, dessen Richtigkeit auch rein analytisch nachweisbar sein muss.
Diesen Nachweis zu erbringen ist aber oft eine nicht zu unterschätzende Kunst.
Dies möge zunächst durch ein paar Beispiele illustrirt werden.
Zu dem Ende wollen wir einmal die erste Formel 21) auf solchem Wege beweisen.
Es wird die Richtigkeit des Schemas:
Li j = ΠhΣkΠl(ai l + 1'l k)0'k h = Πhai h = Ri j darzuthun sein.
Diese ist aber auf den ersten Blick selbst für den Geübten keineswegs ersichtlich.
Man kann verbal überlegen:
Im Πl muss l ≠ k und in der Σk muss k ≠ h sein.
Folglich ist der Wert h für l effektiv zulässig; denn für l = h wird bei jedem k ≠ h der Forderung l ≠ k schon von selbst genügt sein. D. h. in jedem Glied der Σk tritt der Faktor ai h auf und lässt sich vorziehen bis er dicht hinter dem Πh von Li j steht.
Ist nun bei gegebnem i auch nur eines der ai h gleich 0, so kommt die Gleichung auf 0 = 0 hinaus, weil beiderseits mindestens ein verschwindender Faktor ai h in dem Πh auftritt, und ist ihre Richtigkeit erwiesen.
Dieselbe bleibt demnach nur mehr für den Fall darzuthun, wo alle ai h = 1 sind.
Wenigstens unter dieser Voraussetzung muss dann gezeigt werden, dass der Faktor, den das in Li j = Πhai h · etc. vorgezogene ai h erhält, für jedes h gleich 1 ist.
Dieser Faktor „etc.“ wird rigoros den Ausdruck haben: Σk0'k hΠl(ai l + 1'l k + 1'l h) = 1, weil in dem Πl neben ai k nach Vorziehung von ai h auch dieser Faktor fehlen muss; da jedoch tautologische Wiederholung desselben erlaubt ist, könnten wir auch den letzten Summanden 1'l h hier unterdrücken.
Gleichviel ob mit Ein- oder Ausschluss von eventuell auch ai h ist nun aber das Πl von allen ai l ohne ai k gewiss = 1, weil diese Faktoren eben laut Voraussetzung sämtlich selbst = 1 sind.
Es verbleibt demnach nur Σk0'h k = 1 zu erkennen, was daraus erhellt, dass diese Summe mindestens einen Term 0'h k = 1, wo k ≠ h ist, umfasst, q. e. d.
Man sieht zugleich, dass unser Satz 21) keines Sterns bedarf, d. h. zu seiner Giltigkeit nicht erfordert, dass der Denkbereich 11 mehr als zwei (mindestens drei) Elemente umfasse.
Will man an Stelle der obigen verbalen Überlegung rein rechnerisch zuwerke gehen, so ist das Vorziehen des ai h durch folgende Transformationen zu bewirken: Πl(ai l + 1'l k) = Πl(ai l + 1'l k + 0) = Πl(ai l + 1'l k + 0'l h1'l h) = = Πl(ai l + 1'l k + 0'l h)Πl(ai l + 1'l k + 1'l h) = (ai h + 1'h k)Πl(ai l + 1'l k + 1'l h), weil in dem ersten Πl des zerfällten Produktes ausser dem verbliebenen Faktor ai h + 1'h k alle übrigen wegen des Summanden 0'l h = 1 unwirksam sind.
Wird das Ergebniss nun mit 0'h k multiplizirt, so verschwindet der von 1'h k herrührende Term und haben wir voraussetzungslos:
Li j = Πhai hΣk0'h kΠl(ai l + 1'l k + 1'l h), an welchen Ausdruck nun die übrigen Bemerkungen wesentlich wie oben anzuknüpfen sind, indem man die Möglichkeiten der Fälle gemäss des Schemas 1 = Σh(ai h = 0) + Πh(ai h = 1) zerlegt.
Als ein weitres Paradigma wollen wir das bemerkenswerte Gespann von Sätzen anführen: 23) [Formel] welches in fünfziffrigem Rechnen auf das leichteste zu verifiziren ist, und wollen für die erste Formel desselben auch die Koeffizientenevidenz herbeiführen.
Hier ist zu zeigen, dass Li j = Σhai hΠk(āi k + 1'k h)0'h j + ΠkΣhai h0'h k = Σhai h0'h j = Ri j sein muss.
Dies scheint nur so geschehen zu können, dass man drei Hauptfälle unterscheidet.
Erstens: bei i habe a eine Leerzeile.
Dann ist Σhai h = 0 oder Πh(ai h = 0) und kommt die Behauptung auf 0 = 0 hinaus, ist also richtig.
Zweitens: bei i habe a eine einbesetzte Zeile, und zwar sei ai m = 1 aber Σhai h0'h m = 0.
Dann kommt für j = m die Gleichung abermals auf 0 = 0 hinaus, indem in Li j das allgemeine Glied der Σh mit dem verschwindenden Faktor ai h0'h m behaftet ist, das zweite Πk aber die verschwindende Summe (bei k = m) zum Faktor aufweist.
Dagegen für j ≠ m kommt die Behauptung auf 1 + 0 = 1 hinaus.
Letzteres ist so zu sehen: Ri j wird = 1, weil 0'm j = 1 ist und somit der Term ai m = 1 als Summand auftritt.
In Li j wird das zweite Glied = 0, indem das Πk bei k = m den verschwindenden Faktor Σhai h0'h m aufweist.
In der ersten Summe verschwinden (wegen des bei h ≠ m verschwindenden Faktors ai h) alle Glieder bis auf das dem h = m entsprechende, welches sich als ai m0'm jΠk(āi k + 1'k m) = ai m = 1 erweist, indem hierin das Πk die Negation der laut Voraussetzung verschwindenden Summe Σkai k0'k m ist.
Drittens: bei i habe a eine mehrbesetzte Zeile, indem, m ≠ n gedacht, mindestens sowol ai m = 1 als ai n = 1 ist.
In diesem Falle ist Σhai h0'h k = 1 für jedes k, indem diese Summe (als Summe von allen ai h mit Ausnahme des ai k) von den beiden Gliedern ai m und ai n doch mindestens eines enthält.
Die Negation dieser Summe, worin auch h und k vertauscht werden durften, mithin das Πk(āi k + 1'k h), ist also = 0 und kommt die Gleichung auf 0 + 1 = 1 hinaus.
Sie bewahrheitet sich mithin in allen Fällen, q. e. d.
Hier gestaltet sich die zeilenschematische Verifikation einfach wie folgt: a = 1αβγ0, ā = 0ᾱβ̄γ̄1, ā ɟ 1' = 000γ1, (ā ɟ 1')a = 0000γ0, (ā ɟ 1')a; 0' = 000γ̄0, a; 0' = 111γ̄0, a; 0' ɟ 0 = 11100, L = 111γ̄0 = R, und sticht dagegen augenscheinlich der vorhergehende Beweis durch seine Umständlichkeit — wonicht seine Schwierigkeiten — sehr unvorteilhaft ab.
Wenn nun doch die Herbeiführung der Koeffizientenevidenz zur Unterscheidung verschiedener Zeilenkategorieen uns nötigt, so werden wir diese Unterscheidung und die auf sie zu gründenden Schlüsse am besten sogleich in ihrer konzisesten Gestalt, nämlich in Form der fünfziffrig schematischen Darstellung und Rechnung, vollziehen!
Letzteres Verfahren ist nicht nur als ein vollwichtiges Äquivalent der in §§ 4 und 7 noch anders charakterisirten streng analytischen Methode anzuerkennen, sondern auch wol als eine Vereinfachung oder erhebliche Erleichterung derselben zu begrüssen.
Nur leider ist solches Verfahren bei weitem nicht überall anwendbar, weil eben die grosse Mehrzahl der Probleme keine reinen Parallelreihenprobleme sind.
Bei den Kolonnenproblemen ist die Darstellung und Rechnung genau die gleiche wie bei den Zeilenproblemen die ihnen dual entsprechen.
Eventuell wird man sich nur durch ein nach Art eines musikalischen Notenschlüssels erstmals vorgeschriebenes z oder k — etwa in Gestalt des Ansatzes: a = z1αβγ0 resp. a = k1αβγ0 zum Bewusstsein zu bringen haben, ob die „Ziffern“ auf Zeilen- oder ob sie auf Kolonnenkategorieen hinweisen sollen.
Ein (gar nicht leicht zu verwirklichender) Fortschritt der Theorie dürfte vielleicht dahin zu erhoffen sein, dass unsre parallelreihenschematische Darstellung zunächst auch auf solche Modulknüpfungen eines Relativs ausgedehnt wird, wo Zeilenoperationen vermischt mit Kolonnenoperationen auftreten.
Bezüglich der Koeffizientenevidenz ist immerhin noch zu sagen, dass dieselbe bei allen (unsern) Parallelreihensätzen herbeizuführen als eine Fülle von Übungsaufgaben dem Anfänger sehr empfohlen werden kann.
Die dabei zu erlangende Gewandtheit und Ausbildung des Scharfsinnes wird dann auch solchen Untersuchungen zugute kommen, bei welchen uns Erleichterungen wie die des fünfziffrig schematischen Rechnens nicht mehr zugebote stehen und wir auf jene allein angewiesen sind.
Nicht selten auch fördert das Zurückgehen auf die Koeffizienten interessante Schemata des Aussagenkalkuls wonicht schon des Klassenkalkuls zutage — auf derengleichen wir noch einigemal hinweisen werden.
Um nun noch ein wenig weiter mit den „Parallelreihensätzen“ fortzufahren, so ist zunächst hervorzuheben, dass zwischen den (irreduziblen) primären und den oben hinzugetretenen sekundären Modulknüpfungen 18), 19) folgende Einordnungen bestehen: 24) a ɟ 0 ⋹ (a ɟ 1'); 0' ⋹ (a ɟ 1'); 1 ⋹ a; 0' ɟ 0 ⋹ a; 0' ɟ 1' ⋹ a; 1, wovon die mittlere und die beiden äussersten bemerkenswerte Sätze vorstellen — jene einen zu sich selbst dualen.
Die Einordnungen a ɟ 1' ⋹ (a ɟ 1'); 1 | a; 0' ɟ 0 ⋹ a; 0', etc. bedurften als schon aus 8) sich verstehende keiner besondern Erwähnung.
Ähnliches gilt bezüglich 9) von den Gleichungen:
(a ɟ 1')(ā; 0' ɟ 0) = 0 a; 0' + (ā ɟ 1'); 1 = 1, etc.
Wenn sie auch zum Teil nicht minder leicht auf frühere Sätze schon zurückführbar sind, so mögen doch als bemerkenswert und gelegentlich von Nutzen noch angeführt werden die Sätze: 25) [Formel] 26) [Formel] 27) [Formel] 28) [Formel] 29) [Formel]
Blos als Kuriosum sei der Satz auch angeführt: etc., weil er ausspricht, dass für b = (ā ɟ 1')a gleichzeitig gilt:
Dem Prädikat der ersten Subsumtion ist hier ā ɟ 1' selbst, ebenso das Subjekt der zweiten Subsumtion bereits dem ersten Term seines Prädikates, nämlich dem a; 0' allein schon — leichterweislichermaassen — notwendig eingeordnet, cf. 5) des § 6.
(ā ɟ 1')a ⋹ (a; 0' + ā) ɟ 1' (ā ɟ 1')a; 0' ⋹ a; 0' + ā
b⋹b̄ ɟ 1' b; 0' ⋹ b̄.
Auch den Satz: (a ɟ 1')ā; 0' ⋹ a ⋹ (a; 0' + ā) ɟ 1' etc. werden wir als speziellen Fall (für b = ā) eines allgemeineren Satzes späterhin erkennen; der gegenwärtige aber ist ziffermässig leicht zu verifiziren. 30)
[Formel]
Dass nun auch etc. gilt, erscheint als ein blosses Korollar hierzu aufgrund von 8). 31) [Formel] 32) [Formel] 33) [Formel] 34) [Formel] und dergleichen mehr.
a; 0' · a ⋹ a; 0' ɟ 0 (a ɟ 1'); 1 ⋹ a ɟ 1' + a
Das Bisherige mag genügen, dem Leser eine Ahnung von der grossen Mannigfaltigkeit schon der blos auf Parallelreihen bezüglichen Sätze zu verschaffen, welche unsrer Theorie eigentümlich sind und die wir nunmehr mit dem fünfziffrigen Rechnen beherrschen.
So gross diese ist, so ist aber doch noch grösser die Mannigfaltigkeit der Arten auf welche diese Sätze noch ausserdem bewiesen und auf einander zurückgeführt werden können.
In dieser Hinsicht legt mir der ohnehin zu sehr anwachsende Umfang meines Buches Zurückhaltung auf.
Als besonders beachtenswert mögen nur die Schemata des identischen Kalkuls noch hervorgehoben sein, auf welchen die Koeffizientenevidenz bei den Formeln 29) und 30) beruht.
Bei diesen kommt für die erste Zeile in Betracht, dass: 35) sein muss, wo auch ersetzbar ist
Σh kai hai k0'h k = ΠkΣhai h0'h k Πh k(ai h + ai k + 1'h k) = ΣkΠh(ai h + 1'h k)
die Doppelsumme durch das Doppelprodukt durch Σhai hΣk0'h kai k Πh{ai h + Πk(ai k + 1'h k)}.
Unterdrückt man den durchweg konstanten Index i und sagt für aA, aB, aC, ‥ kürzer a, b, c, ‥, so stellen sich die Gleichungen 35) — rückwärts durchgegangen — einfach als die Schemata dar: 35)a [Formel] , die man unschwer durch Ausmultipliziren unter Berücksichtigung des Absorptionsgesetzes beweist.
Bei jenen haben wir (nach Vertauschung von a mit ā) ebenso: 36) [Formel] wobei die rechte Seite sich nochmals kraft 35) umformen liesse.
Hier liegen ähnlich die Schemata zum Grunde: 36)a [Formel] .
Wahrscheinlich lassen sich Kunstgriffe finden, durch welche die Identitäten 35) und 36) auch ohne Ausdeutung [Ausführung, Evaluation(?)] der Σ und ΠZeichen rechnerisch bewiesen werden können.
Die 35) lassen erkennen, wie mit Hülfe der Relativkoeffizienten unsrer beiden Moduln 1' und 0' hinfort kombinatorische Aggregate (resp. Produkte) — so insbesondre die Klasse der Kombinationen ohne Wiederholungen zu je zweien einer gegebenen (obzwar vielleicht unbegrenzten) Reihe von Elementen — sich aufs konziseste in Gestalt von identischen Summen (resp. Produkten) darstellen lassen.
Nach diesem auch methodologisch instruktiv gewesnen Exkurs über die Parallelreihensätze kehren wir wieder zurück zu unserm Hauptproblem des Paragraphen, welches forderte: die 256 Zeilenrelative von a vermittelst dessen relativer Modulknüpfungen und der identischen 3 Spezies durch a selbst ausdrücken zu lehren.
Zu dem Ende blieben von den Ziffern des a und ā noch die viere α, β, β̄, γ̄ zu isoliren, was nunmehr durch Mitbenutzung der sekundären Modulknüpfungen 18)
[lieber als 19)] auf das leichteste gelingt.
Und zwar ist für a = 1αβγ0, ā = 0ᾱβ̄γ̄1 die Zusammenstellung sämtlicher Isolationsergebnisse: 37) [Formel] .
Aus diesen acht Relativen lassen sich offenbar alle 256 Relative der Zeilengruppe durch blosse Addition zusammensetzen, womit die Aufgabe theoretisch gelöst ist.
Zunächst kann man nämlich auch durch Addition des 2ten und 8ten, 3ten und 7ten, 4ten und 6ten dieser Relative 37) an jede einzelne der drei Mittelstellen einen Einser bringen, indem: 01000 = (a ɟ 1'); 1 · ā; 0' + (a ɟ 1')ā, 00100 = (ā; 0' ɟ 0) · a; 0' · a + (a; 0' ɟ 0) · ā; 0' · ā, 00010 = (ā ɟ 1')a + (ā ɟ 1'); 1 · a; 0' sein muss.
Hiefür stehn freilich noch die übersichtlicheren Ausdrücke zur Verfügung, deren Übereinstimmung mit den vorstehenden bemerkenswerte Sätze liefert: 38) [Formel]
Ähnlich ist unsre zeilenschematische Darstellung überhaupt eine fast unerschöpfliche Fundgrube von Sätzen.
Bemerkt sei z. B. noch, dass die Isolirung von α und β auch sozusagen „voller“ [als in 37) geschehen] bewirkt werden kann in der Gestalt:
0α000 = (a ɟ 1'); 1 · ā; 0' · a; 0' · ā; 1 · a; 1 · a 00β00 = (a; 0' ɟ 0)(ā; 0' ɟ 0) · a; 0' · ā; 0' · a; 1 · ā; 1 · a — analog, a mit ā vertauscht, für γ̄ und β̄.
Hieraus ist es eventuell nützlich zu ersehen, welche Faktoren der konzisesten Darstellung 37) noch zugefügt werden dürfen, mehr aber noch: welche Mitfaktoren, wenn sie daneben auftreten, ebendort unterdrückbar sind.
Nunmehr können wir also jedes Zeilenrelativ darstellen.
Z. B. wird 0ᾱ1γ1 = 0ᾱ000 + 00100 + 000γ0 + 00001 zu erhalten sein als die Summe der Ausdrücke, welche sich für die vier Relative rechterhand in 37) und 38) einzeln angegeben finden.
Der solchergestalt durch Vereinigung gewonnene Ausdruck für ein Zeilenrelativ ist aber — wie schon das Beispiel 38) zeigte — zumeist nicht der konziseste, dessen das Relativ fähig ist.
Statt seiner geben wir, wo nur immer uns ein einfacherer Ausdruck zugebote steht, natürlich diesen letztern an.
Und es bleibt ein Tummelplatz noch ungelöster Aufgaben: für jedes Zeilenrelativ dessen knappsten Ausdruck (eventuell die gleich einfachen konzisesten Ausdrücke desselben) zu finden mit der Minimalzahl der Terme (als da sind Buchstaben a, ā oder Modulzeichen) aus denen sein Name aufgebaut, mit Hülfe deren es hinsichtlich der Art und Weise, wie es aus a hervorgeht, „beschrieben werden kann.
Wir wollen nun diejenigen von den 256 Zeilenrelativen wirklich aufstellen, die man als die ausschliesslich hervorhebenden (oder abwerfenden) bezeichnen könnte — inbezug auf das beliebig gegebene Relativ a. Da von einem „Abwerfen“ der (fünften) Ziffer 0 nicht die Rede sein kann, so gibt es deren 24 = 16 = 1 + 4 + 6 + 4 + 1 je nachdem keine, eine, 2, 3 und 4 von den ersten Ziffern abgeworfen werden, nämlich:
1αβγ0 1α000 10000 1αβ00 10β00 0α000 1α0γ0 100γ0 00β00 10βγ0 0αβ00 000γ0 0αβγ0 0α0γ0 00000.
00βγ0
Lexikalisch geordnet stellen sich diese Relative wie folgt wol am einfachsten dar: 39) 1αβγ0 = a, 1αβ00 = a; 0' · a, 1α0γ0 = (a ɟ 1' + ā ɟ 1'); 1 · a, 1α000 = (a ɟ 1'); 1 · a = (a ɟ 1'); 0', 10βγ0 = (ā; 0' ɟ 0 + a ɟ 1')a = a ɟ 0 + (ā; 0' ɟ 0)a, 10β00 = {a ɟ 0 + (ā; 0' ɟ 0) · a; 0'}a = a ɟ 0 + (a; 0' · ā; 0' ɟ 0)a, 100γ0 = (a ɟ 1' + ā ɟ 1')a = (a ɟ 0 + ā ɟ 1')a = a ɟ 0 + (ā ɟ 1')a, 10000 = a ɟ 0, 0αβγ0 = ā; 0' · a = ā; 1 · a, 0αβ00 = ā; 0' · a; 0' · a = ā; 1 · a; 0' · a, 0α0γ0 = ā; 1 · a · (a ɟ 1' + ā ɟ 1'); 1, 0α000 = (a ɟ 1'); 1 · ā; 0' = (a ɟ 1')ā; 0', 00βγ0 = (ā; 0' ɟ 0)a, 00β00 = (a; 0' · ā; 0' ɟ 0)a, 000γ0 = (ā ɟ 1')a, 00000 = 0.
Darnach sind auch zu ā die hervorhebenden Relative unschwer hinzuschreiben.
Ferner wollen wir noch die schematisch blos aus Einsern und Nullen bestehenden 25 = 32 Relative für den Gebrauch zurechtstellen: 40) [Formel] .
Zöge man vor, das Problem der 256 Zeilenrelative durch (identische) Multiplikation, anstatt durch Addition, zu lösen, wofür ja Gründe vorliegen können, so müsste man neben 1 = 11111, 0 = 00000, a = 1αβγ0, ā = 0ᾱβ̄γ̄1 anstatt derjenigen 37) folgende acht Relative zugrunde legen: 41) [Formel] wozu etwa noch — entsprechend 38) — die Ausdrücke für die drei Relative 10111, 11011, 11101 aus 40) heranzuziehen wären.
Die Gleichsetzung der beiden Ausdrücke für jedes auf die eine und auf die andre Weise — als Summe und als Produkt — dargestellte Zeilenrelativ fördert viele Parallelreihensätze zutage.
Unschwer sind die Untersuchungsergebnisse dieses Paragraphen für den Fall zu modifiziren, wo der Denkbereich 11 blos drei, sowie für den, wo er blos zwei Elemente umfasst.
Im Denkbereiche 1 ⅓ aus drei Elementen kommt die mittlere Zeilenkategorie β in Wegfall; als Zeilenschema von a verbleibt: a = 1αγ0.
Es fallen allemal die vier Relative in eines zusammen, deren bisherige Zeilenschemata sich blos durch die Besetzungsweise der mittleren oder dritten Ziffernstelle (mit β, β̄, 1 oder 0) unterschied.
Mithin schrumpft a priori die Anzahl der noch zu unterscheidenden Zeilenrelative von a auf höchstens ihren vierten Teil, das ist auf 64 zusammen.
Und es behalten alle bisherigen Sätze volle Geltung — genau so als ob in dem allgemeinen Relativ a = 1αβγ0 die Kategorie β als unvertreten durch den Horizontalstrich zu ersetzen gewesen wäre, wo wir a = 1α - γ0 gehabt haben würden.
Zu diesen Sätzen kommen blos, kraft der vorhergehenden Bemerkung, noch zahlreiche weitre Äquivalenzen hinzu.
Alle diese wird der Leser sich im Bedarfsfalle mit Leichtigkeit zusammensuchen.
Bemerkt zu werden verdient, dass die 64 Zeilenrelative hier schon mit denen 1) bis 7) vollständig gegeben sind.
Das unter 7) S. 208 gegebene Tableau schrumpft hier zusammen zu:
Hier wird man also zur Darstellung aller Zeilenrelative gar keiner sekundären Modulknüpfungen 18) oder 19) bedürfen, vielmehr schon mit den primären auskommen.
Und zwar drücken jene sich durch diese beispielsweise — vergl. 7) und 6) — wie folgt aus: (a ɟ 1'); 1 = a; 0' · (a ɟ 1' + a) = a ɟ 1' + a; 0' · a = a; 0' ɟ 0, (a ɟ 1'); 0' = a; 0' · a, a; 0' ɟ 1' = a ɟ 1' + a.
Weil nun aber blos drei Zeilen vorhanden sind, so werden niemals alle vier Zeilenkategorieen gleichzeitig vertreten sein können; mindestens eine von ihnen muss in a unvertreten sein, und wir haben die vier Fälle zu unterscheiden: a = 1αγ-, a = 1α - 0, a = 1 - γ0, a = -αγ0, in deren erstem und letztem die Anzahl der möglicherweise noch verschiednen Zeilenabwandlungen sich leicht als 32 erweist, während sie sich in den beiden mittleren Fällen sogar nur als 16 herausstellt.
Die oben erkannte Maximalanzahl der Zeilenrelative von a kann also faktisch höchstens hälftig erreicht werden und reduzirt sich eventuell noch weiter.
Dem Anfänger eröffnet sich hier ein kleines Untersuchungsfeld.
11 00 α1 ᾱ0 αγ ᾱγ̄ 0γ 1γ̄ α0 ᾱ1 αγ̄ ᾱγ 1γ 0γ̄ 10 01.
Noch anders liegt die Sache beim Denkbereiche 1 ½ von zwei Elementen.
Hier verlieren manche von unsern allgemeinen Sätzen ihre Geltung; es treten Ausnahmen ein — allerdings nur da vielleicht, wo relative Moduln in die Knüpfungen eingehn.
Nicht nur kommt hier ebenfalls die Kategorie β in Wegfall, sondern es fallen auch die beiden Kategorieen α und γ in eine zusammen; es ist: α = γ, weil die einbesetzten Zeilen hier auch einlückige sein müssen.
Behalten wir α als Namen für diese koinzidirenden Kategorieen bei, so werden wir als allgemeines Zeilenschema haben: a = 1α0, und kann die Anzahl der Zeilenabwandlungen 16 jedenfalls nicht übersteigen — das um so weniger, als es jetzt überhaupt nur 16 Relative gibt.
Wie sonst ist: a; 1 = 110, a ɟ 0 = 100, ā = 0ᾱ1, ā; 1 = 011, ā ɟ 0 = 001.
Für a; 0' und a ɟ 1' dagegen würde das Schema 3) S. 205 nicht aufrecht zu erhalten sein, indem es sowol 110 wie 1ᾱ0, resp. 1ᾱ0 wie 100 widersprechend ergäbe, jenachdem die mittlere Ziffer von a angesehen wird als Repräsentant der frühern Kategorie α, oder der γ.
In Wirklichkeit gilt bei a; 0' das letztere, bei a ɟ 1' das erstere, mithin bei beiden Modulknüpfungen übereinstimmend das nämliche.
Doch muss man, um dies zu eruiren, auf die ursprüngliche Koeffizientenbedeutung für die Modulknüpfungen a; 0' und a ɟ 1' zurückgehn.
Halten wir das, eine bestimmte von den beiden Zeilen markirende i fest, und denken uns den Kategorieen 1, α oder 0 entsprechend die beiden ai h (für h = i und h ≠ i) gegeben, so bleibt uns für jedes der beiden j zu ermitteln: (a; 0')i j = Σhai h0'h j = ai A0'A j + ai B0'B j | | (a ɟ 1')i j = Πh(ai h + 1'h j) = (ai A + 1'A j)(ai B + 1'B j).
Von den beiden Modulkoeffizienten wird sicher der eine = 0, der andre = 1 sein, weil j entweder A oder B bedeuten muss.
Sind daher nach h beide ai h gleich 1, so werden auch unsre Modulknüpfungskoeffizienten sicher gleich 1, sind jene beiden gleich 0, so werden es auch diese.
Den Voll- und Leerzeilen von a entsprechen also wieder Voll- resp. Leerzeilen bei a; 0' und a ɟ 1'.
Gehört dagegen die ite Zeile von a der Kategorie α an, so muss von den nach h beiden ai h das eine = 1, das andre = 0 sein.
Nennen wir dann j den von i verschiednen Index, so wird in Betracht kommen:
(a; 0')i i = ai i0'i i + ai j0'j i = ai j (a ɟ 1')i i = (ai i + 1'i i)(ai j + 1'j i) = ai j, (a; 0')i j = ai i0'i j + ai j0'j j = ai i (a ɟ 1')i j = (ai i + 1'i j)(ai j + 1'j j) = ai i.
Auch konnten diese Schemata schon zur Verifikation der vorhergehenden Ergebnisse verwendet werden.
Ist nun ai i = 1, somit ai j = 0, so folgt: (a; 0')i i = 0 = (a ɟ 1')i i, (a; 0')i j = 1 = (a ɟ 1')i j.
Ist dagegen ai i = 0, somit ai j = 1, so folgt: (a; 0')i i = 1 = (a ɟ 1')i i, (a; 0')i j = 0 = (a ɟ 1')i j.
Das heisst: in beiden Fällen verkehrt sich die Zeile α von a bei den relativen Knüpfungen mit den relativen Moduln in ᾱ; und es gilt in unserm Denkbereiche 1 [Formel] : a; 0' = a ɟ 1' = 1ᾱ0.
Die erstere Gleichung hat begreiflich eine gewaltige Reduktion aller Formeln zur Folge.
Wieder aber muss, weil überhaupt nur zwei Zeilen vorhanden sind, von den drei Zeilenkategorieen mindestens eine unvertreten sein in jedem Relative a. Oder man hat die drei Fälle: a = 1α-, a = 1 - 0, a = -α0, deren mittlerer nur 4, deren beide äusseren blos 8 Zeilenflexionen zulassen.
§ 16.
Die inversen Zeilen- oder Kolonnenprobleme.
Die im vorigen Paragraph gelösten mögen füglich „direkte“ Parallelreihenprobleme genannt werden.
Sie liefen auf zweierlei hinaus:
Einmal, jedes einer „Parallelreihengruppe“ von a angehörige Relativ, mittelst der fünfziffrig schematischen Ausrechnung desselben, nach seiner Entstehung aus a auf die konziseste und durchsichtigste Weise beschreiben zu lernen — wenn wir zur „Zeilen-(resp. Kolonnen-)gruppe von a alle diejenigen Relative zählen, welche aus a abgeleitet sind lediglich mittelst der drei identischen Spezies in Verbindung mit solchen relativen Modulknüpfungen, die eingangs des § 15 als blosse „Zeilen- (resp. Kolonnen-)operationen“ charakterisirt wurden.
Sodann auch umgekehrt: jedes in schematisch fünfziffriger Darstellung gegebne Relativ vermittelst der ersten sechs Spezies unsrer Theorie (wobei von den relativen nur solche der vorhin charakterisirten Art zu verwenden sind) ausdrücken zu lernen durch a.
Diesen „direkten“ Parallelreihenproblemen stehen nun noch andre gegenüber, die als die „inversen“ bezeichnet zu werden verdienen.
Letztere sind — der fünften Vorlesung gemäss — teils Auflösungs- teils Eliminationsaufgaben.
Das allgemeinste zu den „Parallelreihenproblemen“ gehörige Auflösungsproblem besteht darin, eine Gleichung 1) F(x) = 0 aufzulösen, deren Polynom F(x) eine Parallelreihen-(z. B. Zeilen-) Abwandlung von x ist, d. h. zu dessen Zeilen- oder Kolonnengruppe gehört.
Formell noch etwas allgemeiner wäre das Problem der Auflösung sei es einer Subsumtion sei es einer Gleichung:
2) φ(x) ⋹ψ(x) resp. φ(x) = ψ(x), worin beide Seiten der Zeilengruppe von x angehören.
Für solche praktisch immerhin wichtige Fälle sei der Rat eingeschaltet, sie auf die vorige Form zurückzuführen gemäss den Schemata: φ(x)ψ(x)͞ = 0 resp. φ(x)ψ(x)͞ + φ(x)͞ψ(x) = 0, indem man — x = 1αβγ0 gesetzt — erst zeilenschematisch ihre beiden Seiten φ(x) und ψ(x) selbst ausrechnet und deren so gewonnene Darstellungen nach Bedarf negirt, nicht aber in Gestalt von φ̄(x), ψ̄(x) die Negation schon an den analytischen Funktionsausdrücken ausführt.
Die Zurückführung der Aufgaben 2) auf die speziellere Form 1) vollzieht sich alsdann mit solcher Leichtigkeit, dass es nicht verlohnt, das für diese 1) vorzutragende Auflösungsverfahren auch auf die Aufgaben 2) ausdrücklich auszudehnen, für welche es sich in der That unschwer modifiziren aber doch nicht ohne Umständlichkeiten schildern lassen würde.
Immer das Analoge für Kolonnen mit zu sagen unterlassen wir fortan.
Wie sich zeigen wird liefert die Elimination von x aus 1), sofern diese Gleichung nicht absurd ist, allemal keine Resultante und ist die Gleichung immer auflösbar.
Aus diesem Grunde kann hier das Auflösungsproblem unabhängig von und vor dem Eliminationsprobleme erledigt werden.
Und soll bei den Zeilenproblemen überhaupt von einer Eliminationsaufgabe die Rede sein, so müssen wir diese in der ihr im § 12, S. 174 gegebenen weiteren Fassung formuliren als die Aufgabe: aus einer Gleichung 3) f(u) = x, in welcher x gegeben ist und f(u) eine blosse Zeilenabwandlung von u vorstellt, das unbestimmte Relativ u zu eliminiren.
Von diesen beiden inversen Problemen wollen wir nunmehr das Auflösungsproblem 1) in Angriff nehmen.
Zu einem leichten und eleganten Verfahren, dasselbe systematisch zu lösen, gelangen wir, indem wir die Lösung einer grösseren Anzahl (32) von vorgängigen Aufgaben vorausschicken, von denen aber nur eine Minderzahl (nämlich 7) als etwas schwierigere hervortreten.
Die (wie man sehn wird: 32) fundamentalen Aufgaben charakterisiren sich wie folgt:
Durch ein arbiträres Relativ u jedes solche Relativ darzustellen, in welchem von den fünf Zeilenkategorien (Ziffern) 1αβγ0 irgendwelche unvertreten sind.
Dass mit diesen Aufgaben unser Problem 1) gelöst sein wird, ist leicht so zu sehen.
Allgemein kann man x zeilenschematisch als x = 1αβγ0 ansetzen und dann das zugehörige (der „Zeilengruppe“ von x laut Voraussetzung angehörende) Polynom F(x) der aufzulösenden Gleichung 1) mit Leichtigkeit fünfziffrig ausrechnen.
Man erhält auch für dieses einen zeilenschematischen Ausdruck von der Form 1αβγ0, in welchem jedoch — je nach der Natur der gegebenen Funktion F — einzeln und unabhängig von den übrigen Ziffern eine jede von den vorstehenden Ziffern auch durch 0 oder 1, ausserdem von den drei mittleren Ziffern eine jede auch durch ihre Negation vertreten sein kann.
Die Gleichung 1) verlangt nun, dass jede Zeilenkategorie des x, deren Ziffer bei der Ausrechnung des F(x) sich nicht ohnehin in eine 0 verwandelt, in x unvertreten sei, was auch umgekehrt zu ihrer Erfüllung genügt; sie fordert nämlich, dass F(x) lauter Leerzeilen aufweise.
Darnach wird also x einfach gleich einem solchen f(u) zu setzen sein, welches die betreffende von den 32 Hülfsaufgaben löst.
In dem Falle wo sich F(x) = 11111 herausstellt, und nur in diesem, wird daher die Gleichung 1) absurd sein, keine Wurzel zulassen und bleibt die Aufgabe unmöglich.
Falls dagegen F(x) = 00000 sich ergibt, bleibt x = u vollkommen unbestimmt oder willkürlich.
In jedem andern Falle gibt es spezifische Ausdrücke für die allgemeine Wurzel, die durch die Lösung einer bestimmten von den 32 — 2 = 30 verbleibenden Hülfsaufgaben dargeboten werden.
Das Unvertretensein einer Zeilenkategorie deuten wir durch einen an die Stelle ihrer Ziffer gesetzten Horizontalstrich an.
Dann gibt es in der That 25 = 1 + 5 + 10 + 10 + 5 + 1 = 32 Probleme, jenachdem kein, 1, 2, 3, 4, 5 Striche in das Zeilenschema eintreten.
Was zunächst die drei mittleren Kategorieen betrifft, so haben wir die 23 = 1 + 3 + 3 + 1 = 8 Möglichkeiten:
?αβγ? ?αβ-? ?α-γ? bei denen wir die Besetzung der beiden äussersten Kategorieen durch ein Fragezeichen angedeutet, unentschieden gelassen haben. ?-βγ? ?α--?
Aus diesen 8 gehen — in 4 Oktaden — die 32 Möglichkeiten hervor, indem wir: ?-β-? ?--γ? erstens das erste Fragezeichen durch 1, das letzte durch 0 ersetzen, ?---? zweitens das erste durch 1, das letzte durch den Strich, drittens das erste durch Strich, das letzte durch 0, viertens beide Fragezeichen durch den Horizontalstrich ersetzen.
Von der ersten Oktade fällt jedoch die erste Möglichkeit fort, weil es keine Bestimmung des gesuchten Relativs („Aufgabe 1“) 1αβγ0 involvirt, von demselben zu verlangen, dass in ihm alle fünf Kategorieen eventuell vertreten seien, keine ausgeschlossen. M. a. W. als Lösung wäre zu notiren: 4)
[Formel] .
Desgleichen kommt von der letzten Oktade die letzte Möglichkeit in Wegfall, weil es absurd ist, ein Relativ („Aufgabe 32“) ----- konstruiren zu wollen, welches weder besetzte noch Leerzeilen (d. h. überhaupt keine Zeilen) habe, worin m. a. W. jede Zeilenkategorie ausgeschlossen.
Die Stelle der Lösung vertritt bei dieser Aufgabe der Ansatz: 5)
[Formel] .
Es bleiben also nur 30 wirkliche Probleme.
Von diesen ist auch aus der zweiten und dritten Oktade eines, das letzte, sofort abgethan durch die Bemerkung, dass: 6)
(„Aufg. 16“)(x = 1----) = (x = 1) | (x = ----0) = (x = 0)(„Aufg. 24“) ist.
Dies sind die beiden einzigen von den 32 Aufgaben, wo sich die Unbekannte als völlig bestimmt erweist.
Es bleiben also nur 28 Probleme, nämlich von der ersten Oktade die 7 letzten, von den drei übrigen Oktaden je die 7 ersten.
Von diesen 28 lassen sich die 3 × 7 = 21 Aufgaben, wo im schematischen Ausdruck des gesuchten x die Ziffer 1 und 0, oder wenigstens eine von diesen beiden Ziffern vorkommt — das sind also die Aufgaben aus den drei ersten Oktaden — ohne weitres lösen (und zwar im Allgemeinen auf mehrere „wesentlich verschiedene“ Arten) — sodass nur die 7 ersten Aufgaben der vierten Oktade als etwas schwierigere Probleme verbleiben.
Jenes genauer wie folgt.
Um irgend eine Aufgabe der ersten Oktade (x = 1???0) zu lösen — so, dass die allgemeine Wurzel auch der Adventivforderung genügt — ersetze man in dem für x geforderten Zeilenschema jeden Horizontalstrich durch 1 oder durch 0 auf jede mögliche Weise.
Jedes so gewonnene Zeilenschema (ihre Anzahl wird gleich 2 hoch der Anzahl jener Horizontalstriche sein) lässt sich nach § 15 (wenn dort u für a gesagt wird) durch u = 1αβγ0 ausdrücken und liefert sein Ausdruck f(u), gleich x gesetzt, eine richtige und befriedigende allgemeine Lösung (Wurzel) der Aufgabe.
Für jedes u ist nämlich klar, dass x = f(u) eine richtige Lösung sein muss, indem die in u vielleicht vorhandnen, in x aber stets unvertreten geforderten Zeilenkategorieen in der That in f(u) fehlen werden, sintemal sie sämtlich hier sei es in volle sei es auch in leere Zeilen verwandelt wurden und so blos die Menge der ohnehin vielleicht vorhandnen Voll- und Leerzeilen des u vermehren — während die übrigen Zeilenkategorieen des u sich in f(u) unverändert wiederfinden.
Also jedes f(u) ist eine Wurzel.
Dies f(u) liefert aber auch jede mögliche Wurzel x, indem es sein Argument u wiedererzeugt sobald in u( = x) die unvertreten gewünschten Zeilenkategorieen von vornherein fehlten — und diese brauchten ja in der That in u nur eventuell vertreten zu sein, sie durften auch von vornherein darin fehlen.
Um irgend eine Aufgabe der zweiten Oktade (x = 1???-) zu lösen, verwandle man jeden Horizontalstrich des für x verlangten Schemas in die Ziffer 1,
Um irgend eine Aufgabe der dritten Oktade (x = -???0) zu lösen, dagegen in 0, und verwerte das so gewonnene Zeilenschema in gleicher Weise, wie bei der ersten Oktade geschildert.
Die Begründung ist hierbei die analoge.
Im Einzelnen werden wir haben: 7)
[Formel] — wie aus den Ansätzen x = 1αβ10 resp. 1αβ00 nach dem angegebnen Verfahren zu erhalten.
Ohne Rücksicht auf die Adventivforderung würden auch noch die Ansätze x = 1αβ̄10, 1αβ̄00, 11βγ̄0, 10βγ̄0, 11β̄γ̄0, 10β̄γ̄0 analog verwertbar sein und richtige aber nicht befriedigende Ausdrücke f(u) für die allgemeine Wurzel x liefern.
Auf solche Lösungsmöglichkeiten wollen wir künftig kaum je noch einen Seitenblick werfen. 8)
[Formel] wie aus x = 1α1γ0 resp. 1α0γ0 erhältlich. 9)
[Formel] aus x = 11βγ0 resp.
10βγ0. 10)
[Formel] aus x = 1α110, resp. 1α100, 1α010, 1α000. 11)
[Formel] aus x = 11β10 resp.
11β00, 10β10, 10β00. 12)
[Formel] aus x = 111γ0, 110γ0, 101γ0, 100γ0. 13)
[Formel] aus x = 1???0 für ??? = 111 resp. 110, 101, 100, 011, 010, 001, 000.
Vergl. 40) des § 15.
Von diesen acht verschiednen Darstellungen des allgemeinsten Relativs, welches nur aus vollen oder auch leeren Zeilen besteht, mögen wir ihrer Einfachheit halber künftig die erste als die Lösung katexochen benutzen (ebenbürtig mit ihr wäre auch die letzte).
Ohne Rücksicht auf die Adventivforderung würden sich sogar alle Formeln 40) des § 15 ohne die erste und letzte derselben — mithin ihrer 30 — zur Darstellung solchen Relativs verwenden lassen.
Hiermit ist die erste Oktade unsrer Aufgaben erledigt, welche sich hinsichtlich ihrer Lösungen als die vielförmigste erweist.
Zweite Oktade. 14)
[Formel] aus x = 1αβγ1 — gibt das allgemeinste Relativ mit lauter besetzten Zeilen, m. a. W. ohne Leerzeilen. 15)
[Formel] aus x = 1αβ11 — gibt das allgemeinste Relativ mit lauter mehrbesetzten Zeilen. 16)
[Formel] aus x = 1α1γ1. 17)
[Formel] aus x = 11βγ1. 18)
[Formel] aus x = 1α111 — gibt das allgemeinste Relativ ohne Mehrlückzeilen. 19)
[Formel] aus x = 11β11. 20)
[Formel] aus x = 111γ1.
Dritte Oktade — vergleiche demnächst 39) des § 15. 21)
[Formel] aus x = 0αβγ0 — gibt das allgemeinste Relativ mit lauter Lückzeilen, m. a. W. ohne Vollzeilen. 22)
[Formel] aus x = 0αβ00. 23)
[Formel] aus x = 0α0γ0. 24)
[Formel] aus x = 00βγ0 — gibt das allgemeinste Relativ mit lauter Mehrlückzeilen. 25)
[Formel] aus x = 0α000. 26)
[Formel] aus x = 00β00. 27)
[Formel] aus x = 000γ0 — gibt das allgemeinste Relativ ohne mehrbesetzte (d. i. mit höchstens einbesetzten) Zeilen.
Die vorstehende Aufzählung der Lösungsformen für die Aufgaben unsrer drei ersten Oktaden ist zwar in Hinsicht auf die angewendete Methode als eine vollständige zu bezeichnen.
Dagegen macht sie auf Vollständigkeit überhaupt natürlich keinen Anspruch.
Weitre Lösungsformen würden sich schon ergeben, wenn man die Zeilenkategorie β durch β̄ vertreten liesse, desgleichen da wo γ fehlt, die α durch γ̄, und eventuell wo α fehlt, die γ durch ᾱ, sodann wie bisher verführe; nur müsste dabei der Erfüllung der Adventivforderung noch besonders Rechnung getragen werden.
Ferner würden sich aber noch ganz neue Lösungsformen ergeben, wenn man die in dem arbiträren u eventuell vorhandenen in x unvertreten gewünschten Zeilenkategorien — anstatt sie wie bisher zu den Kategorieen der Ziffern 1 oder 0 mittelst geeigneter Umwandlung zu schlagen — vielmehr zu den in x durch Ziffern α, β oder γ vertretenen Zeilenkategorien schlüge.
Auch dieses lässt sich verwirklichen auf eine Weise, die wir nun genötigt sind bei der vierten Oktade darzulegen, weil wir dort zu dieser Methode unsre Zuflucht nehmen müssen, indem ein andres Verfahren gar nicht zugebote steht.
So könnten auch für die bisherigen Aufgaben noch Lösungsformen aufgestellt werden, wo der Ausdruck für die allgemeine Wurzel gar kein „reines Zeilenrelativ“ mehr ist — siehe demnächst.
Vierte Oktade.
Die Lösung der nunmehr noch verbleibenden sieben schwierigern Aufgaben letzter Oktade lässt sich nicht, wie die bisherigen, durch ein „reines Zeilenrelativ“ darstellen, d. h. durch einen Ausdruck, welcher lediglich „Zeilenoperationen“ an u auszuführen vorschreibt — zu denen wir ja nächst den „Zeilen-(Modul-)knüpfungen“ des § 15 blos die 3 identischen Spezies zählten.
Vielmehr wird zum Aufbau gedachter Lösungen auch noch identische Multiplikation mit 1' oder 0' heranzuziehen sein, und bei einer von den 7 Aufgaben, der „Aufgabe 30“, sogar dies nicht ausreichen.
Während die beiden absoluten Moduln, als durch die „Zeilenoperationen a + ā = 1, aā = 0 aus diesem ableitbare, zur „Zeilengruppe“ jedes Relativs a eo ipso gehören, ist dies nämlich mit den beiden relativen Moduln nicht der Fall: 1' und 0' selbst lassen sich aus a nicht durch blosse Zeilenoperationen ableiten.
Denn erstens gelten die Analoga zu vorstehenden Ableitungen:
1' ⋹ a + ā̆, aā̆ ⋹ 0' bekanntlich nicht als Gleichungen sondern blos als Subsumtionen, und zweitens gehört die dabei mitverwendete Operation der Konversion, welche ja vielmehr Zeilen- und Kolonnenknüpfungen in einander verkehrt, nicht zu den „Zeilenoperationen“.
Wer die Behauptung nicht zugeben wollte, wäre verpflichtet — was eben niemand vermag — das Gegenteilige zu leisten und sie damit zu widerlegen.
1' und 0' finden sich im Allgemeinen nicht unter den 256 Relativen der Zeilengruppe von a.
In Gestalt des Moduls 1' aber verfügen wir über ein spezielles Relativ welches lediglich aus einbesetzten Zeilen (der Kategorie γ) besteht, und in Gestalt von 0' vermögen wir ein solches anzugeben, das nur einlückige Zeilen (von der Kategorie α) enthält.
Bringen wir irgend eine Vollzeile zum Schnitt mit 1', so erhalten wir eine einbesetzte Zeile — die nämlich ihr einziges Auge als Zeilenreiter auf der Hauptdiagonale trägt.
Und bringen wir eine Vollzeile zum Schnitte mit 0', so verwandelt sie sich in eine einlückige Zeile — mit der Lücke auf der Hauptdiagonale.
Umfasst der Denkbereich 11 blos 2 Elemente, so schliessen diese beiden Kategorieen einander nicht aus, vielmehr wird die durch den Schnitt erhaltene Zeile eine einbesetzte und einlückige zugleich sein.
Umfasst (dagegen) — unter der Herrschaft des Sternes *, die wir für das folgende zur Voraussetzung erheben — der Denkbereich 11 mehr als 2 Elemente, so werden die einbesetzten Zeilen von 1' zugleich mehrlückige, die Zeilen von 0' auch mehrbesetzte einlückige Zeilen sein, und ebenso bezüglich die erwähnten Schnittzeilen. Dieselben werden alsdann in disjunkte Zeilenkategorien fallen.
Auf obigen Wahrnehmungen beruht es nun, dass von unsern 7 noch ausstehenden Aufgaben sich sechse sofort lösen lassen, und wollen wir, anstatt die zum Ziel führende Methode noch abstrakt voraus zu charakterisiren, ungesäumt in’s Detail eintreten.
[Formel] 28) wo f(u) = ū; 1 · u + 1'(u ɟ 0 + ū ɟ 0) genommen werden kann, darin das 1' aber auch durch 0' ersetzt werden dürfte.
Ebenso, etwas symmetrischer, könnte man nehmen: 28)a f(u) = ū; 1 · u + 0'(u ɟ 0) + (ū ɟ 0)1' wozu zu merken wäre, dass man die beiden relativen Moduln auch durch irgend einen von ihnen ersetzen, jeden in den andern verwandeln, z. B. auch sie vertauschen darf.
Herleitung und Begründung.
Es ist das allgemeinste Relativ zu konstruiren, welches nur besetzte Lückzeilen hat, der Vollzeilen sowol als der Leerzeilen entbehrt Wir bilden x = 0αβγ0 + 10001 · 1' oder auch 0', wonicht: x = 0αβγ0 + 10000 · 0' + 00001 · 1'.
Im letzteren Ausdruck werden die etwaigen Vollzeilen des Relativs u = 1αβγ0 in einlückige mehrbesetzte, dessen etwaige Leerzeilen in einbesetzte mehrlückige verwandelt, dessen besetzte Lückzeilen aber in Gestalt der Ziffern αβγ von ū; 1 · u = 0αβγ0 beibehalten erscheinen.
[Formel] 29) wo f(u) = ū; 1 · u; 0' · u + 0' {u ɟ 0 + (ū ɟ 1'); 1}.
Entstehung aus: x = 0αβ00 + 10011 · 0' — in Anbetracht, dass hier das allgemeinste Relativ zu bilden ist, welches nur mehrbesetzte Lückzeilen hat.
Der einzig gangbare Weg hiezu wird der sein, dass wir von einem beliebigen Relativ u = 1αβγ0 die Zeilenkategorien αβ beibehalten, die übrigen in solche von der Kategorie α (vermittelst ihres Schnittes mit 0', nachdem sie in Vollzeilen verwandelt worden) umwandeln — sintemal uns eben eine Verwandlungsmöglichkeit derselben oder eines Teils derselben in solche der Kategorie β nicht zugebote steht (vergl.
„Aufg. 30“).
[Formel] , 30) wo f(u) = ū; 1 · u · (u ɟ 1' + ū ɟ 1'); 1 + {(u; 0' + ū)(ū; 0' + u) ɟ 0} · 1' oder 0', und für das zweite Glied von f(u) auch genommen werden könnte: (u ɟ 0) · 0' + (u; 0' · ū; 0' ɟ 0) · (0' oder 1') + (ū ɟ 0) · 1' — desgleichen 1' und 0' vertauscht.
Es ist ein Relativ zu bilden in welchem blos einlückige nebst einbesetzten Zeilen vorkommen können.
Wir heben aus einem beliebigen Relativ u in Gestalt von 0α0γ0 hervor dessen einlückige und einbesetzte Zeilen und fügen dem hinzu das mit sei es 0' sei es 1' (oder auch zum einen Zeilenbestande mit 0' zum andern mit 1') multiplizirte Relativ 10101 = 10000 + 00100 + 00001.
Da letztres Relativ nur aus Vollzeilen und Leerzeilen besteht, und jene (die den Leerzeilen von 0α0γ0 entsprechen) durch die Multiplikation mit 0' in einlückige, durch die mit 1' in einbesetzte umgewandelt werden, während diese (die Leerzeilen) dabei ungeändert und bei der Addition ohne Einfluss bleiben, so wird auf diese Weise sicher unser Ziel verwirklicht — und zwar, wie leicht zu sehen, auf die allgemeinste Weise.
Denn, soll ein irgendwie als -α-γ- gegebenes x erhalten werden, so braucht man nur u gleich diesem selbst zu nehmen; dann wird es mit dem ersten Glied von f(u) sich nämlich wiedererzeugen, während das zweite Glied als verschwindend ohne Einfluss bleibt, indem sowol in 0α0γ0 die mit der Ziffer 0 markirten Leerzeilen, als auch in 10101 die mit Ziffern 1 markirten Vollzeilen alsdann fehlen werden, sintemal sie ja den mit Horizontalstrich markirten in u = -α-γ- unvertreten gewesnen Zeilenkategorien zu entsprechen hatten.
[Formel] 31) wo f(u) = (ū; 0' ɟ 0)u + 1' {ū ɟ 0 + (u ɟ 1'); 1}.
Es ist das Relativ anzugeben, welches nur mehrlückig besetzte Zeilen (besetzte Mehrlückzeilen) enthält.
Dasselbe entsteht aus x = 00βγ0 + 11001 · 1'.
[Formel] wo f(u) = (u ɟ 1'); 1 · ū; 0' + 0'(u ɟ 0 + ū; 0' ɟ 0) = 32) = (u ɟ 1') ū; 0' + {(ū; 0' + u) ɟ 0}
0' das allgemeinste Relativ angibt, welches in der That nur einlückige Zeilen besitzt.
Dasselbe entsteht aus x = 0α000 + 10111 · 0'.
Bemerkenswert ist aber hier, dass man noch eine zweite, in Hinsicht auf u und ū symmetrische, dafür aber etwas kompendiösere Form der allgemeinen Lösung aufstellen kann, welche von der obigen „wesentlich“ verschieden ist, doch ebenfalls der Adventivforderung genügt.
Da nämlich γ̄ zur selben Kategorie gehört wie α, so wird die Aufgabe x = -α-γ̄- mit der hier zu lösenden zusammenfallen.
Aus x = 0α0γ̄0 + 10101 · 0' wird man daher in Gestalt von 32)a f(u) = {u ɟ 1')ū + (ū ɟ 1')u}; 0' + {(ū; 0' + u)(u; 0' + ū) ɟ 0}
0' eine ebenfalls befriedigende Lösung erhalten, welche für u = -α--- ebendieses wiedererzeugt.
Vergl. noch „Aufgabe 31“.
[Formel] fordert, ein Relativ als f(u) auf die allgemeinste Weise so zu bestimmen, dass es lediglich mehrlückig mehrbesetzte Zeilen enthält.
Vermöchten wir auch nur ein spezielles Relativ b von dieser Beschaffenheit anzugeben, so wäre leicht aus x = 00β00 + 11011 · b in Gestalt von 33) f(u) = (u; 0' · ū; 0' ɟ 0)u + (u ɟ 1' + ū ɟ 1'); 1 · b die gesuchte Lösung zu gewinnen.
Damit mehrlückig mehrbesetzte Zeilen β überhaupt existiren können, muss ja der Denkbereich 11 mindestens vier Elemente umfassen.
Und für jeden solchen Denkbereich wird es freilich ein Leichtes sein, eine Matrix hinzuschreiben, welche, weil sie den Anforderungen der Aufgabe genügt, b genannt und als solches verwendet werden dürfte.
Man setze z. B. in jeder Zeile zwei (und nur zwei) Augen an, vielleicht eines auf der Hauptdiagonale und eines ausserhalb, etwa oberhalb derselben!
Allein zu vermissen bleibt ein analytischer Ausdruck für solches Relativ b.
Unter den 256 Relativen der Zeilengruppe eines allgemeinen oder unbestimmten Relativs u ist ein Relativ b der verlangten Art jedenfalls nicht zu finden, und auch wenn man u als einen der vier Moduln spezialisirt, wird es sich nicht ergeben.
Die vier Moduln aber sind die einzigen speziellen Relative, auf welche wir in der allgemeinen Theorie der binären Relative uns rechnerisch zu berufen vermögen.
Um auch die vorliegende sowie die noch von ihr abhängigen Aufgaben analytisch vollends zur Lösung zu bringen wird sonach sich wol kein andrer Weg einschlagen lassen, als dass man ein gewisses „Prinzip (Relativ) r einführt, durch welches alle Elemente des Denkbereichs 11 in eine bestimmte Ordnung oder Reihenfolge gebracht werden — so wie es etwa für die ganzen Zahlen (und mittelbar dann auch für die reellen Zahlen überhaupt) das Relativ thut r = „ [Formel] “ = „um eins grösser als-“.
Dazu würde alsdann blos b als „gleich oder um eins grösser als“: b = „ [Formel] “ = 1' + r anzunehmen sein.
Etc.
Da man sich in jedem Zweig und für jede Anwendung der Theorie auf irgend eine Weise wird helfen können, so nehmen wir auch diese Aufgabe 30 vorderhand als gelöst an.
[Formel] wo f(u) = (ū ɟ 1')u + 1'(u; 0' ɟ 0 + ū ɟ 0) = 34) = (ū ɟ 1')u + 1'{(u; 0' + ū) ɟ 0} das allgemeinste Relativ vorstellt, welches lauter einbesetzte Zeilen hat.
Daneben kann man auch etwas umständlicher, aber symmetrisch bezüglich u und ū nehmen: 34)a f(u) = (ū ɟ 1')u + (u ɟ 1')ū + 1'{(u; 0' + ū)(ū; 0' + u) ɟ 0} — mit im Allgemeinen vom vorigen abweichendem Werte, welcher aber für u = ---γ- mit jenem und u selbst zusammenfällt, sodass auch der letzte Ausdruck der Adventivforderung genügt.
Jenes entsteht aus x = 000γ0 + 11101 · 1', dieses aus x = 0α0γ0 + + 10101 · 1' und stellt eigentlich die Lösung der Aufgabe: x = -ᾱ-γ- vor, welche indess, weil ᾱ zur Kategorie von γ gehört, mit der obigen zusammenfällt.
Das vorstehende Relativ x werden wir in § 30 kennen lernen als das allgemeine Relativ, welches dem Begriffe „Argument von-“ oder Objekt von-“ entspricht.
Er ist das Konverse des Begriffes „Funktion von-“ oder „Bild von-“ mit welchem wir noch vielfach zu thun haben werden — wobei mit dem kurzen „Bild von-“ auf eine (wenn auch nicht umkehrbar) eindeutige Zuordnung oder Abbildung hingewiesen wird.
Das allgemeine Relativ „Funktion von-“ wird somit leicht hinzuschreiben sein als der zu unserm x konjugirte Ausdruck, m. a. W. als das dem analogen Kolonnenprobleme entsprechende Ergebniss.
Die Lösungen der Aufgaben 31 und 29 lassen sich übrigens auch durch Negation auf einander zurückführen.
Die Negation des allgemeinen blos einlückigzeiligen Relativs muss ja das allgemeine blos einbesetztzeilige Relativ sein, und umgekehrt.
Damit jedoch die Adventivforderung gewahrt bleibe, ist mit dem Vollzug der Negation an f(u) zugleich zu verbinden die Ersetzung von u durch ū, m. a. W. das f̄(ū) der einen Aufgabe ist jedesmal das f(u) der andern.
Auf diesem Wege ergeben sich aber von den erwarteten in formaler Hinsicht total verschiedene Ausdrücke — ein in die Augen fallender Beleg für die Vielförmigkeit unsrer Disziplin — und es ist wieder als eine gute Übung für Anfänger empfehlenswert, sich von der gleichwol bestehenden Identität der Ergebnisse zu überzeugen, wobei das fünfziffrige Rechnen die besten Dienste leistet.
Durch das gleiche Verfahren muss (weil β̄ zur selben Kategorie wie β gehört) die Lösung der Aufgabe 30 wieder in sich selbst übergehen (und sie thut es).
Ebenso müssen die Aufgaben 26 und 28 miteinander, die 27 sowie die 25 mit sich selbst zusammenhängen — von den früheren Aufgaben zu geschweigen.
Am Ende unsrer Serie von Aufgaben angelangt wollen wir nochmals zusammenfassen, wie nunmehr jedes Auflösungsproblem der Zeilensorte rein mechanisch auf jene 32 vorstehend gelösten zurückzuführen ist.
Nachdem für x = 1αβγ0 auch F(x) zeilenschematisch ausgerechnet ist, wird dieses sich als eines der 256 Relative der Zeilengruppe darstellen; sein Wert wird aus gewissen von den acht Ziffern 1, α, β, γ, 0, ᾱ, β̄, γ̄ in bestimmter Weise fünfziffrig zusammengesetzt erscheinen.
Man hebe nun aus vorstehendem Schema von x diejenigen Ziffern hervor, an deren Stelle im ausgerechneten Werte von F(x) Nullen stehen, indem man die übrigen Ziffern von x je durch einen Horizontalstrich ersetzt.
So erhält man ein Schema, bestehend aus fünf teils Strichen teils (unnegirten!) Ziffern, welches, wieder gleich x gesetzt, die Aufgabe löst, nämlich ihre Lösung auf eines (das gleichlautende) von den 32 zuletzt erledigten Problemen zurückführt. —
Es gibt nach Obigem zwar 256 verschiedene Auflösungsprobleme (in Zeilenoperationen).
Die allgemeinen Lösungen derselben lassen sich jedoch — die Nichtlösung der absurden Aufgaben eingerechnet — durch nur 32 Ansätze darstellen.
Dies rührt daher, weil alle diejenigen Gleichungen die nämliche Lösung haben müssen, deren fünfziffrig ausgerechnete Polynome in den Nullziffern übereinstimmen — wie verschieden auch in ihnen die übrigen Ziffernstellen besetzt sein mögen.
Nach diesen Erörterungen halten wir selbst ein Beispiel für überflüssig.
Um demnächst auch das Eliminationsproblem — insoweit dabei nur Zeilenrelative in Betracht kommen — lösen zu können, müssen wir noch für jede der fünf Zeilenkategorien die Bedingung dafür aufstellen, dass sie in einem Relativ a = 1αβγ0 unvertreten sei oder fehle.
Diese Bedingung ergibt sich — bezüglich der Reihe nach für eine jede der 5 Kategorien — sofort aus dem Ansatze: 10000 = 0, 01000 = 0, 00100 = 0, 00010 = 0, 00001 = 0, während für die drei mittleren Kategorien auch die Ansätze:
0α000 = 0, 00β00 = 0, 000γ0 = 0 benutzt werden können.
Darnach erhalten wir, mit einigen Varianten äquivalenter Schreibung die wir darunter setzen, respective: a ɟ 0 = 0, (a ɟ 1')ā = 0, a; 0' · ā; 0' ɟ 0 = 0, (ā ɟ 1') a = 0, ā ɟ 0 = 0 a ɟ 1' ⋹ a, a; 0' ɟ 0 ⋹ (a ɟ 1'); 1, a ⋹ a; 0', 1 = a; 1 a; 0' · a ⋹ (a ɟ 1'); 1 wobei wir für den mittleren Fall noch die Schreibung [(a; 0' ɟ 0)(a ɟ 1' + a) = ](a; 0' ɟ 0)a ⋹ (a ɟ 1'); 1 als weniger einfach unterdrückt haben.
Nebenbei kamen hier in Betracht oder stellen sich heraus die Sätze [deren erster als 22) des § 9 bereits vorgekommen]: 35) 36) 37) [Formel] denen noch eine grosse Menge solcher von ähnlicher Natur zugesellt werden könnte, und von welchen besonders die beiden ersten sehr wichtig sind.
(a; 1 = 0) = (a = 0) = (1; a = 0) (a ɟ 0 = 1) = (a = 1) = (0 ɟ a = 1)
(a; 0' = 0) = (a = 0) = (0'; a = 0) (a ɟ 1' = 1) = (a = 1) = (1' ɟ a = 1)
Übersichtlichst kann man die Ergebnisse unsrer Untersuchung durch die Formeln zusammenfassen (in hufeisen- oder U-förmiger Anordnung): 38) [Formel]
Die Aufgaben 17, 4, 3, 2, 9, deren Lösung ja die Adventivforderung erfüllt, geben einen Fingerzeig, wie die gesuchten Bedingungen wenn man will auch angeschrieben werden könnten in Gestalt von Gleichungen, deren rechte Seite a selbst ist.
In der That sind den die gleiche Stellung einnehmenden von den vorstehenden Bedingungen bezüglich äquivalent:
(ā; 0' · a = a), = (ā; 1 · a = a) (ā ɟ 1' + a = a), = (ā ɟ 0 + a = a) (a ɟ 1' + a = a) = {a ɟ 0 + (ā; 0' ɟ 0)a = a} (a; 0' · a = a) = {(ā ɟ 1')a; 1 + a = a} (a; 0' · ā; 0' ɟ 0 + a = a) = {(a ɟ 1' + ā ɟ 1'); 1 · a = a}.
Das Eliminationsproblem, welches nach S. 224 zu formuliren war als das Problem der Elimination eines Relativs u aus einer Gleichung von der Gestalt 3): f(u) = x erledigt sich nun für alle unsre 256 Zeilenprobleme in folgender Weise vermittelst bequemen fünfziffrig schematischen Rechnens.
Man setze u als ein allgemeines Relativ, in welchem jede Kategorie von Zeilen eventuell vertreten ist, in der Gestalt an: u = 1αβγ0 und rechne das zugehörige f(u) fünfziffrig aus.
Man erhält als Wert von f(u) ein aus gewissen von den 8 Ziffern 1, α, β, γ, 0, ᾱ, β̄, γ̄ in bestimmter Weise fünfziffrig zusammengesetztes Schema.
Erscheinen in letzterem — wenn auch vielleicht an andrer Stelle (als wie in u) — wiederum alle fünf Kategorien vertreten mit Rücksicht darauf, dass ᾱ zur selben Kategorie gehört wie γ, γ̄ zur selben wie α, und β̄ zur nämlichen wie β, so ist auch der Wert von x = f(u) ein völlig unbestimmt allgemeiner, kann (und wird bei geeigneter Wahl des u) jedes verlangte Relativ vorstellen.
Alsdann braucht x überhaupt keiner Relation zu genügen, m. a. W. es gibt dann keine Resultante, oder wenn man doch von einer solchen sprechen will, so ist als solche hinzustellen die Gleichung 0 = 0. Liegt dieser Fall nicht vor, so werden in dem Schema von f(u) gewisse Kategorien, es wird deren mindestens eine unvertreten sein, und dann existirt auch eine Resultante.
Behufs deren Gewinnung stelle man für x ein neues Schema auf, indem man die in f(u) vertretnen Kategorien in die maassgebende Reihenfolge bringt und die unvertretnen mit einem Horizontalstriche markirt:
Man ziehe also sämtliche Einser aus dem Schema von f(u), falls deren vorhanden waren, in einen einzigen Einser zusammen (nehme falls nur einer vorkam ebendiesen) und setze ihn in dem für x zu bildenden Schema an die erste Stelle — falls keiner vorkam, hier einen Horizontalstrich anbringend.
Ebenso vereinige man alle etwa vorkommenden Nullen zu einer einzigen 0, welche an die letzte oder fünfte Stelle des Schema’s für x zu setzen.
Ein etwaiges β̄ an der dritten Stelle verwandle man ebenda in β, und ein allenfalls vorkommendes γ̄ an der vierten Stelle schreibe man in ein α verwandelt an die zweite Stelle, ebenso ein ᾱ von der zweiten als γ an die vierte Stelle.
Kommt im Schema von f(u) ein ᾱ an der zweiten neben γ an der vierten Stelle vor, so notire man blos letztres an vierter Stelle und markire die zweite Stelle durch einen Horizontalstrich; die Kategorie der einlückigen Zeilen α ist dann in x jedenfalls unvertreten, und die anscheinend doppelt (durch ᾱ und γ) vertretene Kategorie der einfach besetzten Zeilen von f(u) ist dann, weil die Vertretung von α in u doch auch blos eine eventuelle gewesen, nur einfach (simply) irgendwie vertreten — wie denn eine analoge Bemerkung inbezug auf die eventuell durch mehrere Einser resp. Nullen vertretenen Voll- resp.
Leerzeilen von x zu machen wäre.
Ebenso, falls neben α auch γ̄ in f(u) zu erblicken sein sollte, notire man für x blos α an der zweiten Stelle und versehe die vierte mit einem Horizontalstrich.
Auf diese Weise ergibt sich auch für x ein geordnetes Schema, welches in der typischen Form x = 1αβγ0 die in x eventuell vertretenen Zeilenkategorien aufzeigt, bei welchem aber gewisse von den fünf Ziffern nicht angeführt, sondern durch einen Horizontalstrich ersetzt sein werden, weil die denselben entsprechenden Zeilenkategorien kraft der Relation x = f(u) in x notwendig fehlen.
Nun haben wir oben hinsichtlich einer jeden der fünf Kategorien die Bedingung dafür aufgestellt, dass dieselbe in einem Relativ a unvertreten sei oder fehle.
Hebt man aus diesen fünf Bedingungen 38) für a diejenigen hervor, welche das Fehlen einer Kategorie ausdrücken, die in dem vorstehenden Schema des x durch einen Horizontalstrich vertreten ist, sagt in ihnen x für a und bildet ihre vereinigte Gleichung, so ist ebendiese F(x) = 0 die gesuchte Resultante der Elimination des u aus der Gleichung f(u) = x.
Und zwar ist sie nicht etwa blos, weil notwendig erfüllt, „eine“ gültige Resultante, sondern zuverlässig „die“ vollständige Resultante, weil in jedem Falle leicht zu sehen und anzugeben (aber nur umständlich allgemein zu beschreiben) ist, wie man die Zeilen des u hätte annehmen können, um irgend einen gewünschten von den überhaupt zulässigen Werten des x als den Wert von f(u) zu erhalten.
[Zu dem Ende braucht man von den allfällig in eine mehrfach vertretene Kategorie des x übergehenden Kategorien von Zeilen des u immer nur eine einzige in freier Wahl beizubehalten — die andern von ihnen in u als unvertreten voraussetzend — und diese eine so anzunehmen, dass sie bei der Verwandlung, die ihr die Bildung von f(u) auferlegt, gerade die gewünschte Zeilenkategorie des x liefert].
Exempel 1 zur Elimination.
Aus x = (ū ɟ 1'); 1 + u sei u zu eliminiren.
Auflösung.
Setze u = 1αβγ0, so wird: ū = 0ᾱβ̄γ̄1, ū ɟ 1' = 000γ1, (ū ɟ 1'); 1 = 00011, und x = 1αβ11.
Sonach ist x beliebig von der Form: x = 1αβ-- entbehrt nämlich der einbesetzten und der Leerzeilen.
Umgekehrt kann x jedes Relativ mit mehrbesetzten Zeilen bei geeigneter Annahme von u vorstellen.
Die gesuchte Resultante ergibt sich darnach aus dem Produkt der zwei obersten Aussagen rechts vom Striche in 38) in der Gestalt: (x; 1 = 1)(x ⋹ x; 0') oder x̄ ɟ 0 + (x̄ ɟ 1')x = 0, wo die beiden Faktorenaussagen auch als Einzelresultanten zu etwaigen Schlussfolgerungen verwendet werden können.
Ihre Zusammenfassung repräsentirt die volle Resultante, und ist am raschesten zu gewinnen aus dem Ansatze 00011 = 0 mittelst 40) des § 15 in der Gestalt (x̄ ɟ 1'); 1 = 0, was sich noch wegen 35) vereinfacht zu x̄ ɟ 1' = 0 oder: x; 0' = 1.
Von dieser Gleichung stellt der gegebene Ausdruck für x die allgemeine Wurzel vor, die auch durch u + (ū ɟ 1'); 0' darstellbar — vergl. auch Aufg. 10 sowie das zweite und dritte Inversionstheorem in § 18, 19.
Exempel 2. Um zu zeigen, mit welcher Leichtigkeit auch die anscheinend verwickeltsten Aufgaben der vorliegenden Art sich nunmehr lösen lassen, wollen wir auch noch die Aufgabe behandeln, u zu eliminiren aus der Gleichung: x = ū ɟ 0 + (u ɟ 1'); 1 · ū; 0' + (u ɟ 1')ū + (ū ɟ 1')u + (u; 0' · ū; 0'
ɟ 0)ū desgleichen (resp. oder auch) aus dieser: x = ū ɟ 0 + (u ɟ 1'); 1 · u; 1 · ū; 1 + (ū ɟ 1')u + (u; 0' ɟ 0) · ū; 0' · ū.
Auflösung.
Für u = 1αβγ0 haben wir zu summiren .
Sonach ist x von der Form: x = 1-βγ0 ein allgemeines Relativ, welches lediglich der Forderung unterliegt, keine einlückigen Zeilen zu besitzen.
Die Bedingung hiefür ist zu entnehmen aus der zweiten Formel links in 38) und lautet: x ɟ 1' ⋹ x, und als äquivalente, aber minder einfache Formen dieser Resultante liessen sich anführen: x ɟ 1' ⋹ x ɟ 0, (x ɟ 1'); 1 ⋹ x, (x ɟ 1'); 1 = x ɟ 1', (x ɟ 1'); 1 ⋹ x ɟ 0 + x̄ ɟ 0, etc.
Die allgemeine Wurzel der Resultante bei Aufrechterhaltung der Adventivforderung ist nachzusehen in „Aufgabe 4“.
Siebente Vorlesung.
Die elementaren Inversionsprobleme.
§ 17. Erste 4 Inversionsprobleme und -Theoreme.
Eine jede Aufgabe lässt sich auch „umkehren“, invertiren — gewöhnlich sogar in mehrfacher Weise, und sie wird dadurch zum Ausgangspunkt für noch weitre Aufgaben.
Die ursprüngliche Aufgabe verlangt, dass man von Gegebenem ausgehend ein Gewünschtes, Gefordertes verwirkliche, aus irgendwelchem Bekannten ein Unbekanntes, Gesuchtes herleite.
Sie wird umgekehrt, indem man dieses letztere nun als gegeben ansieht und dafür etwas von jenem (vorhin Gegebenen) nun als gesucht hinstellt.
Was man haben und was man wünschen wird, lässt sich nicht für alle Fälle voraussehen.
Ist eine Operation ersonnen um für den Fall, dass man dies habe und jenes wünsche, das Bedürfniss zu decken, so kann die Sache doch auch umgekehrt liegen, und sich ein inverses Problem von dem durch die Operation gelösten aufdrängen.
Und thatsächlich kommen solche Konjunkturen vor.
Darauf beruht der Nutzen der Probleme, deren Grundgedanke in der Umkehrung schon gelöster Aufgaben wurzelt.
Aber auch abgesehen von allen Fragen des Nutzens beanspruchen die Inversionsprobleme ein hohes theoretisches Interesse — ganz mit demselben Rechte, wie die Wissenschaft überhaupt.
Zu allen möglichen Prämissen die Konklusionen sozusagen „auf Lager“ zu halten — oder wenigstens die Methoden, um schnellstens zu diesen zu gelangen — erscheint mir als eins der vornehmsten, wonicht als das letzte Ziel der Mathematik und Logik überhaupt, und ich kann daher einer Äusserung des Herrn Perice nicht zustimmen, die 9c p. 193 den Wert der inversen Operationen herabzusetzen scheint, indem sie dieselben als fast immer nutzlos hinstellt, wofern sich nicht eine direkte Operation mit einer „inversen Quantität“ für sie substituiren lasse — einem bedeutungsvollen Ausspruch, auf den wir S. 261 noch näher eingehn werden.
Von den Inversionsproblemen stehn im Vordergrund die „elementaren“, welche die Umkehrung von einer der sechs Grundoperationen oder Spezies zum Gegenstande haben.
Ist x̄ = a oder aber x̆ = a gegeben, so hat man augenblicklich x = ā resp. x = ă.
Die nicht knüpfenden beiden Spezies lösen daher die inversen Aufgaben ihrerselbst, und ihre Umkehrungen sind gleichwie sie selber eindeutige Operationen.
[Die direkten Aufgaben bestanden hier darin, wenn x = a gegeben war, das Negat x̄( = ā) und das Konverse x̆( = ă) zu bilden und wurden durch die Festsetzungen (11) und (13) gelöst].
Mit dieser Bemerkung sind die Inversionsprobleme für die Spezies der Negation und Konversion erledigt.
Was ferner die beiden identischen von den vier knüpfenden Spezies betrifft, so haben wir uns in Bd. 1 so gründlich mit denselben beschäftigt, dass wir auch diese als abgethan hinstellen dürfen; das Interesse für dieselben ging schliesslich auf in dem allgemeineren Interesse an der Auflösung von Gleichungen überhaupt — im identischen Kalkul.
Und so gipfelt nun unser nächstes Interesse in den Problemen, welche aus der Umkehrung der beiden relativen Knüpfungen entspringen.
Ein solches würde beispielsweise die Auflösung nach der Unbekannten x der Gleichung x; b = a sein.
Weil aber die Gleichung äquivalent ist einem Paare von Subsumtionen, welche als vor- und rückwärts genommene simultan erfüllt werden müssen — wie denn die angeführte Gleichung zerfällt in x; b ⋹ a und a ⋹ x; b — so haben wir dem gedachten Inversionsprobleme zwei einfachere voraufgehen zu lassen, welche auf die Auflösung nach x je einer von diesen Teilsubsumtionen der Gleichung hinauslaufen.
Wir haben demgemäss nicht vier sondern zwölf elementare Inversionsprobleme zu lösen — drei Quadrupel, die wir als erste, zweite und dritte Inversionsprobleme bezeichnen wollen.
Das „erste Inversionsproblem“ verlangt die Auflösung nach dem unbekannten Relativ x je einer der vier Subsumtionen: 1)
[Formel] Die Lösung wird — wie zu sehn in leichtester Weise — vermittelt durch eine Gruppe von Sätzen, welche ich „die ersten Inversionstheoreme“ nenne und die im Hinblick auf ihre Symmetrie und die cyklische Vertauschbarkeit der drei in ihnen vorkommenden Buchstaben ganz leicht zu behalten sind.
Diese Theoreme statuiren die Äquivalenz der nachfolgend einander gleichgesetzten Subsumtionen: 2)
[Formel] .
Mit diesen Formeln sind allerdings die Theoreme zweimal ausgesprochen, indem die zwei letzten Zeilen — jedoch in einer vollkommen gleichberechtigten Form — blos wiederholen, was schon die beiden ersten Zeilen besagten.
Man erkennt dies, indem man dort die drei Buchstaben durch ihre Strichkonverse ersetzt und ausserdem b mit c vertauscht — wodurch in der That das eine Zeilenpaar aus dem andern hervorgehn wird.
Von dem hienach allein zu rechtfertigenden ersten Zeilenpaare geht die eine Zeile aus der andern durch Konvertiren hervor.
Daher bleibt nur die erste Zeile zu begründen.
Von den sechs Subsumtionen der ersten Zeile gehen die drei letzten durch konvertirende Kontraposition aus den drei ersten hervor und ist deshalb blos die Äquivalenz dieser dreie darzuthun.
Letztere ist bereits garantirt durch die Äquivalenz der beiden ersten Subsumtionen.
Denn wenn mit dem Beweis der ersten Gleichung 2) der Satz gewonnen ist, dass in einer Subsumtion von der Form der ersten die drei Buchstaben im Ringe herum vertauscht werden dürfen, so ist man berechtigt diesen Satz auch wiederholt anzuwenden, und man wird die dritte Subsumtion auf demselben Wege aus der zweiten erhalten wie diese aus der ersten.
Dasselbe Verfahren nochmals auf die dritte Subsumtion angewendet liefert dann nichts neues mehr, sondern führt blos wieder auf die erste Subsumtion zurück.
Um aber jenen (einzigen) Beweis zu führen, ist nur zu zeigen dass Πi j(Σhbi hch j⋹āj i) = Πi j(Σhci hah j⋹b̄j i), d. h. Πi j(Σhaj ibi hch j = 0) = Πi j(Σhbj ici hah j = 0), Πi j h(aj ibi hch j = 0) = Πi j h(ah jbj ici h = 0) oder auch — wenn man will: (Σi j haj ibi hch j = 0) = (Σi j hah jbj ici h = 0) sein muss.
Und dies ist evident, weil hier die eine Seite aus der andern hervorgeht durch cyklische Vertauschung der laufenden Zeiger i, j, h, deren Benennung ohnehin gleichgültig ist — mit Rücksicht auf Σj h i = Σi j h — q. e. d.
Zu Zwecken der Anwendung dürften übrigens die minder symmetrischen Ausdrucksformen unsres Satzes häufig bequemer sein: 3)
[Formel]
Bedenkt man noch, dass eine jede von den zwölf einander äquivalenten Subsumtionen in 2) oder 3) auch auf das Subjekt 1 oder auf das Prädikat 0 gebracht werden kann, und ferner, dass sie nach den Theoremen von Robert Grassmann auf zwei Arten in eine Gleichung umgesetzt werden mag — indem z. B. (a; b ⋹ c) = (1 ⋹ ā ɟ b̄ + c) = (a; b · c̄ ⋹ 0) = (a; b · c = a; b) = (a; b + c = c) sein wird — so sieht man, dass wir für jede derartige Subsumtion augenblicklich über 12 + 24 + 24 = 60 Ausdrucksformen verfügen und erkennt man wie ungeheuer vielgestaltig (highly multiform) unsre Disziplin ist.
Ist das ein Vorteil?
Jedenfalls ist es eine Thatsache mit der wir uns abzufinden und vertraut zu machen haben!
Von den in 3) enthaltenen Sätzen ist es noch besonders ratsam sich als vorbildlich denjenigen einzuprägen welcher durch die Äquivalenz der ersten und vierten Subsumtion ausgedrückt wird: (a; b ⋹ c) = (a ⋹ c ɟ b̄̆).
Nach diesem Satze nämlich rechtfertigt sich die erste von den folgenden vier Formeln: 4)
[Formel] welche unser erstes Inversionsproblem schon im Prinzipe lösen, indem sie lehren, die Unbekannte x sei es als Subjekt sei es als Prädikat zu isoliren.
Hiernach kann in einer Subsumtion ein relativer Faktor der einen Seite „nach dem Striche“ (aber nicht „gegen den Strich“!) transponirt, d. h. auf die andre Seite der Subsumtion geschafft werden als relativer Summand, indem man ihn zugleich in sein Strichkonverses verwandelt, und zwar:
ein zweiter oder Nachfaktor kommt hinüber als zweiter oder Nachsummand, ein erster oder Vorfaktor auch als Vorsummand.
Umgekehrt ist das Hinüberschaffen eines relativen Summanden — wieder unter Umkehrung seiner beiden Qualitäten — nur gegen den Strich (oder den mit den Haaren eines zu streichelnden Tieres verglichenen Bogen des Subsumtionszeichens) erlaubt.
Bedenkt man jetzt, dass nach bekannten Auflösungsschemata des identischen Kalkuls [Formel] ist, etc., so haben wir in Gestalt der Formeln: 5) in aller Form die allgemeinen Lösungen unsrer ersten Inversionsprobleme 1) gewonnen.
Macht man mit den gefundnen Ausdrücken der „allgemeinen Wurzel“ x die Probe, und sagt c für u, so gelangt man zu den Formeln: 6)
[Formel] deren Allgemeingültigkeit auch leicht unmittelbar aus der Koeffizientenevidenz zu erweisen ist.
Für die erste z. B. hat man zu zeigen, dass für jedes ij: ΣkΠh(ai h + b̄k h)ci kbk j ⋹ ai j sein muss.
Nun enthält das Πh, welches das allgemeine Glied der Σk ist, bei h = j den Faktor: ai jci kbk j. Folglich lässt sich in der That linkerhand der Faktor ai j vorziehen und ist die linke Seite eingeordnet diesem, q. e. d.
Von diesen Formeln wollen wir noch die speziellen Fälle für c = 1 resp. 0 hervorheben: 7) aus welchen ihrerseits auch wieder die allgemeinern 6) a fortiori nach 1) des § 6 folgen, sintemal (a ɟ b̄̆)c ⋹ a ɟ b̄̆, also auch (a ɟ b̄̆)c; a ⋹ (a ɟ b̄̆); a, etc.
Für diese Formeln 7) aber, als 21) des § 8, S. 126, hatten wir bereits selbständigen Beweis gegeben.
Dass die Aufgaben 1) keine Resultante der Elimination des x bedingen können, erhellt aus dem Umstande, dass denen links durch x = 0, rechts durch x = 1, in allen Fällen genügt werden kann, wie immer auch a und b gegeben sein mögen.
Bei Benutzung dieser Partikularlösungen kann man leicht nach § 12 auch die rigorose Lösung unsrer ersten Inversionsprobleme hinschreiben, und stellt sich dieselbe folgendermaassen dar: 8) was wir zur Vergleichung — wenn nicht blos als Kuriosum — einmal angeführt haben wollen.
Die oben ausgeführte „Probe“ der Lösungen 5) war diejenige, die wir als die „Probe 1“ zu bezeichnen pflegen; sie lieferte uns beim ersten Problem die Überzeugung, dass {x = u(a ɟ b̄̆)} ⋹ (x; b ⋹ a) sein muss, worin, da dies für jedes u gilt, der linken Seite auch ein Summenzeichen nach u vorgesetzt werden mag.
Die „Probe 2“ hat nun zu erhärten, dass auch umgekehrt [Formel] sein muss, d. h. dass es einen Wert von u gibt für welchen die Aussage hinter dem Σ erfüllt, = 1 ist, sobald von x die Voraussetzung links erfüllt wird.
Ein solcher Wert von u ist aber in der That dieses x selber.
Denn gilt x; b ⋹ a, so auch nach 4) x ⋹ a ɟ b̄̆, mithin x = x(a ɟ b̄̆), q. e. d.
Zur Übung möge der Leser die Formeln des Viergespanns: etc. aus 6) beweisen.
(a; b̆)(a; b ɟ b̄̆); b ⋹ a; b a ɟ b ⋹ {a ɟ b̆ + (a ɟ b); b̄̆} ɟ b
Nimmt man in 2) oder 3) einen der relativen Faktoren gleich 1' an, so ergeben sich auch die Peirce’schen Sätze 20) vom Schlusse des § 8 als besondre Fälle unsres ersten Inversionstheoremes wieder.
Auf b = a angewendet gibt uns 7): (a ɟ ā̆); a ⋹ a.
Nach 3) des § 8 ist aber 1' ⋹ a ɟ ā̆, woraus folgt: 1'; a ⋹ (a ɟ ā̆); a oder a ⋹ (a ɟ ā̆); a, d. h. es gilt auch die umgekehrte Subsumtion der vorigen oder wir haben die Gleichung bewiesen, deren Gespann einen wichtigen Satz vorstellt: 9)
[Formel] und in etwas an die arithmetischen Sätze a + a - a = a = a - a + a erinnert. —
Von dem Satze 5), der unser Problem gelöst, kommen besonders häufig zur Anwendung die Sonderfälle: 10) [Formel] 11) [Formel] .
§ 18.
Die 4 zweiten Inversionsprobleme nebst zugehörigen Theoremen.
Diese Probleme fordern die vollständige Auflösung nach x der Subsumtionen: 1)
[Formel] — eine jede einzeln genommen.
Eine jede von diesen Subsumtionen involvirt zunächst eine Relation zwischen a und b, ansonst sie unmöglich bestehen kann.
Diese Relation lautet bezüglich: 2)
[Formel] und kann als die Resultante der Elimination des x, sowie auch als die Valenzbedingung für x bezeichnet werden, sintemal es nur, soferne sie von a und b erfüllt ist, ein x geben kann, welches die Subsumtion 1) befriedigt, dann aber auch immer solche x geben wird, die ihr genügen.
Begründung.
Die Resultante lässt sich am raschesten gewinnen, indem man an der selbstverständlichen Subsumtion beiderseits mit b relativ (nach- resp. vor-) multiplizirt, beziehungsweise addirt, z. B. für die erste Aufgabe schliesst: x; b ⋹ 1; b, woraus in Verbindung mit der Prämisse 1) a fortiori die angegebne Resultante 2) folgt.
Auf diese Weise erhellt sogleich die Unerlässlichkeit der Resultante.
x⋹ 1 0 ⋹ x
Dass sie aber auch hinreichende Bedingung für die Erfüllbarkeit der Forderung 1) oder Existenz eines dieser genügenden x ist, geht daraus hervor, dass, sobald sie erfüllt ist, sich sofort als eine zulässige (Partikular-)Lösung darbietet und zwar als die Lösung des Problemes.
x = 1 x = 0
Maximal- Minimal-
Da die Resultante äquivalent ist mit 3)
[Formel] so brauchen wir uns nur mehr mit der Auflösung nach x der Subsumtion zu beschäftigen: 4)
[Formel] in welcher a und b ganz unbedingt willkürlich gegeben zu denkende Relative, m. a. W. unbeschränkt allgemein sind — eine Resultante also nicht mehr vorliegen kann.
Die allgemeine Lösung dieses Problems, das schon erheblich schwieriger ist als das des vorigen Paragraphen, vermag ich sogleich in vier wesentlich verschiedenen Formen anzugeben, deren erste die „rigorose Lösung“ ist, wie sie bei Benutzung der im vorigen Kontext angegebnen Partikularlösung nach 16), 17) S. 174 und leichter Reduktion sich darbietet.
Diese lautet für das erste unsrer Probleme a · 1; b · (x̄ ɟ b̄) = 0 ursprünglich: x = u + 1; a(1; b)(ū ɟ b̄); 1.
Nun gilt aber das Gespann der Sätze: 5)
[Formel] dessen erster sich beweist mit Li j = ΣkΣhai hbi kck j = Σhai h · Σkbi kck j = Ri j.
Nach dem dritten dieser Sätze können wir also im zweiten Gliede unsres x den Faktor 1; b heraussetzend für 1; a(1; b)(ū ɟ b̄) schreiben 1; a(ū ɟ b̄) · 1; b welches identische Produkt dann noch mit 1 relativ nachzumultipliziren bleibt.
Dabei lässt sich wiederum anwenden das erste Schema des folgenden Sätzegespannes: 6)
[Formel] welches sich leicht beweist mit:
Li j = Σhai hΣkbk h = Σh kai hb̆h k = Ri j.
Und so gelangen wir zu der folgenden Form der rigorosen Lösung unsrer Probleme 4): 7)
[Formel] — welche Gleichungen, in eckige Klammern hinter ein Zeichen [Formel] geschrieben, den ebenfalls eingeklammerten Gleichungen 4) bezüglich äquivalent gesetzt zu denken sein werden.
Merkwürdigerweise gehen nun die drei andern Formen der allgemeinen Lösung unsres Problems aus dieser rigorosen hervor, indem man von den beiden als Terme in sie eingehenden Moduln 1 resp. 0 den einen oder den andern oder beide unterdrückt.
Von diesen Formen wird die letztgenannte die beste sein als diejenige, welche sich am weitesten von der rigorosen Lösung entfernt und dem nicht schon glücklich mit u erratenen x weder Vollzeilen noch Vollkolonnen zu haben auferlegt.
Diese wollen wir darum auch nachher als die allgemeine Lösung katexochen mit voller Ausführlichkeit hinschreiben.
Wir haben also als richtige (auch der Adventivforderung genügende) allgemeine Lösungen der Probleme 4) sowol: 8)
[Formel] als auch: 9)
[Formel] und endlich — in vollständiger Schreibung: 10) [Formel] — so für die unabhängig beliebigen Parameter a, b.
Für die durch das Problem 1) noch in Abhängigkeit gesetzten Parameter a, b hingegen muss mit der Angabe der allgemeinen Wurzel x auch diejenige der Resultante verbunden werden, indem man schreibt: 11) — eine Fassung, in der die allgemeine Lösung des zweiten Inversionsproblemes ebenfalls zur Verfügung gestellt sein soll, da zu Zwecken der Anwendung zuweilen 11) der Fassung 10) noch vorzuziehen sein wird.
Sagt man endlich in 11) oben links a; b für a, so wird die Resultante von selbst erfüllt, und erhält man das Formelgespann: 12)
Die vier Lösungsformen 7), 8), 9), 10) liefern natürlich, sobald man u gleich einer Wurzel x der Aufgabe annimmt, übereinstimmend diese selber.
Sobald man aber das unbestimmte oder willkürliche u so annimmt, dass es für x eingesetzt der Aufgabe nicht selbst schon genügt, liefern zwar die entsprechenden Formeln der vier Chiffren stets unfehlbar richtige aber im Allgemeinen von einander verschiedene Wurzeln.
Dies lässt sich schon durch einfache Beispiele erhärten, wie etwa für das erste Problem durch die Annahmen:
[Formel] .
Die Formen sind daher, obwol sie alle die Qualifikation als eine „allgemeine Lösung“ der Aufgabe verdienen, nicht blos formell oder äusserlich, sondern wesentlich verschieden zu nennen.
Ich habe mich nunmehr über Herleitung und Beweis der Formeln 8), 9), 10) auszusprechen.
Der Beweis der ersten Formel 10) zerfällt in zwei „Proben“.
Probe 1 läuft daraus hinaus, dass wir den angeblichen Wurzelwert von x in die aufzulösende Proposition einsetzen und uns überzeugen, dass dieselbe durch ihn allgemein, für ein beliebiges u, erfüllt wird.
Zu dem Ende ist also zu zeigen, dass: a · 1; b ⋹ u; b + a(ū ɟ b̄); b̆; b, d. h. in den Koeffizienten, dass Lj j ⋹ Ri j, nämlich ai jΣhbh j⋹Σlui lbl j + Σh kΠlai k(ūi l + b̄l k)bh kbh j allgemein sein muss.
Letzteres gelingt durch den Nachweis, dass die linke Seite selbst als Glied der Summe rechterhand figurirt.
Hebt man in der That aus der Σh k bei Ri j den für k = j sich ergebenden Term hervor und fügt denselben tautologisch hinzu, so entsteht: Ri j = Σlui lbl j + ai jΠl(ūi l + b̄l j)Σhbh j + Σh kΠl · etc. = Σlui lbl j + ai jΣhbh j + Σh kΠl · etc. = Li j + etc. weil beim mittleren Terme der Faktor Πl(ūi l + b̄l j) als Negation des vorhergehenden Termes unterdrückbar war.
Somit ist in der That Li j ⋹ Ri j, q. e. d.
Für die Formeln [7)], 8) und 9) braucht nun die „Probe 1“ nicht mehr gemacht zu werden.
Dass sie auch für diese stimmt, folgt nämlich a fortiori aus dem soeben Erwiesenen.
Denn nennen wir für die erste Aufgabe des Gespannes 10) den zweiten Term a(ū ɟ b̄); b̆ der Wurzel x zur Abkürzung v, so wurde soeben erkannt, dass a · 1; b ⋹ u; b + v; b.
Bei 8) ist aber x = u + v; 1 und bei 9) x = u + 1; v [bei 7) x = u + 1; v; 1].
Wegen v ⋹ v; 1 ist gewiss u; b + v; b ⋹ u; b + v; 1; b, und falls hiervon der linken Seite das a · 1; b als eingeordnet nachgewiesen ist, so muss es um so mehr auch der rechten Seite eingeordnet sein.
Ähnlich ist aber auch v ⋹ 1; v, u. s. w. — q. e. d.
Natürlich lassen sich auch diese Einordnungen direkt in den Koeffizienten nachweisen, was eine empfehlenswerte Übungsaufgabe für Anfänger bildet.
Sagt man c für u, so erscheint durch unsre Probe 1 auch aus 10) gerechtfertigt das Gespann von Sätzen: 13) [Formel] deren oberste man übrigens auch in der Gestalt hätte ansetzen können:
Sagt man in 13) oben links wieder a; b für a, wo dann wegen a; b ⋹ 1; b das Subjekt sich zu a; b · 1; b = a; b vereinfacht, so entsteht noch diese zu Verweisungen bequeme Form des Formelgespannes: 14) [Formel] Bemerkenswert ist, dass für den Sonderfall a = 1 resp. 0 die Subsumtionszeichen in diesen Formeln in Gleichheitszeichen übergehen, weil — wie aus deren letzter Gestalt, wegen d; b ⋹ 1; b, etc. zu sehn ist — die rückwärtigen Subsumtionen alsdann ohnehin gelten.
Sagt man schliesslich a für c, so gelangt man zu dem Gespann von Gleichungen: 15) [Formel] wovon z. B. den beiden untersten auch die Gestalt gegeben werden kann:
Alle diese allgemeinen Sätze enthalten natürlich grosse Mengen von spezielleren unter sich, von denen man besonders beachtenswerte dadurch erhalten wird, dass man einzelne von den Buchstaben a, b, c mit einem der Moduln identifizirt.
Z. B.:
a · 1; b ⋹ {c + a(c̄ ɟ b̄); b̆}; b c{(a + c̄; b̄) ɟ b̆} ɟ b ⋹ a + 0 ɟ b.
a; {b + ă; (ā ɟ b̄)} = a; 1 a ɟ b (ă ɟ ā; b̄) = a ɟ 0.
a; {ă; (ā ɟ 1') + 0'} = a; 1 a ɟ (ă ɟ ā; 0') 1' = a ɟ 0.
Probe 2 läuft hinaus auf den Nachweis des Erfülltseins der Adventivanforderung: dass nämlich ein den Bedingungen der Aufgabe genügendes x aus dem allgemeinen Ausdrucke der Wurzel durch die Annahme u = x selber hervorgehe.
Dieser Probe muss vorausgeschickt werden ein kleiner Hülfs-
Satz.
Allgemein gilt: 16) [Formel]
Beweis der ersten Formel.
Es ist Li j = Σhai hΠkb̄h k · bh j = 0, indem jedes Glied der Σh aus dem Grunde verschwindet, weil das Πk bei k = j den Faktor b̄h j aufweist, der sich mit dem darauffolgenden bh j aufhebt.
Insbesondre hat man für a = 1 resp. 0, wenn hernach a statt b geschrieben wird: 17) [Formel] aus welchen letztern Formeln auch schon die vorigen a fortiori folgen, sodass man nur diese 17) aus den Koeffizienten hätte zu beweisen brauchen.
Denn wenn z. B. erkannt ist, dass (0 ɟ b̄̆); b ⋹ 0 ist, so muss wegen a(0 ɟ b̄̆) ⋹ 0 ɟ b̄̆ umsomehr auch a(0 ɟ b̄̆); b ⋹ 0 sein.
Dies vorausgesetzt ist nun leicht zu zeigen, dass, wenn durch ein x die Forderung a · 1; b ⋹ x; b erfüllt ist, dann auch x = x + a(x̄ ɟ b̄); b̆ sein muss.
Die Voraussetzung lässt sich nämlich schreiben: a · 1; b · (x̄ ɟ b̄) ⋹ 0 oder a(x̄ ɟ b̄) ⋹ 0 ɟ b̄, woraus durch beiderseitiges relatives Nachmultipliziren mit b̆ hervorgeht: a(x̄ ɟ b̄); b̆ ⋹ (0 ɟ b̄); b̆ ⋹ 0 — letztres nach dem ersten Schema 17) auf b̆ statt a angewendet.
Damit kommt dann offenbar die Behauptung auf x = x + 0 hinaus, q. e. d.
Ebenso trifft dann aber auch zu: x = x + 0; 1, x = x + 1; 0, [x = x + 1; 0; 1] und stimmt hienach die Probe 2 auch bei den übrigen Lösungen 8), 9)
[und 7)], q. e. d.
Da die soeben in Probe 2 gerechtfertigte „Behauptung“ auch einfacher als Subsumtion, Einordnung ihres letzten Gliedes unter x, geschrieben werden kann, so ist durch das Bisherige erwiesen, dass: (a · 1; b ⋹ x; b) ⋹ {a(x̄ ɟ b̄); b̆ ⋹ x} worin rechts das Prädikat auch durch 0 ersetzbar.
Bemerkenswert ist, dass diese Aussagensubsumtion auch umgekehrt gilt, mithin als Gleichung.
Wir haben überhaupt die Äquivalenzen: 18) — worin obendrein links vom Mittelstriche dem Subjekte rechterhand auch ein relativer Faktor 1 vor- oder nachgesetzt werden dürfte, rechts vom Mittelstriche dem Prädikate rechterhand ein relativer Summand 0. [Darnach konnten die Lösungen 10) auch aufgrund des Satzes 1) des § 13 entdeckt werden.]
Beweis.
Gilt a(x̄ ɟ b̄); b̆ ⋹ x, so folgt nach dem ersten Inversionstheoreme: a(x̄ ɟ b̄) ⋹ x ɟ b̄, a(x̄ ɟ b̄) ⋹ (x ɟ b̄)(x̄ ɟ b̄) = xx̄ ɟ b̄ = 0 ɟ b̄, also a · 1; b · (x̄ ɟ b̄) ⋹ 0, a · 1; b ⋹ x; b, q. e. d.
Ist nun z. B. v; 1 ⋹ x, so folgt ebenso nach dem citirten Satze: v ⋹ x ɟ 0 ⋹ x, also v ⋹ x, etc. wie soeben.
Die oben bei „Probe 2“ gemachte Überlegung, aus welcher hervorgeht, dass ein der ersten Aufgabe genügendes x jedenfalls (für u = x) in der Form existirt: x = u + a(ū ɟ b̄); b̆ und der Gedanke nahe liegt, mit diesem Ausdrucke nun auch für ein beliebiges u die Probe 1 zu machen, welche alsdann, wie oben gezeigt, die Vermutung bestätigen wird, dass vorstehender Ausdruck die allgemeine Wurzel vorstelle — diese Überlegung kann man wol als die ungezwungenste Herleitung unsrer Resultate 10) hinstellen.
Allerdings kommt dabei etwas ein glückliches Erraten zur Wirkung, und erscheint es sonderbar, dass folgendes Räsonnement, welches man mit gleichem Recht anstellen könnte, ja was noch näher liegt, nicht zum Ziele führt.
Es ist ja auch schon für die Wurzel x: a · 1; b · (x̄ ɟ b̄) = 0.
Also muss mit x = u + a · 1; b · (ū ɟ b̄) gewiss die Probe 2 stimmen: auch dieser Ausdruck umfasst alle Wurzeln und gibt uns für u = x jede Wurzel x richtig wieder.
Aber es stimmt die Probe 1 nicht.
Der Ausdruck gibt nicht ausschliesslich Wurzeln.
In der That ist im Allgemeinen nicht a · 1; b ⋹ u; b + a(1; b)(ū ɟ b̄); b, wie schon die Annahme u = 0 erkennen lässt, wo a · 1; b ⋹ a(1; b); b gelten müsste, was für b = 0' das offenbar unrichtige a ⋹ a; 0' ergäbe.
Ich habe zuerst die Formeln 10) durch eine sehr viel mühsamere Untersuchung gewonnen, indem ich der Koeffizientenforderung (der ersten Aufgabe) mittelst arbiträrer Parameter ui j „symmetrisch allgemein“ zu genügen suchte.
Von dieser Forderung: ai jΣhbh j⋹Σhxi hbh j muss ja in der That der allgemeine Koeffizient von x: xi h = ui h + ΣkΠlai k(ūi l + b̄l k)bh k die „symmetrisch allgemeine Lösung“ nach dem unbegrenzten System der Unbekannten xi h vorstellen.
Da es jedoch auch bei diesem Verfahren nicht ganz ohne glückliches Raten abging, will ich den Leser mit dieser meiner Herleitung verschonen und mich mit dem Verweise auf die oben angedeutete Herleitung begnügen.
Zum Schlusse seien noch ein paar Partikularlösungen und Unterfälle des Problems hervorgehoben.
Als Partikularlösungen, von immerhin noch grosser Allgemeinheit, unsrer zweiten Inversionsprobleme 4) verdienen besondre Beachtung: 19)
[Formel]
Namentlich also (für w = 0 resp. 1) genügt x = a; b̆ immer der ersten Aufgabe 4) sofern sie lösbar, also der Forderung a ⋹ x; b.
In der That gilt der Satz: 20) [Formel]
Beweis des ersten:
Li j = ai jΣhbh j, Ri j = Σh kai hbk hbk j. Letztere Summe enthält (für h = j) die Terme ai jΣkbk j = Li j, q. e. d.
Dass hernach auch der allgemeinere Ausdruck 19) der Forderung unsres Problems genügt, folgt leicht a fortiori.
Schreibt man in 20) — es ist immer zunächst die erste Formel des Gespannes gemeint — a; b für a, so erhält man wegen a; b ⋹ 1; b, mithin auch a; b · 1; b = a; b, das Formelgespann: 21) [Formel]
Und nimmt man in 20) a = 1 an, so kommt: 1; b ⋹ 1; b̆; b.
Da aber wegen 1; b̆ ⋹ 1 die umgekehrte Subsumtion ohnehin gilt, so muss vorstehende die Kraft einer Gleichung haben und gewinnen wir, a für b sagend, den Satz: 22) [Formel] dessen direkte Rechtfertigung mittelst der Koeffizientenevidenz als eine der leichtesten Übungen für Anfänger zu empfehlen ist.
Die Vereinfachungen von 10) für den Fall a = 1 resp. 0 sind leicht hinzuschreiben.
Für die Annahme b = 1 resp. 0 aber erhält man zuerst (beim ersten Probleme): 23) [Formel] , wo die letzte Transformation sich gründet auf das erste Schema des Satzes: 24) [Formel] dessen Beweis mit: Li j = ΣhΠkai kbi hch j = Πkai k · Σhbi hch j = Ri j gegeben ist.
Bemerkenswert aber ist, dass diese Lösung 23) durch eine nicht blos formell einfachere, sondern wesentlich davon verschiedene und bessere ersetzt werden kann, nämlich die erste des folgenden Gespannes: 25) was zu beweisen ist wie folgt:
Probe 1 bestätigt dass: a⋹u; 1 + a(ū ɟ 0); 1 = u; 1 + a; 1 · (ū ɟ 0) = u; 1 + a; 1 — vergl. 24) — ist, weil schon a ⋹ a; 1.
Probe 2 zeigt dass für a ⋹ x; 1 mithin a(x̄ ɟ 0) = 0 auch x = x + a(x̄ ɟ 0) = x + 0 in der That ist.
Auch beim allgemeinen Probleme a · 1; b ⋹ x; b erhält man (wie ich zuletzt noch fand) eine richtige allgemeine Lösung, indem man in 10) den letzten Term b̆ durch 1 ersetzt; nämlich noch obendrein ist: 26) [Formel] wie der Studirende sich nun leicht beweisen wird.
Diese Lösungsform ist aber, obzwar im Ausdruck noch einfacher als wie die frühere 10) erscheinend, doch nicht so gut als sie, sintemal sie, bei einem nicht schon als Wurzel glücklich erratenen u, dem x des ersten Problemes wiederum die Spezialität auferlegt, Vollzeilen zu haben, andere Wurzeln also, als wie solche die auch Vollzeilen besitzen, mit ihr nicht anders als durch Erraten derselben gefunden werden können.
Die Sätze 10 oder 11 oder 12), 13 oder 14) und 18) sollen künftighin als „die zweiten Inversionstheoreme“ citirt werden; auch bei 26) wäre solches zulässig.
Im nächsten Paragraphen werden wir noch eine „Erweiterung des zweiten Inversionsproblemes“ behandeln und zugehörige Sätze begründen, die für die Lösung des dritten Inversionsproblems und seiner nächstliegenden Erweiterungen wesentlich sind.
§ 19.
Die 4 dritten Inversionsprobleme.
Wir haben uns nun zu beschäftigen mit der vollständigen Auflösung nach x einer jeden von den Gleichungen: 1)
[Formel]
Diese Aufgabe ist schwieriger als die beiden schon gelösten Probleme, führt aber zu wichtigen Sätzen und eröffnet interessante Ausblicke.
Da die Gleichung jene Subsumtionen 1) der beiden vorigen Paragraphen als ihre Teilsubsumtionen involvirt, von welchen die letztere eine Resultante nach sich zog, so müssen wir auch diesmal auf eine solche gefasst sein; es drängt sich die Vor-Aufgabe uns auf: die vollständige Resultante der Elimination des x aus 1) zu ermitteln und ihr durch geeignete Bestimmung von a und b zu genügen.
Diese Resultante lautet: 2)
[Formel] worin die Subsumtionszeichen auch in Gleichheitszeichen verwandelbar sind, da nach 7) des § 17 die rückwärtigen Subsumtionen ohnehin gelten.
Herleitung und Beweis — für die erste Aufgabe.
Wir haben x; b ⋹ a zu erfüllen, was nach § 17 äquivalent ist mit x ⋹ a ɟ b̄̆ und die Folgerung zulässt: x; b ⋹ (a ɟ b̄̆); b. Andrerseits sollte aber auch a ⋹ x; b werden, woraus im Hinblick auf das letzte Ergebniss die angegebene Resultante a fortiori folgt.
Dass sie, oder die mit ihr äquivalente Gleichung 20) a = (a ɟ b̄̆); b die volle Resultante ist, geht daraus hervor, dass, sobald sie erfüllt ist, sich in Gestalt von x = a ɟ b̄̆ eine Wurzel der Gleichung x; b = a angeben lässt.
Insbesondre involvirt diese Resultante 2) auch jene Unterresultante a ⋹ 1; b des zweiten Inversionsproblemes, welche in der That aus (a ɟ b̄̆); b ⋹ 1; b und 2) a fortiori folgt.
Es gibt noch ein eleganteres Verfahren, als das vorstehende, die Resultante 2) aus 1) zu gewinnen.
Diesem liegt zugrunde ein fundamentaler
Satz.
Allgemein gilt das Gespann von Formeln: 3)
[Formel]
Beweis 1 der ersten (direkt).
Es ist zu zeigen, dass Li j = Ri j, d. h. ΣhΠk(Σlai lbl k + b̄h k)bh j = Σhai hbh j für jedes i j sein muss.
Wir zeigen zuerst, dass Ri j ⋹ Li j, hernach das Umgekehrte.
Das Aggregat in der Klammer links enthält (bei l = h) jedenfalls auch den Term: ai hbh k + b̄h k = ai h + b̄h k, daher kann man den Term ai h vorziehend (wenn man will unter tautologischer Wiederholung desselben) schreiben:
Li j = ΣhΠk(ai h + etc.)bh j = Σh(ai h + Πk · etc.)bh j was augenscheinlich als Summanden auch die rechte Seite Ri j einschliesst.
[NB. das „etc.“ hätte rigoros den Ausdruck: Σl0'l hai lbl k + b̄h k, worin jedoch wegen Zulässigkeit von Tautologien der Faktor 0'l h auch unterdrückbar.]
Für das Umgekehrte oder Li j ⋹ Ri j ist etwa zu zeigen, dass Li jR̄i j = 0, d. h. ΣhΠkΣl(ai lbl k + b̄h k)bh jΠm(āi m + b̄m j) = 0 sein muss.
Hierin kann man das Zeichen Πm auch bis dicht vor das Σl nach links vorschieben — vergl. 3) S. 113.
[Auch könnten wir dann m mit k identifizirend die beiden Produktzeichen in ein einziges Πk zusammenziehen; doch ist dies hier nicht vorteilhaft.]
Alsdann ist zu zeigen, dass für irgendwie gegebene i, j, h mindestens ein Faktor unsres als allgemeines Glied der Σh auftretenden Doppelproduktes gleich 0 wird, und da jeder solche Faktor eine Σl ist, so muss dabei jedes Glied dieser Summe verschwinden. D. h. es ist zu zeigen, dass es ein Wertepaar k, m gibt, für welches bei jedem l: (ai lbl k + b̄h k)bh j(āi m + b̄m j) = 0 ist.
Dies ist in der That bei k = j, m = l der Fall, indem: (ai lbl j + b̄h j)bh j(āi l + b̄l j) = 0 identisch ist, q. e. d.
Die hiermit bewiesenen Formeln, welche entfernt an die bekannten Schemata (a - b) + b = a und (a + b) - b = a der Arithmetik anklingen, statuiren: dass die beiden relativen Knüpfungen, als Vor- resp. Nachknüpfungen, mit einem Relativ und dessen Strichkonverse in irgend einer Ordnung hintereinander ausgeführt einander aufheben — aber nur dann wenn der Operand selbst aus der zuletzt ausgeführten Knüpfung hervorgegangen ist.
Es sind hier also drei successive Knüpfungen erforderlich, damit zwei (successive) von ihnen sich kompensiren.
Dies ist leicht zu merken.
Schreibt man im ersten Schema 3)
x für a, und setzt beiderseits den Wert a für x; b aus 1) ein, so gelangt man schnellstens zur Resultante 2).
Entdeckt habe ich die Sätze 3) indem ich umgekehrt verfuhr, nämlich den Wert von a aus 1) in die schon gerechtfertigte Resultante 2) eintrug.
Dadurch ergeben sich sofort die Formeln 3) — nur (die obersten) in den Buchstaben x und b statt a und b.
Es können aber auch x und b als völlig allgemeine Relative angesehen werden, denn wie immer sie auch gegeben sein mögen, so kann man doch jedenfalls x; b = a nennen.
Dieses Verfahren stellt sich also dar als ein vollgültiger, zugleich heuristischer und jedenfalls — wenn er auch ein „mittelbarer“ zu nennen ist — als der müheloseste Beweis der Formeln 3) — „Beweis 2“.
Um nunmehr die Resultante 2) zu erfüllen empfiehlt es sich, b willkürlich zu lassen und derselben durch geeignete Bestimmung von a zu genügen.
Dass durch Elimination von a keine Relation für b resultiren kann, folgt daraus, dass bei jedem b der Wert a = 0 resp. 1 der Forderung 2) genügt.
Die Bestimmung von a führt zu — oder beruht auf — dem Satze: 4) wo die Subsumtionen auch als Gleichungen angesetzt werden dürften.
Dieser Satz gibt die allgemeine Wurzel x der Subsumtion oder Gleichung linkerhand zwar richtig an, ausnahmsweise jedoch nicht so, dass auch die Adventivforderung erfüllt wäre.
Die Probe 1 bewährt sich hier sofort auf Grund von 3).
Die Probe 2 jedoch ist zu leisten, indem man — nicht wie sonst immer u = x, sondern jetzt: u = x ɟ ā̆ nimmt (beim ersten Probleme).
Wollte man (bei diesem) auch die Adventivforderung erfüllt haben, so müsste man x = (u ɟ ā̆); a als den Ausdruck für die allgemeine Wurzel hinstellen. D. h. es wäre mit Rücksicht auf die Adventivforderung an Stelle des Theorems 4) zu notiren gewesen: 40) was aber minder einfach als 4) ist.
Ich will demnächst blos für das erste unsrer Probleme 1) die weitre Entwickelung besprechen.
Also: nach dem in 4)
Statuirten, oder auch unmittelbar aus dem Anblick der Resultante 2), geht hervor, dass, wofern die Gleichung x; b = a auflösbar sein soll, a notwendig von der Form sein muss: 5) a = c; b, indem unter c mindestens das Relativ a ɟ b̄̆ verstanden werden kann.
Aber auch wenn c neben b ganz willkürlich gegeben ist, erfüllt der Ausdruck 5) von a die Resultante 2) kraft 3) und erfüllt sie auf die allgemeinste Weise.
Die Annahme 5) für a, d. h. die Annahme dass es ein c gebe, derart, dass a = c; b ist, ist notwendige und hinreichende Bedingung für das Erfülltsein der Resultante 2) und für die Existenz einer Wurzel x der Gleichung x; b = a.
Wir können darnach unser Problem mit zweierlei Unterstellungen weiter behandeln.
Entweder (erste Unterstellung) wir beschäftigen uns nur mehr mit der Auflösung einer Gleichung 6)
x; b = c; b in welcher wir die Parameter b und c als vollkommen willkürlich gegebene, von einander unabhängige oder unbeschränkt allgemeine Relative ansehen.
Oder (zweite Unterstellung) wir suchen die Gleichung 1)
x; b = a nach x zu lösen, wo von a die Resultante 2) a = (a ɟ b̄̆); b erfüllt gedacht wird.
Dann kann man ebenfalls die Gleichungen 5) und 6) zugrunde legen, indem unter c der Wert verstanden wird: 7) c = a ɟ b̄̆.
Dieses — ich nenne es das „bedingte“ c — ist aber dann nicht neben b beliebig, sondern geht mit letzterm eine Relation ein, welche lautet:
8) c = c; b ɟ b̄̆ und erhalten wird, indem man den Wert 5) von a in 7) einträgt.
Ergebniss der Betrachtungen ist also:
Die Auflösung der Gleichung 1)
x; b = a lässt sich wann man will zurückführen auf die einer Gleichung 6)
x; b = c; b, in welcher zwischen b und c die Relation 8) besteht.
Die allgemeine Lösung dieser und einer Hülfsaufgabe, auf die sie leicht zurückzuführen, hat mich über ein Jahr lang vexirt.
Zwar gelang es mir nach und nach für zahlreiche Partikularfälle des Problems die allgemeine Lösung zu gewinnen, doch führte jeder erdenkliche Versuch, auch für das allgemeine Problem aufgrund der beiden ersten Inversionstheoreme die allgemeine Wurzel zu finden, in einen circulus vitiosus.
Ich will mich, durch eine Bemerkung von Peirce veranlasst, zuerst über die Wünschbarkeit solch allgemeiner Lösung aussprechen.
Bei dem allgemeinen Probleme, das wir nun auch in der Form x; b = a; b ansetzen mögen, wo a und b unabhängig beliebig gegeben zu denken, vermögen wir an Partikularlösungen zunächst dreie anzugeben: Erstens: x = a, zweitens: x = a; b ɟ b̄̆.
Diese beiden verstehen sich — die letztere aus 3) — von selbst.
Drittens aber — was ich früh durch Zufall entdeckte: x = a · a; b; b̆.
Dies beruht auf dem Satze: 9)
[Formel]
Beweis (des ersten).
Es ist Li j = Σhai hΣk lai kbk lbh lbh j, was mit k = h, l = j die Glieder Ri j = Σhai hbh j liefert, sodass Ri j ⋹ Li j also R ⋹ L feststeht.
Umgekehrt versteht sich L ⋹ R schon daraus, weil a(a; b; b̆) ⋹ a sein muss, q. e. d.
Besässen wir nun die allgemeine Wurzel x des Problems x; b = a; b in geschlossener Form oder überhaupt, so würden wir imstande sein, ebenso alle möglichen Relative anzugeben, welche mit b relativ nachmultiplizirt a liefern, und verfügten wir damit sofort über eine unbegrenzte Fülle von Sätzen, wie 3) und 9).
Und solches wäre doch schon zur Kompletirung des Formalismus unsrer Disziplin dringend zu wünschen!
Ich vermag daher Herrn Peirce kaum beizustimmen, wenn er 9c p. 193 sozusagen abfällig von den „inversen Operationen“ spricht.
Die allgemeine Wurzel unsres dritten Inversionsproblemes, als Knüpfungsergebniss zwischen a und b (Funktion von a und b — neben u) aufgefasst, würde uns eben die (eine) „inverse Operation“ zur relativen Multiplikation darstellen (die man auch relative Teilung nennen könnte, die andre als relative Messung davon unterscheidend, und beide als die relativen Divisionen bezeichnend).
Die Äusserung des genialen Meisters ist zu merkwürdig als dass sie nicht wörtlich hier angeführt werden sollte — es mag ja auch ein Korn von Wahrheit daran sein:
„The student must at the outset disabuse himself of the notion that the chief instruments of algebra are the inverse operations.
When an inverse operation is identical with a direct operation with an inverse quantity (as subtraction is the addition of the negative, and as division is multiplication by the reciprocal), it is useful; otherwise it is almost always useless.
In ordinary algebra, we speak of the »principal value« of the logarithm, etc., which is a direct operation substituted for an indefinitely ambiguous inverse operation.“
Ich entgegne:
Würden wir denn überhaupt auf den Hauptwert des Logarithmus gekommen sein, wenn wir nicht die Umkehrungen der Potenzirungsaufgabe studirt hätten?
(Vielleicht doch, aber erst in der Integralrechnung!) Und hat nicht das so fundamentale Problem der Auflösung von algebraischen Gleichungen weiter nichts zum Vorwurfe, als die Umkehrung, Inversion der (allerdings sehr zusammengesetzten) „Operation“, als welche die Bildung, Herstellung einer „ganzen“ Funktion sich darstellt?
Überdies scheint die Äusserung innerlich im Widerspruche zu stehn mit einer andern implicite das Auflösungsproblem betreffenden und sehr entschiedenen Stellungnahme desselben Autors — vergl. § 12, S. 175. Darin nun dürfte Herr Peirce völlig Recht haben — und vielleicht zielte er hauptsächlich darauf ab: dass es sich schwerlich empfiehlt, die Bildung solch vieldeutigen Ausdrucks, wie unsres f(a, b, u), etwa als Knüpfungsergebniss mit [Formel] zu bezeichnen und die Knüpfung den elementaren Spezies zuzugesellen.
Wol aber muss ihre Beschaffenheit ermittelt und studirt werden. —
Demnach will ich nun den Plan verfolgen: zuerst die allgemeine Lösung unsres allgemeinen Problems x; b = a, sowie solcher Aufgaben, die damit auf’s nächste zusammenhängen, schlechthin zu offenbaren; sodann unter Aufstellung und Beweis der benötigten Sätze die „geoffenbarten Lösungen auf kürzestem Wege zu verifiziren.
Alsdann werden wir Musse haben auch auf die Heuristik, Herleitung der Lösungen einzugehen und den vexatorischen Charakter unsres Problems zu besprechen — Dinge, worüber orientirt zu sein für eine (erst noch zu schaffende!) Methodik unsrer Disziplin wol lehrreich sein muss.
Endlich mögen wir dann noch auf gewisse partikulare (und eventuell selbständig lösbare) Fälle des Problems hierselbst, auf andre später (in § 29) spezieller eingehen.
Es war nach x die Gleichung aufzulösen: x; b = a, wo a = c; b und c = a ɟ b̄̆, also a = (a ɟ b̄̆); b.
Die Gleichung zerfällt in die beiden Subsumtionen: x; b ⋹ a und a ⋹ x; b.
Von diesen ist nach dem ersten Inversionstheoreme 4) des § 17 die erstere äquivalent mit x⋹a ɟ b̄̆, das heisst mit: x ⋹ c. Ihr kann in allgemeinster Weise auf das leichteste genügt werden durch den Ansatz: x = cu, wo u noch unbestimmt ist (zudem auch durch x selbst ersetzt werden dürfte), und bleibt dann noch der zweiten Subsumtion in Gestalt der Forderung a ⋹ cu; b durch geeignete Bestimmung von u zu genügen.
Wir gelangen somit zu der Hülfsaufgabe: eine Subsumtion der Form 10) a⋹cx; b nach x allgemein aufzulösen.
Diese Aufgabe erscheint als eine Erweiterung des zweiten Inversionsproblems, in welches sie ja durch die Annahme c = 1 ersichtlich übergeht.
Auf das letztre bereits gelöste Problem ist ihre Lösung überraschenderweise nicht zurückführbar.
Dem Mathematiker wäre es geläufig zu sagen: man brauche blos cx = y zu setzen, aus der Forderung a ⋹ y; b gemäss vorhandenem Schema, 11) des § 18, erst auf die allgemeinste Weise y zu bestimmen, hernach — was nach den Regeln des identischen Kalkuls ein Kinderspiel — die Gleichung cx = y nach x aufzulösen.
Dies scheitert aber daran, dass in unsrer Disziplin ebendiese Gleichung cx = y eine Resultante der Elimination des x involvirt, nämlich die Bedingung: y ⋹ c in sich schliesst.
Zufolge dieser ist der Parameter u (oder v) im Ausdruck der allgemeinen Wurzel y jener Subsumtion a ⋹ y; b nicht mehr willkürlich, sondern muss er eine gewisse Relation — die genannte: y ⋹ c — erfüllen, und diese Forderung erweist sich auf den ersten Blick als erheblich verwickelter als wie die ursprüngliche Aufgabe.
Der Versuch, ihr selber oder nach und nach ihren Teilforderungen zu genügen, führt allemal zu einem Zirkel.
Es musste also eine selbständige Lösung des Problems gefunden werden.
Die Lösung ist gegeben durch das Gespann (zum „erweiterten zweiten“ Inversionsprobleme): 11) [Formel] wobei durch die unter den Term b̆ gesetzte 1 resp. 0 eine zweite sonst völlig gleichlautende Lösungsform mitangeführt ist, in der nur jener Term durch diese 1 etc. ersetzt zu denken.
Diese „untere“ Lösungsform 11) ist jedoch die minder gute.
Beweis — zum ersten Satze 11).
Aus xc; b ⋹ c; b folgt zunächst die angegebne Resultante und erweist sich durch die Wurzel x = 1 als die volle.
Ferner stimmt die Probe 2, indem für a ⋹ xc; b ja a{x̄ + c̄) ɟ b̄} = 0 wird.
Sobald aber die Resultante a ⋹ c; b erfüllt ist, hat man a = a · c; b und verlangt die Probe 1, dass a · c; b ⋹ uc; b + [a{(ū + c̄) ɟ b̄}; b̆]c; b als allgemein gültige Formel nachgewiesen werde — desgleichen für das durch 1 ersetzte b̆.
Nennt man uc; b = d, so ist sogar a · c; b ⋹ d + (ad̄; b̆)c; b ⋹ d + (ad̄; 1)c; b als bedingungslos für alle a, b, c, d gültig nachweisbar.
Für den letzten Teil könnte durch überschiebendes Multipliziren von c; b ⋹ c; b mit ad̄ ⋹ ad̄; 1 mit Rücksicht auf 5) des § 18 der Beweis selbständig geleistet werden.
Derselbe wird jedoch durch den der vorhergehenden Subsumtion überflüssig gemacht.
Für diese kann zwar mittelst Li j = ai jΣhci hbh j, Ri j = di j + Σh kai kd̄i kbh kci hbh j die Koeffizientenevidenz schon leicht herbeigeführt werden, indem in Ri j mit k = j auch die Glieder vorkommen: di j + ai jd̄i jΣhci hbh j = di j + Li j, denen also Li j in der That eingeordnet ist, q. e. d.
Doch lässt sich selbst dieser einfache Beweis noch weiter vereinfachen mittelst Aufstellung eines an sich interessanten Hülfssatzes: a · c; b ⋹ (a; b̆)c; b, dessen Beweis sich mit ai jΣhci hbh j ⋹ Σh kai kbh kci hbh j aus der Bemerkung erledigt, dass die Glieder linkerhand auch unter denen rechterhand, bei k = j, sämtlich vorkommen.
Nach diesem Hülfssatze müssen wir nun, ad̄ für a sagend, eine Formel haben, welche unmittelbar auf die oben zu beweisende hinausläuft.
Unsre Ausbeute an Sätzen bei vorstehenden Beweisen besteht — wenn wir noch einige Buchstabenvertauschungen vornehmen, auch zu Gespannen ergänzen — vor allem aus den Hülfssätzen“: 12) [Formel] deren konjugirte sich nicht nur vereinigen lassen würden, sondern auch a fortiori enthalten erscheinen in der noch weiter gehenden Behauptung: 13) — deren Beweis (linkerhand) sich daraus ergibt, dass im allgemeinen Koeffizienten: Σh k lci kbh kai hbh jal hcl j des Prädikates bei k = j, l = i sich auch derjenige des Subjektes enthalten zeigt.
a; b · c ⋹ (c; b̆)a; b(ă; c) (c ɟ b̆ + a) ɟ (b + ă ɟ c) ⋹ a ɟ b + c
Natürlich kann man auch dem Prädikate immer wieder den Faktor c beifügen und durch fortgesetzte Anwendung eines der linkseitigen Schemata 12) und 13) immer komplizirtere „Einwickelungen“ erhalten, die immer engere und engere relative Produkte liefern, welchen das identische Produkt a; b · c eingeordnet sein muss. —
Und ferner mag als eine Konsequenz von 12) das Gespann von Sätzen notirt werden: 14) [Formel] durch welches, als das allgemeinere und dennoch einfachere, die Formelgespanne 13) und 14) des § 18 überflüssig gemacht werden.
Es war mir erst kurz vor Thorschluss, als der Beginn des Druckes schon eingeleitet war, gelungen auch das erweiterte zweite Inversionsproblem 11), und die davon abhängigen Aufgaben, zur Lösung zu bringen, sodass — schon der zahlreichen Verweisungen halber — nicht mehr allzu radikal an der Anlage des Manuskripts geändert werden konnte.
Der Leser wolle es mit solchem Umstande entschuldigen, wenn zuweilen ein in dem Buche aufgestellter Satz durch einen später folgenden allgemeineren überholt werden sollte.
Mittelst identischer Erfüllung der Resultante kann man nun die Lösungen 11) des erweiterten zweiten Inversionsproblemes auch schreiben: 15)
Mit dieser Errungenschaft sind nun auch in geschlossener Form die allgemeinen Lösungen gesichert nicht nur für das dritte Inversionsproblem, sondern auch für die zwei nächstliegenden Erweiterungen desselben, die sich ergeben, wenn man in den zwei Subsumtionen x; b ⋹ a und a ⋹ x; b entweder den einen, oder den andern der beiden doppelt vorkommenden Parameter a, b des Problemes einmal durch einen neuen Wert c eines allgemeinen Relativs ersetzt.
Wir gelangen so zu den beiden Problemen 16) und 17), die ein zu einer Doppelsubsumtion zusammenfliessendes Subsumtionsprodukt nach x aufzulösen fordern, und für die ich nunmehr die Lösungen angeben und sogleich begründen will — wobei ich mich aber nur an den ersten Repräsentanten des Gespannes halte.
16) [Formel]
etc. Begründung und Herleitung.
Die Resultante, welche aus der zweiten Subsumtion, der: x; b ⋹ c mit x ⋹ c ɟ b̄̆ und x; b ⋹ (c ɟ b̄̆); b a fortiori folgt, erweist sich dadurch als die volle, dass, wenn sie erfüllt ist, sich x = c ɟ b̄̆ als eine Wurzel zu erkennen gibt, indem sie die erste Subsumtion kraft der Resultante selbst, die zweite kraft des Satzes 7) des § 17: (c ɟ b̄̆); b ⋹ c erfüllt.
Wird nun c ɟ b̄̆ = d genannt, so folgt wie gesagt x ⋹ d oder x = dx pariter aus der zweiten Subsumtion und bleibt allein noch der ersten als der Forderung a ⋹ xd; b zu genügen, d. h. wir finden uns auf die Lösung des erweiterten zweiten Inversionsproblems verwiesen.
Wir können demnach gemäss Schema 11) — blos d oder c ɟ b̄̆ für c setzend — unmittelbar hinschreiben was bewiesen werden sollte. 17) [Formel] etc.
Begründung und Herleitung.
Aus der ersten Subsumtion folgt äquivalent nach dem ersten Inversionstheorem: x ⋹ a ɟ b̄̆, also x; c ⋹ (a ɟ b̄̆); c, und damit a fortiori die angegebene Resultante.
Ist diese erfüllt, so genügt aber x = a ɟ b̄̆ den beiden Subsumtionen der Aufgabe und zwar der zweiten kraft der Resultante selbst, der ersten kraft 7) des § 17.
Die Resultante ist mithin die volle.
Nennt man jetzt a ɟ b̄̆ = d, so gibt die erste Subsumtion äquivalent den Schluss x ⋹ d oder x = xd, und bleibt darnach blos noch die zweite als a ⋹ xd; c zu erfüllen, was das erweiterte zweite Inversionsproblem ist und durch 11) gelehrt wird, q. e. d.
Wird in 16) c = a, oder auch in 17) c = b gesetzt, so ergibt sich (übereinstimmend) die gesuchte Lösung unsres dritten Inversionsproblemes: 18) [Formel] .
Erfüllt man noch die Resultante identisch, indem man a; b für a sagt beim ersten Probleme, so lautet das Gespann der die Lösung angebenden Sätze: 19) [Formel] .
Um beim ersten Probleme für gegebne Relative a, b und ein beliebig angenommenes u die Wurzel x zu „berechnen“, muss man hienach zuerst (ā ɟ b̄); b̆ herstellen, dasselbe zu ū identisch addiren, zur Summe relativ b̄ (nach-)addiren, das Ergebniss mit a; b zum Schnitt bringen, dies Resultat mit b̆ (oder 1) relativ nachmultipliziren, das neue Ergebniss mit u in identischer Addition zusammenschlagen und die Summe mit a; b ɟ b̄̆, dem Negate des zuerst hergestellten Relativs, identisch multipliziren, schneiden.
Es ist förderlich, hiemit die beiden Proben zu machen.
Behufs Probe 2 muss unter der Annahme, dass x; b = a; b sei, die Lösung sich für u = x bewahrheiten.
Wegen x; b ⋹ a; b, x ⋹ a; b ɟ b̄̆ ist dann aber x · (ā ɟ b̄); b̆ = 0 und folglich x̄ + (ā ɟ b̄); b̆ = x̄.
Wegen a; b ⋹ x; b ist ferner (a; b)(x̄ ɟ b̄) = 0 und bleibt x = (a; b ɟ b̄̆)x, was ersichtlich gilt.
Behufs Probe 1 sieht man — unter x den Ausdruck der allgemeinen Wurzel mit beliebigem u verstanden — sofort dass x; b ⋹ (a; b ɟ b̄̆); b, also x; b ⋹ a; b sein wird — nach 5) des § 6, weil a; b ɟ b̄̆ ein Faktor von x ist, und wegen 3).
Um nachzuweisen, dass aber auch umgekehrt a; b ⋹ x; b ist, bilde man unter Ausmultipliziren der viereckigen Klammer [] dieses x; b und nenne das erste Glied davon (a; b ɟ b̄̆) u; b = c.
Dann lässt sich auch das andre Glied, in dem c̄ vorkommt, sehr viel einfacher schreiben und entsteht: x; b = c + (a; b ɟ b̄̆){(a; b)c̄; b̆}; b. Dass diesem a; b eingeordnet sei, deckt sich mit der Behauptung, dass (a; b)c̄ dem zweiten Gliede eingeordnet.
Nennen wir aber dieses (a; b)c̄ = d, so ist d = (a; b)d und zu zeigen dass d ⋹ (a; b ɟ b̄̆)(d; b̆); b sei, was nach dem Schema 12) mit (a; b)d ⋹ (d; b̆)a; b wegen a ⋹ a; b ɟ b̄̆ a fortiori folgt, q. e. d.
Es ist also unser x, oben, der allgemeinste Ausdruck welcher, mit b relativ nachmultiplizirt, a; b liefert.
Drücken wir letzteres durch eine Formel aus, indem wir noch c für u schreiben, so erhalten wir das Gespann von Sätzen: 20) [Formel] , welche die 3) und 9) als ganz partikulare Fälle unter sich begreifen und die „allgemeinen dritten Inversionstheoreme“ genannt werden dürfen.
Es erfordert immerhin noch eine gewisse Kunst, die Sonderfälle in ihrer einfachsten Gestalt aus dem allgemeinen Theorem 20) abzuleiten, welches ja linkerhand 13 Terme aufweist und wobei zur Vereinfachung der Teilausdrücke oder Ausdruckteile der linken Seite oft keine allgemeinen Sätze zur Verfügung zu stehn scheinen.
Dies ist besonders hinsichtlich 9) der Fall, wo sich in der ersten Gleichung bei der Annahme c = a · a; b; b̆ die linke Seite a priori zu c; b vereinfachen muss.
Wir kommen hierauf in § 29 zurück.
Was die erste Gleichung 3) betrifft, so wolle der Studirende den Nachweis versuchen, dass sich dieselbe aus (der ersten) 20) beispielsweise durch eine jede der drei Annahmen c = a; b ɟ b̄̆, c = 1, c = ā ɟ b̄ ɟ b̄̆ ergibt.
Bei solchem Nachweise müssen die aus a; b ⋹ a; b, a ⋹ a; b ɟ b̄̆ fliessenden Formeln:
ā + a; b ɟ b̄̆ = 1, a · (ā ɟ b̄); b̆ = 0, a(a; b ɟ b̄̆) = a, ā + (ā ɟ b̄); b̆ = ā, a + a; b ɟ b̄̆ = a; b ɟ b̄̆, ā · (ā ɟ b̄); b̆ = (ā ɟ b̄); b̆ gelegentlich zwecks Vereinfachung berücksichtigt werden.
Weiter zeigt die Annahme c = 0, sowie die c = a; b; b̆, dass allgemein auch x = (a; b ɟ b̄̆) · a; b; b̆ eine partikulare Lösung oder Wurzel der Gleichung x; b = a; b sein muss, oder dass die Formel gilt: 21) (a; b ɟ b̄̆)(a; b; b̆); b = a; b, etc., u. a. m. Und ähnlich ist das Th. 20) wol überhaupt eine (noch nicht genügend ausgeschöpfte) Fundgrube von schätzbaren Formeln, die gelegentlich doch mindestens zur Vereinfachung von Ausdrücken in unsrer schwierigen Disziplin der relativen Algebra dienlich.
Von den Partikularfällen des dritten Inversionsproblems dürften diejenigen von der häufigsten Anwendung sein, wo b einen der vier Moduln zum Wert hat: b = 1, 0, 1' oder 0' ist.
Es verlohnt, deren Lösungen besonders zusammenzustellen, und zwar — entsprechend 18), 19) — in den zwei Formen: mit erst zu erfüllender sowie mit identisch bereits erfüllter Resultante.
Solche Lösungen lassen sich auch selbständig gewinnen, wie ich sie in der That so, lange vor denen des allgemeinern Problems, aufgestellt hatte.
Die selbständige Herleitung weist nicht nur für die Methodik unsrer Disziplin lehrreiche Momente auf, sondern sie führt auch in dem letzten der vier Fälle, bei b = 0', zu einer neuen Lösungsform 26), die von der durch Partikularisiren (Einsetzen) aus 18), 19) hervorgehenden verschieden ist und als die bessere bezeichnet werden muss, schon weil sie sich aus nur 10 statt 12 Termen aufbaut.
Man findet nämlich als die allgemeine Wurzel der Gleichung x; 0' = a; 0' aus 19) den Ausdruck: 22) x = (a; 0' ɟ 1')[u + (a; 0')({ū + (ā ɟ 1'); 0'} ɟ 1'); 0'] der allgemein anscheinend nicht weiter vereinfachbar.
Dass derselbe dennoch von dem in der ersten Zeile von 26) angegebnen nicht wesentlich verschieden ist, wird sehr wahrscheinlich, wenn man bemerkt, dass für u = 1, 0, a und ā die beiden Werte von x übereinstimmen (wie zeilenrechnerisch zu erhärten), folglich auch sooft u überhaupt ein Zeilenrelativ von a vorstellt.
Ebenso, was minder leicht darzuthun, für u = 1' und 0'.
Im übrigen muss ich die Frage noch offen lassen.
Indem wir sonach für den letzten Fall nur die bessere Lösungsform anführen, so haben wir die 8 Formelgespanne: 23) [Formel] 24) [Formel] [Formel] 25) [Formel] 26) [Formel] — wovon die unchiffrirten, in denen x völlig unbestimmt bleibt resp. völlig bestimmt, gleich a, sich erweist, wol keiner Diskussion benötigen.
Bis exklusive 25) ergeben sich die Formeln auch aus 18), 19) für b = 1, 0, 1' mit Leichtigkeit.
Es wird demnach jetzt für das erste 23) resp. 24) und für das letzte 25) resp. 26) der vier Unterprobleme die Lösung selbständig abzuleiten sein.
Um bei 24) der Gleichung x; 1 = a; 1 zu genügen, muss x so eingerichtet werden, dass alle Zeilen von x; 1 mit den entsprechenden von a; 1 übereinstimmen.
Diese wie jene erhält man aber, indem man die besetzten Zeilen (von a resp. x) in Vollzeilen verwandelt, die Leerzeilen beibehält.
Um der Forderung zu genügen ist daher unerlässlich und hinreichend, dass x einerseits die Leerzeilen von a ebenfalls zu Leerzeilen habe, und dass andrerseits den besetzten Zeilen von a auch besetzte Zeilen von x entsprechen; natürlich dürfen die letzteren aber bei x auch irgendwie anders als wie bei a besetzt sein.
Dies lässt sich nun leicht erwirken, indem man das Relativ a; 1 (dem die Leerzeilen von a wie gesagt als Leerzeilen angehören, die besetzten Zeilen von a als Vollzeilen) identisch multiplizirt mit irgend einem Relative y welches nur keine Leerzeile besitzt (mithin das Konverse einer „nie undeutigen Abbildung“ vorstellt), für welches also y; 1 = 1 oder 1 ⋹ y; 1 ist.
Als Ausdruck eines solchen hatten wir aber in 14) des § 16 gefunden: y = ū ɟ 0 + u für ein willkürliches u, vergl auch 25) § 18.
Folglich muss x = a; 1 · (ū ɟ 0 + u) die gesuchte allgemeine Wurzel sein, q. e. d.
Ungeachtet der Evidenz dieser Herleitung führen wir beide Proben aus.
Probe 1:
Es ist (a; 1)(ū ɟ 0 + u); 1 = a; 1 · (ū ɟ 0 + u); 1 = a; 1 · {(ū ɟ 0); 1 + u; 1} = = a; 1 · (ū ɟ 0 + u; 1) = a; 1 · 1 = a; 1, q. e. d.
Probe 2. Ist x; 1 = a; 1, so muss x = a; 1 · (x̄ ɟ 0 + x) als richtig nachgewiesen werden, d. h. x = x; 1 · (x̄ ɟ 0 + x) = x; 1 · x, was durch x ⋹ x; 1 garantirt erscheint, q. e. d.
Hiernach — aus 24) — versteht sich auch 23) von selbst, zumal über die Resultante kein Wort mehr zu verlieren ist.
Um bei 26) der Gleichung x; 0' = a; 0' zu genügen, könnte man die zur Lösung führende Diskussion auch bequem an die von den Koeffizienten zu erfüllende Forderung anknüpfen, wonach etwa für eine bestimmte, mit i markirte Zeile bewirkt werden muss, dass für jedes j werde Σhxi h0'h j = Σhai h0'h j, d. h. xi A + xi B + ‥ (ohne xi j) = ai A + ai B + ‥ (ohne ai j).
Indessen, wenn man bedenkt, dass um a; 0' zu bilden man die mehrbesetzten Zeilen von a in Vollzeilen, die einbesetzten Zeilen von a in ihre Negation (also in einlückige Zeilen) zu verwandeln und die Leerzeilen von a zu belassen hat — analog bei x um x; 0' zu bilden — so kann man auch ohne weiteres an den Relativen selbst einsehen, dass entsprechen müssen:
den Leerzeilen von a auch Leerzeilen bei x,
den mehrbesetzten Zeilen von a auch mehrzählig (aber vielleicht irgendwie anders) besetzte Zeilen von x,
den einbesetzten Zeilen von a dagegen auch genau in gleicher Weise, kongruent damit, einaugig besetzte Zeilen von x — sowie dass diese Bedingungen auch hinreichende sein werden.
Darnach muss x sich additiv aus zwei Teilen zusammensetzen (welche unter a; 1 enthalten sein werden), nämlich aus dem mit a selbst multiplizirten Relativ ā ɟ 1', d. h. zum einen Teile aus dem (ā ɟ 1)a, welches bekanntlich (§ 15) die einbesetzten Zeilen von a aus diesem Relative ausschliesslich hervorhebt.
Und zum andern Teile aus dem Relative a; 0' ɟ 0 welches blos die mehrbesetzten Zeilen von a in Vollzeilen verwandelt, dieses aber multiplizirt mit irgend einem (dem allgemeinsten) Relative y, welches nur mehrbesetzte Zeilen aufweist.
Ein solches ergibt sich nach den ersten und zweiten Inversionstheoremen systematisch als die Auflösung der Subsumtion: 27) [Formel] — oder auch, weil das Problem ein reines „Zeilenproblem“ ist, nach den Methoden des § 16 — vergl. 15) S. 229.
Damit ist dann die erste Formel von 26) gefunden.
Auch mit dieser seien die beiden Proben gemacht.
Probe 1 kann in zwei Teile zerlegt werden.
Einmal ist zu zeigen, dass bei beliebigem u: 28) (a; 0' ɟ 0){u + (ū ɟ 1'); 1}; 0' = a; 0' ɟ 0 ist, sodann aber, dass auch: 29) (ā ɟ 1')a; 0' + a; 0' ɟ 0 = a; 0'.
Alsdann wird in der That — unter x den fraglichen Ausdruck der Wurzel verstanden — x; 0' = a; 0' erwiesen sein.
Jenes — der Beweis von 28) — kommt nach dem ersten Schema 25) des § 18 wegen 1; 0' = 1 auf u; 0' + (ū ɟ 1'); 1 = 1 d. h. auf den Satz 9) des § 15: v + v̄; 1 = 1 hinaus.
Dieses — der Beweis von 29) — würde unmittelbar in den Koeffizienten nur umständlich zu leisten sein; die Formel ist aber als ein „reines Zeilentheorem“ in fünfziffrigem Rechnen ganz leicht zu verifiziren.
Sie ist Repräsentant eines beachtenswerten Viergespanns von Sätzen.
Am bequemsten ist überhaupt der Nachweis für die Richtigkeit der gefundnen Lösung 26) oder die Probe 1 ganz in der „schematischen“ Darstellung der Zeilenrelative zu leisten wie folgt.
Sei a = 1αβγ0, so ist a; 0' = 111γ̄0 und zu zeigen, dass für ein ganz beliebiges u = 1'α'β'γ'0' auch — unter x die angebliche Wurzel verstanden — x; 0' = a; 0' sein muss.
Die Ziffern von u mussten hier durch Accente von denen des a unterschieden werden, weil sie (trotz der bei den Voll- oder Leerzeilen sicher gleichartigen Besetzung) ganz andre Zeilenkomplexe repräsentiren mögen.
Wir haben nun: ā = 0ᾱβ̄γ̄1, ā ɟ 1' = 000γ1, (ā ɟ 1')a = 000γ0, a; 0' ɟ 0 = 11100, ū = 0'α'̄β'̄γ'̄1', ū ɟ 0' = 0'0'0'γ'1', (ū ɟ 1'); 1 = 0'0'0'1'1', y = u + (ū ɟ 0'); 1 = 1'α'β'1'1', z = (a; 0' ɟ 0)y = 1''α''β''00.
Die drei ersten Ziffern von y mussten hier in z mit noch einem weitern Accente versehen werden, um darauf hinzuweisen, dass nicht der volle Bestand der Zeilenkategorien 1', α', β' von y für z erhalten bleibt, sondern nur soviel davon als unter die mehrbesetzten Zeilen 1αβ von a, d. h. in die 111 des a; 0' ɟ 0 hineinfällt; diese aber konserviren sich als mehrbesetzte Zeilen für z sämtlich, weil y nur mehrbesetzte Zeilen hat.
Nun ist also x = (ā ɟ 1')a + z = 1''α''β''γ0, wo die drei ersten Ziffern, wenn sie auch nicht Zeilenkomplexe repräsentiren, welche denen 1αβ von a einzeln entsprechen, doch zusammen dasselbe Zeilensystem erfüllen, wie diese.
Es folgt sodann: x; 0' = 1''1''1''γ̄0 = 111γ̄0 mit Rücksicht auf das soeben Gesagte, mithin x; 0' = a; 0' wie zu zeigen gewesen.
Die Probe 2 besteht in dem Nachweise, dass die gefundene Lösung 26) jede Wurzel x der Gleichung x; 0' = a; 0' zu liefern fähig ist, und zwar, dass sie eine bestimmte x bei der Annahme u = x selber liefert.
Aufgrund der von x als erfüllt vorausgesetzten Gleichung ist also zu zeigen, dass x = (ā ɟ 1')a + (a; 0' ɟ 0){(x̄ ɟ 1'); 1 + x} = (x̄ ɟ 1')a + (x; 0' ɟ 0){(x̄ ɟ 1'); 1 + x} das heisst: x = (x̄ ɟ 1')a + (x; 0' ɟ 0)x sein muss.
Dies geht am bequemsten schematisch.
Sollte für a = 1αβγ0 überhaupt x; 0' = a; 0' sein, so musste x die Form haben: x = 1'α'β'γ0, wo die Zeilenkategorien γ, 0 von x mit denen γ, 0 von a bezüglich identisch sind, dagegen von den Zeilenkategorien 1'α'β' des x nur erforderlich ist, dass sie zusammen dieselben Zeilen erfüllen wie die 1αβ von a.
Nun wird: x; 0' ɟ 0 = 1'1'1'00 = 11100, x̄ ɟ 1' = 000γ1 = 0'0'0'γ1 also in der That: (x̄ ɟ 1')a + (x; 0' ɟ 0)x = 0'0'0'γ0 + 1'α'β'00 = 1'α'β'γ0 = x, q. e. d. Stellt x = f(u) die allgemeine Wurzel vor, so haben wir also sicher auch die Adventivforderung erfüllt: (x; 0' = a; 0') = {f(x) = x}.
Nunmehr ist noch die erste Gleichung 25) zu rechtfertigen.
Man erhält die in ihr angeführte Resultante nach dem allgemeinen Schema 2).
Mit Rücksicht auf diese lässt sich die aufzulösende Gleichung schreiben: x; 0' = (a ɟ 1'); 0', woraus erhellt, dass man den Ausdruck für die allgemeine Wurzel bekommen wird, indem man in dem der ersten Gleichung 26) das a durch a ɟ 1' ersetzt.
So ergibt sich zunächst: x = (ā; 0' ɟ 1')(a ɟ 1') + {(a ɟ 1'); 0' ɟ 0}y, wenn wir für den letzten nur u enthaltenden Faktor die Abkürzung y wie in 27) benutzen.
Nun ist in fünfziffrigem Zeilenschema leicht nachzurechnen, dass für jedes a als Formeln gelten: (ā; 0' ɟ 1')(a ɟ 1') = (a ɟ 1')ā, (a ɟ 1'); 0' ɟ 0 = a ɟ 0, wovon wir letzteres schon unter 21) des § 15 gebucht haben.
Folglich entsteht: x = (a ɟ 1')ā + (a ɟ 0)y wie in 25) angegeben. —
Eine Formel für die allgemeine Wurzel x der Gleichung x; b = a; b, welche wenigstens für b = 1, 0, 1', 0' gültig unsre einschlägigen Ergebnisse 24) bis 26) empirisch zusammenfasst, würde sein: x = (ā ɟ b̄); b̆; b · a + (a; b ɟ b̄̆ ɟ b̄){(ū ɟ b̄); b̆; b + u} — wie im letzten Falle aufgrund des zeilenrechnerisch zu erhärtenden (ā ɟ 1'); 1 · a = (ā ɟ 1')a zu sehn ist.
Allgemein aber bewahrheitet sich diese Formel keineswegs!
Letztres erkennt man am schnellsten etwa so, dass andernfalles auch für u = 1 sicher sein müsste: (a; b ɟ b̄̆ ɟ b̄); b ⋹ a; b, das heisst: a; b ɟ b̄̆ ɟ b̄ ⋹ a; b ɟ b̄̆, ganz allgemein.
Nimmt man aber [Formel] und b = ā an, so lässt sich letztres widerlegen, indem als Subjekt:
[Formel] , als Prädikat:
[Formel] erscheint. —
Obwol es nach alledem nicht ausgeschlossen erscheint, dass auch für das allgemeine dritte Inversionsproblem noch bessere Lösungsformen als die von uns gegebne allgemeine Lösung möglich sind — vielleicht auch nur für umfassendere Klassen von Partikularfällen desselben — dürfte es nicht ganz leicht sein, solchen auf die Spur zu kommen.
Wie wir sahen lief die Lösung des dritten Inversionsproblems (und von dessen Erweiterungen) hinaus auf das „erweiterte zweite“.
Ich glaube nun schuldig zu sein anzugeben auf welche Weise mir die Lösung 11) des letzteren zu finden gelang, da eine blos kundgegebene und verifizirte Lösung das Erkenntnisstreben sicherlich nicht befriedigt:
Obwol ein günstiger Zufall mitwirkte, ist in meiner Herleitung doch vielleicht ein Stück Methode zu erblicken woraus sich etwas lernen lässt.
Während die Resultante a ⋹ c; b als erfüllt vorausgesetzt wird, sollte der Forderung a ⋹ xc; b durch geeignete Bestimmung von x auf die allgemeinste Weise genügt werden.
Für 1 ⋹ (Πi)Πj(āi j + Σlci lbl j) ist also die Subsumtion 1 ⋹ (Πi)Πj(āi j + Σlxi lci lbl j) nach den Unbekannten xi l symmetrisch allgemein aufzulösen.
Da diese durchweg nur mit demselben ersten Index i vorkommen, braucht man die Aufgabe nur für ein bestimmtes i zu lösen und das Resultat hernach allgemein (für jedes i) in Anspruch zu nehmen; m. a. W. man kann vorstehend das Πi unterdrücken (worauf wir sogleich durch dessen Einklammerung hinweisen wollten) und die ganze Untersuchung als eine nach i allgemeine — unter der Herrschaft dieses Zeichens, „sub Πi“ — führen.
Für jedes j, wofür āi j = 1 also ai j = 0 ist, haben wir einen ineffektiven Faktor des Πj, wird unsre Forderung nichtssagend und liefert sie keine Bestimmung.
Für jedes j dagegen, wo āi j = 0 also ai j = 1 ist, wird laut Voraussetzung Σlci lbl j = 1 sein und soll auch Σlxi lci lbl j = 1 werden.
Das heisst: dann ist nach den xi l die Gleichung aufzulösen: Σlxi lci lbl j = Σlci lbl j.
Dies geschieht nach dem unter Aufgabe 20 in § 51 des Bd. 2 hervorgehobnen partikularen Falle mittelst des Ansatzes: xi l = ui l + Πk(ūi k + c̄i k + b̄k j)Σhci hbh j, was = Uj zur Abkürzung ad hoc genannt werde.
Hienach muss für jedes j, wofür ai j = 1 ist, sein: xi l = Uj allgemein für alle i und l, oder also es muss werden: sub ΠiΠl) 1 ⋹ Πj{āi j + ai j(xi l = Uj)}.
Letztres schreibt sich leicht um in: Σj(xi lai jŪj + x̄i lai jUj) = 0 und gibt nach bekannten Auflösungsmethoden des identischen Kalkuls: sub ΠiΠlΠj) ai jUj⋹xi l⋹āi j + Uj, oder sub ΠiΠl) Σjai jUj⋹xi l⋹Πj(āi j + Uj).
Dies involvirt die Resultante: Σjai jUj⋹Πj(āi j + Uj) und würde darnach, sobald diese erfüllt ist, sich leicht berechnen: xi l = Σjai jUj + ui lΠj(āi j + Uj).
Sucht man nun vorab der Resultante durch geeignete Bestimmung der ui l zu genügen, so verwickelt das in viel schwierigere Aufgaben oder Zirkel und bleibt alles vergebens.
Evaluirt man dagegen, unbekümmert um die Resultante, das Subjekt und Prädikat unsres xi l, so findet man mit einiger Rechnung: Σjai jUj = [u · a; 1 + a(c; b){(ū + c̄) ɟ b̄}; 1]i l, Πj(āi j + Uj) = (u + [ā + {(ū + c̄) ɟ b̄}(c; b)] ɟ 0)i l, wonach sich durch Einsetzung in die letzte Formel mittelst Durchgangs durch den allgemeinen Koeffizienten xi l ergibt: x = u + a(c; b){(ū + c̄) ɟ b̄}; 1 — worin a(c; b) auch einfacher durch a ersetzbar.
Dies ist aber die „untere“ Lösung 11), und muss es als glücklicher Zufall gepriesen werden, dass mit der so gefundenen die Probe 1 stimmt.
Die Ersetzbarkeit der 1 durch b̆ liess mich schliesslich die Analogie mit dem beim spezielleren Probleme schon in § 18 Erkannten vermuten — welche Analogie auch schon bequemer zur Entdeckung (mittelst Ratens) der Lösung mich hätte führen können, wenn ich nicht so systematisch zuwerke gegangen wäre.
Zum Schlusse will ich mich der Methodik zuliebe über den „vexatorischen Charakter“ unsres dritten Inversionsproblems noch weiterhin äussern.
Wir hatten das Problem x; b = a, wo a = c; b und c = a ɟ b̄̆, zurückgeführt auf die Erfüllung der beiden Subsumtionen: 30) x⋹c und c; b ⋹ x; b, und es schliesslich zur Lösung gebracht, indem wir zuerst die erste, sodann die zweite Forderung erfüllten.
Man kann es auch mit der umgekehrten Reihenfolge versuchen.
Der zweiten Forderung genügt nach 10) des § 18 auf die allgemeinste Weise identisch: x = u + (c; b)(ū ɟ b̄); b̆.
Soll dies auch der ersten Forderung genügen, so muss sein [Formel]
Letztre Forderung erfüllt: u = v + (c; b · c̄; b)(v̄ ɟ b̄); b̆.
Soll dies aber dem Rückstand aus der ersten Forderung genügen, so muss [Formel] sein.
Letztres thut wieder: v = w + (c; b · c̄; b)(w̄ ɟ b̄); b̆.
Soll dies aber auch dem Reste (v ⋹ c) aus der ersten Forderung genügen, so muss [Formel] sein und so fort in infinitum.
Nennt man 31) (c; b · c̄; b)(ȳ ɟ b̄); b̆ = f(y) und y + f(y) = F(y), so hatten wir gefunden: u = F(v), v = F(w), … in inf., und wenn wir rückwärts einsetzend das letzte unbestimmte Relativ ω nennen, so ist gefunden, dass jedenfalls u = F∞(ω) sein muss, woferne die successiven Residuen der ersten Forderung erfüllt sein sollen.
Die so erfüllten erschöpfen aber die erste Forderung noch nicht und bleibt davon immer noch diese ω ⋹ c rückständig, welcher „endlich“ durch den Ansatz ω = uc zu genügen ist — für ein neues u.
Genauer: das verbleibende; im strengen Sinne ein „letztes“ gibt es nicht.
Hiernach schiene denn 32) x = F∞(uc) + (c; b){F∞(uc)͞ ɟ b̄}; b̆ die gesuchte Lösung zu sein.
Die unbegrenzten Iterationen der Funktion F, welche in diesem Ausdruck vorkommen, sind im Hinblick auf die Form 31)
(zweite Gleichung) dieser Funktion nach den Ergebnissen des § 13, S. 182 sicher konvergent.
Der Ausdruck 32) muss auch alle überhaupt möglichen Lösungen unsres Problems 30) umfassen, und in der That stimmt mit ihm die Probe 2.
Stellt nämlich x irgend eine Wurzel der Aufgabe vor, für die also die Voraussetzungen 30) von vornherein zutreffen, und nimmt man u = x, so bewahrheitet sich die Gleichung 32) wie folgt.
Wegen 30) ist: uc = xc = x und (c; b)(x̄ ɟ b̄) = 0, also f(uc) = f(x) = 0; b̆ = 0 und F(uc) = F(x) = x selbst, mithin auch nach § 13, S. 188sq.: F∞(uc) = F∞(x) = x.
Damit verschwindet das letzte Glied in 32) und läuft diese Gleichung auf die Identität x = x hinaus, q. e. d.
Ist so die „fragliche“ Lösung 32) einerseits in der That ohne Zweifel vollständig, so ist sie andrerseits — wie wir demnächst genauer nachweisen — doch nicht ausschliesslich, d. h. sie liefert im Allgemeinen nicht unbedingt, nicht für jedes u, eine richtige Wurzel. M. a. W. die Formel 32) ist nicht die gesuchte allgemeine Lösung.
Dieser Umstand ist im Hinblick auf den Gedankengang, der zu der Formel führte — bei dem man doch wähnen mochte, sämtliche Anforderungen, die das Problem stellt, erfüllt zu haben! — sehr überraschend.
Derselbe kann nicht verfehlen, zu lehrreichen Untersuchungen (die ich mir hiernächst versagen muss) noch Anlass zu geben, und mahnt solche Erfahrung jedenfalls in unsrer Disziplin zu grosser Behutsamkeit und Vorsicht.
Die Thatsache dokumentirt sich zunächst darin, dass es auf keine Weise gelingen will, mit der fraglichen Lösung auch die „Probe 1“ zu machen: zu zeigen, dass der Ausdruck 32) für x gesetzt nun die Forderung x; b = c; b bei beliebigem u erfülle.
Vielmehr stellt sich bei solchem Versuche heraus, dass u selbst noch eine Relation erfüllen muss, die unendlich viel komplizirter scheint, als es die aufzulösende Gleichung für x gewesen.
Um durch Exemplifikation zu erhärten, dass die Gleichung 32) Gefahr läuft, auch „falsche“ Wurzeln, d. h. noch andre Werte, als wie Wurzeln unsres Problems zu liefern, genügt es bereits, dieselbe für b = 0' in Anspruch zu nehmen.
Zwar für b = 1, 0, 1' zeigt sich leicht, dass f(y) = 0, F(y) = y = F∞(y) wird, die Entwickelung sofort abbricht und in Übereinstimmung mit 23)sqq. die richtige Lösung liefert — im ersten Falle, zu x; 1 = a, allerdings in der neuen Form: x = a{u + (ā + ū) ɟ 0}, die man aber als eine von der 23) nur unwesentlich verschiedene mit Rücksicht auf die Resultante a = a; 1 unschwer auf jene zurückführt.
Dagegen für b = 0' bricht die Entwickelung nicht sofort und im Allgemeinen nicht ab.
Hier muss zuvörderst, soll x; 0' = a = 1αβγ0 auflösbar sein, a = (a ɟ 1'); 0' = 1α000 sein, d. h. a von vornherein der Zeilenkategorien β und γ entraten.
Es wird c = a ɟ 1' = 1ᾱ000 und c; b · c̄; b = 0α000 im Allgemeinen ≠ 0. Nennt man uc = y, c; 0' · c̄; 0' = d, d(ȳ ɟ 1'); 0' = f(y), F(y) = y + f(y) = z, F∞(y) = ω, so ist x = ω + (c; 0')(ω̄ ɟ 1'); 0' zu berechnen.
Mit den Annahmen [Formel] , [Formel] findet man — nach leichter Herstellung der Schemata zu elf Zwischenwerten — [Formel]
Abbrechen thut die unendliche Entwickelung in 32) zum mindesten immer dann, wenn in 31) f(y) = 0 wird, wo wir haben f(y) = y = f∞(y), und folglich aus 32) erhalten: x = uc + (c; b){(ū + c̄) ɟ b̄}; b̆.
Wie, wegen c = a ɟ b̄̆ und c; b = a, Vergleichung mit 18) zeigt, würde dies erst dann die richtige allgemeine Lösung von x; b = a (auch für den Fall des Nichtabbrechens) darstellen, wenn rechts der Faktor c als gemeinsamer Faktor vorträte.
Eine hinreichende Bedingung für das Abbrechen ist das Verschwinden von d = c; b · c̄; b.
[Sagt man a; b für a, um unabhängig beliebige Parameter a, b zu haben, so wird d = a; b · (ā ɟ b̄); b̆; b, und bringt man die Forderung d = 0 leicht auf die Form: a; b; b̆; b ⋹ a; b, welche Subsumtion mit Rücksicht auf 21) des § 18 die Kraft einer Gleichung besitzt.
Sie ist z. B. erfüllt, wenn b; b̆ = 1', oder aber b̆; b = 1', desgleichen wenn a = a; 1 System ist.]
Die vorstehenden Untersuchungen haben uns über die inversen Operationen der beiden relativ knüpfenden Spezies (d. i. wenn man will die „relativen Divisionen“ und „Subtraktionen“) einigermaassen orientirt, auch in den Charakter unsrer Disziplin manchen Einblick gewährt.
Als eine Moral derselben, die sich uns noch öfter aufdrängen wird, ist zu verzeichnen, dass — im Kontraste zur arithmetischen Analysis — mit der Lösung aller Teilaufgaben oder Unterprobleme einer zusammengesetzten Aufgabe die Lösung der letzteren in unsrer Disziplin noch keineswegs gewährleistet ist.
So wäre es auch sehr voreilig, zu glauben, dass man nunmehr auch für jede „reine Subsumtion oder Gleichung d. h. für jede Aufgabe, in der der Name der Unbekannten blos einmal figurirt, die allgemeine Wurzel müsse hinschreiben können (indem man durch von aussen nach innen fortschreitende Ablösung aller andern mit x verknüpften Terme diese Unbekannte allmälig isolirte).
Sogar das so einfache Auflösungsproblem x; b = a selbst ist wol noch nicht genügend erforscht.
Eine Menge Fragen drängen sich noch auf, wie z. B. (dessen „Determination“ betreffend) die: wann die Wurzel eindeutig bestimmt, also x konstant, unabhängig von u, sein werde?, u. a. m. Wir werden deshalb noch ein paarmal auf das Problem zurückzukommen haben. —
§ 20. Vorübergehend „Transoperationen“ genannte Knüpfungen und deren Inversionsprobleme. Quaderrelative.
Eine wichtige aber schwere Frage ist die nach der Vollständigkeit unsrer Algebra der binären Relative, nämlich die Frage: ob diese Disziplin mit ihren sechs Spezies für alle Zwecke der reinen und angewandten Theorie (insbesondre auch der Logik binärer Relativbegriffe) notwendig ausreicht?
Wir hoffen dieser Frage später noch näher zu treten, uns hier begnügend, mit einer kleinen Episode zu derselben zunächst einmal blos ein Scherflein beizusteuern.
Beim ersten Blick auf die Definitionen (12) S. 29 der beiden relativen Knüpfungen vermittelst des allgemeinen Koeffizienten ihres Erzeugnisses nimmt man wahr, dass sich durch blosse Vertauschung der Zeichen Σ und Π in ihnen zwei neue und eigenartige Knüpfungsweisen ergeben müssen.
Hätte man nicht vielleicht nötig gehabt, auch diese beiden — sagen wir (vorübergehend): als zwei „Transoperationen — nämlich als eine zu definiren mittelst der Festsetzung: 1) und somit noch die Ausdrücke: unsrer Theorie als Erzeugniss zweier weitern „Spezies“ einzuverleiben?
„Transmultiplikation „Transaddition“
In 5 p. 52 gebraucht Peirce diesen Namen in einem ganz andern, mit Recht von ihm wieder fallen gelassenen Sinne.
(a ⌢ b)i j = Πhai hbh j (a ⌣ b)i j = Σh(ai h + bh j)
a ⌢ b sprich a „ab“ b a ⌣ b sprich a „auf“ b
Diese spezielle Frage wenigstens ist zu verneinen.
Nach bekannten Festsetzungen und Schemata des Aussagenkalkuls kann man nämlich zerlegen und wieder vereinigen: woraus hervorgeht, dass die Relative 2) als durch die bisherigen 6 Spezies schon hinreichend einfach ausdrückbare, zu ihrer Darstellung aparte Knüpfungszeichen in der That nicht erfordern.
Vielmehr ist ad notam zu nehmen, dass: 3)
(a ⌢ b)i j = Πhai hΠhbh j = (a ⌣ b)i j = Σhai h + Σhbh j = = Πh(ai h + 0h j)Πh(0i h + bh j) = = Σhai h1h j + Σh1i hbh j = = (a ɟ 0)i j(0 ɟ b)i j = = (a; 1)i j + (1; b)i j = = {a ɟ 0)(0 ɟ b)}i j = (a; 1 + 1; b)i j
a ⌢ b = (a ɟ 0)(0 ɟ b) a ⌣ b = a; 1 + 1; b
Πhai hbh j = {(a ɟ 0)(0 ɟ b)}i j Σh(ai h + bh j) = (a; 1 + 1; b)i j.
Wir wollen gleichwol die obigen Knüpfungszeichen (dieselben nebenbei, mit denen Peano die identischen Knüpfungen darstellt) noch eine kurze Weile provisorisch beibehalten, weil sich mit ihnen gewisse Eigenschaften unsrer Trans-Knüpfungen besonders übersichtlich ausdrücken lassen.
Man wolle übrigens absehen von der zufälligen Übereinstimmung oder Ähnlichkeit des Transadditionszeichens ⌣ mit dem als Hyphen (Bindestrich) übergesetzten Konversionszeichen: um diesen unbeabsichtigten Einklang zu vermeiden hätten wir statt der runden etwa spitze Zeichen ⋀, ⋁ wählen können; indessen sind die andern schön vorrätig gewesen.
Es gelten natürlich die Analoga zu De Morgan’s Theoremen: sodass sich mittelst der Negation die eine Transoperation auch auf die andre zurückführen liesse.
a ⌢ b͞ = ā ⌣ b̄ a ⌣ b͞ = ā ⌢ b̄
Zudem sind die beiden Trans-Knüpfungen aber auch assoziativ.
Es ist indem die beiderseitigen Koeffizienten übereinstimmend hinauslaufen auf:
Dies gibt in unsre gewöhnliche Zeichensprache übertragen die bemerkenswerten Formeln: 4)
[Formel] welche auch leicht mittelbar zu rechtfertigen — z. B. rechts vom Mittelstriche durch relatives Ausmultipliziren mit Rücksicht auf 1; 1 = 1.
a ⌢ (b ⌢ c) = (a ⌢ b) ⌢ c = a ⌢ b ⌢ c a ⌣ (b ⌣ c) = (a ⌣ b) ⌣ c = a ⌣ b ⌣ c
Πh kai hbh kck j Σh k(ai h + bh k + ck j).
Ähnlich haben wir als das Knüpfungsergebniss von vier in bestimmter Ordnung genommenen Relativen: a ⌢ b ⌢ c ⌢ d = (a ɟ 0)(0 ɟ b ɟ 0)(0 ɟ c ɟ 0)(0 ɟ d)| |a ⌣ b ⌣ c ⌣ d = a; 1 + 1; b; 1 + 1; c; 1 + 1; d woraus nun das allgemeine Bildungsgesetz auch für beliebig viele Terme einleuchtet.
Bei mehrern Termen sind die Ergebnisse der Transoperationen symmetrisch (oder „kommutativ“) inbezug auf alle zwischenliegenden, intermediären oder eingeschlossenen Terme und nur die beiden äussersten, extremen oder Rand-Terme gehn auf eigne Weise in sie ein.
Im Gegensatz zu den identischen und den relativen haben die beiden Transoperationen keine Moduln.
Z. B. es ist ein Relativ x derart, dass für ein beliebiges oder allgemeines a stets x ⌣ a = a wäre, nicht möglich.
Denn für dieses müsste Σh(xi h + ah j) = ai j sein, sonach bei ai j = 0 müsste sowol xi h = 0 als ah j = 0 für jedes h sein, welch letzteres einen Widerspruch mit der für h ≠ i zuzulassenden Möglichkeit eines ah j ≠ 0 vorstellt.
Was aber die Transknüpfungen zwischen einem allgemeinen Relativ a und einem der vier sonstigen Moduln betrifft, so überzeugt man sich leicht aus dem Abacus, dass 0 = 0 ⌢ a = a ⌢ 0 = 0' ⌢ a = a ⌢ 0' = 1' ⌢ a = a ⌢ 1'| |1 = 1 ⌣ a = a ⌣ 1 = 1' ⌣ a = a ⌣ 1' = 0' ⌣ a = a ⌣ 0', ist.
Die fraglichen Modulknüpfungen sind also zumeist reduzibel und kommen, soweit sie es nicht sind, auf schon anderweitig diskutirte relative Knüpfungen hinaus.
1 ⌢ a = 0 ɟ a 0 ⌣ a = 1; a a ⌢ 1 = a ɟ 0 a ⌣ 0 = a; 1
So viel über den Formalismus, die formalen Gesetze unsrer Transoperationen — von dessen Erledigung ab wir auch von den provisorischen Knüpfungszeichen keinen Gebrauch mehr machen wollen.
Leicht zu durchschauen ist die Konstitution, Struktur oder Bildungsweise der beiden Relative (a ɟ 0)(0 ɟ b) und a; 1 + 1; b die unsre Beachtung auf sich gezogen haben.
Das erstre Relativ ist der Schnitt der Vollzeilen von a mit den Vollkolonnen von b, hat Augen nur an den Gitterpunkten der Matrix, wo jene mit diesen zusammentreffen.
Keine zwei „zu einander schief stehende“ (d. h. weder in derselben Horizontal- noch in derselben Vertikalflucht liegende) Augen können dem Relative c = (a ɟ 0)(0 ɟ b) angehören, ohne dass ihm auch die beiden andern Augen angehörten, welche mit jenen zusammen die Ecken eines Reihenrechtecks bilden, m. a. W. es ist für alle i, j, h, k: (ci j = 1)(ch k = 1) = (ci k = 1)(ch j = 1) oder die Augen unsres Relativs c stehen durchgängig sozusagen „in Quadern“.
Beweis.
Ist Πlai lbl j = 1 und Πlah lbl k = 1, so muss auch Πlai lbl k = 1 und Πlah lbl j = 1 sein, weil die vorkommenden vier Reihen von Koeffizienten der a, b sämtlich selber = 1 sein werden.
Bei dem zweiten Relativ d = a; 1 + 1; b verhält es sich geradeso mit den Leerstellen oder Lücken, stehn ebendiese in Quadern und ist:
(di j = 0)(dh k = 0) = (di k = 0)(dh j = 0).
Die Matrix von d setzt sich zusammen aus einem System von Vollzeilen verbunden mit einem System von Vollkolonnen, und zwar entspringen die Vollzeilen von d aus den besetzten Zeilen von a, die Vollkolonnen von d aus den besetzten Kolonnen von b.
Es lässt sich zeigen, dass die vorstehend betonten Eigenschaften: 5) charakteristisch für Relative von der Entstehungsweise unsres c und d sind.
Πi j h k(ci jch k = ci kch j) Πi j h k(d̄i jd̄h k = d̄i kd̄h j) oder: Πi j h k(di j + dh k = di k + dh j)
Dies braucht blos für b gezeigt zu werden, weil d sich offenbar als Negat eines für ā, b̄ gebildeten c ansehen lässt.
Gilt nun also für ein irgendwie gegebnes Relativ c stets:
ci jch k = ci kch j, so muss gezeigt werden, dass c sich als (a ɟ 0)(0 ɟ b) für ein gewisses Paar von Relativen a und b darstellen lässt.
Dies gelingt mit der Annahme a = c; 1, b = 1; c, wo dann nach 16) des § 15: a ɟ 0 = c; 1 ɟ 0 = c; 1, 0 ɟ b = 0 ɟ 1; c = 1; c, somit (a ɟ 0)(0 ɟ b) = c; 1; c, {(a ɟ 0)(0 ɟ b)}i j = Σh kci hck j laut Hypothesis = Σh kci jch k = ci jΣh kch k = ci j sein muss, indem unter den Gliedern der Σh k sich auch ci j selbst befindet.
Somit ist in der That für die genannten Werte von a und b bewiesen, dass c = (a ɟ 0)(0 ɟ b).
Wir wollen demgemäss die provisorisch als Erzeugniss von „Transoperationen“ eingeführten Relative von den Sorten c und d hinfort als Quaderrelative bezeichnen.
Und zwar soll ein Relativ von der Form c = (a ɟ 0)(0 ɟ b) ein Augenquaderrelativ heissen [genauer: das Augenquaderrelativ zu a und b, während das Augenquaderrelativ „zu a und a“, nämlich (a ɟ 0)(0 ɟ a), kürzer blos das Augenquaderrelativ „zu a“ genannt werde].
Desgleichen soll ein Relativ von der Form d = a; 1 + 1; b ein Lückenquaderrelativ heissen (genauer: etc.).
Unter einem Stellenquader verstehn wir dabei ein System von vier solchen Stellen, welche die Ecken eines Reihenrechtecks bilden, in denen also irgend zwei Zeilen mit irgend zwei Kolonnen zusammentreffen.
Grenzfälle des Augenquaderrelativs sind: 0 selbst, ferner ein Relativ, welches blos ein Auge und sonst lauter Leerstellen hat (Einauge), weiter ein solches, das zwei oder mehr in einer (sei es Horizontal- sei es Vertikal-) Flucht stehende Augen und sonst lauter Leerstellen hat.
In diesen Ausartungsfällen sind noch keine eigentlichen Augenquader in dem Relativ zu erblicken.
Analog mit 1, etc. für die Lücken beim Lückenquaderrelativ.
Es scheinen diese Relative qua Quaderrelative schon die Aufmerksamkeit von Peirce2 p. 52 auf sich gezogen zu haben, ohne dass er jedoch Ausdrücke für dieselben gegeben und Sätze über sie publizirt hätte.
Er spricht einmal von Blöcken oder „collections of squares“.
Durch den unter 5) gegebnen Beweis sind folgende Wahrnehmungen nahe gelegt.
Jedes Augenquaderrelativ c lässt sich auch in der Form u; 1; v und sogar in der noch spezielleren w; 1; w, nämlich als c; 1; c selbst, darstellen, und umgekehrt muss jedes Relativ von einer dieser Formen ein Augenquaderrelativ sein und sich auch auf die andern Formen bringen lassen.
Jedes Lückenquaderrelativ d lässt sich in der Form u ɟ 0 ɟ v, ja sogar, als d ɟ 0 ɟ d selbst, in der Form w ɟ 0 ɟ w darstellen, und umgekehrt muss jedes Relativ von einer dieser Formen ein Lückenquaderrelativ sein, etc. — Zunächst gilt in der That: 6)
[Formel]
Dies leuchtet links wie folgt ein.
Nehmen wir von vornherein c = (a ɟ 0)(0 ɟ b) an, so gilt für c nach dem über 5) gegebnen Beweise die Charakteristik 5), und ist aus dieser in dem unter 5) gegebnen Beweise — durch Komparation der zwei letzten isolirt gestellten Gleichungen — der Schluss zu ziehen: c; 1; c = c — q. e. d. Dual entsprechend ist für d = a; 1 + 1; b auch d ɟ 0 ɟ d = d.
Ferner aber muss auch sein — nach 16) des § 15 und 5) des § 11:
7) woraus die Werte erkennbar sind: die man blos den Symbolen u, v im obigen Texte unterzulegen braucht.
(a ɟ 0)(0 ɟ b) = (a ɟ 0); 1; (0 ɟ b) a; 1 + 1; b = a; 1 ɟ 0 ɟ 1; b
u = a ɟ 0, v = 0 ɟ b u = a; 1, v = 1; b
Endlich dürfte noch Beachtung verdienen, dass nach 24) des § 18 man für die linke Seite der linkseitgen Gleichung 6) auch die Darstellung erhält: (a ɟ 0)(0 ɟ b) · (0 ɟ b); 1; (a ɟ 0), womit diese Gleichung auf die Subsumtion hinausläuft: (a ɟ 0)(0 ɟ b) ⋹ (0 ɟ b); 1; (a ɟ 0), die sich aus 0 ɟ b ⋹ (0 ɟ b); 1 und a ɟ 0 ⋹ 1; (a ɟ 0) von selbst versteht — sodass hiemit ein zweiter Beweis für 6) gegeben ist.
Umgekehrt ist nach 5) des § 11 und 16) des § 15:
8) wonach denn ein Relativ der Form a; 1; b zu bezeichnen ist als das Augenquaderrelativ zu a; 1 und 1; b, ein solches der Form a ɟ 0 ɟ b als das Lückenquaderrelativ zu a ɟ 0 und 0 ɟ b.
a; 1; b = (a; 1 ɟ 0)(0 ɟ 1; b) a ɟ 0 ɟ b = (a ɟ 0; 1 + 1; (0 ɟ b)
Wird für den Augenblick das Relativ rechterhand (somit auch das linkerhand) in Gleichung 8) mit c resp. d bezeichnet, so gilt nach 6) c = c; 1; c, d = d ɟ 0 ɟ d, und somit haben wir auch noch den Satz: 9) aus welchem zu ersehen ist in welcher Weise ein Ausdruck der Form a; 1; b gebracht werden kann auf die speziellere Form c; 1; c, indem er nämlich sich darstellen lässt als (a; 1; b); 1; (a; 1; b), etc.
a; 1; b; 1; a; 1; b = a; 1; b a ɟ 0 ɟ b ɟ 0 ɟ a ɟ 0 ɟ b = a ɟ 0 ɟ b
Auch über das Quaderrelativ (der einen oder andern Art) zu zwei (verschiednen oder auch identischen) Quaderrelativen (sei es derselben, sei es der entgegengesetzten Art) lassen sich noch (nicht uninteressante) Sätze aufstellen, die wir dem Studirenden überweisen.
Als beachtenswert dürfte schliesslich zu erwähnen sein, dass zwischen den Ergebnissen unsrer Transoperationen und denen der übrigen knüpfenden Spezies folgende Einordnungen bestehen: 10) [Formel] deren letzte als das Analogon zur ersten bei den Transoperationen erscheint.
Für die relativen knüpfenden Spezies gibt es solche Analoga (zu der obigen Subsumtion zwischen den identischen Knüpfungsergebnissen) nicht.
Von diesen Sätzen folgen die der zweiten und dann auch die der letzten Zeile a fortiori aus den bekannten 8) des § 15 etc.
Die der dritten Zeile sind leicht aus den Koeffizienten zu rechtfertigen, weil das Produkt im Faktor, das Glied in der Summe enthalten ist.
Die der vorletzten Zeile fliessen a fortiori aus a ɟ 0 ⋹ a ɟ b, a; b ⋹ a; 1, etc.
Es ist also das „Transprodukt“ zweier Relative eingeordnet den Ergebnissen aller vier knüpfenden „Spezies“ und von letztern jedes wiederum eingeordnet der „Transsumme“ ebendieser Relative. —
Nunmehr wollen wir auch für die Transoperationen die zwölf elementaren Inversionsprobleme lösen, was besonders bei dem dritten Quadrupel einiges theoretisches Interesse darbietet.
Nach den Aussagenschemata 6) des § 8 müssen wir haben: 11) [Formel]
Nach den Ergebnissen 25) des § 18 lassen sich daher die Lösungen für das erste Quadrupel unsrer Inversionsprobleme unmittelbar hinschreiben als: 12) [Formel] .
Nach bekannten Schemata — den letzten 3) des § 6 — ist ferner: 13) worin der erste Aussagenfaktor jeweils die Resultante der Elimination von x aus der Proposition linkerhand (somit auch die Valenzbedingung für x) vorstellt.
Ersetzt man den zweiten Aussagenfaktor rechts durch seine schon mittelst 10) des § 17 gegebne Auflösung nach x, so hat man auch die Lösungen für das zweite Quadrupel unsrer Inversionsprobleme, welche wirklich hinzuschreiben wir dem Leser überlassen.
{a ⋹ (x ɟ 0)(0 ɟ b)} = (a ⋹ 0 ɟ b)(a ⋹ x ɟ 0) (x; 1 + 1; b ⋹ a) = (1; b ⋹ a)(x; 1 ⋹ a) {a ⋹ (b ɟ 0)(0 ɟ x)} = (a ⋹ b ɟ 0)(a ⋹ 0 ɟ x) (b; 1 + 1; x ⋹ a) = (b; 1 ⋹ a)(1; x ⋹ a)
Somit bleibt nur noch zu erledigen das dritte Gespann unsrer Inversionsprobleme, welches die Auflösung nach x der Gleichung fordert, die in den folgenden Aussagenäquivalenzen als linke Seite auftritt und für die wir sogleich in Gestalt des ersten Aussagenfaktors der rechten Seite die Resultante der Elimination des x und in Gestalt des zweiten Aussagenfaktors rechterhand die allgemeine Wurzel oder Auflösung nach x angeben wollen: 14) [Formel] .
Auch diese Probleme lassen sich hienach elegant in geschlossener Form lösen.
Die Herleitung und Detail-Nachweise wollen wir etwa für die erste Gleichung rechts vom Mittelstriche erbringen.
Die Gleichung zerfällt in zwei Teilsubsumtionen, deren Lösung und eventuell Resultante wir einzeln bereits anzugeben vermögen.
Die eine ist die obere rechts vom Mittelstriche in 11).
Die andre liefert konform 13):
[Formel] . Vergleicht man beide Wurzelausdrücke, so erhellt, dass man nur noch der Gleichung 15) u + a(ū ɟ 0)(0 ɟ b̄) = v(a ɟ 0) durch geeignete denkbar allgemeinste Bestimmung von u und v zu genügen habe.
Ebendies erscheint jedoch als eine nicht ganz leichte Aufgabe.
Wir nehmen dieselbe nachher in Angriff.
Zuvor jedoch wollen wir die Angaben von 14) auf kürzestem Wege verifiziren.
Dabei ist zuerst die Resultante herzuleiten, sodann als die volle nachzuweisen; endlich sind für die Lösung die beiden Proben zu machen.
Vom zweiten Teilproblem her ist klar dass 1; b ⋹ a jedenfalls „eine Resultante sein muss.
Wegen 1; b ⋹ a ɟ 0 + 1; b ist diese in der That durch die oben angegebene mitverbürgt, jedoch ohne sie ihrerseits zu bedingen; sie ist blos eine Unter-Resultante dieser angegebnen, die wir als die volle nachweisen werden.
a⋹x; 1 + 1; b gibt a(0 ɟ b̄) ⋹ x; 1, und x; 1 ⋹ a ist nach dem ersten Inversionstheorem äquivalent mit x ⋹ a ɟ 0, was die Folgerung gestattet: x; 1 ⋹ (a ɟ 0); 1.
Aber nach 16) des § 15 ist (a ɟ 0); 1 = a ɟ 0.
Also haben wir auch x; 1 ⋹ a ɟ 0 und damit a fortiori: a(0 ɟ b̄) ⋹ a ɟ 0, d. h. 16) a⋹a ɟ 0 + 1; b.
Damit ist die behauptete Resultante gewonnen — in Anbetracht dass wegen der Partialresultante 1; b ⋹ a, in Verbindung mit der Formel a ɟ 0 ⋹ a, die umgekehrte Subsumtion ohnehin gelten, das Subsumtionszeichen also hier die Kraft des Gleichheitszeichens erlangen muss.
Die obige Subsumtion aber kann nicht selbst als die volle, sondern blos als eine (die) zweite Unter-Resultante hingestellt werden, welche erst mit der ersten verbunden (multiplizirt) oder zu der Gleichung a = a ɟ 0 + 1; b zusammengezogen die volle Resultante liefert.
Dass letztere vollständig, geht nun leicht daraus hervor, dass, sobald sie erfüllt ist, immer in Gestalt von x = a ɟ 0 eine Wurzel der aufzulösenden Gleichung angebbar sein wird.
Probe 1 für die Wurzel.
Nach Schema 24) des § 18 wird: x; 1 + 1; b = (a ɟ 0) · {u; 1 + (ū ɟ 0) · (0 ɟ b̄); 1} + 1; b = = (a ɟ 0){u; 1 + (0 ɟ b̄); 1}(0 ɟ b̄) + 1; b = (a ɟ 0)(0 ɟ b̄) + 1; b = = a ɟ 0 + 1; b = a, q. e. d.
Denn wegen 0 ɟ b̄ ⋹ (0 ɟ b̄); 1 muss (0 ɟ b̄); 1 · (0 ɟ b̄) = 0 ɟ b̄ sein, wonach denn das zweite Glied in { } durch 1 ersetzbar.
Probe 2. Ist x; 1 + 1; b = a und a = a ɟ 0 + 1; b, so muss auch sein: x = (a ɟ 0){x + (x̄ ɟ 0)(0 ɟ b̄)}.
Denn durch Kontraposition der ersten Voraussetzung folgt: (x̄ ɟ 0)(0 ɟ b̄) = ā und gilt bekanntlich — vergl. 9) des § 15 — (a ɟ 0)ā = 0, also bleibt nur noch x = (a ɟ 0)x oder x ⋹ a ɟ 0 zu erweisen, was wir schon vorhin aus x; 1 ⋹ a gefolgert haben — q. e. d.
Die systematische Herleitung des Ergebnisses in 14) aber bietet folgende Momente.
Man kann aus 15) von den beiden Unbekannten u und v die eine eliminiren und die andre zu bestimmen suchen.
Zur Elimination von v genügen schon die Regeln des identischen Kalkuls, und ergibt sich für u die Bedingung: u + a(ū ɟ 0)(0 ɟ b̄) ⋹ a ɟ 0 welche schneller aus x; 1 ⋹ a oder x ⋹ a ɟ 0 zu erlangen, da die linke Seite den der einen Teilsubsumtion der aufzulösenden Gleichung genügenden Wert von x darstellt, welcher nun blos noch der andern Teilsubsumtion zu genügen hat.
Aus analoger Erwägung ergäbe sich im Hinblick auf 11) als Resultante der Elimination von u: a(0 ɟ b̄) ⋹ v(a ɟ 0); 1 = (a ɟ 0) · v; 1. Beide Resultanten zerfallen.
Jene in u⋹a ɟ 0 und a(ū ɟ 0)(0 ɟ b̄) ⋹ a ɟ 0 oder ū ɟ 0 ⋹ a ɟ 0 + ā + 1; b.
Diese in a(0 ɟ b̄) ⋹ a ɟ 0 und a(0 ɟ b̄) ⋹ v; 1.
Was jene betrifft, so ist merkwürdig, dass man zu einem Zirkel geführt wird, sobald man u zuerst ihrer zweiten Teilforderung entsprechend bestimmt — was nach den zweiten Inversionsproblemen keine Schwierigkeit bereitet.
Dagegen führt der umgekehrte Gang zum Ziele: indem man mittelst u = w(a ɟ 0) die erste Teilforderung auf die allgemeinste Weise erfüllt, ergibt sich für w aus der zweiten: (w̄ + ā; 1) ɟ 0 = w̄ ɟ 0 + ā; 1 ⋹ a ɟ 0 + ā + 1; b — vergl. 24) des § 18 — und dies zerfällt in ā; 1 ⋹ a ɟ 0 + ā + 1; b, was zur Resultante der Elimination von x einen Beitrag, der kein andrer als 16) ist, liefert, und in w̄ ɟ 0 ⋹ a ɟ 0 + ā + 1; b, welcher Forderung durch geeignete Bestimmung von w nun noch leicht zu genügen ist.
Man findet durch Rückwärtseinsetzung den in 14) angegebenen Wurzelwert, wenn die zuletzt verbleibende Unbestimmte schliesslich (unter Aufgebung vorgängiger Benennungen) wieder u genannt wird.
Was diese, die Resultante nach u, die nur noch v enthält, betrifft, so ist deren erste Teilforderung schon selber jener Beitrag 16) zur Resultante nach x, und führt die Auflösung nach v der zweiten Teilforderung noch rascher zu dem gewünschten Ergebnisse — indem man den Ausdruck von v gemäss 25) des § 18 gebildet in denjenigen der Wurzel x einträgt und die kleine Reduktion von (a ɟ 0)a in a ɟ 0 vornimmt.
Auf zwei Wegen liess sich also die gesuchte Lösung des Problems aus denen früherer Probleme systematisch herleiten.
Es bleibt nun noch die Frage zu erledigen: auf welche Weise der Relation zwischen a und b, als welche die Resultante nach x bei unserm Probleme sich darstellt, auf die allgemeinste Weise zu genügen ist, m. a. W. es bleibt diese Resultante noch nach den Unbekannten a und b aufzulösen.
Ich will nicht nur die Begründungen, sondern auch die Ergebnisse blos für die Gleichung 17) a = a ɟ 0 + 1; b als den Repräsentanten der vier Probleme angeben.
Diese Gleichung liefert als eine Relation für a selbst eine Resultante durch Elimination von b.
Zwar durch Elimination des Terms „1; b“ findet man weiter nichts als die Forderung a ɟ 0 ⋹ a, die als identisch erfüllte auf 0 = 0 hinausläuft.
Anders bei Elimination von b.
Diese Thatsache ist für den Mathematiker geradezu verblüffend.
In ihr dokumentirt sich ein weitrer tiefwurzelnder Unterschied zwischen den Eliminationsproblemen in Arithmetik und Logik.
[Ein Unterschied bestand schon in der Unabhängigkeit des Problems von der Anzahl der Gleichungen hier, gegenüber seiner Abhängigkeit dort.]
Wenn in der arithmetischen Analysis ein Eliminand x überall nur in der Verbindung φ(x) vorkommt, so ist im Allgemeinen die Elimination von x zugleich mit der von φ(x) geleistet; beide Eliminationen liefern dieselbe Resultante, die erstere läuft einfach auf die letztere hinaus.
Hier dagegen kommt der Eliminand b lediglich in der Verbindung 1; b vor und dennoch führt die Elimination von b und die von 1; b zu ganz verschiednen Resultanten!
Woran liegt dies nun?
Bei genauerm Zusehn erkennt man wie dies davon kommt, dass der Ausdruck 1; b nicht jedes beliebige Relativ, sondern nur Relative von einer bestimmten Sorte vorzustellen fähig ist, m. a. W. davon: weil die [zur relativen Multiplikation mit 1] inverse Operation nicht unbedingt ausführbar ist.
Und darnach erscheint natürlich die so frappante Thatsache doch als begreiflich.
Die Resultante lautet: 18) a⋹a ɟ 0 ɟ a worin das Subsumtionszeichen, da die umgekehrte Einordnung ohnehin stattfindet, auch in ein Gleichheitszeichen verwandelt werden darf.
Sie ergibt sich wie folgt.
Wie schon erkannt, ist die Gleichung 17) äquivalent dem Produkt der beiden Subsumtionen: (a ⋹ a ɟ 0 + 1; b)(1; b ⋹ a).
Die erstre von diesen gibt: 0 ɟ b̄ ⋹ a ɟ 0 + ā, die letztere: b⋹ 0 ɟ a, 1; ā ⋹ b̄, 0 ɟ 1; ā = 1; ā ⋹ 0 ɟ b̄.
Aus beiden Ergebnissen folgt a fortiori: 1; ā ⋹ a ɟ 0 + ā oder a ⋹ a ɟ 0 + 0 ɟ a = a ɟ 0 ɟ a, q. e. d.
Dass unsre Resultante 18) die volle ist, geht daraus hervor, dass man, sobald sie erfüllt ist, der Forderung 17) immer durch b = 0 ɟ a genügen kann, wie mit Rücksicht auf 1; (0 ɟ a) = 0 ɟ a leicht zu sehn ist — q. e. d.
Man kann nun zuerst die allgemeinste Wurzel a der Gleichung 18) aufsuchen und darnach aus der Doppelsubsumtion: 19) ā; 1 · a ⋹ 1; b ⋹ a das b berechnen.
Ersteres zu leisten lehrt ein bemerkenswerter
Satz 20) worin auf der linken Seite der Aussagenäquivalenzen auch ⋹ für = schreibbar.
Beweis.
Bei beliebigem u stimmt die Probe 1.
Für x = u; 1; u wird nämlich nach 9): x; 1; x = u; 1; u; 1; u; 1; u = u; 1; u = x, q. e. d.
Man kann jedoch hier auch so schliessen:
Nach 5) des § 11 ist x; 1; x = u; 1; u; 1 · 1; u; 1; u.
Nun gilt ferner der
Satz 21) [Formel]
Der erste dieses Gespannes beweist sich wie folgt.
Es ist: Li j = Σh k lai hak l = Σhai h · Σk lak l = Σhai h = Ri j weil Σhai h ⋹ Σk lak l = ΣkΣhak h sein muss, indem die rechte Seite bei k = i die linke als Summanden aufweist — q. e. d.
Man kann den Beweis hier auch mittelbar führen.
Die zu beweisende Formel ist richtig (indem sie auf 0 = 0 hinausläuft) für a = 0.
Also bleibt sie nur noch für a ≠ 0 zu beweisen.
Nun ist nach vorhin citirtem Schema: L = a; 1 · 1; a; 1 = R · 1; a; 1.
Aber für a ≠ 0 ist 1; a; 1 = 1, somit in der That L = R, q. e. d.
Nach den linkseitigen Schemata 21) erhalten wir also oben: x; 1; x = u; 1 · 1; u = u; 1; u mithin = x, q. e. d. — d. h. es stimmte für den Satz 20) die Probe 1.
Dass auch die Probe 2 stimmt, nämlich dass die Formel x = u; 1; u für ein derart gegebenes x dass x; 1; x = x ist, ebendieses bei der Annahme u = x liefert, ist augenscheinlich.
Nach alledem werden wir nun also der Forderung der Resultante 17) in unabhängigen Parametern α, β auf die allgemeinste Weise genügen können, indem wir setzen: 22) [Formel] wo sich die erste Formel 22) nach dem zweiten Schema 20) ergibt, indem man α für u sagt.
Die zweite 22) geht aus der folgenden dritten hervor, indem nach 21) leicht zu zeigen, dass 0 ɟ a = 0 ɟ α, ā; 1 = ᾱ; 1 wird.
Diese dritte aber ergibt sich systematisch, indem man erst der zweiten Subsumtion 19) mittelst b ⋹ 0 ɟ a oder b = β(0 ɟ a) genügt, und den Wert in die erste einträgt.
Diese wird: ā; 1 · a ⋹ 1; β(0 ɟ a) = 1; β · (0 ɟ a) und zerfällt in ā; 1 · a ⋹ 0 ɟ a, was auf 18) hinauskommt, und in ā; 1 · a ⋹ 1; β, welcher letztern Forderung nach dem Schema 25) des § 18 durch geeignete Bestimmung von β zu genügen ist.
Die Lösung wird: β = u + ā; 1 · a · (0 ɟ ū), womit b = (0 ɟ a)u + (0 ɟ a) · ā; 1 · a · (0 ɟ ū) gewonnen ist, was sich noch wegen (0 ɟ a)a = 0 ɟ a vereinfacht.
Sagt man schliesslich β für die definitiv verbleibende Unbestimmte u des Ergebnisses, so hat man die dritte Formel 22) gefunden.
Es ist eine gute Übung für Anfänger auch die Proben 1 und 2 mit dem Ergebnisse 22) zu machen, also erstens zu zeigen, dass die Resultante 17) für beliebige α und β durch das System der Ausdrücke 22) erfüllt wird, und zweitens nachzuweisen, dass man ein gegebenes der Resultante 17) genügendes Wertepaar a, b mittelst der Annahme α = a, β = b aus 22) richtig erhält.
Jenes führt durch Einsetzung nach einigen Umformungen unter Anwendung bereits bekannter Sätze zu der Formel: α ɟ 0 ɟ α = α ɟ 0 + (0 ɟ α) · 1; β + (0 ɟ α) · 1; ᾱ; 1, welche sowol für α = 1 als für α ≠ 1 mit einiger Kunst zu rechtfertigen ist.
Dieses führt auf die aus der Voraussetzung 17) zu verifizirende Relation:
(0 ɟ a){b + ā; 1 · (0 ɟ b̄)} = b oder (0 ɟ a) · ā; 1 · b̄(0 ɟ b̄) + b · 1; ā = 0 wo in der That der erste Term wegen ā; 1 · (0 ɟ b̄) = ā und ā(0 ɟ a) = 0, der letzte wegen (1; b ⋹ a) = (b ⋹ 0 ɟ a) = (1; ā ⋹ b̄) verschwindet.
Wir haben oben die Resultante der Elimination von b aus der Gleichung 17) abgeleitet.
Man kann aber endlich auch die Frage aufwerfen nach der Resultante der Elimination von a aus dieser Gleichung 17) — als einer Relation für b.
Die Antwort lautet:
eine solche gibt es nicht.
Das Relativ b kann beliebig angenommen werden, und es lässt sich allemal ein a bestimmen, welches dann die Gleichung 17) erfüllt.
Zu dem Ende braucht man in der That nur in dem Ausdrucke 22) a = α ɟ 0 ɟ α zu nehmen: α = 1; b.
Damit wird auch 0 ɟ α = 1; b und a = 1; b ɟ 1; b = 1; b, welch letzterer Vereinfachung zugrunde liegt der
Satz, der ein interessantes Gegenstück zu dem 21) bildet und allgemein für jedes Relativ a gilt: 23) [Formel]
Behufs Beweises der ersten Formel dieses Gespannes kann man mittelbar zuwerke gehn und nach dem Satze 22) des § 18 ansetzen: (a ɟ 0); (a ɟ 0) = (a ɟ 0)1; (a ɟ 0) = (a ɟ 0) · 1; (a ɟ 0) = a ɟ 0, letztres in Anbetracht, dass der erste Faktor des vorhergehenden identischen Produktes dem zweiten eingeordnet ist, q. e. d.
Auch direkt in den Koeffizienten ist der Beweis nicht schwer zu führen und sei dem Anfänger als Übungsaufgabe empfohlen.
Nachdem wir nun für unser früheres a oben a = 1; b gefunden hatten, ergibt sich auch a ɟ 0 + 1; b = 1; b ɟ 0 + 1; b = 1; b, weil der erste Term der identischen Summe schon in dem zweiten enthalten ist, und damit ist erwiesen a ɟ 0 + 1; b = a, was zu zeigen gewesen.
Anmerkung.
Soferne überhaupt a ≠ 1 ist, lässt sich geometrisch leicht einsehen, dass 1; b = 0 ɟ a sein muss (mithin auch 1; b = 0 ɟ α), indem a sich nur aus Vollzeilen und Vollkolonnen additiv zusammensetzt.
Analytisch ist Vorstehendes wie folgt zu zeigen.
Wir hatten oben S. 287 schon erkannt, dass b ⋹ 0 ɟ a, mithin auch 1; b ⋹ 0 ɟ a sein muss.
Weiter folgt aber nach dem Satze 24) des § 18 rechts:
0 ɟ a ⋹ 0 ɟ (a ɟ 0 + 1; b) = 0 ɟ a ɟ 0 + 1; b. Ist also a ≠ 1, somit auch 0 ɟ a ≠ 1, so haben wir 0 ɟ a ɟ 0 = 0, mithin 0 ɟ a ⋹ 1; b, womit die behauptete Gleichheit als vor- und rückwärtige Subsumtion erwiesen ist.
Andernfalles haben wir a = 1, 0 ɟ a = 1, 0 ɟ a ɟ 0 = 1 und ergibt sich für 1; b keinerlei Bestimmung.
Hiermit dürfte denn unser Problem gründlich erledigt sein.
Zum Schlusse mag noch der Satz hier eine Stelle finden: 24) nach welchem in dem Ausdrucke jedes Quaderrelativs die identische Knüpfung auch durch die gleichnamige relative ersetzbar wäre.
(a ɟ 0); (0 ɟ b) = (a ɟ 0)(0 ɟ b) a; 1 ɟ 1; b = a; 1 + 1; b,
Der Beweis kann mittelbar aus 24) des § 18 geleistet werden, wonach sich zunächst ergibt: (a ɟ 0)1; (0 ɟ b) = (a ɟ 0) · 1; (0 ɟ b), was wegen 16) des § 15 mit der rechten Seite der ersten Formel 24) übereinstimmt.
Auch ist die Herbeiführung der Koeffizientenevidenz nicht uninteressant, z. B. rechterhand:
Li j = Πh(Σkai k1k h + Σl1h lbl j) = Πh(Σkai k + Σlbl j) = Σkai k + Σlbl j = Ri j q. e. d.
Die einfachste Form, welche sich der Charakteristik eines Quaderrelativs geben lässt, ist wol diese: 25)
x; 1; x = x x ɟ 0 ɟ x = x.
Ein Relativ x ist immer dann und nur dann ein Augenquaderrelativ, wenn es der Relation links in 25) genügt, ein Lückenquaderrelativ, wenn es die Forderung rechts erfüllt.
Beweis (nochmals in andrer Weise).
Denn ist x = (a ɟ 0)(0 ɟ b), so haben wir im Hinblick auf 5) des § 11 sowie 24) des § 18: x; 1; x = (a ɟ 0)(0 ɟ b); 1 · 1; (a ɟ 0)(0 ɟ b) = (a ɟ 0)(0 ɟ b) · (0 ɟ b); 1 · 1; (a ɟ 0), wo wegen a ɟ 0 ⋹ 1; (a ɟ 0), etc. die beiden letzten Faktoren unterdrückbar sind, mithin x; 1; x = x.
Und umgekehrt lässt sich jedes solche x als (x; 1 ɟ 0)(0 ɟ 1; x) darstellen, q. e. d.
Begreiflich ist das Konverse eines Quaderrelativs wiederum ein solches der nämlichen, das Negat aber ein solches der entgegengesetzten Art.
Die Formen, in welchen ein Quaderrelativ dargestellt werden kann, sind hienach sehr mannigfaltig.
Ein Augenquaderrelativ z. B. kann in folgenden 8 Gestalten als identisches sowol wie als relatives Produkt angesetzt werden: (a ɟ 0)(0 ɟ b) = (a ɟ 0); (0 ɟ b), a; 1 · 1; b = a; 1; b, a; 1 · (0 ɟ b) = a; (0 ɟ b), (a ɟ 0) · 1; b = (a ɟ 0); b und können in diesen noch unbeschadet der Allgemeinheit a und b durch ein und dasselbe Relativsymbol c ersetzt werden.
Ebenso ein Lückenquaderrelativ mit: a; 1 + 1; b = a; 1 ɟ 1; b, a ɟ 0 + 0 ɟ b = a ɟ 0 ɟ b, a; 1 + 0 ɟ b = a; 1 ɟ b, a ɟ 0 + 1; b = a ɟ 1; b.
Will man Sätze über solche Relative statuiren, so wird man, um die Formeln nicht unnötig zu vervielfältigen, gut thun, eine von diesen Formen als typische zu bevorzugen und scheinen sich hiezu die beiden: a; 1; b und a ɟ 0 ɟ b durch ihre Einfachheit am besten zu eignen.
Es gelten über die Einordnung zwischen Quaderrelativen und Moduln, desgleichen zwischen jenen unter sich, eine Reihe von bemerkenswerten Sätzen.
Und zwar zunächst: 26) 27) [Formel] 28) [Formel] 29)
[Formel]
(a; 1; b = 0) = (a = 0) + (b = 0)
(1 = a ɟ 0 ɟ b) = (1 = a) + (1 = b),
Beweise (links).
Zu 26).
Soll Li j = Σhai h · Σkbk j = 0 sein, so muss, weil dies ein Aussagenprodukt ist, dessen Faktoren dem Wertbereich 0, 1 angehören, entweder der erste Faktor, d. h. jedes ai h, oder der zweite Faktor, d. h. jedes bk j gleich 0 sein.
Zu 27).
Soll stets 1'i j oder auch 0'i j ⋹ Σhai hΣkbk j sein, so muss für jedes i, j sein Σhai h = 1 und Σkbk j = 1, da man zu jedem j ein i angeben kann, welches ihm gleich, sowie auch ein solches, welches ihm ungleich ist, wo dann immer das betreffende Subjekt gleich 1 sein wird.
Etc.
Die bisherigen Sätze besitzen auch einen hohen Grad von geometrischer Evidenz.
Man kann übrigens auch schliessen:
0' ⋹ a; 1 · 1; b, 0' ⋹ a; 1, 0'; 1 ⋹ a; 1; 1, also 1 ⋹ a; 1, etc., q. e. d.
Zu dem sehr merkwürdigen Satze 28) links lautet der Beweis: L = Πi j(Σh kai hbk j ⋹ 0'i j) = Πi(Σh kai hbk i = 0), sintemal die Forderung für j ≠ i nichtssagend ist.
Also: L = Πi h k(ai hbk i = 0) = Πh k(Σibk iai h = 0) = Πk h{(b; a)k h = 0} = R, desgleichen L = Πh i(ai hΣkbk i = 0) = Πh i{(ă · 1; b)h i = 0}, etc. q. e. d.
Zu 29) ist L = Πi j(Σh kai hbk j ⋹ 1'i j) = Σi j h k(ai h0'i jbk j = 0) = Πk h(Σj ibk j0'j iai h = 0) = = Πk h{(b; 0'; a)k h = 0} = R, etc. q. e. d.
Statt auf die Koeffizienten zurückzugehn, kann man jedoch auch mittelbar schliessen und hat nach dem ersten Inversionstheoreme die Reihe von äquivalenten Transformationen — zu 28): a; (1; b) ⋹ 0', a ⋹ 0' ɟ (b̄̆ ɟ 0) = b̄̆ ɟ 0, a; 1 ⋹ b̄̆, a; 1 · b̆ = 0, b̆ ⋹ ā ɟ 0, ă; b̆ ⋹ 0, b; a = 0, was auch schon aus a ⋹ b̄̆ ɟ 0 direkt erhältlich.
Ebenso zu 29): a ⋹ 1' ɟ b̄̆ ɟ 0, d. h. sowol b; 0'; a ⋹ 0 als 0'; a; 1 ⋹ b̄̆, 0'; a; 1 · b̆ = 0. Etc.
Schaltete man die spätern Schemata 9) des § 27 schon hier ein, so könnte man auch etwas umständlicher so schliessen: a; 1 · 1; b ⋹ 1', a; 1 ⋹ 1' + 0 ɟ b̄, a ⋹ (1' + 0 ɟ b̄) ɟ 0 = 1' ɟ (0 + b̄̆ ɟ 0) = 1' ɟ b̄̆ ɟ 0. Etc. q. e. d.
Die Sätze über Einordnung zwischen Quaderrelativen unter sich (sowie also auch mit Systemen und Systemkonversen) verschieben wir besser auf eine andre Gelegenheit.
Achte Vorlesung.
Die einfachsten Auflösungsprobleme der Theorie.
§ 21.
Die Probleme, welche in zwei Buchstaben möglich sind.
Erste Stufe der Probleme in drei Buchstaben.
Das allgemeinste Problem von universaler Natur auf dieser Stufe.
Solvirender Faktor.
Haben wir in der vorigen Vorlesung schon die bemerkenswerten Auflösungsprobleme behandelt, welche aus der Umkehrung (Inversion) der beiden relativen Knüpfungen entspringen, so wollen wir jetzt die „einfachsten“ Auflösungsprobleme unsrer Theorie (der binären Relative) überhaupt systematisch aufsuchen und soweit es in unsern Kräften steht zur Lösung bringen.
Unter diesen werden sich bereits jene Probleme, welche uns zu Herrn Dedekind’s „Theorie der Ketten“ — und damit zu theoretisch wie praktisch hochwichtigen Anwendungen — führen, mit vorfinden.
Wie wir in § 11 gesehen haben, läuft jedes Auflösungsproblem hinaus auf die Ermittelung eines unbekannten Relativs x, welchem die Auflage gemacht, von welchem verlangt ist, dass es eine gegebene Proposition (Subsumtion, oder, wenn man will: Gleichung) erfülle.
Und dem eigentlichen Auflösungsgeschäfte hat im Allgemeinen die Elimination dieser Unbekannten x und die Erfüllung der eventuell sich ergebenden Resultante voraufzugehen.
Neben der Unbekannten x mögen (oder mögen auch nicht) irgendwelche andre Relative in die aufzulösende Proposition als Operationsglieder oder Terme eingehen.
Diese letztern können sämtlich oder zum Teile Moduln sein, oder überhaupt bestimmte, speziell gegebene Relative. Dieselben können aber auch unbestimmte oder allgemeine Relative a, b, c, … sein, welchen — soweit es die Resultante zulässt — ein von Hause aus beliebig zu gebender Wert beigelegt zu denken ist, und werden sie in solchem Falle „die Parameter“ des Problems genannt.
Der Fall, wo alle neben x in der aufzulösenden Proposition vorkommenden Relative solch allgemeine Buchstaben-Parameter sind, begreift aber die Fälle mit unter sich, wo etwa einzelne von diesen Parametern in einen Modul degeneriren oder einen speziellen Wert annehmen, und deshalb werden wir die grösste Allgemeinheit der Untersuchungen erzielen, wenn wir fordern, dass in der aufzulösenden Proposition von vornherein nur Buchstaben (also keine Moduln!) als Terme vorkommen.
Diese Forderung aufzustellen ist in der That dem Geiste der analytischen Methode (Analysis) gemäss, welche strebt das Allgemeine thunlichst vor dem Speziellen, somit die ungeheure Mannig faltigkeit des Letztern mit einem Schlage zu erledigen.
Bei den solchergestalt möglichst allgemein gefassten Propositionen wird es nun nahe liegen, verschiedene Grade der Komplikation oder Verwickeltheit zu unterscheiden je nach der Anzahl der Buchstaben, die, um sie zu statuiren, verwendet oder geschrieben werden müssen (indem man also auch bei wiederholtem Auftreten eines gleichen Buchstabens diesen mehrfach zählt).
Wird ja doch zugleich mit der Menge dieser Buchstaben auch die Anzahl der knüpfenden Operationen im Allgemeinen wachsen, welche als mit Parametern und Unbekannten auszuführende in der Proposition vorgeschrieben erscheinen!
Verdient demnach jene Anzahl — sozusagen als die natürliche Grundlage — das vorwiegende Einteilungsprinzip abzugeben für eine Klassifikation der Propositionen überhaupt nach ihrer Komplikation, so werden nunmehr hinsichtlich der Einfachheit der Probleme, welche die Auflösung dieser Propositionen nach einer Unbekannten x fordern, weitre Unterscheidungen und Abteilungen zu machen sein je nach der Anzahl der Male, wie oft der Name dieser Unbekannten x (ohne oder auch mit Negationsstrich oder Konversionsringel) in die aufzulösende Proposition eingeht.
Mit diesen Bemerkungen ist, wenn wir in der Theorie vom Einfachern zum Verwickelteren fortschreiten wollen, der Plan für unser Zuwerkegehen im Grossen und Ganzen gegeben.
Da die Proposition zwei (durch ⋹, = oder ≠ etc. verbundene) „Seiten“ hat, deren jede zu ihrer Vertretung mindestens einen Buchstaben erfordert, so wird die Klasse der „einfachsten“ Propositionen aus denen bestehen, in welchen blos zwei Buchstaben vorkommen, in die sie nämlich als deren beide Seiten eingehen.
Die Klasse der nächstkomplizirtern Propositionen wird diejenigen umfassen, in welche drei Buchstaben eingehen, und zwar einer isolirt als die eine Seite der Proposition, die beiden andern als Terme zu einem Ausdrucke verknüpft, der die andre Seite derselben vorstellt.
Bei vier Buchstaben sind schon die beiden Fälle zu unterscheiden, wo entweder deren einer isolirt die eine Seite der Proposition bildet und die drei andern (durch zwei successive Operationen verknüpft) die andre Seite zusammensetzen, oder aber wo auf jeder Seite zweie von den vieren in eine eigenartige Knüpfung eingehen.
Auch kann man ein System von zwei Propositionen zwischen je nur zweien von den vier Buchstaben als „von gleicher Einfachheit“ mit einer alle viere enthaltenden Proposition hinstellen oder gelten lassen — so wenigstens, sofern es sich um Subsumtionen handelt.
In Anbetracht überhaupt, dass jede Gleichung ja einem System von zwei simultanen Subsumtionen äquivalent ist, werden sich, je nachdem als aufzulösende Proposition eine Subsumtion oder eine Gleichung vorliegt, noch weitre Abstufungen der Komplikation ergeben.
Die Auflösung einer Subsumtion wird auch bei gleicher Buchstabenzahl und Übereinstimmung der beiderseitigen Ausdrücke als die „einfachere“ Aufgabe zu bezeichnen sein, gegenüber der Auflösung der Gleichung.
Und thatsächlich ist auch die letztere fast allemal schwieriger aufzulösen.
Wir beschränken uns nun hiernächst auf die im Haupttext genannten beiden einfachsten Klassen von Propositionen.
An die damit angebahnte Aufzählung der einfachsten Auflösungsprobleme müsste sich meines Erachtens auch die rationelle Klassifikation der Relative selbst anlehnen.
Eine solche ist von wie mir scheint engeren Gesichtspunkten aus schon von verschiednen Seiten (Peirce2, 5, p. 51, 47, De Amicis1, Vailati1) versucht worden.
Als wichtigste Klassen von eigenartigen Relativen, welche auch eine Belehnung mit besonderen Namen in erster Linie verdienen, möchten aber wol diejenigen zu bezeichnen sein, welche — wenn mit x bezeichnet — durch eine Proposition von einfachster Gestalt charakterisirt zu werden vermögen.
Die Vermutung wird in der Folge vielfache Bestätigung finden — namentlich wenn man noch für etwaige Parameter gewisse Moduln eintreten lässt.
Eine Proposition, in welcher gar keine Unbekannte vorkommt, kann nicht im eigentlichen Sinne zur Bestimmung einer solchen x dienen.
Derartige Propositionen sind entweder wahr oder falsch und haben darnach den Aussagenwert 1 oder 0.
Im ersten Falle lassen sie x gleich u vollkommen unbestimmt oder willkürlich; im letztern Falle bleibt es unmöglich, x so zu bestimmen oder anzunehmen, dass die Proposition erfüllt werde.
Dies kann bezüglich durch die Formeln ausgedrückt werden: 1) .
Letztere Bezeichnung trifft selbstverständlich nur zu, soferne für x nicht noch anderweitige Bestimmungen vorliegen, soferne also — was uns bei den Auflösungsproblemen immer vorschwebt — es sich um die Ermittelung einer Unbekannten, nicht aber eines schon bekannten Relativs handelt, eines Relativs vielmehr, welches lediglich durch die vorgelegte Proposition beschränkt gedacht wird.
Mit 1 äquivalent ist aber jede „analytische“ Proposition, jede Formel, wie z. B. die x ⋹ x.
Als Auflösung der letztern nach der Unbekannten x würde also ebenfalls der Ausdruck [Formel] hinzustellen sein, wofür wir aber — im Hinblick auf 1) — den kürzeren Namen 1 selbst künftighin beibehalten wollen.
Ebenso ist mit 0 äquivalent jede absurde oder unauflösbare Proposition, wie z. B. die x̄ = x.
Bei der Zusammenstellung der Auflösungsergebnisse oder allgemeinen Wurzeln möge das Aussagensymbol 0 selbst auf das Nichtvorhandensein, die Unmöglichkeit einer Wurzel hinweisen.
Wir studiren also nur mehr Propositionen, in welchen der Name x der Unbekannten mindestens einmal vorkommt, und wenden uns zuerst zur einfachsten Klasse, nämlich zu den Auflösungsproblemen mit zwei Symbolen.
Das eine dieser Symbole ist die Unbekannte x, somit sind zwei Abteilungen zu unterscheiden, je nachdem das andre Symbol ein Parameter a, oder aber ebenfalls die Unbekannte x oder eine von deren Verwandten ist.
Mit 2), 3) chiffrirt stellen wir hiernächst die Probleme der erstern, und mit 4) ‥ 7) chiffrirt die der letztern Abteilung samt den zugehörigen Lösungen übersichtlichst und vollständig zusammen.
Zufolge Zusammenfallens, logischer Äquivalenz, von einzelnen auf den ersten Blick oder formell verschiedenen von diesen Auflösungsproblemen lassen sich deren nur 12 + 7 = 19 zählen.
2) , 3)
[Formel] 4)
[Formel] 5)
[Formel] , 6) , 7)
(x̄̆ = x) = 0 = (x̄ = x̆).
Was Herleitung und Beweis dieser Angaben betrifft, so gehen zunächst die einander äquivalent gesetzten (von u noch freien) Subsumtionen resp. Gleichungen aus einander hervor durch beiderseitiges Negiren (Kontraposition) oder Konvertiren — bei 5) auch mit Rücksicht auf die Definition der Gleichheit.
Nur bei der dritten Zeile von 4) ist eine andre, aus dem identischen Kalkul bekannte Transformation mit der aufzulösenden Subsumtion vorzunehmen.
Aus der abgeleiteten Form, sofern sie nicht selbst schon die Lösung vorstellt, geht diese bei 1) bis 4) nach bekannten Sätzen derselben Disziplin hervor — vergl. Bd. 2, S. 33, Th. 43) — sodass diese keines weitern Kommentars bedürfen.
Erläuterungsbedürftig sind nur noch die Sätze 5) bis 7).
Eine jede von den Propositionen der ersten Zeile von 5) charakterisirt x als ein „symmetrisches“ Relativ — nämlich als symmetrisch inbezug auf die Hauptdiagonale.
Am besten wird man die Gleichung x̆ = x zu dieser Charakterisirung verwenden.
Das fundamentum relationis bei einem solchen Relative x wird eine wechsel- oder gegenseitige Beziehung (a mutual relation) zu nennen sein, wofern man nicht vorzieht auch sie eine „symmetrische“ zu nennen.
De Morgan will solche Relative „umkehrbare“ oder „konvertible“ genannt wissen.
Beispiele sind unbedingt: „gleich“, sowie „ungleich mit-“, „Freund von-“, „Ehegespons von-“.
Das Korrelat ist hier dasselbe x vom Relate, wie dieses vom Korrelate.
Im Gegensatz, Kontrast zu dieser wichtigen Klasse von Relationen stehen die „eventuell unsymmetrischen“, wie bei kleiner als-“, „Diener von-“
„Vater“, „Bruder von-“ (eventuell einer Schwester).
In der zweiten Zeile von 5) ist nun jedes symmetrische Relativ x durch ein unbestimmtes Relativ u ausgedrückt und zwar auf zwei wesentlich verschiedene Arten, die — ebenso wie die Lösungen von 6) — leicht zu erraten gewesen.
Für uns taugt diese Benennung nicht, weil jedes Relativ konvertirt werden kann.
Der scholastische Name für unser „symmetrisches“ Relativ ist „relativum aequiparantiae“ als Gegensatz zum „relativum disquiparantiae“ — vergl. Peirce2 p. 52.
So Pschlacher in Petrus Hispanus:
„Relativa aequiparantiae: quae sunt synonyma cum suis correlativis … Relativa disquiparantiae: quae non sunt synonyma cum suis correlativis.
Ferner Ockham Quodlibetum 6 qu. 20:
„Quaedam sunt relationes aequiparantiae, quaedam disquiparantiae.
Primae sunt relationes similium nominum, secundae relationes dissimilium nominum.
Exemplum primi est quando idem nomen ponitur in recto et in obliquo, sicut simile simili est simile …
Exemplum secundi est quando unum nomen ponitur in recto sed aliud in obliquo, sicut pater est filii pater et non oportet quod sit patris pater.
Wesentlich dieselben Definitionen können in vielen Logiken des späten Mittelalters gefunden werden.
Der Beweis besteht in den beiden Proben.
Bei 5) thut Probe 1) dar, dass für ein beliebiges u, wenn x = uŭ ist, auch x̆ = ŭu, mithin x̆ = x sein muss etc.
Probe 2 zeigt, dass, wenn x̆ = x ist, auch x = xx̆ sein wird.
Etc.
Zu 6) links hat man als Probe 1:
Wenn x = uū̆, so ist x̄̆ = ū̆ + u, mithin x ⋹ x̄̆.
Probe 2. Umgekehrt, wenn x ⋹ x̄̆ ist, so hat man xx̆ = 0, sonach x = x · 1 = x(x̆ + x̄̆) = 0 + xx̄̆ = xx̄̆, man erhält also x selbst aus der allgemeinen Lösung durch die Annahme u = x. Etc. q. e. d.
Die linkseitige Proposition 6) ist äquivalent mit xx̆ = 0 und charakterisirt x als ein „unpariges Relativ“, d. h. als ein solches, welches nur unparige Augen (vergl. S. 138 sq.) besitzt, mithin auch keine individuellen Selbstrelative unter sich begreift d. h. die Hauptdiagonale unbesetzt hat; vielmehr ist dieses x = xx̄̆ ⋹ 0' und gehört x zu den Aliorelativen.
Die rechtseitige Proposition 6) dagegen ist äquivalent mit 1 = x + x̆ und charakterisirt x als ein Relativ mit niemals andern als unparigen Leerstellen, welches also auch, indem 1' ⋹ x + x̄̆ = x sein muss, als Aliorelativnegat sämtliche individuellen Selbstrelative umfasst (cf. S. 132).
Hiernach bleibt nur noch 7) zu erweisen, d. h. zu zeigen, dass es unmöglich ist, die Forderung x̄̆ = x zu erfüllen, oder dass die beiden Forderungen x̄̆ ⋹ x und x ⋹ x̄̆, denen wir in 6) einzeln zu genügen gelehrt haben, mit einander unverträglich sind.
Die Gleichung auf das Prädikat 0 gebracht verlangt nun in der That, dass xx̆ + x̄x̄̆ ⋹ 0 werde.
Nach dem Korollar zu 2) des § 8 ist aber 1' ⋹ dem Subjekte dieser Subsumtion; es würde hienach a fortiori 1' ⋹ 0 sein müssen, was absurd ist.
Auch geometrisch ist es leicht, den Grund der Unmöglichkeit einzusehen.
Zwar seitlich von der Hauptdiagonale lässt sich dem, was die Gleichung fordert, genügen.
Man kann z. B. die Stellen auf der einen Seite — sagen wir oberhalb — der Hauptdiagonale einzeln ganz nach Willkür mit Augen besetzen oder unbesetzt lassen, wofern man alsdann nur unterhalb der Hauptdiagonale als Spiegelbild eines Auges eine Leerstelle, als Spiegelbild einer Leerstelle ein Auge anbringt.
Für j ≠ i wird auf diese Weise allgemein x̄j i = xi j oder xj i = x̄i j werden.
Dagegen bei j = i, das ist auf der Hauptdiagonale selbst, müsste x̄i i = xi i werden, jede Stelle zu gleicher Zeit Leerstelle sein und ein Auge tragen, was sich widerspricht; die Hauptdiagonale kann auf keine Weise der Forderung entsprechend besetzt werden — q. e. d.
Bei der obigen Zusammenstellung der allereinfachsten Probleme sind wir insofern pedantisch vollständig gewesen, als wir auch diejenigen mitaufgeführt haben, welche durch Vertauschung der Unbekannten x mit einem ihrer verwandten Relative x̄, x̆, x̄̆ aus schon angeführten hervorgehen.
In Hinkunft werden wir solches nicht mehr thun:
es überheben uns dessen die Formeln 3) wonach, sobald eines der drei letztern ermittelt ist, auch x gefunden sein wird.
Wir wenden uns hienach zu den Auflösungsproblemen, welche in Subsumtionen- oder Gleichungsform mit Aufwand von drei Buchstaben gestellt werden können.
Diese zerfallen in zwei Stufen, je nachdem die knüpfende Operation auf der zwei Buchstaben aufweisenden Seite eine identische oder eine relative ist.
Diese Knüpfung möge zuerst eine identische sein — sei es Multiplikation sei es Addition.
Die Aufgaben sind dann — bis auf eine 14) — sämtlich leicht oder ziemlich leicht zu lösen.
Sie zerfallen in drei Hauptabteilungen, je nachdem x nur einmal neben zwei Parametern a, b, oder x zweimal neben einem Parameter a, oder x dreimal und kein Parameter in der aufzulösenden Proposition vorkommt.
Erste Hauptabteilung.
Würde x (immer sei es ohne, sei es mit Negationsstrich oder Konversionsringel gedacht) auf der einen Seite isolirt stehn, so hätten wir auf der andern Seite die zwei Parameter a, b vermittelst einer identischen Operation zu einem einzigen Parameter c verknüpft.
Die Aufgabe müsste dann auf eine der schon erledigten 2), 3) hinauslaufen, mit dem einzigen Unterschiede, dass der Parameter c, statt beliebig gegeben, als ein in bestimmter Weise aus a und b zusammengesetzter zu denken wäre.
Daher kommen nur die Aufgaben in Betracht, bei denen x als das eine Operationsglied in die Knüpfung eingeht, die Parameter a, b sich auf die beiden Seiten der aufzulösenden Proposition verteilen.
Wegen der Kommutativität der knüpfenden Operation braucht man nicht zu unterscheiden, ob das unbekannte Operationsglied erstes oder zweites ist, und durch Vertauschung von x mit einem seiner verwandten Relative kann man immer bewirken, dass als dasselbe x selbst (nicht aber x̄, x̆ oder x̄̆) erscheint.
Es können daher in dieser Abteilung nur die folgenden 6 Aufgaben vorliegen, deren Lösung der identische Kalkul ohne weitres liefert, und die wir nur der Vollständigkeit zuliebe sowie behufs etwaiger Vergleichung mit der höheren Stufe angeführt haben wollen: 8)
[Formel] .
Zweite Hauptabteilung.
Dieselbe zerfällt in zwei (Unter-)Abteilungen, je nachdem von den zwei vorkommenden Buchstaben x der eine links, der andre rechts in der aufzulösenden Proposition vorkommt, m. a. W. der eine isolirt, der andre mit dem Parameter verknüpft sich findet, oder aber alle beide x auf der nämlichen Seite (in die Knüpfung eingehend) stehen, während die andre Seite den Parameter isolirt aufweist.
Durch Vertauschung von x mit einem seiner verwandten Relative kann bewirkt werden, dass der eine von den zwei vorkommenden Buchstaben x — eventuell der isolirt stehende — weder Negationsstrich noch Konversionsringel trägt.
Die Aufgaben der ersten Abteilung mitsamt ihren Lösungen vollständig zusammengestellt sind dann die folgenden: 9)
[Formel] 10) 11) 12) 13)
14)
[Formel]
[Formel]
wo g eine gewisse Wurzel der Gleichung 0'ḡ̆ = 0'g, nämlich
ein spezielles (weiter unten beschriebenes) Relativ von den
Eigenschaften gğ = 0 und g + ğ = 0' vorstellt.
Für diejenigen von diesen Aufgaben, welche hienach auf zuvor schon mit ihren Lösungen angegebene zurückkommen, wurden letztere nicht nochmals ausdrücklich hingesetzt; so ist z. B. in der zweiten Zeile von 9) die Lösung zu (x ⋹ a) bereits in 2) oben angegeben.
Bei schwierigern derart auf frühere sich reduzirenden Aufgaben wird künftig Rückverweisung erfolgen.
Die Formeln 9), ebenso nachher die 15) und 22) ergeben sich schon aus dem identischen Kalkul.
Die Rechtfertigung der übrigen versparen wir auf den Schluss der Zusammenstellung.
Die Aufgaben der zweiten Abteilung sind mit ihren Lösungen zusammengestellt — wie leicht zu sehen, vollständig — diese: 15) 16) 17) 18) [Formel] 19) 20) [Formel] 21) [Formel] .
(xx̆ ⋹ a) = (x ⋹ a + x̄̆) (a ⋹ x + x̆) = (ax̄̆ ⋹ x), cf. 12)
(xx̄̆ ⋹ a) = (x ⋹ a + x̆) (a ⋹ x + x̄̆) = (ax̆ ⋹ x), cf. 10)
Bei 18), 20) und 21), wo der Parameter a eine Relation als Resultante zu erfüllen hatte, wurde mittelst identischer Erfüllung ebendieser das Problem auch in ein solches mit beliebigem Parameter umgesetzt und als solches mitsamt seiner Lösung beigefügt.
Die beiden letztern Aufgabenpaare zogen sich ebenhiedurch je in eine gemeinsame Aufgabe zusammen.
Dritte Hauptabteilung.
Durch Vertauschung des unbekannten Relativs x mit einem seiner Verwandten lässt sich immer hinbringen, dass der isolirt stehende von den drei in die Proposition eingehenden Buchstaben x weder Negationsstrich noch Konversionsringel trägt.
Es bleiben dann die Aufgaben: 22) [Formel] 23) [Formel] 24) [Formel] 25) [Formel] 26) [Formel] 27)
[Formel]
Mittel und Wege anzugeben, wie die aufgezählten Ergebnisse sich entdecken liessen, würde zuviel Druckraum beanspruchen.
Als für das weiter Folgende wesentlich müssen nur die Angaben zu 10), 12) und 14) bewiesen werden, denn schon mit Hülfe dieser einfacheren Vor-aufgaben wird sich nachher die Lösung eines viel allgemeineren Problems gewinnen lassen aus welchem die Lösungen aller (übrigen) Aufgaben 1) bis 27) dann als partikulare Fälle hervorgehen.
Für die letzte Aufgabengruppe 22) bis 27) allerdings wird dieser Weg sich nicht empfehlen, vielmehr ist hiezu blos zu sagen, dass der Nachweis der daselbst angegebnen Aussagenäquivalenzen oder die Zurückführung der als äquivalent behaupteten Aussagen auf einander eine leichte Übungsaufgabe für Anfänger bildet.
Ich gebe daher jetzt den Beweis, zunächst zu 10) und 12), wobei ich mich mit der Verifikation der Lösungsformen für die Probleme linkerhand vermittelst der beiden Proben begnüge.
Zur ersten Lösungsform x = u + aŭ von 10) hat man als Probe 1:
x̆ = ŭ + ău, also ax̆ = aŭ + aău ⋹ aŭ + u = x, und als Probe 2: (ax̆ ⋹ x) ⋹, sogar = (x = x + ax̆).
Zur zweiten Lösungsform x = u(ā̆ + ŭ) von 10) ist Probe 1 mit x̆ = ŭ(ā + u), ax̆ = auŭ ⋹ uŭ ⋹ x geleistet und Probe 2 mit (ax̆ ⋹ x) = (x̆ ⋹ ā + x) = (x ⋹ ā̆ + x̆) = {x = x(ā̆ + x̆)}.
Zu 12), mit nur einer Lösungsform x = u + (a + ă)ū̆, folgt x̄̆ = ū̆(āā̆ + u), ax̄̆ = auū̆ ⋹ u ⋹ x, womit denn Probe 1 stimmt.
Ist aber ax̄̆ ⋹ x, so muss auch x = x + (a + ă)x̄̆ sein und stimmt die Probe 2.
Denn es fallen die nachstehenden Probleme zusammen: (ax̄̆ ⋹ x) = {(a + ă)x̄̆ ⋹ x}, und auch = (ăx̄̆ ⋹ x), indem beide Seitenaussagen äquivalent sind mit (a ⋹ x + x̆) = (ă ⋹ x + x̆) = (a + ă ⋹ x + x̆).
Wie im Probleme, so können demnach auch in der Lösung die drei Symbole a, ă und a + ă einander vertreten und hätte man formell einfacher schon x = u + aū̆ als die Lösung hinstellen können, womit die Probe 1 als ax̄̆ = aā̆ū̆ + auū̆ ⋹ aū̆ + u = x ebenfalls stimmte. —
Analog nun die übrigen Lösungen zu verifiziren, die etwaigen Resultanten zu gewinnen und die angeführten Problemäquivalenzen nachzuweisen — wie z. B. bei 11) wo (x ⋹ ax̆) = (x ⋹ a)(x ⋹ x̆) = (x̆ = x)(x ⋹ aă), cf. 5), zunächst zerfällt, u. s. w. — sei als eine nicht zu verachtende Übung, bis auf 14), dem Leser überlassen.
Schwieriger würde die Zumutung der Entdeckung der Lösungen sein, wie sie mir vor Inangriffnahme des allgemeinern Problems einzeln obgelegen.
[Als bemerkenswert verdient vielleicht einmal angeführt zu werden, was eine Art Korollar zu 27) bildet, dass allgemein: ist, mithin das Produkt der drei andern mit einem gegebnen Relativ verwandten Relative stets 0, deren Summe gleich 1 ist.
Dies ist jedoch nicht zu verwundern, sintemal sich unter den dreien stets zweie finden, die Negate von einander sind.
āăā̆ = 0 1 = ā + ă + ā̆
Im Ganzen lieferte uns auf der vorliegenden untersten Stufe die dritte Hauptabteilung — wie man sieht — keine wesentlich neuen Probleme.]
Wir haben uns demnach nur mehr noch mit der Lösung der Aufgabe 14) zu beschäftigen, d. h. mit der Auflösung der Gleichung ax̄̆ = x.
Diese erscheint als die schwierigste von den bisherigen Aufgaben.
Bringt man die Gleichung rechts auf 0, indem man für ā + x̆ schreibt ā + ax̆, so entsteht: āx + a(xx̆ + x̄x̄̆) = 0, und dies zerfällt in x ⋹ a und a ⋹ xx̄̆ + x̄x̆.
Letzteres liefert nach 7) des § 9 die Resultante: a ⋹ 0'.
Dass diese bis jetzt erst als unerlässlich nachgewiesene Resultante auch ausreichend, dass sie die volle Resultante ist, wird sich erst am Schlusse der Untersuchung ergeben.
Wir setzen sie nunmehr als erfüllt voraus, d. h. wir nehmen an, a sei Aliorelativ, habe die Diagonale unbesetzt, es sei a = 0'a.
Um die Aufgabe zu lösen, scheint es das nächstliegende: dass man die aufzulösende Gleichung in ihre beiden Teilsubsumtionen ax̄̆ ⋹ x und x ⋹ ax̄̆ zerfälle und für diese die mit 12) und 13) gegebnen allgemeinen Lösungen benutze.
Der Versuch, die Lösung der einen Teilaufgabe auch der andern genügend zu machen, führt aber allemal in einen Zirkel.
Wir wollen gleichwol diesen Weg ein Stück weit gehen, genügen also der zweiten Teilsubsumtion gemäss 13) auf die allgemeinste Weise, indem wir setzen: x = avv̄̆ womit x̄̆ = ā̆ + v + v̄̆ wird.
Dann fordert die erste Teilsubsumtion, dass aā̆ + av + av̄̆ ⋹ avv̄̆ werde, und zerfällt diese Forderung in die vier Subsumtionen: aā̆⋹v, aā̆⋹v̄̆, av⋹v̄̆, av̄̆⋹v, deren beide erste zu aā̆ ⋹ v ⋹ a + ā̆ zusammenfliessen und durch v = aā̆ + w(a + ā̆), v̄ = āă + w̄(ā + ă), v̆ = āă + w̆(ā + ă), v̄̆ = aā̆ + w̄̆(a + ā̆) auf die allgemeinste Weise befriedigt werden.
Die hiermit sich ergebenden Werte von vv̆ = ww̆(aă + āā̆), v̄v̄̆ = w̄w̄̆(aă + āā̆) in die Zusammenfassung a(vv̆ + v̄v̄̆) = 0 der beiden letzten Subsumtionen eingesetzt, liefern: aă(ww̆ + w̄w̄̆) = 0 als einzig noch von w zu erfüllende Bedingung — wobei wegen a ⋹ 0' also a = 0'a der linken Seite vorn auch der Faktor 0' beigefügt werden dürfte, sodass diese Bedingung äquivalent erscheint mit der Gleichung: 28) 0'aăw̄̆ = 0'aăw.
Wir suchen dieser Forderung zuerst für den Fall a = 1 auf die allgemeinste Weise zu genügen, mithin die allgemeine Wurzel ω der Gleichung 29) 0'ω̄̆ = 0'ω oder 0'(ωω̆ + ω̄ω̄̆) = 0 zu finden.
Genügt ein ω, so auch 1'u + ω.
Darum bleibt der Selbstteil von ω als 1'u unbestimmt und nur noch dessen Alioteil zu ermitteln.
Es ist leicht eine befriedigende allgemeine Lösung dieser Gleichung aufzustellen, sobald man auch nur über eine Partikularlösung, oder spezielle Wurzel derselben verfügt — ohnedies aber wol unmöglich, nicht nur weil alle andern Wege sich als Zirkelgänge erweisen (wie z. B. auch der Versuch einer symmetrisch allgemeinen Auflösung der Koeffizientenanforderung), sondern auch weil a priori ersichtlich ist, dass man von einem arbiträr bleibenden Relativ u ausgehend und immer nur mit diesem operirend niemals dahin gelangen kann, von den beiden Stellen jedes symmetrischen Stellenpaares die eine vor der andern behufs unpariger Besetzung (auf die es hier ankommen wird) bevorzugt erscheinen zu lassen.
Wir konstruiren demnach zuerst ein spezielles Relativ g in der Weise, dass wir dessen Diagonalreihe leer lassend von jedem symmetrischen Stellenpaare die eine Stelle, gleichviel welche, mit einem Auge besetzen, die andre sodann aber definitiv unbesetzt lassen.
Um die Vorstellung zu fixiren (doch wird dies nicht wesentlich sein) mag man etwa alle Stellen unterhalb der Hauptdiagonale voll mit Augen besetzen, die oberhalb derselben (gleichwie sie selber) leer lassen.
In diesem Falle wird für den Denkbereich der reellen Zahlen z. B. unser Relativ g als >, „grösser als“ zu deuten sein, und einer ähnlichen Deutung wird es allemal fähig sein, sobald nur überhaupt ein Prinzip angebbar ist, nach welchem alle Elemente des ersten Denkbereiches eine bestimmte Rangordnung oder Reihenfolge erhalten.
[Auch für die Punkte x, y einer Koordinatenebene, oder für die komplexen Zahlen [Formel] , desgleichen für die Punkte x, y, z des Raumes, etc., ist bekanntlich solche Ordnung möglich, indem man zuerst nach der Grösse der Abscisse x, resp. des reellen Teiles, sodann (bei übereinstimmenden x) nach der Grösse von y, d. i. der Ordinate oder des reellen Faktors im imaginären Teile, eventuell endlich nach der Grösse der Applikate z ordnet.
U. s. w.]
Wir haben darnach als Versinnlichung von g und seinen Verwandten die Fig. 21 (S. 306), worin die Linien, soweit sie ausgezogen, auch vollbesetzt zu denken sind.
In jedem Falle aber, auch wenn man sich bei Befolgung der obigen Vorschrift anders entscheiden sollte, ist: 30) [Formel]
Fig. 21.
Um sich das Verständniss des nun Folgenden zu erleichtern wird der Leser gut thun, die schematischen Figuren Fig. 19 und 20 des § 9 im Auge zu behalten und die dortigen Ausführungen S. 138 sq. zu beachten.
Um jetzt die allgemeine Wurzel ω der Gleichung 29) zu konstruiren, d. h. jedes Relativ zu bilden, welches alle symmetrischen Stellenpaare unparig besetzt zeigt, gehen wir von einem arbiträren Relativ u aus, und heben aus diesem in Gestalt von uū̆ die vielleicht ohnehin schon vorhandnen unparigen Augen hervor.
Die parig besetzten nebst den parig unbesetzten Stellen von u aber, mit Augen bedeckt, fasst vollzählig und ausschliesslich in sich zusammen das Relativ 0'(uŭ + ūū̆) —
(wogegen die Negation des uū̆ ausser den Stellen der Diagonale auch noch die unparigen Leerstellen von u mit Augen besetzt aufweisen würde, was uns nicht dienlich wäre).
Multiplizirt man dieses mit g, so werden die bei u parigen Stellen in unparige verwandelt, nämlich von allen parigen Augen des genannten Relativs, von jedem symmetrischen Augenpaare, blos die eine Hälfte hervorgehoben, die andre weggelassen.
Das Produkt: 0'(uŭ + ūū̆)g, = (uŭ + ūū̆)g, weil 0'g = g, mit jenem erstern Relativ uū̆ additiv vereinigt zeigt dann notwendig alle symmetrischen Stellenpaare unparig besetzt, es stellt also eine Lösung vor: ω = uū̆ + (uŭ + ūū̆)g + 1'u.
Nimmt man noch aus dem ersten Glied den Teil uū̆g in das zweite Glied tautologisch herein, so vereinfacht sich das Ergebniss zu ω = 1'u + uū̆ + (u + ū̆)g, ω̄ = ūŭ + (ū + 0'ŭ)ḡ, ω̆ = 1'u + ūŭ + (ū + ŭ)ğ, ω̄̆ = uū̆ + (u + 0'ū̆)ḡ̆.
Und damit wird: ωω̆ = 1'u + (uŭ + ūū̆)gğ, ω̄ω̄̆ = 0'(uŭ + ūū̆)ḡḡ̆, also wegen 30) in der That 0'(ωω̆ + ω̄ω̄̆) = 0, d. h. die Probe 1 stimmt mit unsrer Lösung.
Noch schneller konnte man sie in der Form 0'ω̄̆ = 0'ω aus 0'ḡ̆ = 0'g bewahrheiten.
Es stimmt aber auch die Probe 2:
unser Resultat ist fähig jede gewünschte Lösung zu liefern.
Denn ist u von vornherein eine solche, mithin jedenfalls 0'u = 0'ū̆, so haben wir auch 0'u = 0'ū̆ = 0'uū̆ = uū̆, also 1'u + uū̆ = 1'u + 0'u = u und muss ω = u selbst werden, indem dessen letztes Glied (u + ū̆)g = (0'u + 0'ū̆)g = 0'ug im ersten u dann eingeht, von ihm absorbirt wird.
Somit ist etablirt der Satz: 31) [Formel] , wo g wie über 30) definirt ist, d. h. (irgend) eine spezielle Wurzel der Gleichung linkerhand vorstellt — und die Aufgabe 29) ist gelöst.
Um nun von hier zur vollständigen Lösung der allgemeinern Aufgabe 28) zu gelangen: 0'aă(ww̆ + w̄w̄̆) = 0, bemerken wir, dass (vergl. § 9) der erste Faktor 0'aă aus dem unter 0' enthaltenen, sonst irgendwie gegebnen Relativ a lediglich dessen parige Augen hervorhebt.
Auf diese müssen nun — so soll w bestimmt werden — sowol bei ww̆ als bei w̄w̄̆ lauter Leerstellen fallen.
Im Hinblick auf die Schemata Fig. 20 des § 9, wenn wir uns diese für ein Relativ w statt a aufgestellt denken, gibt dies zwei Bedingungen.
Um der erstern Forderung zu entsprechen, müssen auf die Stellen der parigen Augen von a bei w fallen: entweder unparig besetzte oder Leerstellen, d. i. Stellen von den Kategorieen 2) oder 3) der ersten Fig. 19.
Um aber der zweiten Forderung zu entsprechen, müssen ebenhierauf bei w fallen: entweder parig besetzte oder unparig besetzte Stellen, d. i. solche von den Kategorieen 1) oder 2) genannter Figur.
Folglich müssen, um beiden Forderungen zugleich zu entsprechen, bei w ebendahin fallen: Stellen der Kategorie 2) jener Figur, das ist: unparig besetzte Stellen.
Wir werden sonach die allgemeinste Wurzel w der Gleichung 28) erhalten indem wir, sie aus zwei Teilen zusammensetzend, erstens aă multipliziren mit dem allgemeinsten Relativ ω mit lauter unparig besetzten Stellen, zweitens hinzufügen das Negat ā + ā̆ von aă, multiplizirt mit einem beliebigen Relativ u, sodass gefunden ist: w = aăω + (ā + ā̆)u, w̄ = aăω̄ + (ā + ā̆)ū w̆ = aăω̆ + (ā + ā̆)ŭ, w̄̆ = aăω̄̆ + (ā + ā̆)ū̆.
[Der Ausdruck von w̄ ergibt sich am schnellsten nach „meinem Theorem des identischen Kalkuls aufgrund der Bemerkung, dass w nach dem Argument aă „entwickelt“ erscheint, also blos die Koeffizienten der beiden Konstituenten negirt zu werden brauchen.
Andernfalls hätte man einige Rechnung und müsste, was übrigens keine Schwierigkeit bietet, am Schlusse das Eingehen, Absorbirtwerden des Gliedes ω̄ū nachweisen.]
In die Ergebnisse könnten wir nun den Ausdruck aus 31) für ω einsetzen.
Dabei verschlägt es nichts, dasselbe Relativ als u zu verwenden, welches bereits im zweiten Gliede von w vorkommt.
[Man würde durch die Wahl zweier verschieden zu bezeichnender, unabhängig beliebiger Relative u und u' für das u ausserhalb und für das innerhalb des Ausdrucks von ω doch kein allgemeineres Ergebniss für w erhalten, als wenn man beide u identifizirt, aus dem Grunde weil die beiden Glieder von w einander gegenseitig ausschliessen, mithin auch bei übereinstimmender Wahl des u der aus diesem zum ersten Glied von w beigesteuerte Komplex von Stellenpaaren unabhängig beliebig bleibt von dem unter das zweite Glied fallenden Teile von u.]
In der That stimmt, da der Term 1'u wegen 1' ⋹ ā (siehe unten) eingehn wird, mit w = aă{uū̆ + (u + ū̆)g} + (ā + ā̆)u, w̄̆ = aă{uū̆ + (u + ū̆)ḡ̆} + (ā + ā̆)ū̆ nicht nur die Probe 1:
0'aăw̄̆ = 0'aăw ersichtlich wegen 0'ḡ̆ = 0'g, sondern auch die Probe 2. Letzteres insofern als, wenn bei a = 0'a das Relativ u selbst schon Wurzel der Gleichung aăū̆ = aău ist, ebendiese als w = u sich wiedererzeugt.
Dann wird nämlich auch aău = aăuū̆; es geht der mit dem Faktor g behaftete Term von w im vorhergehenden Gliede ein und wird: w = aău + (ā + ā̆)u = u, q. e. d.
Als Verallgemeinerung von 31) können wir somit den Satz notiren: 32) [Formel] .
Die zugefügte Resultante folgt nämlich mit aăww̄̆(⋹ ww̄̆) ⋹ 0' und aăw̄w̆(⋹ w̄w̆) ⋹ 0' durch Überaddiren zur Prämisse aă(ww̆ + w̄w̄̆) ⋹ 0 zunächst in der Gestalt aă · 1 oder aă ⋹ 0', woraus durch Überaddiren mit aā̆ ⋹ 0' endlich zu schliessen ist: a · 1 oder a ⋹ 0'.
Mit den gefundnen Werten von w, w̄̆ wird S. 304: v = ā̆(a + u) + aω, v̄̆ = ā̆(a + ū̆) + aω̄̆, av = a(ā̆ + ω), av̄̆ = a(ā̆ + ω̄̆), x = av · av̄̆ = a(ā̆ + ωω̄̆) = a{ā̆ + uū̆ + (u + 0'ū̆)gḡ̆ + 1'uḡ̆} = = a(ā̆ + ω) = a{ā̆ + uū̆ + (u + ū̆)g}, sintemal gḡ̆ = 0'gḡ̆ = 0'g = g sein muss (gleichwie das Analoge in ω gilt) und 1'ḡ̆ = 1', das Glied 1'u aber sich mit dem Faktor a, = 0'a, zerstört.
Damit ist die angegebne Lösung des linkseitigen Problems in 14) gewonnen.
Machen wir mit ihr auch noch die beiden Proben.
Man erhält x̄̆ = ā̆ + a{uū̆ + (u + ū̆)ḡ̆}, ax̄̆ = a{ā̆ + uū̆ + (u + ū̆)ḡ̆}, was sich von x selbst nur durch das Auftreten des Faktors ḡ̆ statt g unterscheidet.
Unter der Herrschaft des Faktors 0', der dem a anhaftet, ist aber die Ersetzung von ḡ̆ durch g gestattet — vergl. 30) — und somit ist ax̄̆ = x und stimmt die Probe 1.
Sollte ferner von vornherein aū̆ = u schon sein (was nur bei a ⋹ 0' möglich), so reduzirt sich x zu x = aā̆ + au + aug = a(ā̆ + u) = aā̆ + u, sintemal wegen u ⋹ a auch au = u sein wird.
Endlich folgt aber ā ⋹ ū, ā̆ ⋹ ū̆, aā̆ ⋹ aū̆ = u, wonach der erste Term im letzten Ausdruck des x vom zweiten absorbirt wird, und wir erhalten: x = u. Das heisst:
es stimmt auch die Probe 2.
Die Lösung des zweiten Problems 14) betreffend ist zu bemerken, dass das Relativ g sich selber nicht dual entspricht.
Demselben würde vielmehr ein Relativ γ dual entsprechen, das durch die Forderungen: γ + γ̆ = 1, γγ̆ = 1' definirt ist.
Man sieht leicht, dass: γ = 1' + g genommen werden kann.
Indem man die Lösung des ersten Problems 14), behufs Gewinnung von der des zweiten, dual umschreibt, wird also g durch 1' + g zu ersetzen sein.
Hier wird dann aber der Term 1' zu unterdrücken sein, weil man dem zweiten Gliede unsrer Lösung den Faktor ā zufügen kann und wegen 1' ⋹ a auch ā ⋹ 0', ā = 0'ā sein muss, der Term 1' hier also mit dem Faktor 0' zusammentrifft, der ihn aufhebt.
Wer diese Überlegung scheut, dem bleibt nichts übrig, als auch mit der angegebnen Lösung des zweiten Problems 14) direkt die beiden Proben zu machen.
Zu Probe 1 erhalten wir: x̄̆ = ā̆{a + uū̆ + (u + ū̆)ḡ̆} also a + x̄̆ = a + ā̆{uū̆ + (u + ū̆)ḡ̆}, wo wieder ḡ̆ als unter der Herrschaft des Faktors ā = ā0' stehend durch 0'ḡ̆ = 0'g = g ersetzbar ist, sodass in der That a + x̄̆ = x sich herausstellt.
Zu Probe 2 sei a + ū̆ = u.
Dann können wir wegen des in 14) bei x vorhandnen Gliedes a in den übrigen Gliedern das ū̆ auch durch a + ū̆ somit u ersetzen, womit sich x zu x = a + ā̆(u + ug) = a + ā̆u reduzirt.
Wegen a ⋹ u ist aber a = au, somit x = (a + ā̆)u. Ebendeshalb ist auch ū̆ ⋹ ā̆, a + ū̆ ⋹ a + ā̆, u ⋹ a + ā̆, (a + ā̆)u = u, somit x = u, q. e. d.
Anhangsweise wollen wir sogleich noch das Problem behandeln: die allgemeinste Relation von universalem Charakter, welche im identischen Kalkul zwischen den Verwandten von x konzipirt werden kann, nach diesem unbekannten Relativ aufzulösen.
Damit wird sich auch jedes System von Gleichungen und Subsumtionen erledigen, in denen die Verwandten des x blos identische Knüpfungen eingehen — bei Ausschluss aber von Ungleichungen.
Gedachte Relation — als die vereinigte Gleichung solchen Systems — hat die Form f(x, x̆) = 0, wenn f eine Funktion identischen Kalkuls vorstellt.
„Entwickelt“ muss sie sich darstellen in der Form: 33) axx̆ + bxx̄̆ + cx̄x̆ + dx̄x̄̆ = 0, worin die Parameter a, b, c, d gegebne von x unabhängige binäre Relative vorstellen.
Diese können aber nicht ad libitum gegeben sein; vielmehr involvirt die Gleichung schon nach dem identischen Kalkul die Relation abcd = 0 als Resultante der Elimination von x und x̆, welche die volle Resultante, die einzige zwischen den Parametern geforderte Relation sein würde, wenn diese beiden Unbekannten von einander unabhängig wären, kurz: wenn es y statt x̆ hiesse.
Bei der Abhängigkeit y = x̆ hingegen involvirt die Gleichung noch viel mehr Beziehungen zwischen den Parametern, und stehen wir zunächst vor einem Elimminationsprobleme.
Zieht man die konvertirte Gleichung mit der ursprünglichen zusammen, so kommt: (a + ă)xx̆ + (b + c̆)xx̄̆ + (b̆ + c)x̄x̆ + (d + d̆)x̄x̄̆ = 0, und folgt als Resultante mindestens schon: 34) (a + ă)(b + c̆)(b̆ + c)(d + d̆) = 0.
Ausmultipliziren liefert 16 Glieder, für die das Verschwinden gefordert ist.
Für die eine Hälfte von diesen aber folgt das Verschwinden bereits durch Konversion von selbst aus dem der andern, sodass wir wesentlich nur 8 partielle Resultanten haben, als deren Zusammenfassung z. B.: a(b + c̆)(b̆ + c)(d + d̆) = 0, oder besser noch: (a + ă)(b + c)(d + d̆) = 0 hingestellt werden kann.
Für die obigen 4 Koeffizienten wollen wir Abkürzungen einführen: α = a + ă, β = b + c̆, γ = b̆ + c, δ = d + d̆.
Dann ist identisch: ᾰ = α, δ̆ = δ, zugleich ist aber auch γ = β̆, β = γ̆, sodass von den beiden Namen β, γ einer, sagen wir γ, entbehrlich ist.
Die zu erfüllende Gleichung heisst jetzt: 35) αxx̆ + βxx̄̆ + β̆x̄x̆ + δx̄x̄̆ = 0, und die bisherige Resultante lautet: 36) αββ̆δ = 0.
Da das Verschwinden des dritten Gliedes durch Konversion aus dem des zweiten folgt und vice versa, so kann von diesen beiden Gliedern irgend eines weggelassen werden:
wir haben wesentlich nur drei Glieder zum Verschwinden zu bringen.
Der Symmetrie zuliebe wollen wir gleichwol alle vier Glieder beibehalten.
Eine weitre partielle Resultante ergibt sich durch folgende Überlegung.
Werden in den vier Verwandten zu x die individuellen Selbstrelative von den Aliorelativen gesondert, so hat man: x = 1'x + 0'x, x̄ = 1'x̄ + 0'x̄, x̆ = 1'x + 0'x̆, x̄̆ = 1'x̄ + 0'x̄̆, sintemal bekanntlich allgemein — 8) des § 9 — 1'ă = 1'a ist.
Damit wird: xx̆ = 1'x + 0'xx̆, xx̄̆ = 0'xx̄̆, x̄x̆ = 0'x̄x̆, x̄x̄̆ = 1'x̄ + 0'x̄x̄̆.
Inbezug auf den Selbstteil (selfpart, Skalar) der unbekannten Verwandten wird also lediglich gefordert sein, dass α1'x + δ1'x̄ = 0 werde, was die Resultante bedingt: 37) αδ1' = 0 oder αδ⋹ 0' und wonach, falls letztre erfüllt ist, der Selbstteil von x schon vorweg ermittelt werden könnte.
Der Rest der dem x auferlegten Forderung bezieht sich darnach nur mehr auf den Alioteil (Vektor) der unbekannten Relative, und die auftretenden Koeffizienten besitzen darin sämtlich den Faktor 0', oder es kann ihnen dieser jederzeit zugefügt werden.
Vereinigung der beiden Resultanten gibt: 38) αδ(1' + ββ̆) = 0, falls α = ᾰ, δ = δ̆, oder 39) (a + ă){1' + (b + c̆)(b̆ + c)}(d + d̆) = 0, was sich als die volle Resultante zu 33) erweisen wird.
Wie leicht zu sehen, kann jene auch äquivalent schon in der Form αδ(ββ̆ + 1'β̄β̄̆) = 0 oder αββ̆δ + 1'αβ̄β̄̆δ = 0 angeschrieben werden.
Denn dem ersten Glied 1' in 38) lässt sich die Negation (β̄ + β̄̆) des zweiten Gliedes als Faktor beifügen; da aber dieser = ββ̄̆ + β̄β̄̆ + β̄β̆ und hievon das erste und dritte Glied ⋹ 0' ist, so kommen von den durch Ausmultipliziren mit 1' entstehenden drei Gliedern zweie in Wegfall.
Etc.
Die Vollständigkeit unsrer Resultante liesse sich wol auf mehrern Wegen darthun, deren andre jedoch durch den ohnehin von uns zu gehenden entbehrlich gemacht werden.
Auf unserm Wege nämlich erledigt sich die Frage von selbst, indem es uns, die bisherige Resultante als erfüllt voraussetzend, eben gelingen wird, eine allgemeine Lösung (Wurzel) der Aufgabe zu gewinnen, mit welcher alsdann unbedingt die beiden Proben stimmen.
Wie der Forderung unsrer Resultante durch symmetrisch allgemeine Auflösung derselben nach den Koeffizienten a, b, c, d zu genügen sei, dies zu eruiren wollen wir uns für den Schluss der Untersuchung aufsparen und zunächst einfach diese Resultante als erfüllt annehmen.
Nach x̆ resp.
x geordnet ist nun unsre Gleichung 35): (αx + β̆x̄)x̆ + (βx + δx̄)x̄̆ = 0 = (αx̆ + βx̄̆)x + (β̆x̆ + δx̄̆)x̄ und liefert durch Elimination der evident gemachten („prominenten“) Unbekannten ohne Rücksicht auf die Abhängigkeit zwischen beiden: αβx + β̆δx̄ = 0 resp. αβ̆x̆ + βδx̄̆ = 0 — zwei Gleichungen, deren eine schon durch Konversion mit der andern zugleich gewährleistet erscheint, sodass wir nur die eine, z. B. erste, von ihnen zu erfüllen haben.
Dies geschieht — da laut Voraussetzung die zugehörige Resultante bereits erfüllt ist — auf die allgemeinste Weise durch den Ansatz: 40) [Formel] worin die mit einer augenscheinlich überflüssigen Klammer umgebenen einfachen Symbole hierdurch gekennzeichnet sein sollen als solche Terme (Faktoren), welche auch unterdrückt werden dürften.
Hiermit geht unsre Gleichung 35) für x gliedweise entsprechend über in diese für y: 41) αβ̄β̄̆yy̆ + ᾱβδ̄yȳ̆ + ᾱβ̆δ̄ȳy̆ + β̄β̄̆δȳȳ̆ = 0.
[Um bequem zu rechnen, multiplizire man αx mit αx̆, βx mit βx̄̆, etc.; auch unterlasse man nicht, die Resultante zu berücksichtigen, kraft welcher sich z. B. αxx̆ = αβ̄β̄̆yy̆ + αββ̆δȳȳ̆ zum ersten Gliede reduzirt, u. s. w.]
Die beiden mittleren Koeffizienten in dieser Gleichung schliessen bereits die Randkoeffizienten aus.
Auch letztere zerfällen wir, sie nach den α, δ vollends entwickelnd, in disjunkte Teile, und erhalten: 42) [Formel]
Indem wir nun die Unbekannte x successive in den unbestimmten Parametern: y (was bereits geschehn), z, w, v, u ausdrücken, bringen wir eines von den Gliedern oder Gliederpaaren unsres Gleichungspolynoms nach dem andern zum Verschwinden.
Bevor wir den Gang dieser Rechnungen näber darlegen sei erinnert, dass bei denselben die Resultante nicht ausser Acht gelassen werden darf.
Der nachrechnende Leser findet sonst zuweilen Koeffizienten, die mit den von mir angegebenen, einfacheren, zuerst nicht übereinzustimmen scheinen.
Zudem wird häufig von dem Satze a + b = a + āb [Th. 33+) Zusatz, in Bd. 1, S. 308] vor- oder rückwärts Gebrauch zu machen sein, wonach z. B. ᾱβ̄̆ + (α + β̆)β sich sofort zu ᾱβ̄̆ + β vereinfacht.
Wegen αββ̆δ = 0 wird aber auch beispielsweise sein:
[Formel] und dergleichen mehr — wie nach geeigneter eventuell mehrmaliger Anwendung genannten Satzes, erforderlichenfalles durch Addiren von (0 =)αββ̆δ, leicht zu sehen ist.
Zuerst bewirken wir, dass die beiden mittleren Glieder unsres Polynoms 35) in x, das ist die beiden unsrer letzten Zeile bei 42) in y, verschwinden, was sie a tempo thun werden, da eines blos das Konverse vom andern ist.
Zu dem Ende ist blos nach dem — etwa ersten — Schema 10) aufzulösen die Subsumtion ᾱβ̆δ̄y̆⋹y.
Wir finden: y = z + ᾱβ̆δ̄z̆, ȳ = z̄(α + β̄̆ + δ + z̄̆), oder besser entwickelt:
y = zz̆ + zz̄̆ + ᾱβ̆δ̄z̄z̆ + 0z̄z̄̆ yy̆ = zz̆ + ᾱβδ̄zz̄̆ + ᾱβ̆δ̄z̄z̆ + 0z̄z̄̆ ȳ = 0zz̆ + 0zz̄̆ + (α + β̄̆ + δ)z̄z̆ + z̄z̄̆ yȳ̆ = 0zz̆ + (α + β̄ + δ)zz̄̆ + 0z̄z̆ + 0z̄z̄̆ y̆ = zz̆ + ᾱβδ̄zz̄̆ + z̄z̆ + 0z̄z̄̆ ȳy̆ = 0zz̆ + 0zz̄̆ + (α + β̄̆ + δ)z̄z̆ + 0z̄z̄̆ ȳ̆ = 0zz̆ + (α + β̄ + δ)zz̄̆ + 0z̄z̆ + z̄z̄̆ ȳȳ̆ = 0zz̆ + 0zz̄̆ + 0z̄z̆ + z̄z̄̆.
Und es bleibt zu erfüllen: 43) 0 = αβ̄β̄̆δ̄zz̆ + αβ̄β̄̆δ(zz̆ + z̄z̄̆) + ᾱβ̄β̄̆δz̄z̄̆, wonach dann sein wird: x = (ᾱ + β̄)zz̆ + (ᾱ + β̄)zz̄̆ + (ᾱ + δ)β̆z̄z̆ + β̆δz̄z̄̆, x̄ = αβzz̆ + αβzz̄̆ + (αδ̄ + β̄̆)z̄z̆ + (β̄̆ + δ̄)z̄z̄̆, x̆ = (ᾱ + β̄̆)zz̆ + (ᾱ + δ)βzz̄̆ + (ᾱ + β̄̆)z̄z̆ + βδz̄z̄̆, x̄̆ = αβ̆zz̆ + (αδ̄ + β̄)zz̄̆ + αβ̆z̄z̆ + (β̄ + δ̄)z̄z̄̆.
Nun bringen wir zuerst das letzte Glied von 43) zum Verschwinden, indem wir z so bestimmen gemäss dem linkseitigen Schema 12), dass: ᾱβ̄β̄̆δz̄̆⋹z.
[Das a des Schema’s ist hier schon = ă = a + ă.]
Dies gibt: z = w + ᾱβ̄βδ̄w̄̆, z̄ = w̄(α + β + β̆ + δ̄ + w̆), besser also:
[Formel] .
Bleibt zu erfüllen: 44) 0 = αβ̄β̄̆δ̄ww̆ + αβ̄β̄̆δ(ww̆ + w̄w̄̆).
Wir bestimmen hiernächst w so, dass hievon das erste Glied verschwindet, also w⋹ᾱ + β + β̆ + δ + w̄̆ wird.
Dies gelingt nach dem rechtseitigen Schema 12) und entsteht: w = v(ᾱ + β + β̆ + δ + v̄̆), w̄ = v̄ + αβ̄β̄̆δ̄v̆, oder bequemer:
[Formel] .
Damit wird nun:
[Formel] .
[Und:
[Formel] ].
Endlich: [Formel] .
Hiermit wird jetzt:
[Formel] und bleibt cf. 37) in der That nur noch zu erfüllen der Kern unsrer Gl. 42): 45) 0'αβ̄β̄̆δ(vv̆ + v̄v̄̆) = 0.
Dies hat zu geschehn nach dem Schema 32) und wird:
[Formel] .
Damit erhalten wir endlich: 46) [Formel] wobei wegen 30) schon die ersten Glieder von xx̆ und x̄x̄̆ eigentlich wegfallen, sintemal auch der Koeffizient αβ̄β̄̆δ als implicite mit dem Faktor 0' behaftet angesehen werden kann.
Darnach wird in der That: αxx̆ = 0, βxx̄̆ = 0, β̆x̄x̆ = 0, δx̄x̄̆ = 0, und stimmt die Probe 1 bei beliebigem u.
Es stimmt aber auch die Probe 2. Genügt nämlich x der Forderung 35), so bewahrheitet sich die obige Lösung 46) für u = x, und zwar geht sie bei Fortlassung der Glieder die von vornherein verschwindende Faktoren haben, über in: x = (ᾱ + αβ̄β̆)xx̆ + (ᾱβ + β̄)xx̄̆ = ᾱxx̆ + β̄xx̄̆, was durch Überaddiren von 0 = αxx̆ + βxx̄̆ übergeht in x = xx̆ + xx̄̆ = x(x̆ + x̄̆) = x · 1 = x, q. e. d.
Man kann indess auch völlig nach den u ordnen und hat: 47) [Formel] wo wieder bei xx̆ und x̄x̄̆ die mit den g behafteten Terme herausfallen.
Es gibt noch (mindestens) eine hievon wesentlich verschiedene, aber ebenbürtige Lösung der Aufgabe, bei welcher die Randglieder mit den vorstehenden übereinstimmen [gleichwie auch in der vorhergehenden Schreibung 46) die in aparte Zeilen gesetzten Anfangsterme ungeändert bleiben], wogegen die beiden mittleren Glieder durch folgende zu ersetzen sind: 48) [Formel] .
Wegen [Formel] kann man nämlich unabhängig von dem Folgenden, oder der Eleganz zuliebe abhängig davon — nach Belieben — g mit ğ, gleichwie g mit ḡ vertauschen.
Überhaupt aber geht die aufzulösende Gleichung durch folgende drei Systeme von Vertauschungen nur in sich selbst über: 49) [Formel] wo die Vertauschungen der zweiten Zeile lediglich der Adventivforderung resp. Eleganz zuliebe (damit g, und nicht ḡ, im Ausdrucke von x figurire) mitausgeführt seien.
Ebendiese Systeme von Vertauschungen sind darum auch bei der Lösung unsrer Gleichung gestattet.
Das erste Vertauschungssystem führt das System der Lösungen nur in sich selbst über, resp. lässt es unverändert.
Dagegen fliesst durch das zweite (und übereinstimmend auch durch das dritte) System von Vertauschungen die neue Lösung 48) aus der zuerst gefundenen 47).
Auf ebendiese zweite Lösung würde man auch heuristisch gekommen sein, wenn man bei der Herleitung der Ergebnisse seinerzeit, um y durch z auszudrücken, anstatt des ersten Schema’s 10) das zweite benutzt hätte, wonach zu setzen gewesen wäre: y = z(α + β̄ + δ + z̆), ȳ = z̄ + ᾱβδ̄z̄̆.
Aus den vorstehend angegebenen zwei Formen oder Schemata der Lösung des allgemeinen Problems 33) lassen sich nachträglich als partikulare Fälle die Lösungen der sämtlichen Elementarprobleme 10) bis 21) mit Leichtigkeit (wieder) ableiten.
Und zwar überall, wo sich dort nur eine Form der Lösung angegeben findet, führen beide Schemata übereinstimmend zu ebendieser.
Wo sich dagegen dort zwei Lösungsformen hintereinander angegeben finden, fliesst die erste Form aus unserm ersten 47), die zweite aus dem letzten Schema 48).
Eine Ausnahme hiezu bildet jedoch das Problem 13), wo auffallenderweise unsre beiden Schemata nur die erste Lösungsform übereinstimmend liefern, wogegen die zweite sich selbständig primo impetu ergab und ganz leicht direkt zu beweisen ist.
Dies lässt allerdings vermuten, dass es auch allgemein noch andre Lösungsformen gibt, auf die vielleicht Benutzung der andern Lösungsform von 13) auf S. 304 hinführen wird. —
Als eine ausserhalb dieses Rahmens liegende Partikularisirung unsres allgemeinen Problems wollen wir endlich noch das folgende Unterproblem samt seiner Lösung hervorheben: 50) [Formel] .
Dasselbe scheint zwar auf den ersten Blick ein Gegenstück zu bilden zu jenem Hülfsprobleme 32), welches wir der Lösung der Aufgabe 14) vorausschicken mussten, erweist sich aber, wie ein Blick auf die Lösungen beider zeigt, als doch von wesentlich anderem Charakter. —
Der Versuch, der Resultante 39) durch symmetrische Bestimmung der vier Koeffizienten a, b, c, d in ebensovielen unbestimmten Parametern allgemein Genüge zu leisten, führt zu einem eleganten Theoreme, welches wir vorweg statuiren wollen:
Die Gleichung 33) axx̆ + bxx̄̆ + cx̄x̆ + dx̄x̄̆ = 0 ist im Allgemeinen absurd, kann keine Wurzel x haben, sie wird erst durch Multiplikation mit 51) M = āā̆ + 0'(b̄c̄̆ + b̄̆c̄) + d̄d̄̆ zu einer nach x lösbaren, deren Bestehen möglich ist; und sie war es von vornherein stets dann und nur dann, wenn 52) a + b + c + d ⋹ M ist, d. h. wenn Multiplikation mit M die sämtlichen Koeffizienten der Gleichung ungeändert lässt.
Dieses M könnte füglich — in Analogie zum „integrirenden Faktor bei Differentialgleichungen — als ein „solvirender (oder resolvirender) Faktor“ der Gleichung bezeichnet werden.
Um zunächst den letzten Teil der Behauptung unsres Theorems (vom; ab) zu beweisen, braucht man sich blos zu überzeugen, dass obige Subsumtion vom Prädikate M mit unsrer Resultante 39) äquivalent ist.
Zu dem Ende wird man die Subsumtion rechts auf 0 bringen.
Man erhält: 53) (a + b + c + d)(a + ă){1' + (b + c̆)(b̆ + c)}(d + d̆) = 0, eine Gleichung, welche einerseits offenbar von der Resultante bedingt wird, wie sie andrerseits auch diese nach sich zieht.
Denn da (a + b + c + d)a = a ist, hat sie jedenfalls beim Ausmultipliziren linkerhand den Teil der Resultante: a{1' + (b + c̆)(b̆ + c)}(d + d̆) = 0 zur Folge, woraus der noch ausstehende Teil dieser: ă mal idem = 0 durch Konvertiren hervorgeht, also damit zugleich gewährleistet erscheint.
Um den ersten Teil unsres Theorems zu beweisen, wollen wir demselben eine etwas andre Fassung geben, in welcher er unmittelbar die symmetrisch allgemeine Lösung (nach den Unbekannten a, b, c, d) der Resultante angibt.
Zu dem Ende empfiehlt es sich, einen kleinen Bezeichnungswechsel vorzunehmen, nämlich die bisherigen Koeffizientenausdrücke α, β, δ sich ad hoc durch irgend welche andre Namen, wie etwa A, B, D, ersetzt zu denken: um so die Buchstaben α, β, γ, δ frei zu bekommen zur Bezeichnung der willkürlichen Parameter, welche unsern Unbekannten a, b, c, d zu entsprechen haben.
Jener Teil unsres Theorems stellt sich dann so dar.
Wird für beliebige α, β, γ, δ 54) ᾱᾱ̆ + 0'(β̄γ̄̆ + β̄̆γ̄) + δ̄δ̄̆ = μ genannt, so ist 55) a = αμ, b = βμ, c = γμ, d = δμ die Lösung, das allgemeinste System von Wurzeln a, b, c, d unsrer Resultante 39).
Beweis.
Probe 1 besteht darin, zu zeigen, dass bei Einsetzung vorstehender Werte von a, b, c, d (nebst μ) in die Resultante 39) dieselbe identisch in α, β, γ, δ — als eine allgemeine Formel — erfüllt ist.
Da augenscheinlich μ̆ = μ ist, erhalten wir — zunächst noch unter Beibehaltung des μ: (αμ + ᾰμ){1' + (βμ + γ̆μ)(β̆μ + γμ)}(δμ + δ̆μ) = 0, oder μ · (α + ᾰ){1' + (β + γ̆)(β̆ + γ)}(δ + δ̆) = 0, was augenscheinlich richtig, indem die linke Seite nichts andres als μμ̄ ist.
Probe 2 verlangt zu zeigen, dass unsre Lösung auch jedes System von Wurzeln der Resultante zu liefern fähig ist.
Sei also a, b, c, d irgend ein System von Werten, welches die Resultante erfüllt.
Alsdann braucht man, um ebendieses zu erhalten, blos α = a, β = b, γ = c und δ = d anzunehmen.
Dadurch wird μ in M übergehen, und dass aus der erfüllten Resultante folgt: a⋹M, b⋹M, c⋹M, d⋹M, somit in der That a = aM, b = bM, c = cM, d = dM wird, haben wir oben schon gezeigt.
Somit stimmt auch die Probe 2, oder es ist auch die „Adventivforderung“ von unsern Lösungen erfüllt. —
Ich hatte das Theorem systematisch gefunden, indem ich unter Benutzung der benötigten von den in Bd. 1 und 2 erledigten Problemen „symmetrisch allgemeiner Lösungen“ zuerst die allgemeinsten Wurzeln A, B, D der Gleichung A(1' + B)D = 0 bestimmte, sodann den Forderungen A = Ă, D = D̆ Genüge leistete, endlich die Gleichungen a + ă = A, b + c̆ = B, d + d̆ = D nach den Unbekannten linkerhand auflöste.
Doch dürfte es zu weitläufig sein, diesen Gang mit allen seinen Stadien hier detaillirt vorzulegen.
Bemerkt mag nur noch werden, dass man die Ausdrücke der beiden Randkoeffizienten — wenn auch: auf Kosten der Symmetrie hinsichtlich aller vier Koeffizienten — durch wesentlich einfachere ersetzen, nämlich als das allgemeinste System der Wurzeln auch dieses hinstellen könnte: a = α(0' + δ̄δ̄̆), b = β(ᾱᾱ̆ + δ̄δ̄̆ + β̄̆γ̄), c = γ(ᾱᾱ̆ + δ̄δ̄̆ + β̄γ̄̆), d = δ(0' + ᾱᾱ̆) und dass es ferner bei b und c gestattet sein würde innerhalb der Klammer das Glied 1' hinzuzufügen — wofür der Nachweis dem Leser überlassen sei.
§ 22. Zweite Stufe der Auflösungsprobleme in drei Buchstaben.
Kettenproblem, Transitivität und anderes.
Die in einer Proposition zwischen drei Buchstaben auf der einen Seite vorkommende Knüpfung sei jetzt eine relative.
Wir haben dann dieselben Haupt- und Unter-Abteilungen der möglichen Auflösungsprobleme wie im vorigen Paragraphen; nur sind die wirklich zu lösenden Aufgaben jetzt zahlreicher, weil einerseits die Knüpfungen nicht mehr kommutativ sind, also Vor- und Nach-Multipliziren resp. -Addiren unterschieden werden müssen, und andrerseits auch die Tautologiegesetze, sowie die Formeln xx̄ = 0, x + x̄ = 1 zur Reduktion der Aufgaben nicht mehr zur Verfügung stehen.
Sollen namentlich zwei Buchstaben x in eine Knüpfung eingehen, so werden wir durch ein Semikolon oder aber das Pluszeichen verknüpft zu denken haben die beiden Werte eines jeden der 16 Paare: 0)
[Formel] während bei identischer Knüpfung von diesen Paaren sogleich die vier der Hauptdiagonale samt den sechs darüber stehenden in Wegfall kamen.
Ausserdem aber sind die entsprechenden Aufgaben jetzt ungleich schwieriger zu lösende, sodass wir vorerst die Fälle, wo die aufzulösende Proposition eine Gleichung ist, beiseite lassen und uns nur mehr mit der Auflösung der (vor- oder rückwärtigen) Subsumtionen beschäftigen wollen.
Die erste Hauptabteilung der Probleme — denen 8) des § 21 entsprechend — wird gebildet von den acht (resp. — bei Mitberücksichtigung auch von Gleichungen — zwölf) elementaren Inversionsproblemen, denen wir bereits eine eigene (die siebente) Vorlesung gewidmet haben, und welche sonach unter den „einfachsten“ Auflösungsproblemen hier systematisch sich einreihen.
Diese Probleme gruppirten sich in zwei (resp. drei) Gespanne und dürfen hier als erledigt gelten.
Wenn wir ferner von jedem Gespanne oder Quadrupel von Problemen blos einen Repräsentanten anführen, so umfasst die zweite Hauptabteilung der Probleme mit ihrer vorläufig ersten Abteilung — denen 9) bis 14) des § 21 entsprechend — die acht Gespanne, deren typische Vertreter die vier Subsumtionen: 1)
x; a ⋹ x, x̄; a ⋹ x, x̆; a ⋹ x, x̄̆; a ⋹ x nebst den dazu rückwärtigen sind: 2)
x⋹x; a, x ⋹ x̄; a, x ⋹ x̆; a, x ⋹ x̄̆; a.
Mit ihrer vorläufig zweiten Abteilung sollte sie — den Problemen 15) bis 21) des § 21 entsprechend — die acht Gespanne umfassen, welche die vier Subsumtionen: 3)
x; x ⋹ a, x; x̄ ⋹ a, x; x̆ ⋹ a, x; x̄̆ ⋹ a samt den dazu rückwärtigen: 4) a⋹x; x, a ⋹ x; x̄, a ⋹ x; x̆, a ⋹ x; x̄̆ vertreten.
Bei Citaten unterscheiden wir die vier Probleme einer jeden Zeile 1) bis 4) durch ein an ihrer Chiffre angebrachtes Suffixum 1 bis 4.
Von den angeführten vier Zeilen kommt nun aber die dritte in Wegfall, indem deren Subsumtionen nach dem ersten Inversionstheoreme bezüglich äquivalent sind mit: x⋹a ɟ x̄̆, x ⋹ a ɟ x̆, x ⋹ a ɟ x̄, x ⋹ a ɟ x, sonach augenscheinlich, in umgekehrter Reihenfolge genommen, den Gespannen der ersten Zeile bereits angehören.
Die Probleme der ersten und dritten Zeile sind also wesentlich dieselben; es ist als Gesamtheit 1) = 3) und verbleiben, was die aufzulösenden Subsumtionen anlangt, statt 16 nur mehr 12 Quadrupel von Problemen in unsrer zweiten Hauptabteilung, den Zeilen 1), 2) und 4) entsprechend — welche wol am besten demgemäss nun auch in drei Abteilungen geschieden werden.
Unter diesen finden sich gleich zu Anfang die hochbedeutsamen Probleme, welche uns später zum Vorwurf, Thema der Dedekind’schen Kettentheorie dienen.
Was Gleichungen anbelangt, würden sich den genannten in zwei weitern Abteilungen die acht Gespanne anreihen, deren Repräsentanten man erhält, indem man in 1) oder 2) und 3) oder 4) die Subsumtionszeichen durch Gleichheitszeichen ersetzt — Probleme, die (bei Gleichungen) sich als wesentlich verschiedene herausstellen.
Sonach umfasst die zweite Hauptabteilung 4 × 3 + 4 × 2 = 20 Quadrupel von Problemen — und ohne die Gleichungen zwölfe.
Was die Probleme der dritten Hauptabteilung betrifft, so erhalten wir die Repräsentanten von deren Gespannen jedenfalls vollständig, wiewol überzählig, wenn wir die 16 Paare 0), je mit eingeschaltetem Semikolon, ⋹ x setzen, ferner diese Subsumtionen auch rückwärtig ansetzen, endlich die ersten 16 Subsumtionszeichen auch in Gleichheitszeichen verwandeln.
Von diesen 16 × 3 = 48 Repräsentanten sind aber die 6 × 3 = 18 wegzulassen, welche von den 6 Paaren unterhalb der Hauptdiagonale in 0) herrühren; denn diese gehören schon bezüglich zu den Gespannen der ihnen symmetrisch oberhalb der Hauptdiagonale gegenüberstehenden Repräsentanten.
Oder umgekehrt.
In der That geht z. B. der Ansatz x; x̄ ⋹ x aus dem x̄; x ⋹ x hervor, indem man x durch x̆ durchweg ersetzt und beiderseits konvertirt.
Etc.
Es verbleiben also höchstens 10 × 3 = 30 Repräsentanten.
Schreiben wir von diesen die ersten zehne, nämlich die „vorwärtigen“ Subsumtionen hin, so erhalten wir aus der Hauptdiagonale zunächst die vier Repräsentanten:
[Formel] und von oberhalb derselben die sechse:
[Formel] .
Dieselben Subsumtionen wären nun auch rückwärtig, sowie als Gleichungen anzusetzen.
Während sich aber diese von uns nicht hingeschriebenen 20 Propositionen als die Repräsentanten von ebensovielen wesentlich verschiedenen und selbständig zu lösenden Problemen erweisen werden, reduziren sich die vorstehend hingeschriebenen 10 Propositionen — die wir uns mit den Zahlen 1 bis 10 numerirt denken wollen — bedeutend, nämlich auf nur fünf Aufgaben.
Die Abteilung umfasst also 25 Probleme (an Subsumtionen 15).
Um dies einzusehen, formen wir unsre zehn Subsumtionen um, indem wir gemäss dem ersten Inversionstheoreme einmal den zweiten und ebenso den ersten relativen Faktor transponiren, d. i. auf die andre Seite schaffen.
Durch Vertauschung von x mit einem seiner Verwandten bewirken wir hierauf, dass der bei diesem Transponiren frei werdende (sich isolirende) Term x selbst wird, und stellen darunter diejenige von den Subsumtionen 1 bis 10 mitsamt ihrer Nummer, zu deren Gespann gehörig sich die erhaltene Umformung erweist.
Auf diese Weise erhalten wir für die vier ersten Subsumtionen das Tableau: und für die sechs letzten dieses: .
Hieraus ist ersichtlich, dass nach den Prinzipien des Dualismus und der Konjugation, eventuell auch mittelst Vertauschung von x mit einem seiner drei verwandten Relative, aufeinander zurückführbar sind die Gespanne von 1 und 7, 2 und 9, 3 und 10, 5 und 6 und 8, wogegen blos dasjenige von 4 unabhängig bleibt von den übrigen.
Die mehrerwähnte Vielförmigkeit unsrer Disziplin erweist sich hier von Vorteil, insofern sie uns gestattet oft mehrere Probleme mit einem Schlage zu lösen.
Was die (ja zahlreicheren) Subsumtionenprobleme unter den vorstehend aufgezählten Aufgaben betrifft, so gelang es mir, dieselben sämtlich zu lösen bis auf zweie, welche der zweiten Hauptabteilung angehören.
Ich will sie mitsamt ihren oft in mehrern Formen möglichen Lösungen nunmehr im Überblick angeben und letztere abteilungsweise begründen.
Zweite Hauptabteilung, bestehend aus 12 Gespannen von Subsumtionenproblemen — in drei (Unter-)Abteilungen — und 8 Gespannen von Gleichungsproblemen — in zwei Abteilungen.
Die zwölferlei Subsumtionenprobleme.
Erste Unterabteilung — aus 1) und 3) entspringend.
Erstes Gespann — zum „Kettenprobleme“: 5)
[Formel] , wo bezüglich 5') [Formel] bedeutet.
Die unbegrenzten Iterationen dieser 8 Funktionen sind hier aber einer bemerkenswert übersichtlichen Darstellung fähig, nämlich die ersten jedes Paares dieser: 5'') [Formel] — somit die zweiten: nachdem ā̆ für a gesetzt ist, links und rechts vom Mittelstriche vertauscht.
Der Art nach ist 5) blos ein konjugirtes Zweigespann, weil schon solche Parametervertauschung die dualen Probleme in einander überführt.
Führt man demnach zwei Abkürzungen ein, indem man definirt als
die „a-Kette“ oder „Kette von a“: das „a-Gekett“ oder „Gekett von a“: 6)
[Formel] so stellen sich unsre Lösungen konzisest wie folgt dar: 5''')
Ich habe geschwankt, ob nicht vielleicht „Seil“ für „Gekett“ den Vorzug verdiene, und will möglicherweise passenderen Benennungsvorschlägen hiermit nicht entgegenstehn.
Anlässlich von 6) wollen wir auch noch für das Knüpfungsergebniss aller dortigen Terme ohne den Anfangsterm sogleich eine weitre Abkürzung einführen, wofür die Benennungen (linkerhand wenigstens) sich in der nächsten Vorlesung rechtfertigen.
Wir definiren ein Relativ a00 als a-Bildkette, oder Kettenbild von a: 7)
[Formel] wo dann sein wird: 8) sowie auch — unter ā0 stets (ā)0 verstanden, etc. vergl. § 5 S. 71: 9)
[Formel]
a0 = 1' + a00, a00 ⋹ a0 a1 = 0'a11, a1 ⋹ a11,
Die damit eingeführten Begriffe besitzen noch viele bemerkenswerte Eigenschaften.
Die Ausführlichkeit, mit der wir in der nächsten Vorlesung auf alles eingehn was mit dem Probleme 5) zusammenhängt, wird es rechtfertigen, wenn wir dasselbe hiernächst blos summarisch, „über Pausch und Bogen — gleich den übrigen — behandeln.
Zweites Gespann: 10) [Formel] 10) [Formel] .
Drittes Gespann. 11)
[Formel] , 11') [Formel]
Auch für diese 8 Funktionen sind die Iterationen von sehr übersichtlichem Bildungsgesetze, nämlich für die erste jedes Paares stellen sich die f∞(u) dar als: 11'') , wie sie sich für die erste Zeile z. B. aus der unschwer direkt zu etablirenden Rekursion leicht rechtfertigt.
f3(u) = ă; f(u); a + f(u) f3(u) = {ă ɟ f(u) ɟ a}f(u)
Wie uns selbstverständlich a1 = a und (a ɟ)1 oder (ɟ a)1 = a bedeutet, so empfiehlt sich (hier), a0 = 1' und (a ɟ)0 = (ɟ a)0 = 0' zu definiren.
Für die zweite Funktion jedes Paares erhält man die analoge Darstellung aus 11''), nachdem man a durch ā ersetzt hat, mittelst geeigneter Umstellung, d. i. Vertauschung der „über’s Kreuz“ stehenden Angaben.
Viertes Gespann. 12)
[Formel] .
Zum letzten Probleme: x; x ⋹ a oder x2 ⋹ a sei eine Anmerkung gestattet — schon weil sich an dasselbe gewisse Distinktionen bei Relativen, und nicht unwichtige Begriffe, knüpfen.
Wie bei allen Problemen, die einen Parameter a enthalten, die Fälle besondre Beachtung verdienen, wo derselbe einen Modulwert annimmt, so auch hier.
Für a = 1 wird x = u vollkommen willkürlich, wie vorauszusehen gewesen.
Für a = 0' ergibt sich x = ū̆u ⋹ 0' als allgemeine Lösung der Forderung x; x ⋹ 0'.
Für a = 1' oder auch 0 ergibt sich keine Vereinfachung des Ausdrucks für die Wurzel x.
Gleichwol verdient der Fall a = 0, in welchem die aufzulösende Subsumtion in eine Gleichung x; x oder x2 = 0 übergeht, besondre Beachtung:
Gibt es überhaupt eine natürliche Zahl n derart, dass xn = 0 ist, so soll nach Peirce’s2 p. 53 treffendem Vorschlage x ein exhaustibles oder erschöpfbares Relativ heissen.
Die Relative zerfallen also in erschöpfbare und unerschöpfliche.
Ein inexhaustibles Relativ ist ein solches, von dem keine Potenz verschwindet.
Ist n = 2, so will Peirce ibidem das Relativ x ein nicht-repetirendes (nicht wiederholendes, „non-repeating“) nennen, wogegen Relative, deren relatives Produkt in sich selbst („Quadrat“) nicht verschwindet, wiederholende“ (repeating) zu nennen wären.
Ich möchte für jenes den Ausdruck: „exhaustes“ oder „erschöpftes Relativ“ vorziehen.
Ein erschöpftes Relativ ist zum Beispiel „Gattin von-“: es gibt keine Gattin von der Gattin (von jemand).
Ein solches Relativ kann sozusagen nicht von sich selbst genommen werden; ein erschöpfbares aber nicht öfter als eine bestimmte Anzahl mal.
Ein erschöpfbares Relativ wäre z. B. „Vorgesetzter (praepositus) von-“, „Sklave von- (manche Negersklaven halten sich selbst noch Sklaven), „Untergebener von-“.
Man muss ja schliesslich zu einem obersten Vorgesetzten, der einen solchen seinerseits nicht mehr hat, gelangen.
Etc.
Ein unerschöpfliches Relativ wäre „Ehegespons von-“ (consort) schon bei monogamischen Institutionen.
Wie durch Konversion zu sehen, muss das Konverse eines erschöpfbaren resp. erschöpften Relativs auch wieder ein solches sein.
Mit Obigem ist nun gefunden, dass das allgemeinste erschöpfte Relativ in den drei Formen angebbar ist: 13) [Formel] .
Es wäre dem Studirenden anzuraten, dass er für einen eng begrenzten Denkbereich mittelst „Ausrechnung“, Evaluation des x für verschiedene aufs Geratewol angenommene Werte von u sich überzeuge, wie eine jede von diesen Formeln sofort zur Kenntniss einer Menge von Relativen führt, deren Quadrat verschwindet.
Damit nicht durchweg die schon bekannte Wurzel x = 0 herauskomme, braucht u blos Leerreihen zu haben (ohne doch selbst zu verschwinden).
Ebenso wie bei n = 2 lässt sich aber auch für jedes andre bestimmte n die allgemeine Wurzel der Gleichung xn = 0 mit dem ersten Anlauf in verschiednen Formen aufstellen.
Und ein Gleiches gilt schon für die noch allgemeinere Subsumtion:
xn⋹a.
Es wird genügen, dies noch für n = 3 darzulegen.
Je nachdem wir in x; x; x ⋹ a den ersten, zweiten oder dritten relativen Faktor mittelst Transponirens der übrigen Faktoren gemäss dem ersten Inversionstheoreme isoliren, erhalten wir: (x3 ⋹ a) = (x ⋹ a ɟ x̄̆ ɟ x̄̆) = (x ⋹ x̄̆ ɟ a ɟ x̄̆) = (x ⋹ x̄̆ ɟ x̄̆ ɟ a) = = {x = x(x̄̆ ɟ x̄̆ ɟ a)(x̄̆ ɟ a ɟ x̄̆)(a ɟ x̄̆ ɟ x̄̆)} — wo im letzten Ausdrucke von den drei letzten Faktoren auch irgend einer oder zweie unterdrückbar.
Demnach ist die allgemeine Lösung gegeben durch: 14) [Formel] — mit dem gleichen Zusatze.
Denn nach dem Vorhergehenden stimmt hiermit augenscheinlich die Probe 2. Dass aber auch die Probe 1 stimmt, erkennt man so.
Wird unter x der ihm gleichgesetzte Ausdruck verstanden, der aus vier resp. mindestens zwei Faktoren besteht, unter denen sich aber der Faktor u befindet, so ist nach 5) des § 6: x; x; x ⋹ α; β; γ, wenn α gleichwie β und γ einen Faktor von x — nach Belieben unter den vieren ausgewählt — bedeutet.
Man kann nun z. B. die Auswahl treffen: α; β; γ = u; (ū̆ ɟ a ɟ u); u ⋹ u; u ɟ a ɟ u; ū̆ ⋹ 0' ɟ a ɟ 0' = a gemäss 7) des § 6, 3) und 11) des § 8.
Und ebenso kann man wählen: α; β; γ = u; u; (ū̆ ɟ ū̆ ɟ a) ⋹ u; (u; u; ɟ ū̆ ɟ a) ⋹ u; (0' ɟ ū̆ ɟ a) = = u; (ū̆ ɟ a) ⋹ u; ū̆ ɟ a ⋹ 0' ɟ a = a, q. e. d.
Die Ausdehnung auf höhere Exponenten unterliegt nicht der geringsten Schwierigkeit und ist nach Bildungsgesetz und Beweis von 14) nur quantitativ verschieden.
Zweite Unterabteilung — aus 2) entspringend.
Erstes Gespann: 15) [Formel] .
Falls a = 1, 0, 1', 0' ein Modul ist, lässt sich die Lösung in geschlossner Form angeben und ist z. B.: 15') [Formel] .
Diese Formel ist blos eine empirische Zusammenfassung der vier Formeln, die sich für die genannten Fälle wiederum aus ihr ergeben, und die leicht einzeln zu entdecken und zu verifiziren waren.
Zweites Gespann: 16) .
Drittes Gespann: 17) [Formel] .
Viertes Gespann: 18) .
Bevor wir zur dritten Unterabteilung — die aus 4) entspringt, und deren Probleme von schwierigerer Art sind — übergehn, wollen wir über Herleitung und Begründung des Bisherigen das Nötige sagen.
Wo verschiedene Formen der Problemstellung einander äquivalent gesetzt sind, wird der Leser diese leicht — durch Transponiren des einen oder andern Terms, eventuell in Verbindung mit beiderseitigem Konvertiren oder auch Kontraposition — auf einander zurückführen.
Für die Probleme, in denen x isolirt als Subjekt steht, ist stets x = 0, für die, wo es als Prädikat steht, ist x = 1 als eine partikulare Lösung angebbar, und deshalb kann keines der bisherigen Probleme eine Resultante involviren.
Die Herleitung oder Entdeckung sämtlicher angegebnen Lösungen ist durch mein Theorem 1) des § 13 nahe gelegt, ja gegeben, weil x bald als Subjekt, bald als Prädikat, zuweilen auch (in den verschiednen Formen einunddesselben Problems) in beiden Eigenschaften von vornherein isolirt oder isolirbar erscheint, was dann auch zu verschiednen Lösungsformen führte.
Wir brauchen darnach die Probe 2 überhaupt nicht mehr zu machen, und die Probe 1 vorweg da nicht, wo die Lösung ausdrücklich als ein f∞(u) sich angegeben findet.
Immerhin wollen wir diese Probe 1, sintemal ein Luxus auch nicht vom Übel, hier wenigstens für die zweite Aufgabe links in 5), das ist das „Kettenproblem“katexochen: a; x ⋹ x, mit beiden Lösungsformen desselben erhärten.
Die erste Lösungsform desselben lautet: x = a0; u = (1' + a + a2 + a3 + …); u = u + a; u + a; a; u + a; a; a; u + … — sintemal 1'; u = u ist — und ist zu zeigen, dass a; x ⋹ x sein müsse bei ganz beliebigem u.
In der That wird a; x = a; a0; u = a; u + a; a; u + a; a; a; u + … sich als die Summe der Glieder unsrer x-Reihe vom Anfangsgliede ab darstellen.
Statt dieses Nachweises konnte man sich auch einfacher schon mit dem des (in nächster Vorlesung noch eingehend ventilirten) Satzes: a; a0 ⋹ a0 begnügen, aus welchem die Behauptung der Probe 1 mittelst beiderseitig relativen Nachmultiplizirens mit u hervorgeht.
Die zweite Lösungsform des Kettenproblems lautet: x = ā̆1 ɟ u = 0'ā̆(ā̆ ɟ ā̆)(ā̆ ɟ ā̆ ɟ ā̆) … ɟ u = u(ā̆ ɟ u)(ā̆ ɟ ā̆ ɟ u)(ā̆ ɟ ā̆ ɟ ā̆ ɟ u) … — sintemal 0' ɟ u = u ist.
Um zu sehn, dass a; x ⋹ x sein muss, bemerken wir, dass in der That a; x = a; u (ā̆ ɟ u)(ā̆ ɟ ā̆ ɟ u) … ⋹ (a; u){a; (ā̆ ɟ u)}[a; (ā̆ ɟ ā̆ ɟ u)] … ⋹ ⋹ (a; ā̆ ɟ u)(a; ā̆ ɟ ā̆ ɟ u) … ⋹ (0' ɟ u)(0' ɟ ā̆ ɟ u)(0' ɟ ā̆ ɟ ā̆ ɟ u) … = = u (ā̆ ɟ u)(ā̆ ɟ ā̆ ɟ u) … = x nach 5) des § 6, dem Satze ab ⋹ b nebst 7)
[und 25)] des § 6, endlich 11) des § 8, sich bewahrheitet.
Auch dieser Nachweis konnte auf den von a; ā̆1 ⋹ ā̆1 reduzirt werden. —
Es kann darum auf obiges Problem und seine Lösung das Bedenken oder der Vorbehalt keine Anwendung finden, den ich zu dem Th. 1 des § 13 für den Fall eines unbegrenzten Denkbereichs S. 189 sq. ausgesprochen habe. —
Nun erweist sich aber die Funktion f(u), deren unbegrenzte Iterationen uns die Lösung nach 1) ausdrücken sollten, bei gerade der Hälfte sämtlicher bisherigen Probleme als invariant.
In diesen Fällen, wo f2(u) = f(u) = f∞(u) ist, wird die Lösung, statt durch x = f∞(u), einfacher schon durch x = f(u) darzustellen sein; die Lösung wird dann in geschlossener Form erhalten.
Umgekehrt, wenn x = f(u) selbst schon die allgemeine Wurzel ist, so muss der stets von unsern Lösungen erfüllten Adventivforderung gemäss, d. h. weil Probe 2: f(x) = x schon stimmt, auch f{f(u)} = f(u) für jedes u sein, m. a. W. ist dann f(u) als invariant erwiesen.
Wir brauchen also blos und müssen noch für alle in geschlossner Form angegebnen Lösungen die Probe 1 nachliefern.
Dies thun wir, nachdem es vorhin bei 5) bereits geleistet ist, je für das erste Problem jeden Gespannes mit seinen sämtlichen Lösungsformen.
Probe 1 zu 10) oder 12).
Für x = ū; a + u wird x̄ = (u ɟ ā)ū, somit x̄; a = (u ɟ ā)ū; a ⋹ ū; a ⋹ x, q. e. d.
Die andern Lösungsformen verstehn sich hier aus der Äquivalenz der Probleme nach dem Schema der vorstehenden.
Zu 12) oder 14).
Für x = ū̆; a + u + a; ū̆ wird: x̄̆; a = (u ɟ ā̆)ū̆(ā̆ ɟ u); a ⋹ ū̆; a ⋹ x, q. e. d.
Man kann (als Variante) auch schliessen: x̄̆; a ⋹ (u ɟ ā̆); a ⋹ u ɟ ā̆; a ⋹ u ɟ 0' = u ⋹ x. Etc.
Zu 16) oder 22). x = ū; a · u gibt x̄ = u ɟ ā + ū, x̄; a = (u ɟ ā); a + ū; a, und da ū; a · u ⋹ ū; a ist, so folgt a fortiori x ⋹ x̄; a, q. e. d.
Zu 18) oder 24). x = ū̆; a · u gibt x̄̆ = ū̆ + ā̆ ɟ u, also x̄̆; a = ū̆; a + (ā̆ ɟ u); a und x ⋹ x̄̆; a, q. e. d.
Dritte Unterabteilung — aus 4) entspringend.
Die grössere Schwierigkeit der Probleme von dieser rührt daher, dass kein Theorem bekannt ist, welches gestattete, wenn ein relatives Produkt als Prädikat steht (resp. eine relative Summe als Subjekt), den einen Term desselben (derselben) durch Hinüberschaffen des andern zu isoliren.
Darum auch verhelfen uns die Theoreme 1) des § 13 diesmal nicht zur Lösung.
Es gelang mir gleichwol für die eine Hälfte der Probleme befriedigende allgemeine Lösungen — in mehreren Formen — zu entdecken, und will ich zuerst diese vortragen und begründen.
Erstes Gespann — blos dyadisch, sive (duales) Zweigespann: 19) [Formel] .
Drittes Gespann: 20) [Formel] .
Zur Entdeckung dieser Lösungen verhalf der Anblick der rigorosen Lösungen, welche — bei den Problemen 41) und 43) — sich aufgrund der partikularen Wurzel x = 1 gemäss 17) des § 12 systematisch ergeben, in Verbindung mit einem ähnlichen Raten, wie es sich schon beim zweiten Inversionsprobleme in § 18, S. 248 als erfolgreich bewährte.
Jene lauten:
[Formel] , [Formel] .
Behufs Beweises der zu diesen Problemen in 19) und 20) angegebenen befriedigenden Lösungen ist nun blos die Probe 1 zu machen.
Denn wegen a(x̄ ɟ x̄) = 0 resp. a(x̄ ɟ x̄̆) = 0 stimmt für u = x schon augenscheinlich die Probe 2.
Probe 1 zu 41).
Mit der ersten Lösungsform x = ab̄; 1 + u, wo u; u = b zur Abkürzung genannt ist, erhalten wir: x; x = ab̄; 1; ab̄; 1 + ab̄; 1; u + u; ab̄; 1 + u; u = ab̄; 1 + b + etc.
Allgemein gilt nun schon a ⋹ ab̄; 1 + b, nämlich ab̄ ⋹ ab̄; 1 nach 8) des § 15, umsomehr also a ⋹ x; x, q. e. d. Analog (konjugirt dazu) ist die Probe für die zweite Lösungsform zu leisten; und für die dritte x = ab̄; 1 + u + 1; ab̄ ist sie mit vorstehendem ebenfalls geleistet, weil x; x für sie gebildet dieselben Glieder wie vorhin und nur noch einige mehr enthalten muss.
Probe 1 zu 43).
Wird u; ŭ = b genannt, und a + ă = α, so ist b = b̆ und α = ᾰ.
Mit x = αb̄; 1 + u wird also x̆ = ŭ + 1; αb̄ und x; x̆ = αb̄; 1; αb̄ + u; ŭ + u; 1; αb̄ + αb̄; 1; ŭ = αb̄; 1 · 1; αb̄ + b + etc.
Nun gilt allgemein αb̄ ⋹ αb̄; 1 · 1; αb̄, somit α ⋹ αb̄̆; 1 · 1; αb̄ + b, d. h. es ist a + ă schon der Summe der beiden ersten Glieder des x; x̆ eingeordnet, q. e. d.
Die Probleme der beiden übrigen Gespanne involviren Resultanten, und zwar sind die vollen Resultanten zum
Vierten Gespanne gegeben mit: 21) [Formel]
Während dieselben kraft 3) des § 8 folgen, ist der Beweis für ihre Vollständigkeit darin zu erblicken, dass, sobald die Resultante erfüllt ist, sich x = 0' sowol als x = 1' als eine partikulare Wurzel bewährt.
Mit deren Hülfe sind wir demnach auch imstande, wenigstens die rigorose Lösung für jedes der vorstehenden Probleme nach 12) des § 12 hinzuschreiben, z. B. [Formel] , worin auch hinter Σ sich 1' für 0' setzen lässt.
Zweites Gespann: 22) [Formel] Hier folgt je eine unbekannte Resultante und steht auch die Lösung in jeglicher Form noch aus.
Die Aufgabe, aus a ⋹ x; x̄ das x zu eliminiren, gehört zu den einfachsten unter den schwierigen und zu den schwierigsten unter den einfachen Eliminationsproblemen.
Dass eine Resultante folgt, m. a. W. dass unser Problem nicht bedingungslos (für a) durch ein x erfüllbar ist, zeigt sich schon auf den niedersten Denkbereichen.
Bildet man für jedes der 16 Relative, welche in 1 ½ existiren und somit daselbst als Wert von x aufgefasst werden könnten, das relative Produkt x; x̄, so erhält man nur 8 verschiedene Ergebnisse und kann man, soll die Aufgabe nicht absurd werden, auch dem a nur gewisse zehn von allen 16 Relativwerten beilegen.
Bezeichnet man, statt mit A, B, C, …, die Elemente eines eng begrenzten Denkbereiches mit den kleinen Suffixziffern 1, 2, 3, …, so kann ja für den Denkbereich 1 ½ die Elimination der vier Koeffizienten von x aus den vier Koeffizientenbedingungen, auf welche die Forderung a ⋹ x; x̄ hinausläuft, nach längst bekannten Methoden wirklich ausgeführt werden, und ergibt sich: a11a22 + (a11 + a22)a12a21 = 0 als die volle Resultante.
Für den Denkbereich 1 ⅓ die neun Eliminanden xi j aus den neun Bedingungen ai j ⋹ Σhxi hx̄h j auszumerzen, erheischt schon so langwierige Rechnungen, dass dieselben ohne eine „Eliminationsmaschine kaum noch durchführbar erscheinen.
Allgemein kann man setzen: 23) x = 1'x + 0'y, x̄ = 1'x̄ + 0'ȳ, wo zwar y = x gedacht werden dürfte, jedoch auch nichts hindert, y ganz unabhängig von x angenommen zu denken, weil die beiden Glieder doch ohnehin disjunkt ausfallen werden.
Da nun 1'x; 1'x̄ = 0, weil ⋹ 1'; x̄ · x; 1' = xx̄ = 0 sein muss, so wird x; x̄ = 1'x; 0'ȳ + 0'y; 1'x̄ + 0'y; 0'ȳ.
Nun gelten die leicht erweislichen Sätze: 24) [Formel] deren duales Entsprechen einleuchtet, wenn man beachtet, dass: 25) [Formel] — wozu gelegentlich noch 1'a = 1'ă zu berücksichtigen ist — cf. 8) des § 9. Aufgrund dieser Formeln können in Theorie und Praxis die zu Relativen der Form 1'a; 1 sowie 1; a1' dual entsprechenden Relativformen (0' + a) ɟ 0 und 0 ɟ (a + 0') ganz und gar vermieden, nämlich überall durch jene als die einfacher zu schreibenden ersetzt werden.
Darnach lautet unsre Forderung: 26) a⋹ 1'x; 1 · 0'ȳ + 0'y · 1; x̄1' + 0'y; 0'ȳ, und gelang es mir, aus dieser wenigstens x zu eliminiren.
Die (volle) Resultante lautet: 27) [Formel] und wird nur mehr aus dieser (noch weiter vereinfachungsfähigen) y vollends zu eliminiren sein.
Man ersieht aus diesen blos skizzirten Angaben wenigstens, dass Wege offen stehen, der Lösung unsres schwierigen Problemes nach und nach immer näher zu kommen.
Für a ⋹ 0' ist die unbekannte Resultante jedenfalls erfüllt, weil dann in Gestalt von x = 0' eine Wurzel angebbar ist, für welche x; x̄ selbst gleich 0' wird.
Indem man das Problem ansetzt in der Gestalt: a · b; b̄ ⋹ x; x̄, wo dann x = b eine partikulare Wurzel sein muss, kann man (auch ohne dass die Resultante zum vorhergehenden Ansatze ermittelt wäre) doch alle lösbaren Probleme derart angeben, für diese auch die rigorose Lösung unschwer aufstellen.
Es erübrigt nun, noch ein Wort zu sagen über die Gleichungsprobleme unsrer zweiten Hauptabteilung, welche sich in zwei weitre Abteilungen gliedern.
Von den vier — tetradischen — Gespannen der
Vierten Unterabteilung: 28) [Formel] involvirt das erste und dritte (weil links für x = 0 erfüllt) keine Resultante, wol aber das zweite und vierte — mit jedem einzelnen seiner Probleme.
Von der
Fünften Unterabteilung endlich, bestehend aus dem einen dyadischen und den drei tetradischen Gespannen: 29) [Formel] involvirt jede Aufgabe eine Resultante.
Diese schon ist aber gar nicht leicht zu ermitteln.
Was z. B. das Problem der Elimination von x aus der Gleichung x; x = a betrifft, welches ebenfalls zu den sehr schwierigen zu zählen, so kann man etwa der Aufgabe von vornherein die etwas allgemeinere Fassung geben: ab⋹x; x ⋹ a + b.
Wegen a = 1'a + 0'a wird man aufgrund des leicht erweislichen Satzes: 30) sowie wegen 24) die bemerkenswerte Darstellung haben: 31) a2 = a; a = 1'a + (1'a; 1 + 1; 1'a)0'a + 0'a; 0'a, und nach diesem Schema kann, wenn x = 1'y + 0'z gesetzt wird, die Aufgabe geschrieben werden: ab⋹ 1'y + (1'y; 1 + 1; 1'y)0'z + 0'z; 0'z ⋹ a + b.
1'a; 1'a = 1'a (0' + a) ɟ (0' + a) = 0' + a,
Es gelingt nun wieder, hieraus wenigstens y zu eliminiren.
Die Resultante, wenn zur Abkürzung a + b + 1' + z̄ = c genannt wird, lautet: ab⋹ (c ɟ 0)(0 ɟ c) + {(c ɟ 0) · (0 ɟ c); 1 + 1; (c ɟ 0) · (0 ɟ c)}0'z + 0'z; 0'z.
Dritte Hauptabteilung.
Subsumtionenprobleme.
Erste Abteilung.
Wir beginnen mit der
Aufgabe.
Nach x aufzulösen die Subsumtion: x; x ⋹ x.
Diese charakterisirt x als ein einer höchst wichtigen Klasse angehöriges, nämlich als ein „transitives“ Relativ — vergl. S. 46.
Wir fassen den Begriff hiermit etwas weiter als De Morgan, in dessen Sinne ein transitives Relativ vielmehr zu charakterisiren wäre mittelst (x; x ⋹ x)(x; x ≠ 0).
Wegen 0 ⋹ x ist nämlich die obige Subsumtion auch sicher dann erfüllt, wenn x; x ⋹ 0 ist, d. h. zu den transitiven Relativen in unserm (weiteren) Sinne gehören eo ipso als eine Unterabteilung derselben auch die oben S. 328 sq. besprochenen „erschöpften“ Relative — und diese letztern will De Morgan von den transitiven Relativen ausgeschlossen wissen.
Zu den transitiven Relationen gehören die allerwichtigsten der von uns in Bd. 1 und 2 studirten Beziehungen: der Subsumtion (Einordnung), Identität (oder Gleichheit) sowie der Unterordnung; „eingeordnet oder „enthalten in“, „gleich mit“, auch „≦“, „<“ und „> als-“ sind transitive Relative: Gleiches mit Gleichem ist Gleiches.
Etc.
Nicht-transitiv (intransitiv) dagegen ist z. B. das Relativ „≠“, „ungleich mit-“, „verschieden von-“ oder „ein andres als“; denn „ungleich etwas Ungleichem“ wird auch das Gleiche sein, „etwas andres wie etwas andres als-“ kann auch „dasselbe“ (das nämliche) genannt werden und wird solches also nicht notwendig wieder „etwas andres als (das gedachte Korrelat)“ bedeuten müssen.
Auch der Freund von einem deiner Freunde braucht nicht dein Freund zu sein, selbst wenn Freundschaft immer gegenseitig.
Wie not es thut, dass eine fest begründete Lehre der Relative (relation-lore) errichtet sei, thun schon die fundamentalen Irrtümer dar, denen man in so vielen, dies Gebiet streifenden Abhandlungen begegnet.
Selbst in einer so angesehenen philosophischen Zeitschrift wie die Revue philosophique konnte von Monsieur George Mouret (August und September 1891) ein Axiom aufgestellt werden, welches darauf hinausläuft, jede symmetrische Relation für transitiv zu erklären.
Vergleiche die ausgezeichnete Klarstellung solchen Irrtums durch Mr. Francis C. Russell in The Monist, Vol. 3, p. 272 ‥ 285.
In seiner Entgegnung, Monist Vol. 4, p. 282 ‥ 294, stellt zwar Herr Mouret die irrige Auffassung seines Rezensenten Russel, wonach das fragliche Axiom Mr. Herbert Spencer zuzuschreiben sei, dahin richtig, dass wir ihm selber (Herrn Mouret) dieses „Axiom“ zu verdanken(?) haben, erhält dasselbe jedoch trotz alledem in seinem Wortlaut:
„Two things which have the same symmetric relation to a third thing, have between them that same relation“ aufrecht!
Die prätendirte Rechtfertigung des letztern erscheint mir als ein Muster von Sophistik und Verdunkelung durch Phrasen.
Die allgemeine Wurzel der Subsumtion x; x ⋹ x, mithin das allgemeinste transitive Relativ x vermögen wir in mehrern verschiedenen Formen anzugeben.
Da von den vier Moduln nur der 0' der Forderung nicht genügt, so wären, je nachdem 1, 0 oder 1' als die bekannte Partikularlösung benutzt wird, von vornherein sogleich drei Formen einer „rigorosen“ Lösung angebbar, von denen die beiden ersten sich wie folgt darstellen:
[Formel] .
Abgesehn von (solchen) rigorosen somit unbefriedigenden Formen der allgemeinen Lösung vermögen wir letztere in befriedigender Weise aufzustellen: auf drei Arten in geschlossener Form, und auf (mindestens) eine Art in offener oder ungeschlossener, d. h. in Gestalt einer unbedingt konvergenten unendlichen Entwickelung.
Jene drei geschlossenen Formen der allgemeinen Wurzel ergeben sich leicht primo impetu, nämlich aufgrund des Gedankenganges, den ich Bd. 1, S. 498 und 503 als den ersten Schritt einer (noch weiter auszubildenden) Methode der symmetrisch allgemeinen Lösungen bezeichnet habe.
Die Lösungen sind: 32) [Formel] .
Man erhält nämlich durch Transponiren des ersten oder zweiten relativen Faktors aufgrund des ersten Inversionstheoremes die Äquivalenzen: (x; x ⋹ x) = (x ⋹ x̄̆ ɟ x) = (x ⋹ x ɟ x̄̆) = {x ⋹ (x̄̆ ɟ x)(x ɟ x̄̆)} = = {x = (x̄̆ ɟ x)x} = {x = x(x ɟ x̄̆)} = {x = (x̄̆ ɟ x)x(x ɟ x̄̆)}, aufgrund von deren Umschreibung in der letzten Zeile sogleich die Probe 2 mit den drei angegebnen allgemeinen Lösungen stimmt.
Zugleich damit ist erkannt, dass wenigstens für gewisse u (nämlich für u = x) die Unbekannte in jenen drei Formen angebbar sein müsse, die man erhält, wenn man in den primären Gleichungen unsrer letzten Zeile rechterhand x durch ein unbestimmtes Relativ u ersetzt.
Nun stimmt aber, selbst bei beliebigem u, wie sich herausstellt, mit ebendiesen Ausdrücken auch die Probe 1 — wonach sie eben die allgemeine Wurzel vorstellen werden.
Dies beruht auf einem Satze, oder eigentlich auf drei Sätzen, die man durch die eine Formel darstellen kann: 33) (ā̆ ɟ a)a(a ɟ ā̆); (ā̆ ɟ a)a(a ɟ ā̆) ⋹ (ā̆ ɟ a)a(a ɟ ā̆) mit dem Zufügen, dass in dem dreimal vorkommenden identischen Produkte auch der erste oder aber der letzte Faktor durchweg unterdrückbar.
Um zunächst diese Formel zu beweisen, nennen wir L die linke Seite derselben, und haben zu zeigen, dass sowol L⋹ā̆ ɟ a als L ⋹ a und L ⋹ a ɟ ā̆ ist.
Direkt, aufgrund der Koeffizientenevidenz wäre dies nur umständlich zu bewerkstelligen.
(Empfehlenswerte Übung).
Mittelbar gelingt es dagegen leicht wie folgt.
Nach dem fundamentalen Satze 5) des § 6 können wir, sooft ein relatives Produkt von der Form abc …; αβγ … vorliegt, irgend einen der identischen Faktoren vor und irgend einen hinter dem Semikolon ausheben, und werden, sie in dieser Folge zu einem relativen Produkt vereinigend, ein Relativ erhalten, welchem das gegebne relative Produkt eingeordnet sein muss.
Hienach muss z. B. sein: L⋹ (a ɟ ā̆); a, was nach 9) des § 17 gleich a ist, also: L ⋹ a. Ebenso muss sein: L⋹ (ā̆ ɟ a); (ā̆ ɟ a) ⋹ ā̆ ɟ a; ā̆ ɟ a ⋹ ā̆ ɟ 0' ɟ a = ā̆ ɟ a im Hinblick auf 7) des § 6 und 3) und 11) des § 8, endlich: L⋹ (a ɟ ā̆); (a ɟ ā̆) ⋹ a ɟ ā̆; a ɟ ā̆ ⋹ a ɟ 0' ɟ ā̆ = a ɟ ā̆, wie zu zeigen gewesen.
Vielleicht noch eleganter (oder mnemonischer) mag mit regelmässigem Wechsel zwischen u und ū̆ die hiermit gerechtfertigte Lösung so geschrieben werden: 34) [Formel] mit dem Zusatze: dass auch der erste oder letzte von den drei identischen Faktoren unterdrückbar.
In Gestalt einer unendlichen Entwickelung lässt sich daneben die allgemeine Lösung unsrer Subsumtion wie folgt darstellen: 35) [Formel] .
Um dies zu entdecken, bemerke man zuerst, dass auch: (x; x ⋹ x) = (x = x + x; x) ist.
Auf demselben Grundgedanken, welcher vorhin Erfolg gewährte, fussend kann man hiernach dessen gewiss sein, dass die Unbekannte in der Form x = u + u; u angebbar sein muss, mit welcher ja die Probe 2 schon stimmt.
Wirft man hierauf die Frage auf, ob dieser Ausdruck auch für ein beliebiges u eine Wurzel darstelle, so bestätigt sich indessen diese Vermutung nicht, indem (u + u2); (u + u2) = u; u + u2; u + u; u2 + u2; u2 = = u2 + u3 + u4 nicht ⋹ u + u2 allgemein sein kann; Probe 1 stimmt mithin nicht.
Wohl aber thut sie dies, wenn wir noch etwas weiter gegangen sein werden.
Setzt man in der mit der Aufgabe äquivalenten Gleichung x = x + x; x etwa für das letzte x fortgesetzt seinen Wert aus der Gleichung selbst ein, so gelangt man zu der — unschwer durch Schluss von n auf n + 1 strenge zu rechtfertigenden — Darstellung: x = x + x2 + x3 + … + xn, welche auch für ein ohne Ende wachsendes n in Anspruch genommen werden kann und uns liefert: x = x + x; x + x; x; x + … = x + x2 + x3 + x4 + … = x00.
Zufolge dessen stimmt mit dem Ausdrucke x = u00 = u + u2 + u3 + … in infinitum jedenfalls auch die Probe 2.
Mit ebendiesem stimmt nun aber auch die Probe 1, indem bei ganz beliebigem u nach 4) des § 6: x; x = (u + u2 + u3 + …); (u + u2 + u3 + …) = u2 + u3 + u4 + … somit ⋹u + u2 + u3 + u4 + … = x sein muss, und jedenfalls als allgemeine Formel gilt: 36)
a00; a00 ⋹ a00 a11⋹a11 ɟ a11.
Anstatt mit den vorstehenden Überlegungen — was ich für nützlich hielt — den früheren Gedankengang im Einzelnen zu illustriren, hätten wir uns auch einfach auf das Th. 1) des § 13 bezüglich sämtlicher Lösungsformen berufen können.
Nach alledem sind für das
Erste Gespann die Ergebnisse gerechtfertigt: 37) [Formel] , wo von dem dreitermigen (trinomischen) Ausdruck für x auch der erste oder letzte Term unterdrückbar.
Dreie von den Moduln: 0, 1 und 1' sind Wurzeln des ersten Problemes.
Diesem wollen wir nun ohne viel Umstände auch die übrigen Gespanne mit ihren Lösungen anreihen.
Zweites Gespann (der Modul 1 blos genügt linkerhand): 38) [Formel] , wo von den 3 letzten Termen des viertermigen x irgend zweie, desgleichen einer, unterdrückbar.
Drittes Gespann (0, 1 und 1' genügen links): 39) [Formel] und von den drei Termen des dreitermigen f(u) der erste oder dritte unterdrückbar.
Viertes Gespann (Modul 1 genügt linkerhand): 40) .
Fünftes Gespann (0, 1 und 0' genügen links): 41) [Formel]
Durch Transponiren, Konvertiren und Kontraposition ergeben sich zu den drei angegebenen noch neun weitre Subsumtionen je als äquivalente Formen des Problems, und lassen für das erste Problem z. B. diese zwölf Subsumtionen sich zusammenfassen zu: 42) [Formel]
Von den Iterationen jedes Tripels von Funktionen f(u) scheinen jeweils die der dritten des übersichtlichen Ausdrucks teilhaftig zu sein.
Z. B. für f(u) = u(ŭ ɟ u) wird: f∞(u) = u(ŭ ɟ u)(ŭ ɟ ŭ ɟ u)(ŭ ɟ ŭ ɟ ŭ ɟ u) … · (ŭ ɟ u ɟ u)(ŭ ɟ ŭ ɟ u ɟ u) … · (ŭ ɟ u ɟ ŭ ɟ u) … · (ŭ ɟ u ɟ u ɟ u) … … wo die 2n Faktoren einer Kolonne aus denen der vorhergehenden erhalten werden, indem man ŭ ɟ vor, desgleichen ɟ u hinter dieselben schreibt, sodass also zwischen dem ersten ŭ ɟ und dem letzten ɟ u alle Variationen der n — 2 kombinatorischen Elemente ŭ und u (je durch ɟ verbunden) enthalten sind.
Beispiele, wie [Formel] zeigen, dass f(u) nicht invariant ist.
Begründungen sind nur für die Fälle der Invarianz von f(u) mittelst Probe 1 nachzuliefern, und für 37) bereits gegeben.
Probe 1 zu 38) — erstes Problem. x = u + ū; ū gibt x̄ = ū(u ɟ u), somit x̄; x̄ ⋹ ū; ū ⋹ x, q. e. d. Ebenso x = u + ū̆; ū + ū; ū + ū; ū̆ gibt x̄ = ū(ŭ ɟ u)(u ɟ u)(u ɟ ŭ), also x̄; x̄ ⋹ ū; ū ⋹ x, q. e. d.
Weiter x = u + ū̆; ū gibt x̄ = ū(ŭ ɟ u) und x̄; x̄ ⋹ ū; (ŭ ɟ u) ⋹ ū; ŭ ɟ u ⋹ 0' ɟ u = u ⋹ x, q. e. d. Etc.
Um (x̄; x̄ ⋹ x) = (x̄̆; x̄ ⋹ x) nachzuweisen, transponire man den zweiten Term von links nach rechts: x̄ ⋹ x ɟ x̆, darin den ersten von rechts nach links: x̄̆; x̄ ⋹ x̆, und konvertire: x̄̆; x̄ ⋹ x, und vice versa.
Etc.
Probe 1 zu 40) oder 4. x = u + ū̆; ū̆ gibt x̄̆ = ū̆(u ɟ u), also x̄̆; x̄̆ ⋹ ū̆; ū̆ ⋹ x, q. e. d.
Zweite Abteilung.
Wenn die S. 323 mit den Chiffren 1 bis 10 (ohne Halbklammer) markirten Subsumtionen, welche wir in der ersten Abteilung als vorwärts gelesene erledigt haben, rückwärtig angesetzt zu denken sind, so wollen wir diesen Chiffren einen rückwärts geneigten Accent (accent grave) geben.
Erstes Gespann (alle vier Moduln genügen): 43) [Formel] . Bemerkenswerte Partikularlösungen links sind x = 1'u und x = uu2u3u4 ….
Zweites Gespann (0 und 1' genügen links): 44) .
Drittes Gespann (alle vier Moduln genügen): 45) [Formel] .
Viertes Gespann (0 und 1' genügen links): 46) .
Fünftes Gespann (0 und 0' genügen links): 47) [Formel] .
Sechstes Gespann (alle vier Moduln genügen): 48) [Formel] .
Siebentes Gespann (0 und 0' genügen links): 49) [Formel] .
Diese Probleme also charakterisiren x als Alio- resp. Selbstrelativ.
Achtes Gespann (0 und 0' genügen links): 50) [Formel] .
Hier also wird x ⋹ 0' | 1' ⋹ x sein — jedoch ohne dass die Erfüllung dieser Forderung ausreichte um x zu einer Wurzel des Problems zu stempeln.
Neuntes Gespann (0 und 1' genügen links): 51) .
Zehntes Gespann (0 und 0' genügen linkerhand): 52) [Formel] .
Begründung für die behaupteten Invarianzen.
Probe 1 zu 44) 2‵.
Mit x = u · ū; ū wird x̄ = ū + u ɟ u, also x̄; x̄ = ū; ū + ū; (u ɟ u) + (u ɟ u); ū + (u ɟ u); (u ɟ u) und x⋹ū; ū ⋹ x̄; x̄, q. e. d.
Zu 46) 4‵. x = u · ū̆; ū̆ gibt x̄̆ = ū̆ + u; u, also x̄̆; x̄̆ = ū̆; ū̆ + etc. und x ⋹ ū̆; ū̆ ⋹ x̄̆; x̄̆, q. e. d.
Zu 49) 7‵. Dass x ⋹ 0' sein muss, folgt aus 3) des § 8.
Mit x = 0'u haben wir aber x̄̆ = 1' + ū̆, somit: x̄̆; x = 0'u + ū̆; 0'u, somit x = 0'u ⋹ x̄̆; x, q. e. d.
Analog x ⋹ x; x̄̆.
Die Äquivalenz der beiden Probleme lässt sich hier nicht mittelst Transponirens von Termen (etc.) nachweisen, wofür uns ja kein allgemeiner Satz zur Verfügung stünde, sondern sie folgt a posteriori aus der Koinzidenz ihrer allgemeinen Lösung!
Zu 51)
9. Mit x = u · ū̆; ū wird x̄ = ū + ŭ ɟ u, x̄̆ = ū̆ + ŭ ɟ u, somit x̄̆; x̄ = ū̆; ū + etc., also x ⋹ ū̆; ū ⋹ x̄̆; x̄, q. e. d.
Gleichungenprobleme.
Dritte Abteilung aus 4 + 6 = 10 Gespannen bestehend und sich darnach wenn man will noch in zwei Unterabteilungen gliedernd.
Sie umfasst die vier dyadischen: 53) [Formel] und die sechs tetradischen Gespanne: 54) [Formel] deren Probleme wol sämtlich nicht leicht zu lösen sind.
Hier, wie am Ende der vorigen Hauptabteilung, öffnet sich dem Forscher ein reiches Feld von Aufgaben.
Von der Gleichung x; x = x bot sich im § 4 das Relativ „Teiler von- als eine bemerkenswerte Wurzel dar.
Dasselbe zeigt zugleich, dass die Bemerkung des Herrn Charles S. Peirce2 p. 52 nicht umkehrbar ist, wonach Relative diese Eigenschaft haben, sobald ihre Augen resp.
Elementepaare sich in (? von der Hauptdiagonale halbirte) Quadrate (mit horizontalen und vertikalen Seiten) gruppiren „like this:
A : A, A : B, A : C B : A, B : B, B : C C : A, C : B, C : C“.
Ein x, welches inbezug auf eine Knüpfung die Eigenschaft x2 = x hat, nennt des Genannten Vater Benjamin Peirce einen „idempotent“.
Ch. S.
Peirce will solche Relative ibidem „kopulative“ genannt wissen — sodass ein kopulatives Relativ, mit sich selbst (relativ) multiplizirt, sich wiedererzeugt.
Wie schon aus diesem und den verschiedentlich eingestreuten Anläufen ersichtlich ist, geben die Probleme dieser Vorlesung, insofern sie mit ihrer Forderung ein Relativ zu charakterisiren vermögen, die einfachsten Einteilungsgründe ab zu einer (rationellen) Klassifikation der Relative.
Doch wollen wir auf dieses Thema erst näher eingehn, nachdem wir in der Theorie noch weiter fortgeschritten sein werden. —
Neunte Vorlesung.
Die Theorie der Ketten.
§ 23. Dedekind’s Kettentheorie und der Schluss der vollständigen Induktion.
Vereinfachung jener.
Schon lange fragt sich wol der Leser, was denn mit dem so ausgedehnten Kapital unsrer Theorie überhaupt sich Wertvolles leisten lassen werde?
(Wenn ich sage „unsre Theorie“, so meine ich die in diesem Buche vorgetragne Theorie, deren Anfänge auf A. de Morgan zurückgehen und welche vor allem Herrn Charles S. Peirce zuzuschreiben ist; diesen Autoren mich zuzugesellen, dazu berechtigt mich wol der Umstand, dass es mir doch auch zufiel, so Manches an dieser Theorie erst auszugestalten).
Geduld!
Das Instrument ist noch in zu unfertigem Zustande.
Je mehr sein Ausbau fortschreitet und in je weiteren Kreisen seine Anwendungen Platz greifen, um so mächtiger wird es sich erst erweisen.
Um indessen nicht allzuspät eine Probe seiner Leistungsfähigkeit zu geben, will ich nunmehr an die Aufgabe herantreten, die R. Dedekind’sche „Theorie der Ketten“ in das Lehrgebäude unsrer Disziplin einzugliedern.
Der Gewinn, der dieser Theorie dabei erwachsen wird und den ich hoffe deutlich hervortreten zu lassen, wird geeignet sein, den Wert unsrer Disziplin erstmals zu dokumentiren.
Die „Kettentheorie“ ist nur ein Teil, obzwar ein fundamentaler, der epochemachenden Arbeit Dedekind’s „Was sind und was sollen die Zahlen? — welche vollends, auch mit ihren andern wesentlichsten Teilen, dem Gebäude der allgemeinen Logik einzufügen mir als eines der vornehmsten Ziele bei meiner Arbeit vorschwebt.
Ich muss deshalb mit einer Besprechung dieser Schrift beginnen und werde wiederholt auf dieselbe zurückzukommen haben.
Dabei will ich die 167 Sätze und (Begriffs-)Erklärungen Dedekind’s kurz mit D 1 bis 167 citiren, die etwa anzuführenden eignen Worte dieses Autors mit Anführungszeichen » « kenntlich machen, mir jedoch vorbehalten, Einzelnes durch kursiven Druck eigenmächtig hervorzuheben.
Ungeachtet der Anerkennung seitens der mathematischen Welt, welche unter anderm darin zu erblicken ist, dass die Auflage dieser Schrift alsbald vergriffen gewesen und inzwischen ein unveränderter Neudruck erfolgte, ist dieselbe doch vonseiten vereinzelter Mathematiker sowol nach ihrer Tendenz als nach ihrem Verdienste noch gründlich verkannt worden — am unverhohlensten in der ablehnenden Rezension des bekannten Herausgebers einer mathematischen Zeitschrift, Herrn R. Hoppe, der in Dedekind’s Schrift wesentlich nur eine „geistige Gymnastik“ erblickt, und dem was der Verfasser mit dem Ganzen hat erreichen wollen“ „durchaus dunkel“ geblieben.
Desgleichen sind die Errungenschaften, die wir darin Herrn Dedekind verdanken, von philosophischer oder zur Philosophie sich bekennender Seite (Frege5, Husserl3) wol bei weitem noch nicht ausreichend berücksichtigt und gewürdigt worden.
Es wird dem Verf. deshalb zur Genugthuung gereichen, jene soviel an ihm ist in das rechte Licht stellen zu dürfen.
Um die Tendenz der Arbeit des Herrn Dedekind zu kennzeichnen, geben wir zunächst ihm selbst das Wort.
»Was beweisbar ist, soll in der Wissenschaft nicht ohne Beweis geglaubt werden.
So einleuchtend diese Forderung erscheint, so ist sie doch, wie ich glaube, selbst bei der Begründung der einfachsten Wissenschaft, nämlich desjenigen Teiles der Logik, welcher die Lehre von den Zahlen behandelt, auch nach den neuesten Darstellungen noch keineswegs als erfüllt anzusehen.
Indem ich die Arithmetik (Algebra, Analysis) nur einen Teil der Logik nenne, spreche ich schon aus, dass ich den Zahlbegriff für gänzlich unabhängig von den Vorstellungen oder Anschauungen des Raumes und der Zeit, dass ich ihn vielmehr für einen unmittelbaren Ausfluss der reinen Denkgesetze halte.
Meine Hauptantwort auf die im Titel dieser Schrift gestellte Frage lautet: die Zahlen sind freie Schöpfungen des menschlichen Geistes, sie dienen als ein Mittel, um die Verschiedenheit der Dinge leichter und schärfer aufzufassen.
Durch den rein logischen Aufbau der Zahlen-Wissenschaft und durch das in ihr gewonnene stetige Zahlen- Reich sind wir erst in den Stand gesetzt, unsre Vorstellungen von Raum und Zeit genau zu untersuchen, indem wir dieselben auf dieses in unserm Geiste geschaffene Zahlen-Reich beziehen.
Verfolgt man genau, was wir beim Zählen der Menge oder Anzahl von Dingen thun, so wird man auf die Betrachtung der Fähigkeit des Geistes geführt, Dinge auf Dinge zu beziehen, einem Dinge ein Ding entsprechen zu lassen, oder ein Ding durch ein Ding abzubilden, ohne welche Fähigkeit überhaupt kein Denken möglich ist.
Auf dieser einzigen, auch sonst ganz unentbehrlichen Grundlage muss nach meiner Ansicht, wie ich auch schon bei einer Ankündigung der vorliegenden Schrift ausgesprochen habe, die gesamte Wissenschaft der Zahlen errichtet werden.«
Verweis auf des Verfassers Lehrbuch der Arithmetik und Algebra 1 und auf die Abhandlungen von Kronecker und Helmholtz über den Zahlbegiff und über Zählen und Messen in der Sammlung der an E. Zeller gerichteten philosophischen Aufsätze, Leipzig 1887.
»Das Erscheinen dieser Abhandlungen ist die Veranlassung, welche mich bewogen hat, nun auch mit meiner, in manchen Beziehungen ähnlichen, aber durch ihre Begründung doch wesentlich verschiedenen Auffassung hervorzutreten, die ich mir seit vielen Jahren und ohne jede Beeinflussung von irgendwelcher Seite gebildet habe.«
Hinweis auf § 3 von Herrn Dedekind’s Schrift2 über Stetigkeit und irrationale Zahlen.
Hinweis auf Herrn Dedekind’s Vorlesungen über Zahlentheorie3 von Lejeune Dirichlet1, dritte Aufl. 1879, § 163, Anm. auf pag. 470.
Nach einer kurzen Vorgeschichte seiner Abhandlung hebt Herr Dedekind als Hauptpunkte aus derselben hervor: die scharfe Unterscheidung des Endlichen vom Unendlichen (D 64), den Begriff der „Anzahl“ von Dingen (D 161), den Nachweis, dass die unter dem Namen der vollständigen Induktion (oder des Schlusses von n auf n + 1) bekannte Beweisart wirklich beweiskräftig (D 59, 60, 80), und dass auch die Definition durch Induktion (oder Rekursion) bestimmt und widerspruchsfrei ist (D 126).
»Diese Schrift kann Jeder verstehen, welcher Das besitzt, was man den gesunden Menschenverstand nennt; philosophische oder mathematische Schulkenntnisse sind dazu nicht im Geringsten erforderlich.
Aber ich weiss sehr wohl, dass gar mancher in den schattenhaften Gestalten, die ich ihm vorführe, seine Zahlen, die ihn als treue und vertraute Freunde durch das ganze Leben begleitet haben, kaum wiedererkennen mag; er wird durch die lange, der Beschaffenheit unsres Treppen-Verstandes entsprechende Reihe von einfachen Schlüssen, durch die nüchterne Zergliederung der Gedankenreihen, auf denen die Gesetze der Zahlen beruhen, abgeschreckt und ungeduldig darüber werden, Beweise für Wahrheiten verfolgen zu sollen, die ihm nach seiner vermeintlichen inneren Anschauung von vornherein einleuchtend und gewiss erscheinen.
Ich erblicke dagegen gerade in der Möglichkeit, solche Wahrheiten auf andere, einfachere zurückzuführen, mag die Reihe der Schlüsse noch so lang und scheinbar künstlich sein, einen überzeugenden Beweis dafür, dass ihr Besitz oder der Glaube an sie niemals unmittelbar durch innere Anschauung gegeben, sondern immer nur durch eine mehr oder weniger vollständige Wiederholung der einzelnen Schlüsse erworben ist.
Ich möchte diese, der Schnelligkeit ihrer Ausführung wegen schwer zu verfolgende Denkthätigkeit mit derjenigen vergleichen, welche ein vollkommen geübter Leser beim Lesen verrichtet; auch dieses Lesen bleibt immer eine mehr oder weniger vollständige Wiederholung der einzelnen Schritte, welche der Anfänger bei dem mühseligen Buchstabiren auszuführen hat; ein sehr kleiner Teil derselben, und deshalb eine sehr kleine Arbeit oder Anstrengung des Geistes reicht aber für den geübten Leser schon aus, um das richtige, wahre Wort zu erkennen, freilich nur mit sehr grosser Wahrscheinlichkeit; denn bekanntlich begegnet es auch dem geübtesten Korrektor von Zeit zu Zeit, einen Druckfehler stehen zu lassen, d. h. falsch zu lesen, was unmöglich wäre, wenn die zum Buchstabiren gehörige Gedankenkette vollständig wiederholt würde.
So sind wir auch schon von unsrer Geburt an beständig und in immer steigendem Maasse veranlasst, Dinge auf Dinge zu beziehen und damit diejenige Fähigkeit des Geistes zu üben, auf welcher auch die Schöpfung der Zahlen beruht; durch diese schon in unsre ersten Lebensjahre fallende unablässige, wenn auch absichtslose Übung und die damit verbundene Bildung von Urteilen und Schlussreihen erwerben wir uns auch einen Schatz von eigentlich arithmetischen Wahrheiten, auf welche später unsre ersten Lehrer sich wie auf etwas Einfaches, Selbstverständliches, in der inneren Anschauung Gegebenes berufen, und so kommt es, dass manche, eigentlich sehr zusammengesetzte Begriffe (wie z. B. der der Anzahl von Dingen) fälschlich für einfach gelten.
In diesem Sinne … mögen die folgenden Blätter als ein Versuch, die Wissenschaft der Zahlen auf einheitlicher Grundlage zu errichten, wohlwollende Aufnahme finden, und mögen sie andere Mathematiker dazu anregen, die langen Reihen von Schlüssen auf ein bescheideneres, angenehmeres Maass zurückzuführen.
Dem Zwecke dieser Schrift gemäss beschränke ich mich auf die Betrachtung der Reihe der sogenannten natürlichen Zahlen.«
So viel zunächst aus dem Vorworte des genannten Autors.
Von den „beweisbaren“, zumeist jedoch ohne Beweis geglaubten Sätzen möchte ich von vornherein wenigstens ein paar hervorheben; dazu zählen in der That Sätze wie diese: dass es in jeder endlichen Menge von Zahlen eine grösste und eine kleinste Zahl gibt (D 114); dass, wenn ein Teil eines Systems unendlich ist, das ganze System unendlich sein muss (D 68) — und dergleichen mehr.
Es ist also die Ausfüllung einer grossen und bedeutungsschweren Lücke, welche sich bislang in allen Darstellungen, in allen Lehr- und Handbüchern der Arithmetik und Algebra (auch das des Verfassers1 nicht ausgenommen) findet — die sich Herr Dedekind mit Erfolg hat angelegen sein lassen!
Die Lücke klaffte gerade da, wo die Wissenschaft der Arithmetik entspringen sollte aus der allgemeinen Logik, wo sie in dieser wurzelnd ihren Ursprung nehmen sollte, um von da sich immer weiter von ihr abzuzweigen.
Zu vermissen war — und ist, genauer gesagt, teilweise noch — der Anschluss jener Disziplin der Arithmetik an die Algebra der Relative, die ja ihrerseits die Lehre von der eindeutigen Zuordnung oder Abbildung als einen partikularen oder Sonder-Zweig ganz unter sich begreift.
Wenn ich mir übrigens vergegenwärtige, wie weit einerseits die Entwickelung der rechnerischen Logik schon vorgeschritten sein musste, damit es überhaupt möglich wurde, die vermisste Verbindung wirklich glatt herzustellen, und wie grossen Scharfsinn andrerseits mit Dedekind die Ausfüllung jener Lücke benötigt (ich liefre hiernächst sozusagen nur den Kitt hinzu), so kann ich aus dem frühern Vorhandensein solcher Lücke weder mir noch andern Darstellern der Arithmetik einen Vorwurf machen; dagegen muss der Leistung, welche das fehlende Verbindungsglied schuf, um so grössere Bewunderung gezollt werden.
Endziel der Arbeit ist: zu einer streng logischen Definition des relativen Begriffes „Anzahl von-“ zu gelangen, aus welcher sich alle auf diesen Begriff bezüglichen Sätze rein deduktiv werden ableiten lassen.
Dass damit auch dem endlosen Streite gleichwie dem Philosophastern über das Wesen der Zahl der Nährboden endgültig entzogen sein wird, dürfte nebenbei als ein nicht zu unterschätzender „Nutzen“ dieser Arbeit Erwähnung verdienen.
Da indessen der Begriff der Anzahl nur auf endliche Mengen (von „Einheiten“) sich anwendbar zeigt, ist zur Verwirklichung unsres Zieles die vorgängige Feststellung des Endlichkeitsbegriffes ohnehin unerlässlich.
Schon dieser ist kein sehr einfacher.
Wie wahr aber die frappante Bemerkung Dedekind’s ist, dass der Anzahlbegriff fälschlich für einfach gelte, das wird sich auch in unserm Buche greifbar herausstellen.
Als eine besondre Feinheit der Dedekind’schen Schrift sei noch hervorgehoben, dass in ihr die Ordinalzahlen eingeführt werden vor den Cardinalzahlen, und zwar sehr viel früher als diese.
Dies entspricht nebenbei auch dem historischen Entwickelungsgange auf einer Reihe von Grössengebieten, in welche wir den Quantitätsbegriff allmälig einführen und da beherrschen gelernt haben.
Wie es z. B. in der Physik bei dem Begriff der Härte einer Substanz noch heute der Fall ist (vergleiche die Moser’sche Härteskala) — bei dem Begriff der Temperatur aber erst seit Einführung des absoluten Nullpunktes nicht mehr — und in der Physiologie bei der Schätzung der Intensitäten oder Grade von gleichartigen Sinneseindrücken, auf wirtschaftlichem Gebiete bei so manchen Wertermittelungen und in der Ästhetik sogar wol noch bei allen Vergleichungsakten — vermögen wir die unter einen Begriff fallenden Objekte oft in eine gewisse Ordnung, Rang-, Stufen- oder Grössenfolge zu bringen ohne dass wir vermöchten sie auch in absolutem Maasse zu messen, lange bevor es uns gelingt sie darzustellen als gleichwertig einer „Anzahl“ von Maasseinheiten.
Als „vergleichbare“ sind sie noch lange nicht „messbare“ Grössen — „Grössen“ im vollsten Sinne des Wortes.
Bei zwei gegebnen festen Substanzen z. B. ist es ja in jedem Falle entscheidbar, welche von ihnen verdient die „härtere“ genannt zu werden, und gleichwol vermögen wir mit der Forderung der doppelten Härte, des „Zweimalsohartseins“, (noch) keinen Begriff zu verbinden.
Etc.
Ebenso nun steht auch in der That der Ordinalzahl als dem ursprünglichen und einfacheren Begriffe derjenige der Cardinalzahl als der abgeleitete und minder einfache gegenüber.
So viel über die Dedekind’sche Schrift im Allgemeinen.
Indem ich nun vom Standpunkte unsrer Theorie in eine Revision derselben eintrete, muss ich drei — wenn auch räumlich nicht durchaus zusammenhängende — Teile der Schrift unterscheiden und bei der Besprechung scharf auseinanderhalten.
Der „erste Teil“ besteht aus Dedekind’s § 1, welcher mit „Systeme von Elementen“ überschrieben ist und die, sei es Erklärungen, sei es Sätze, D 1 bis D 20 umfasst.
Derselbe ist wesentlich nur eine Darstellung der elementarsten (für den Autor unentbehrlichen) Begriffserklärungen und Sätze des identischen Kalkuls als eines Kalkuls mit („Klassen“ oder) „Gebieten“, für welches letztre Wort — das ich in meinem Bd. 1 vorwiegend verwendete — bei Dedekind eben das Wort „Systeme“ einspringt, dem ich in gegenwärtigem Bd. 3 ebenfalls den Vorzug gebe.
Die Erklärungen führen ein:
das „System“ von „Elementen“ (unsern Individuen“ des ersten Denkbereichs), ferner die Beziehungen der Einordnung oder des Enthaltenseins des „Teils“ im „Ganzen“, sowie der Gleichheit, und der Unterordnung des „echten“ Teils unter das Ganze, endlich das identische Produkt (bei Dedekind „Gemeinheit“ genannt) und die identische Summe von zwei oder mehrern Systemen (welche letztre Dedekind als das aus ihnen „zusammengesetzte“ System bezeichnet).
c heisst Gemeinteil“ von a und b, wenn c ⋹ a und c ⋹ b ist; ebenso heisst i „gemeinsames“ Element von a und b, falls i ⋹ a und i ⋹ b (D 17).
Die Sätze sind die allbekannten oder ganz nahe liegende Korollare von solchen, welche wir hier nicht blos für (D’s) „Systeme“, sondern auch für binäre Relative überhaupt in Anspruch zu nehmen bereits berechtigt sind.
Dieser erste Teil kommt hienach — für uns — in Wegfall, indem wir, statt seine Sätze anziehen zu müssen, mit den allergeläufigsten Errungenschaften des identischen Kalkuls auskommen werden.
In diesem Wegfall des gedachten Teiles (mit seinen 20 Sätzen), der durch sein Aufgehen in einer ohnehin vorhandenen nichts weniger als trocknen, vielmehr an Anwendungen reichen Disziplin vorbereitet ist, dürfte vielleicht schon eine kleine „Abkürzung“ der fast ermüdend langen Schlussreihen von Dedekind — wenigstens als solcher — zu erblicken sein.
Sonst freilich kann nicht gesagt werden, dass an dieser Stelle durch meinen voluminösen Bd. 1 gerade eine Abkürzung jener bewirkt werde.
Erwähnt sei noch, dass das in unserm Bd. 1 als „Prinzip II“ angeführte Schema des Subsumtionsschlusses in D 7 als „Satz“ mit einem Beweise“ gegeben wird.
Im Sinne des Autors, der sich durchweg des Argumentirens auf die Individuen (Elemente)“ bedient, kann man dies gelten lassen — während wir ebenso berechtigt waren l. c. das Schema von unserm dortigen Ausgangspunkte aus als unbeweisbar hinzustellen.
Begreiflich muss sich durch gedachten ersten Teil ein (wirklicher) Dualismus ziehen.
Wol zufolge des eben gekennzeichneten Umstandes (dass fortwährend auf Individuen argumentirend vorgegangen wird) kommt derselbe aber nicht ganz rein zum Ausdruck und fehlt z. B. als ein ausdrücklich statuirter der dual entsprechende Satz zu D 9.
Im übrigen dokumentirt sich auch bei Dedekind der Dualismus wenigstens darin, dass dual entsprechende Sätze jeweils als Nachbarn unmittelbar aufeinander folgen.
Ich werde, wo mir in späteren Teilen Gelegenheit dazu wird, den Dualismus, wie bisher stets, durch Gegenüberstellung der entsprechenden Sätze oder Formeln noch schärfer hervorheben.
Über die Frage, ob nicht das schlechtweg als Gedanken-Ding hingestellte „Element“ bei Dedekind doch etwas zu weit gefasst und einer begrifflichen Einschränkung bedürftig wäre, behalte ich mir für eine spätere Gelegenheit noch eine Äusserung vor.
Der „zweite Teil“ besteht aus D 22 bis incl. D 24 des mit „Abbildung eines Systems“ überschriebenen D § 2, dazu dem ganzen Inhalte — D 36 ‥ D 63 — des „Abbildung eines Systems in sich selbst“ betitelten D § 4.
Derselbe gipfelt in der Statuirung und dem Beweise des Satzes D 59, 60, welcher „die wissenschaftliche Grundlage des Schlusses der vollständigen Induktion“ bildet.
Dieser die „Theorie der Ketten“ enthaltende Teil ist es, der uns demnächst allein beschäftigen wird.
Den „dritten Teil“ bildet der ganze Rest der Schrift, nämlich D 21 nebst D 25 des D § 2, der D § 3 mit D 26 ‥ 35, endlich D § 5 ‥ 14 mit D 64 ‥ 167. Ungeachtet der hohen Wichtigkeit und des fundamentalen Charakters, welche schon dem zweiten Teile eignen, ist dieser dritte Teil ja als der allerwichtigste zu bezeichnen und in ihm der Schwerpunkt und Hauptinhalt der ganzen Arbeit zu erblicken.
Wir werden jedoch an denselben viel später erst herantreten, auch nicht nach seinem ganzen Umfange ihn zu inkorporiren haben.
Der Teil beginnt da und umfasst alle die Sätze, wo die für Dedekind’s „Abbildung“ geforderte Eindeutigkeit als eine wesentliche Voraussetzung der Untersuchungen eintritt, m. a. W. sich für die Geltung der Sätze wirklich unentbehrlich zeigt.
Als ganz besonders merkwürdig müssen wir nämlich nunmehr konstatiren, dass der gesamte „zweite Teil“ von Dedekind’s Arbeit, den ich eben mit Rücksicht hierauf als solchen abgegrenzt habe, von jener (ihm auferlegten) Voraussetzung unabhängig ist.
Die Sätze, welche dieser zweite Teil in sich schliesst, gelten nicht nur bezüglich der von Dedekind, gleichwie auch in unsrer Theorie, als „Systeme bezeichneten Relative, sondern sie gelten schon von den Relativen überhaupt; sie gelten nicht blos für die im Sinne Dedekind’s als „eindeutige“ Zuordnung aufgefasste „Abbildung“, sondern sie bleiben auch dem Wortlaut nach vollgültig bestehn, wenn man das Wort „Abbildung“ in dem weitesten Sinne gebraucht, dessen es fähig scheint, nämlich darunter versteht: eine gelegentlich auch „mehrdeutige“, nicht minder, wie eventuell auch unterbleibende (versagende, „undeutige“) Zuordnung — in welchem Falle das Wort synonym ist mit dem allgemeinen Begriff des (binären) Relatives.
Dem „zweiten Teile“ von Dedekind’s Schrift kommt also ein viel weiterer Geltungsbereich, eine grössere Tragweite zu, als ihm der Autor selber zugeschrieben; und darin, dass diese Thatsache klar hervortreten wird, dürfte immerhin schon ein Gewinn zu erblicken sein, welcher Dedekind’s Kettentheorie aus ihrer Eingliederung in die Algebra der Relative erwachsen muss.
Sogar Dedekind’s Beweise zu seinen einschlägigen Sätzen können zumeist und jedenfalls in den Hauptzügen beibehalten werden; sie sind nur ab und zu — weil jedes Argumentiren auf die „Elemente“ zu unterbleiben hat (als womit ein Satz blos für „Systeme“ bewiesen würde) — ein wenig zu modifiziren.
Was das Verhältniss der hier zur Anwendung kommenden Terminologie zu der Dedekind’schen betrifft, so suche ich zwar an letztere mich möglichst nahe anzuschliessen.
Ich werde demgemäss den D’schen Ausdruck „Bild von-“ (inbezug auf ein gegebenes Zuordnungsprinzip a, welches bei Dedekind zumeist unerwähnt bleibt) im Texte beibehalten, obgleich wir demselben die oben beschriebene erweiterte Bedeutung unterzulegen haben.
Gleichwol werden einige kleine Abweichungen unvermeidlich sein.
Wir werden in den Formeln niemals das Abbildungsprinzip unerwähnt lassen, dürfen im Texte seltener es totschweigen, und so müssen wir hier für Dedekind’s b' = „das Bild von b“ sagen: a; b = „das a-Bild von b“, was uns gleichbedeutend sein wird mit „(ein) a von b“, wo a, wie b, ein beliebig gewähltes binäres Relativ vorstellt.
Analog haben wir für Dedekind’s b0 = „die Kette von b“ zu sagen: a0; b = „die a-Kette von b“.
Unter a0 = „die a-Kette“ oder „die Kette von a“ verstehen wir sonach etwas wesentlich anderes als was Dedekind darunter verstehen müsste, nämlich ein gewisses (aus a ableitbares) Relativ, welches in Dedekind’s Kettentheorie gar nicht ausdrücklich vorkommt — ähnlich unter b0.
Und demgemäss ist auch für uns zu übersetzen Dedekind’s b0' = „die Bildkette von b“ mit: a00; b = „die a-Bildkette von b“, wobei a00 = „die a-Bildkette“ — für uns = „die Bildkette von a“ — wiederum eine selbständige Bedeutung als eines gewissen aus a allein ableitbaren Relatives hat.
Der Leser verfügt hiermit über den Schlüssel zur Übersetzung der einen Darstellung der Kettentheorie in die andre.
Wie zu sehn, ist unsre Bezeichnungsweise die ausdrucksvollere.
Dergleichen ist gewöhnlich nur mit dem Opfer einer grösseren Weitläufigkeit zu erkaufen — wie sie nicht selten auch in Pedanterie ausartet.
Das Verfahren hat jedoch auch manchmal sein Gutes, und speziell hier wird zu sehen sein, wie das kleine Opfer, welches wir durch die grössere Ausführlichkeit in unsrem Bezeichnungssysteme bringen, durch andre Vorteile reichlich aufgewogen ist, und wie trotz allem unsre Darstellung der Kettentheorie an Übersichtlichkeit keiner andern — auch derjenigen eines Meisters der Präzision und Knappheit, wie es ihr Urheber ist, nicht — nachstehn wird.
Nach diesen Vorbemerkungen, die mir durch die in der Literatur zu wünschende Stetigkeit des Überganges von einer Entwickelungsphase einer Theorie zur andern geboten schienen, könnten wir in medias res eintreten, wenn ich nicht glaubte, noch eines Umstandes im Voraus gedenken zu sollen.
Während, wie erwähnt, durch den „ersten Teil“ von Dedekind’s Schrift sich ein wirklicher Dualismus zieht, tritt in dem zweiten Teile ebenfalls ein Dualismus hervor, den ich aber nur als einen
Pseudo- oder Scheindualismus bezeichnen könnte.
Derselbe offenbart sich darin, dass die auf Bilder oder Ketten von Summen und von Produkten bezüglichen Sätze paarweise mit analogem Wortlaut auftreten und bei D sich unmittelbar folgen.
Während aber der eine Satz solchen Paares eine Gleichheit statuirt, vermag auffallenderweise der andre nur einseitig eine Einordnung zu konstatiren, die erst dann in Gleichheit übergeht, wenn die von Dedekind betrachtete eindeutige Abbildung als eine auch umkehrbar oder gegenseitig eindeutige vorausgesetzt wird.
Ich werde solche einander „pseudodual entsprechende“ Sätze durch doppelten Mittelstrich getrennt einander gegenüberstellen.
Die Aufhellung dieses Scheindualismus möchte ich — wenn es sich dabei auch nur um ästhetische Anforderungen des Intellekts handelt (der sich durch die erwähnte frappante Thatsache unmöglich befriedigt fühlen kann) — als einen weitern Gewinn verzeichnen, der für die Kettentheorie aus unsrer Revision herausspringt.
Daneben wird dann endlich auch der wirkliche Dualismus zu seinem Rechte kommen, der uns, in Verbindung mit dem Konjugationsprinzipe, die Fülle der durch Dedekind’s Leistung erschlossenen Erkenntnisse mit einem Schlage vervierfacht.
Ich beginne damit, zunächst blos in der Zeichensprache unsrer Algebra einen Überblick zu geben über sämtliche Definitionen und Sätze aus welchen sich Dedekind’s Kettentheorie aufbaut, und zwar in der für sie maassgebenden Reihenfolge — ohne Kommentar.
Nur der letzte D 63 von diesen Sätzen bleibe vorerst ausser Betracht, da ihn Dedekind blos anhangsweise, beiläufig, anführt ohne einen Beweis dafür zu geben, auch jemals Anwendung davon zu machen.
Die Buchstaben des kleinen lateinischen Alphabets bedeuten irgendwelche binäre Relative und es dürfen die Formeln sämtlich allgemeine Geltung in deren Algebra beanspruchen.
Ich bringe dieselben nach Opportunitätsrücksichten in Gruppen.
10)
[Formel]
20)
[Formel]
30)
[Formel]
40)
[Formel]
50) [Formel]
Den Satz D 51 gibt Dedekind nur als vorwärtige Subsumtion.
Die vorstehenden dreissig chiffrirten Sätze bilden mit ihrer Begründung den Inhalt von Dedekind’s Theorie der Ketten.
In dieser werden wir uns gründlich zu orientiren haben, und so wollen wir denn die Sätze zunächst einmal sozusagen gemütlich besprechen.
Wenn auch einzelne von diesen Sätzen gelegentlich später noch anderweitige Anwendung finden mögen, so ist der „Hauptzweck“ ihrer Aufstellung und für uns hier der einzige Zweck ihrer Zusammenstellung, den wir nicht aus dem Auge verlieren dürfen, der: einen Beweis des Satzes der vollständigen Induktion D 59 vorzubereiten und zu ermöglichen, welcher keinen Zirkelschluss enthält, bei dem also unterweges niemals vom Schlussverfahren der vollständigen Induktion selbst — noch weniger von einer „Definition durch Induktion“ — Gebrauch gemacht worden sein darf!
Es ist das Verdienst des Herrn Dedekind, das unter dem Namen des „Schlusses von n auf n + 1“ bekannte und weitverbreitete Beweisverfahren erstmals seines arithmetischen Beiwerks entkleidet, den logischen Kern desselben herausgeschält und so den „Satz der vollständigen Induktion als einen Satz der allgemeinen Logik formulirt zu haben, der sich unabhängig vom Zahlbegriffe und selbst vor Einführung der Zahlenreihe darstellen und einsehen lässt.
Nicht minder aber darf Herr Dedekind auch das Verdienst beanspruchen, diesen Satz dann auch korrekt, auf den (oben betonten) Anforderungen der Strenge in der That genügende Art, erstmals bewiesen zu haben — und zwar in einer überaus kunstvollen Weise.
Es dürfte dieser Beweis seinen Wert nicht verlieren, selbst wenn es uns hernach gelingen wird, solchen Beweis wesentlich vereinfacht zu liefern.
Der Satz schreibt sich, wie man sieht, mittelst Aufwandes von nur neun Buchstaben.
Ausser den Zeichen, welche schon geläufig sind aus der allgemeinen Theorie der Relative, kommt darin blos ein apartes Zeichen vor: a0, und zwar durchweg in der Verbindung: a0; b — ein Zeichen, welches einem besondern Zweig jener Disziplin, nämlich der „Kettentheorie“ eigentümlich ist.
Das ist mehr, als — beiläufig bemerkt — das „Volapük“ zu leisten vermag und jemals imstande sein wird zu leisten!
Der Etablirung des Satzes D 59 wird daher eine Definition von sei es a0, sei es sogleich a0; b, voraufzugehen haben, und diese Definition — von Dedekind mit D 44 (oder auch in Gestalt von D 48) geliefert — wird das punctum saliens, den Ausgangspunkt der ganzen Theorie vorstellen.
Von ihrer Wahl wird die Gestaltung der Kettentheorie wesentlich abhängen.
Ehe ich auf die bei dieser Definition zu überkommenden Schwierigkeiten eingehe, welche lediglich durch die Rücksichtnahme auf unsern „Hauptzweck“ bedingt sein werden, will ich einige Bemerkungen einflechten, die — sozusagen rein äusserlich — auf eine Verringerung (um mehr als die Hälfte) des noch fernerhin in Betracht zu ziehenden Systems von Sätzen abzielen:
Mit der Erklärung D 36 wird eine Redensart eingeführt, von der Dedekind in der Kettentheorie selbst gar keinen Gebrauch macht, obzwar sie in den späteren Teilen seiner Schrift ausgiebig verwendet wird.
Es dürfte ohnehin in Frage zu ziehen sein, ob diese Redensart, wenn unter b nicht notwendig ein „System“, sondern ein Relativ überhaupt, ebenso unter a nicht blos eine „eindeutige Abbildung“, sondern ein allgemeines Relativ verstanden wird, noch als hinreichend zutreffend beizubehalten wäre — ob man nicht vielleicht besser thäte zu sagen:
„a bezieht b in sich ein“, oder „bildet es in sich ein“ (statt „ab“), und dergleichen.
Jedenfalls können auch wir uns der Anwendung solcher Redensart enthalten und die Def. D 36 für das Folgende ignoriren.
Wenn wir ebenso die unter D 60 zu gebende Erläuterung vorerst zurückstellen, so verbleiben uns von den 30 noch 28 Sätze.
Von den verbleibenden Sätzen scheinen für uns sogleich die achte in Wegfall zu kommen, die ich durch ein Ringelchen gekennzeichnet habe: D 22, 23, 24, 38, 39, 54, 61, 62.
Dieselben verstehen sich nämlich aus den allgemeinen Sätzen unsrer Algebra 1), 4) und 5) des § 6 geradezu von selbst, beziehungsweise sie fallen mit diesen drei Peirce’schen Sätzen entweder völlig zusammen oder sind blos Sonderfälle, partikulare Anwendungen derselben — die von D 54 an jedoch aufgrund der Unterstellung, dass a0 seine Erklärung als ein binäres Relativ finde oder gefunden habe.
Solange diese Unterstellung blos inbezug auf „a0; b“ zutrifft, werden wir allerdings die drei letzten von den acht angeführten Sätzen zunächst noch beizubehalten haben!
Jedenfalls aber verdienen die fünf ersten derselben überhaupt nicht als besondre Sätze chiffrirt und angeführt zu werden.
Es sei denn zu dem Zwecke, um sich dieselben in verbaler Fassung vertraut zu machen — unter Einübung der Redensarten „a-Bild von-“, Kette inbezug auf a“ (D 37) und „a-Kette von-“.
In dieser Absicht möge hier notifizirt werden:
D 22.
Ist b enthalten in c, so ist auch das a-Bild von b enthalten im a-Bild von c, oder: Das Bild eines Teils ist ein Teil vom Bilde des Ganzen.
D 23.
Das a-Bild einer Summe ist einerlei mit der Summe der a-Bilder von deren Gliedern.
D 24.
Das a-Bild eines Produktes ist enthalten in dem Produkte (ist „Gemeinteil“) der a-Bilder von dessen Faktoren — Summe und Produkt natürlich immer als identische verstanden.
D 38.
Der Denkbereich 12 ist Kette inbezug auf jedes Relativ (a — in ihm selber).
Der schon anderweitig bekannte Satz a; 1 ⋹ 1 kann auch nach 1) des § 6 in Gestalt von a; 1 ⋹ 1; 1 gemäss dem Abacus aus a ⋹ 1 gefolgert werden.
D 39.
Das a-Bild einer Kette inbezug auf a ist eine Kette inbezug auf a.
Dies leuchtet ein, wenn man die Konklusion in der Gestalt a; (a; b) ⋹ a; b aus der Prämisse zieht und sie in ebendieser mit dem Schema D 37 vergleicht.
[D 54.
Die a-Kette eines Teiles ist Teil der a-Kette vom Ganzen.
— Wird ausfallen.]
D 61.
Die a-Kette einer Summe ist einerlei mit der Summe der a-Ketten ihrer Glieder.
D 62.
Die a-Kette eines Produkts ist Gemeinteil der a-Ketten seiner Faktoren.
Unter demselben Gesichtspunkt erscheint aber auch D 56 als eine doch allzunahe liegende Folgerung aus D 53, als dass dieselbe verdienen könnte als ein besondrer Satz registrirt zu werden.
Und Ähnliches gilt von dem (vorhin in andrer Hinsicht erwähnten) D 54, welches mit D 52 und 53 schon a fortiori gegeben erscheint.
Ich möchte deshalb den Leser bitten, sooft im Nachfolgenden von dem Formelkomplex der Kettentheorie gesprochen wird, sich die drei Zeilen der Gruppe 40), welche fünf Sätze D 52 ‥ D 56 anführt, ausgemerzt und durch die zwei Zeilen der folgenden Gruppe ersetzt denken zu wollen: 60) [Formel] — welche ihrerseits nur drei Sätze enthält, indem von den drei Aussagensubsumtionen der ersten Zeile blos die zwei ersten bewiesen zu werden brauchen.
Ganz ebenso endlich wäre D 49 als blosses Korollar zu D 45 zu unterdrücken.
Das ist freilich nur eine Kleinigkeit, die aber doch etwas beitragen wird, die Schönheit der Theorie zu erhöhen, bei der die übergrosse Menge so kleiner Sätze fast verwirrend wirkt.
Sodann will ich dem „Schein-Dualismus“ kurz zuleibe gehen, von dem ich in der Einleitung gesprochen.
Derselbe macht sich bei sechs Sätzen — zunächst bei den Formeln der zweiten und denen der letzten Zeile unsrer Zusammenstellung — bemerklich, sobald dieselben nur in der Dedekind’schen (oder in einer ihr angepassten) Bezeichnung vorgeführt werden.
Sind in der That die Formeln wie folgt geschrieben: so scheinen die nebeneinanderstehenden geradezu einander dual entsprechen zu müssen (mit Bezug auf den unwillkürlich, aber eben unberechtigterweise festgehaltenen „Bild-“ resp. „Ketten-“Begriff, den der Accent resp. das Suffixum 0 bei Dedekind repräsentirt).
Mit solch dualem Entsprechen bleibt jedoch unvereinbar: die Verschiedenheit der Beziehungszeichen, welche links als Gleichheits-, rechts als Einordnungszeichen sich darstellen.
Die — wenn ich so sagen darf — „Paradoxie“ dieses Pseudodualismus rührt nur von der „unzulänglichen“ Bezeichnung her, und hellt sich auf, sobald man die Sätze — so wie es in 10 und 50) von uns geschehen — hinreichend „ausdrucksvoll“ darstellt.
Da erkennt man denn sofort — was dem Accent z. B. nicht anzusehen gewesen — dass der Begriff „a-Bild von-“ imgleichen wie der „a-Kette von-“ sich selber keineswegs dual entspricht, und dass die einander (als „pseudoduale“) gegenübergestellten Sätze in der That aus ganz verschiedenen Formelgespannen der allgemeinen Theorie entstammen, die links nämlich dem Gespanne 4), die rechts dem Gespanne 5) des § 6, in welchem letztern statt der Gleichheitszeichen nur Subsumtionszeichen obwalten konnten.
D 23. (b + c + …)' = b' + c' + … D 24. (bc …)' ⋹ b' c' … D 61. (b + c + …)0 = b0 + c0 + … D 62. (bc …)0 ⋹ b0c0 …,
Ähnlich dürfen auch die Sätze D 42 und 43 nur scheindual genannt werden, obwol in beiden gleichermassen ein Subsumtionszeichen steht. —
Wollen wir nun also die Kettentheorie unter engstem Anschluss an Dedekind uns möglichst einfach zurechtlegen, dieselbe in den Rahmen unsrer allgemeineren Disziplin einpassend, so wird von der ganzen Gruppe 10) nur die Definition jener Redensart D 37 beizubehalten oder in Erinnerung zu bringen sein, die wir ja übrigens schon nebenher in § 22 sub 5) in unsere Disziplin aufgenommen haben.
Sodann werden wir jetzt einfürallemal zu erledigen haben die vier Sätze der Gruppe 20), welche dem „punctum saliens“ D 44 noch vorangehen.
Von diesen möchte ich die Sätze D 42 und 43 lieber vorannehmen — als die elementareren und weil sie von allgemeinerem Interesse sind, wogegen die D 40 und 41 mehr nur als Hülfssätze zu später benötigten Beweisführungen ihre Berechtigung zu haben scheinen, sodann auch, weil letztere ebendadurch unmittelbaren Anschluss gewinnen an die mit D 44 beginnenden Betrachtungen, deren Zwecke sie zu fördern bestimmt sind, und mit denen sie Zugehörigkeit verraten.
D 42 und 43 statuiren:
Die Summe resp. das Produkt von Ketten inbezug auf ein Relativ a ist eine Kette inbezug auf ebendieses.
Um ihre Formeln in 20) zu beweisen, braucht man blos die Prämissen überschiebend durch Addition resp. Multiplikation zu verknüpfen, wodurch sich ergibt: a; b + a; c + … ⋹ b + c + … resp. a; b · a; c … ⋹ b · c … und dann das Schema 4) resp. 5) des § 6: a; b + a; c + … = a; (b + c + …) resp. a; bc … ⋹ a; b · a; c … in Anwendung zu bringen.
Die Konklusion zum Satze links wird alsdann pariter (d. i. als äquivalente Transformation), die zum Satze rechts aber a fortiori gewonnen.
Die beiden Sätze würden sich vereinigen und zugleich ausdehnen lassen zu dem allgemeinern:
Das Ergebniss irgendwelcher Knüpfungen (mittelst identischer Operationen) von irgendwelchen Ketten inbezug auf einunddasselbe Relativ a ist wieder eine Kette inbezug auf ebendieses.
Sind z. B. b, c, d, e, f Ketten bezüglich a, so ist bc + def sowie (b + cd)e + f, etc. wieder eine solche.
Der Satz gälte sogar ohne die Worte in Klammer.
D 40: (a; c ⋹ c)(b ⋹ c) ⋹ (a; b ⋹ c) besagt: Das Bild eines Kettenteiles ist Teil dieser Kette, genauer: das a-Bild a; b des Teils b einer Kette c inbezug auf a ist enthalten in dieser Kette c.
Der Beweis ergibt sich, indem man aus der zweiten der beiden Teilprämissen, in welche die gegebene Prämisse wie vorstehend angegeben zerfällt, mittelst beiderseitigen relativen Vormultiplizirens mit a gemäss 1) des § 6 den Schluss zieht: a; b ⋹ a; c, und diesen mit der ersten Teilprämisse behufs Anwendung des Subsumtionsschlusses zusammenhält.
D 41. [Formel] — wie der Satz nach Zerfällung der beiderseitigen Aussagen lautet, besagt:
Ist das a-Bild von b Teil einer Kette c inbezug auf a, so gibt es eine Kette u (Kette inbezug auf a) derart, dass sie b in sich enthält und ihr a-Bild in c enthalten ist, m. a. W. von der b ein Teil ist und deren a-Bild Teil von c ist.
Der Beweis (etwa beginnend mit:
„Denn es ist …“) kann auch als Fortsetzung des Satzes ausgesprochen werden:
„Und zwar ist“ u = b + c eine solche Kette.
Dieselbe erfüllt nämlich in der That die drei Forderungen der vorstehend zerlegten Behauptung, und zwar die dritte kraft der in 20) noch unzerlegten Prämisse, die zweite identisch wegen b ⋹ b + c und die erste a fortiori mit Rücksicht auf die dritte nebst c ⋹ b + c.
Die 4 hiermit erledigten Sätze könnten noch zur „Einleitung“ der Kettentheorie gerechnet werden, die nun erst recht — mit dem punctum saliens D 44 — beginnt, und wenn man will schon mit D 59 abschliesst.
In dieser werden uns nach dem Vorbemerkten 14 (zu 15 — falls man etwa die Zusatzdefinition zum Satze D 57 gesondert zählt) — sage vierzehn — Erklärungen oder Sätze (noch keine halbe Druckseite!) zu studiren bleiben.
Diese Reihe von Sätzen aber werden wir jetzt von zwei ganz verschiedenen Standpunkten aus durchgehen und einsehen — man kann beinah vollkommen zutreffend sagen:
in den zwei entgegengesetzten Richtungen hin und her, oder „vorwärts“ und „rückwärts“.
Der „Rückweg“ („Herweg“) ist bei weitem kürzer, dazu bequemer und leichter, zumal er auch nicht ganz zu Ende gegangen zu werden braucht und sogar die schon als „Einleitung“ erledigte Gruppe 20) von Sätzen für ihn entbehrlich bleibt.
Diesen Weg zuerst zu gehn erscheint aus didaktischen Gründen geboten.
Dagegen erweist nur der „Hinweg“ („? Vorweg“), d. h. der „vorwärts“ zurückzulegende Weg, sich als mit unserm „Hauptzwecke“ der Kettentheorie vereinbar!
Jenen Rückweg zu gehn empfiehlt nachträglich auch Herr Dedekind selbst seinem Leser — p. 40 unter D 131.
Dabei würde von dem Ergebnisse D 58 auszugehen sein, welches sich mit Rücksicht auf die unmittelbar vorhergehende Definition D 57 auch in der Gestalt schreiben lässt: a0; b = b + a; a0; b und nun, indem man rechterhand immerfort den Wert der linken Seite aus der Gleichung selbst einträgt, zu der „unendlichen“ (unbegrenzten) Entwickelung führt: 0)
[Formel] wodurch es nahe gelegt erscheint, das in Klammer stehende Relativ selbst als a0 zu definiren.
Wir werden diesen Gang noch nicht unwesentlich vereinfachen, indem wir, statt von der Betrachtung des a0; b auszugehen, lieber sogleich a0 selbst (nebst a00) einführen.
Der Rückweg.
Handelt es sich lediglich darum, die Formel D 59 als einen allgemeinen Satz in der Theorie der binären Relative zu beweisen, indem man die Bedeutung ebendesselben als des „Satzes der vollständigen Induktion“ ignorirt, und demgemäss sich nicht scheut, da wo etwa unendliche Entwickelungen vorkommen, das Bildungsgesetz derselben ver mittelst des „Schlusses der vollständigen Induktion“ festzustellen — mithin ganz so zuwerke zu gehen, wie wir es in den frühern Vorlesungen, da wo eine Lösung nicht in geschlossener Form zu geben war, immer thaten (und auch künftig, obzwar dann mit fester begründetem Rechte, wieder thun werden) — so führt uns folgender modus procedendi zum Ziele.
Wir lassen aus Dedekind’s Kettentheorie die schwerkalibrigen Sätze D 44 und 48 ganz beiseite (auch sie vom gegenwärtigen Ausgangspunkte aus zu gewinnen, sei in die Studien des nächsten Paragraphen verwiesen) und definiren die „a-Bildkette“ a00 und die „a-Kette“ a0 oder „Kette eines beliebigen Relativs a“ wie links vom Striche folgt: 1) 2)
a00 = a + a; a + a; a; a + … a11 = a(a ɟ a)(a ɟ a ɟ a) …
a0 = 1' + a00 a1 = 0'a11.
Nun ist natürlich: 3) 4) und ferner gilt: 5) 6) 7) wie durch Einsetzen der als Bedeutung von a00 und a0 hingestellten Reihen und relatives Ausmultipliziren mit Leichtigkeit zu sehen.
1' ⋹ a0 a1⋹ 0'
a⋹a00⋹a0 a1⋹a11⋹a
a; a00 = a00; a00 = a00; a ⋹ a00 a11⋹a ɟ a11 = a11 ɟ a11 = a11 ɟ a
a; a0 = a00 = a0; a ⋹ a0 a1⋹a ɟ a1 = a11 = a1 ɟ a
a0; a0 = a0 a1 ɟ a1 = a1
Man hat z. B. a; a00 = a; (a + a; a + a; a; a + …) = a; a + a; a; a + a; a; a; a + … a00; a00 = (a + a; a + a; a; a + …); (a + a; a + a; a; a + …) = = a; a + a; a; a + a; a; a; a + …, welche Glieder hier allerdings zunehmend in tautologischer Wiederholung erhalten werden, sintemal man jedes Glied der einen Reihe im Geiste zu verknüpfen hat mit jedem Gliede der andern.
Beidemal kommt mithin die Summe der zu a00 zusammengefassten Glieder vom ersten Gliede ab heraus (die man vielleicht auch a000 nennen könnte — und so fort).
Bei 6) hat man ebenso: a; a0 = a; (1' + a + a; a + …) = a + a; a + a; a; a + … = a00, sintemal a; 1' = a ist.
Zum Beweise von 7) braucht man nun die analoge Überlegung nicht nochmals zu machen, sondern kann den Satz auf den 5) zurückführen ohne nochmals mit unendlichen Reihen zu operiren — wie folgt: a0; a0 = (1' + a00); (1' + a00) = 1'; 1' + a00; 1' + 1'; a00 + a00; a00 = = 1' + a00 + a00; a00 = 1' + a00 = a0, sintemal das dritte Glied der letzten Zeile wegen der mit 5) erwiesenen Subsumtion a00; a00 ⋹ a00 vom vorhergehenden absorbirt wird.
Man wolle übrigens a00 nicht etwa fälschlich auffassen als „Kette von a0“, das ist (a0)0.
Solchen Missverständnissen beugen beiläufig die Sätze vor: 8)
[Formel]
Es ist also die „Kette der Kette von a“ nichts andres als die „Kette von a“.
Ebendarum wäre es thöricht, jene mit dem doppelten Suffix 00 darstellen zu wollen, und wird letzteres für andre Bezeichnungszwecke verfügbar.
— Die Sätze 8) wird sich der Leser leicht aus 7) und 5) rechtfertigen, z. B. es muss (a0)0 = 1' + a0 + a0; a0 + a0; a0; a0 + … = 1' + (1' + a00) + a0 + a0 + … = a0 sein.
Etc.
Die Operationen des Kette- oder Bildkettenehmens können an einer Bildkette oder Kette immer sogleich ausgeführt werden.
Zum Beweise von D 59 bedürfen wir nun blos der drei Sätze D 45, D 55 und D 47.
D 45 besagt:
jedes Relativ b ist Teil der a-Kette von ihm selber, und versteht sich als der Satz: 9)
[Formel] aus 3) sozusagen von selber; durch beiderseitiges relatives Multipliziren mit b folgt ja: 1'; b ⋹ a0; b also b ⋹ a0; b, q. e. d.
Ebenso haben wir mit Rücksicht auf 6) und 4): (b ⋹ a0; c) ⋹ (a; b ⋹ a; a0; c = a00; c ⋹ a0; c) und damit D 55 bewiesen, oder den Satz: 10) [Formel] d. h. das a-Bild eines Teils b der a-Kette von c ist ebenfalls Teil von dieser.
Endlich der Satz D 47 gehört dem Gespanne an: 11) [Formel] und zerfällt dessen Prämisse in: (a; c ⋹ c)(b ⋹ c).
Derselbe besagt deshalb:
Ist b Teil einer Kette c inbezug auf a, so ist auch die a-Kette von b Teil dieser Kette c. Behufs Beweises ziehn wir aus der zweiten Prämisse, in stetem Hinblick auf die erste, die unbegrenzte Reihe von Schlüssen:
b⋹c, a; b ⋹ a; c, also a; b ⋹ c, a; a; b ⋹ a; c, a; a; b ⋹ c, a; a; a; b ⋹ a; c, a; a; a; b ⋹ c, und so weiter . . . . . . . . . . . . . Überschiebendes Addiren der linkerhand stehenden Folgerungen liefert dann — mit Rücksicht auf b = 1'; b — die Konklusion: a0; b ⋹ c.
Dieser Schluss ist die Wiederholung des bei D 40 gemachten, braucht aber für jetzt nicht gerade als ein Satz formulirt zu sein.
Man sieht, dass bei diesem „und so weiter“ der „Schluss von n auf n + 1“ gemacht worden und in der That unentbehrlich ist.
Um ihn auf das schärfste als solchen hervortreten zu lassen, brauchen wir blos — was für n = 1 und 2 schon zutrifft — für ein bestimmtes n als erwiesen anzunehmen, dass aufgrund der Voraussetzungen unsres Satzes bereits an; b ⋹ c erwiesen sei, und darnach mittelst der Schlüsse: a; an; b ⋹ a; c ⋹ c darzuthun, dass alsdann auch an + 1; b ⋹ c gelten muss.
Daraufhin ist nun die Folgerung an; b ⋹ c als eine für jede Zahl n gültige hinzustellen, indem, wenn sie für eine bestimmte Zahl gilt, sie immer auch für die nächst höhere gelten muss, und sie für n = 1 ja gilt (folglich auch für n = 2, zufolgedessen wieder für n = 3 und so fort in infinitum).
Auf diesen Teilschlüssen aber beruhte der obige Beweis. —
Beiläufig kann man denselben auch für den ganzen Satz auf einmal führen in Gestalt einer unbegrenzten Serie von äquivalenten Aussagentransformationen.
Zu dem Ende schreiben wir das Schema des D 40 „voller“ an in der Gestalt: 12) (b + a; c ⋹ c) = {b + a; (b + c) ⋹ c} = (b + a; b + a; c ⋹ c), indem wir die Hypothesis des Satzes in der Thesis nochmals miterwähnen, die Voraussetzung bei der Behauptung wiederholend, sie zu dieser schlagen und mit ihr vereinigen — was nach dem principium identitatis des Aussagenkalkuls gestattet ist.
Weil dann der Schluss von der Voraussetzung auf die Behauptung auch rückwärts zulässig, indem diese ja jene mit in sich schliesst, so geht hierbei die Aussagensubsumtion in eine Aussagenäquivalenz oder Gleichung über.
Diese Bemerkung, aufgrund deren auch offenbar 13) (a; c + b ⋹ c) ⋹ {a; (b + c) ⋹ c} sein muss, schlägt nebenbei eine Brücke von D 40 zu D 41, dessen Thesis hiernach auch eine Konklusion sein muss zur Hypothesis von D 40.
Bemerkt man nun, dass die dritte Aussage 12) von derselben Form ist wie die erste und sich von ihr blos dadurch unterscheidet, dass das Glied b dort hier vertreten ist durch b + a; b, so offenbart sich, dass uns der Satz 12) ein Recht gibt, so lange fortgesetzt als wir mögen seine Aussage äquivalent umzuschreiben dadurch, dass wir b durch b + a; b ersetzen.
Nun ist blos noch die „Wahrnehmung“ erforderlich, dass der Effekt solcher Ersetzung, wenn sie durchweg mit b vorgenommen wird, ganz derselbe ist, wie wenn sie blos an dem letzten b vollzogen wird, und so werden wir leicht als mit den Aussagen 12) äquivalent die folgenden hinzugewinnen:
= (b + a; b + a2; b + a; c ⋹ c) = (b + a; b + a2; b + a3; b + a; c ⋹ c) = …, welche bei der erlaubten Unterdrückung des Gliedes a; c — d. h. bei Verschweigung des Aussagenfaktors (a; c ⋹ c) — uns die Konklusionen vorstellen, die auf eine unbegrenzte Gliedermenge ausgedehnt unsern Satz D 47 ausmachen.
Jene „Wahrnehmung“ allgemein zu begründen genügt der Nachweis, dass, wenn etwa (1' + a + a2 + a3 + … + an); b = fn(b) genannt wird, fn(b + a; b) = fn + 1(b) sein muss — wo dann schliesslich f∞(b) = a0; b ist.
Dieser Nachweis unterliegt aber in der That keiner Schwierigkeit.
Indem f1(b) = f(b) = b + a; b = (1' + a); b hier bedeutete und ohnehin (1' + a)n; (1' + a) = (1' + a)n + 1 sein muss — vergl. die in § 13 unter 8) gegebene „induktorische“ oder „rekurrente“ Definition der Potenz — kann man den zu liefernden Nachweis auch dahin vereinfachen, dass man blos durch den Schluss von n auf n + 1 zeigt, dass 14) (1' + a)n = 1' + a + a2 + a3 + a4 + … + an sein muss:
Gilt dies für ein bestimmtes n, so erhält man nämlich, beide Seiten mit 1' + a relativ nach- und rechts dabei ausmultiplizirend: (1' + a)n + 1 = 1' + a + … + an + an + 1 unter tautologischer Wiederholung aller Glieder zwischen dem ersten und letzten.
Damit wird auch 15) a0 = (1' + a)∞ gewonnen sein. —
Soferne also der Schluss der vollständigen Induktion seine Berechtigung erst aus dem Satze D 59 schöpft, der seinerseits nur aufgrund von D 47 zu beweisen sein wird, enthält der Beweis von D 59 (zu dem wir nachher schreiten) noch einen Zirkel und hat blos den Wert, die Überzeugung zu gewähren: dass, wenn jener Induktionsschluss in dem einen hier vorliegenden Falle — bei D 47 wenigstens — materiell berechtigt gewesen, er dann auch formale oder allgemeine Geltung, für jeden Fall seiner Anwendung, wird beanspruchen dürfen.
Vor allem seien jetzt nebenher auch die übrigen Sätze unsres Überblicks von unserm Standpunkt aus erledigt.
D 46 — einfacher als a00; b ⋹ a0; b zu schreiben — versteht sich aus 4); ebenso D 49 als a; b ⋹ a00; b, und D 50; D 57 aus 6), D 58 aus 2).
D 52 versteht sich mittelst der Überlegung: (b ⋹ c) ⋹ (a0; b ⋹ a0; c) wegen D45 oder 9) a fortiori, und darnach auch D 53 mittelst (b ⋹ a0; c) ⋹ (a0; b ⋹ a0; a0; c = a0; c) aus 7).
Bleibt nur mehr die Gleichung D 51 als Subsumtion vor- und rückwärts zu beweisen.
Wegen (b ⋹ b) = 1 ist: (a; b ⋹ b) = (a; b ⋹ b)(b ⋹ b) = (a; b + b ⋹ b) ⋹ (a0; b ⋹ b) — nach D 47, für c = b in Anspruch genommen — falls man nicht etwa ganz ähnliche Schlüsse wie dort wiederholen will.
Da nun nach D45 oder 9) die umgekehrte Subsumtion ohnehin gilt, so ist die in D 51 rechts behauptete Gleichung aus der Prämisse links erwiesen.
Umgekehrt folgt diese aus jener, indem dann wegen D50 oder 4): a; b ⋹ a0; b ⋹ b wird sein müssen.
So leicht war der Herweg zu gehen — bei dem schon die Schlüsse dieses Kontextes einen Luxus bildeten!
Der Satz der vollständigen Induktion D 59 gehört dem Gespanne an: 16) [Formel]
Sein Beweis ist in Anbetracht, dass seine Prämisse zerfällt in I. a; (a0; b)c ⋹ c und II. b ⋹ c, wie folgt zu leisten.
Es ist: b ⋹ a0; b nach D45 oder 9), und dies mit II vereinigt gibt den Schluss: III. b ⋹ (a0; b)c.
Andrerseits ist: IV. (a0; b)c ⋹ a0; b, woraus nach D 55 oder 10) — für b statt c und (a0; b)c statt b in Anspruch genommen — folgt:
a; (a0; b)c ⋹ a0; b, und dies mit der Prämisse I vereinigt gibt: V. a; (a0; b)c ⋹ (a0; b)c.
Die Vereinigung von III und V lautet: a; (a0; b)c + b ⋹ (a0; b)c.
Dies fällt nun unter das Schema der Prämisse von D 47 oder 11) — worin nur c vertreten erscheint durch den zusammengesetzteren Ausdruck (a0; b)c — gestattet somit nach dem Vorbild jenes Satzes den Schluss: a0; b ⋹ (a0; b)c, und da die umgekehrte Subsumtion — IV — ohnehin gilt, so ist die Gleichung gewonnen: VI. a0; b = (a0; b)c, aus welcher wegen (a0; b)c ⋹ c zugleich die Konklusion fliesst: a0; b ⋹ c, welche zu beweisen gewesen.
Woferne nur die formalen Grundlagen 9, 10, 11) dieses Beweises späterhin auf einem zirkel- resp. einwandsfreien Wege gewonnen werden, wird auch der vorstehende Beweis vollkräftig und braucht nicht wiederholt zu werden.
Versucht man etwa den Satz 16) kunstlos mittelst Einsetzung der Reihe für a0 zu verifiziren, so hat man die Prämissen: b ⋹ c, a; bc ⋹ c, a; (a; b)c ⋹ c, a; (a2; b)c ⋹ c, a; (a3; b)c ⋹ c, … und muss suchen die Konklusionen zu gewinnen: b⋹c, a; b ⋹ c, a2; b ⋹ c, a3; b ⋹ c, ….
Nun ist zwar a; bc ⋹ a; b (sei es wegen bc ⋹ b, sei es wegen a; bc ⋹ a; b · a; c ⋹ a; b).
Und ebenso ist a; (a; b)c ⋹ a; (a; b) = a2; b, und so weiter.
Die Konklusionen würden sonach leicht zu ziehen sein, wenn diese Subsumtionen im entgegengesetzten Sinne, wenn sie als die umgekehrten, rückwärts Geltung hätten.
Da solches keineswegs ersichtlich, so scheitert obiger Versuch und wird man inne, dass ein einfacherer Beweis als der eben vorgetragne — trotz so verschiednen Aussehens — wesentlich Dedekind’sche, schwerlich geliefert werden kann.
Man kann den Satz D 59 — ihn zunächst lediglich als ein Theorem über binäre Relative in’s Auge fassend — auch in Worte kleiden wie folgt:
Um zu beweisen, dass die a-Kette eines Relativs b ganz in einem dritten Relativ c enthalten ist, braucht man blos zweierlei darzuthun, nämlich genügt es zu zeigen:
erstens, dass b selber in c enthalten ist,
zweitens, dass von jedem der a-Kette von b angehörigen Elementepaar, welches in c enthalten ist, auch das a-Bild in c enthalten sein muss.
M. a. W. a0; b muss Teil von c sein, sobald b Teil von c und auch das a-Bild jedes gemeinsamen Elementepaars von a0; b und c Teil von c ist.
[Das a-Bild der Summe aller im identischen Produkte (a0; b)c enthaltnen Elementepaare, welche letztern ebendieses Relativ additiv zusammensetzen — mithin a; (a0; b)c — ist ja einerlei mit der Summe der a-Bilder von allen diesen Elementepaaren.]
Soferne b und c uns späterhin „Systeme“ vorstellen, wird man im vorigen Texte das Wort „Elementepaar“ auch durch „Element“ zu ersetzen berechtigt sein.
Nunmehr wollen wir an Stelle von D 60 versuchen, dem Leser in Kürze einleuchtend zu machen, wieso der Satz D 59 oder 16) in der That »die wissenschaftliche Grundlage für die unter dem Namen der vollständigen Induktion (des Schlusses von n auf n + 1) bekannte Beweisart bildet.
Hiezu ist blos erforderlich, dem Denkbereich 1 und den Buchstabenrelativen a, b, c in dem Satze die folgenden Bedeutungen beizulegen.
Der Denkbereich 11 bestehe aus den Individuen 1̇, 2, 3, 4, … der unbegrenzten Zahlenreihe, deren erstes, oder die Zahl Eins, wir ad hoc durch den Tupfen in Gestalt von 1̇ von dem Modul 1 unsrer Theorie unterscheiden.
Im Denkbereiche12 oder 1 wird ein jedes Element dieser Zahlenreihe sich als ein Relativ darstellen, welches die jenem entsprechende Zeile zur Vollzeile und alle übrigen Zeilen zu Leerzeilen hat, und jedes System von Zahlen wird als das Relativ erscheinen, dessen Matrix die seinen Elementen entsprechenden Zeilen zu Vollzeilen, die übrigen zu Leerzeilen hat.
Dies sei zunächst in Erinnerung gebracht, obwol es im Folgenden gerade keine wesentliche Rolle spielt.
Die Zahlenreihe ist als eine wohlgeordnete eingeführt zu denken vermittelst eines Zuordnungs- oder Abbildungsprinzips, welches von einer jeden zur nächstfolgenden hinüberleitet und damit alle Zahlen mittelbar aus der ersten von ihnen als der „Grundzahl“ 1̇ der Zahlenreihe entstehen lässt.
Dies Abbildungsprinzip ist das Relativ: a = „um 1̇ grösser als-“.
Die auf 1̇ folgenden Zahlen sind also m. a. W. wie folgt definirt zu denken: die „Zahl“ zwei als „um 1̇ grösser als 1̇“, das ist: 2 = 1̇ + 1̇, und ebenso 3 = 2 + 1̇, 4 = 3 + 1̇, … — wo die Pluszeichen als arithmetische aufzufassen — oder in der Bezeichnungsweise unsrer Disziplin: 2 = a; 1̇, 3 = a; 2, 4 = a; 3, … d. h. jede Zahl ist definirt als das „a-Bild“ ihres Vorgängers — ausgenommen die Grundzahl 1̇ selbst, welche bei der Beschränkung, die wir oben dem Denkbereiche auferlegten, keinen Vorgänger besitzt.
Die Matrix dieses binären Relativs a ist beiläufig gesagt so beschaffen:
sie hat die erste Zeile zur Leerzeile, in jeder folgenden Zeile aber ein (und nur ein) Auge, und zwar an derjenigen Stelle, welche der links von (sive unterhalb) der Hauptdiagonale dieser am nächsten stehende Gitterpunkt ist.
Die ganze Zahlenreihe, oder das Zahlensystem (schlechtweg), als der Inbegriff, die Gesamtheit oder identische (aber nicht arithmetische!) Summe aller Zahlenindividuen, stellt sich hiernach dar als die a-Kette der Grundzahl 1̇. M. a. W. es ist der Modul: 1 = a0; 1̇.
Überhaupt ist die a-Kette von irgend einer Zahl weiter nichts als die Gesamtheit der Zahlen, welche sich von ihr an (mithin sie selber eingerechnet) in der Zahlenreihe finden: a0; i = i + (i + 1̇) + (i + 2) + (i + 3) + … — wogegen die „a-Bildkette“ solcher Zahl i: a00; i = (i + 1̇) + (i + 2) + (i + 3) + … der Inbegriff der Zahlen von ihr ab (mit Ausschluss ihrerselbst) sein würde.
Dies vorausgesetzt bedeute jetzt das Relativ b etwa das Element 1̇ selbst, sei also: b = 1̇.
Diese Deutung genügt zunächst für die speziellste Anwendungsweise des Induktionsschlusses, welche darauf abzielt die Überzeugung herbeizuführen, dass, wenn ein Satz für die Zahl 1̇ gilt, und wenn, sooft er für eine Zahl n gilt, er auch für die nächst höhere Zahl n + 1̇ oder a; n gelten muss, er dann schlechtweg für alle Zahlen gelten müsse.
Für eine formell etwas allgemeinere Anwendungsweise des Induktionsschlusses kann jedoch b auch eine höhere Zahl als 1̇ vorstellen, überhaupt sogar irgend ein (endliches oder unendliches) „System“ von Zahlen bedeuten, z. B. ein solches, welches aus gewissen Zahlen — von m einschliesslich, eventuell bis incl. r — irgendwie (auch eventuell mit Auslassungen) zusammengesetzt ist.
Solchen Fall werden wir nachher ebenfalls berücksichtigen.
Dann stellt uns also a0; b wiederum die ganze Zahlenreihe vor.
Endlich bedeute nun das Relativ c die Gesamtheit, das „System der Zahlen, die eine bestimmte Eigenschaft E besitzen, m. a. W. für die ein bestimmter Satz S, in welchem von einer unbestimmten Zahl n die Rede ist, gilt.
Um nachzuweisen, dass der Satz S für alle Zahlen gelte, dass nämlich a0; b ⋹ c sei, genügt es dann nach D 59, zu zeigen:
erstens dass der Satz für die Zahl b = 1̇ gilt, dass also b ⋹ c sei,
zweitens dass auch für das Bild a von jeder Zahl (n) für die unser Satz S gilt — welche Zahlen eben in dem Ausdrucke (a0); b)c zusammengefasst erscheinen — dieser Satz gelten müsse, d. h. also, dass auch a; (a0; b)c ⋹ c sein müsse.
Gemeinhin zu reden wird damit zu zeigen gewesen sein, dass, sobald der Satz für eine bestimmte Zahl n gilt, er auch für die nächst höhere Zahl n + 1̇ gelten müsse.
Stellt uns dagegen — noch allgemeiner — b eine bestimmte Zahl m vor, oder auch irgend ein System von Zahlen, welches als die niederste die Zahl m in sich schliesst, so wird a0; b die Gesamtheit der Zahlen von m an vorstellen.
Um zu beweisen, dass ein Satz S für alle Zahlen dieser Reihe m, m + 1̇, m + 2, … in infinitum gelte, muss es dann genügen, „erstens zu zeigen, dass er für die Zahlen des Systems b gelte, ja ist es blos erforderlich, seine Geltung für die Zahl (b =)m selbst darzuthun, und „zweitens“ etc.
(Wortlaut wie vorhin).
[Für die Zahlen unterhalb m braucht der Satz dann überhaupt nicht zu gelten.]
Hiermit dürfte denn die als D 60 von Herrn Dedekind gegebne Erläuterung über die Bedeutung und Tragweite des Satzes D 59 beigebracht sein.
Rekapituliren wir nochmals thunlichst mit den Worten des genannten Autors: D 60.
Um zu beweisen, dass alle Elemente der Kette a0; b eine gewisse Eigenschaft E besitzen, genügt es zu zeigen,
erstens dass alle Elemente von b die Eigenschaft E besitzen,
zweitens dass dem Bilde a; n jedes solchen Elements n „von a0; b“, welches die Eigenschaft E besitzt, dieselbe Eigenschaft zukommt.
Unter c brauchte man hiebei blos das System aller Elemente, welche diese Eigenschaft E besitzen, zu verstehen, um D 60 als die verbale Übersetzung der Formel D 59 zu erkennen.
Hiezu jedoch dürfte noch eine Bemerkung nicht überflüssig erscheinen, welche durch die Vergleichung von D 59 mit D 47 nahe gelegt wird.
Liessen wir im vorstehenden Texte die Bestimmung „von a0; b weg, so hätten wir die verbale Übertragung und Nutzanwendung von D 47 vor uns.
Auch diese Formel kann in der That schon dazu verwendet werden, um eine Behauptung, Thesis a0; b ⋹ c rechtskräftig zu begründen und zwar aufgrund der beiden Nachweise, dass erstens b ⋹ c und zweitens a; c ⋹ c sei.
Diese zweite Teilforderung der Hypothesis ist aber — wegen (a0; b)c ⋹ c — bei D 47 eine weiter gehende, als bei D 59.
Bei Weglassung jener Bestimmung wird behufs Etablirung der Thesis mehr, als unbedingt nötig ist, zu leisten verlangt; das Theorem D 59 begnügt sich dem D 47 gegenüber mit formell geringeren Voraussetzungen, die man als erfüllte noch wird nachzuweisen haben.
Und wenn demnach in manchen Fällen vielleicht auch schon das Theorem D 47 zur Erreichung des Zieles ausreicht, so wird man doch im Allgemeinen nur das Theorem D 59 als den logischen Kern des Schlusses der vollständigen Induktion hinstellen können.
Der „Hinweg“.
Hier muss ich zuvörderst den Leser bitten, den Namen „a0; b“ als ein einfaches oder unpräjudizirliches, nichtssagenwollendes Zeichen für ein von a und b abhängig zu definirendes Relativ — wie meinetwegen x oder höchstens φ(a, b) — gelten lassen und ansehen zu wollen, von der Art also, wie jener Name sich zusammengesetzt zeigt, vorläufig ganz abzusehen!
Dass man berechtigt ist, gedachtes x als ein relatives Produkt in b, als ein gewisses Relativ a0 genommen von b hinzustellen und zu bezeichnen, die Funktion φ(a, b) speziell in der Form a0; b anzusetzen, wird sich erst ganz am Schlusse der Untersuchung herausstellen — in der Weise, wie wir es bereits unter 0) S. 361 geschildert haben.
Solches aber von vornherein zu thun, müsste bei unserm Gange beanstandet und als durch nichts gerechtfertigt abgelehnt werden.
D 44 definirt die „a-Kette von b“ als ein von a und b abhängiges — wie gesagt vorgreifend — mit „a0; b“ bezeichnetes binäres Relativ, und zwar als das identische Produkt Π nach u aller derjenigen Relative u des Denkbereiches 12, welche die in 30) unter das (erste) Π-zeichen gesetzte „Erstreckungsbedingung“ a; u + b ⋹ u erfüllen.
Da diese Bedingung in die beiden a; u ⋹ u und b ⋹ u zerfällt, wovon die erstre fordert, dass u „Kette“ sei inbezug auf a, die letztre aber, dass u auch b als einen Teil seinerselbst in sich schliesse, so kann man die Definition mit Worten so ausdrücken:
Unter der a-Kette von b soll verstanden werden das identische Produkt (die „Gemeinheit“) aller der Ketten inbezug auf a, von welchen b Teil ist.
Dass solches „Produkt“ wirklich existirt, nämlich nicht etwa, als jeglichen Faktors entbehrend, in einen sinnlosen Namen ausarten kann, geht schon daraus hervor, dass es allermindestens den Faktor 1 aufweisen wird, weil u = 1 stets die Erstreckungsbedingung erfüllt.
»Es gelten nun für diesen sehr wichtigen Begriff die folgenden Sätze«
D 45.
Es ist b ⋹ a0; b.
[In Worte bei 9) gefasst.]
Beweis.
Weil, nach dem zweiten Teile der Erstreckungsbedingung, b in jedem Faktor u des Produktes Πu enthalten — „Gemeinteil“ dieser Faktoren — ist, so muss es auch in dem Produkte derselben enthalten sein.
Als das bei diesem Schlusse zur Anwendung kommende Schema des identischen Kalkuls würde anzuziehen sein:
[Formel] — vergl. (3×) des Bd. 1, für unbegrenzt viele Faktoren in Anspruch genommen, hier in ε) S. 39 gebucht.
D 46.
Es ist a; (a0; b) ⋹ a0; b.
Die „a-Kette“ von irgend einem Relativ ist eine „Kette inbezug auf a“.
Beweis.
Denn nach dem ersten Teil der Erstreckungsbedingung unsres Πu ist jeder Faktor u dieses Produkts eine „Kette inbezug auf a“, und folglich — gemäss D 43 — auch das Produkt Πu ebendieser.
D 47. (a; c ⋹ c)(b ⋹ c) ⋹ (a0; b ⋹ c).
[Betreffs der verbalen Fassung vergleiche 11).]
Beweis.
Denn nach den Voraussetzungen des Satzes ist c ein die Erstreckungsbedingung erfüllender Wert des u.
Derselbe figurirt deshalb unter den Faktoren unsres Πu, und da ein identisches Produkt seinem Faktor eingeordnet sein muss, so haben wir Πu ⋹ c und erscheint die Konklusion gerechtfertigt.
D 48 ist bei Dedekind nicht als „Satz“ hingestellt, sondern — abgesehn von den blos äusserlichen Abweichungen in der Bezeichnung — lautet das darüber Gesagte wörtlich:
»D 48. Bemerkung.
Man überzeugt sich leicht, dass der in D 44 erklärte Begriff der a-Kette von b durch die vorstehenden Sätze D 45, 46, 47 vollständig charakterisirt ist.«
Die „Bemerkung“ ist also ein Luxus der Theorie, indem sie uns nur beiläufig mit einer neuen, nicht uninteressanten Manier, die Definition D 44 von a0; b zu formuliren, bekannt macht, und kann dieselbe aus unserm Lehrgange auch weggelassen werden.
Wir haben dieselbe in die Zeichensprache eingekleidet und wollen sie in dieser Gestalt als mit D 44 äquivalent gleichwol rechtfertigen.
Zu dem Ende wollen wir der Druckersparniss halber für den oft vorkommenden Ausdruck [Formel] schreiben — die Erstreckungsbedingung a; u + b ⋹ u also blos durch ein NB (Notabene) andeutend und unter [Formel] schlechtweg, wie immer, ein Produkt verstehend, welches die volle Erstreckung über alle erdenklichen Relative u besitzt.
Ferner soll die in D 48 vorkommende Subsumtion NB ⋹ (x ⋹ u) oder {(a; u + b ⋹ u) ⋹ (x ⋹ u)} = S zur Abkürzung genannt werden.
Schreiben wir uns alsdann, den Namen x für a0; b einführend, die Def. D 44 in der Gestalt an:
[Formel] , so zeigt die Vergleichung mit D 48, dass es uns obliegen wird, die folgende Aussagenäquivalenz zu rechtfertigen:
[Formel] deren linke Seite L, die rechte R heissen möge, und die sich auch sogleich ergibt, wenn man den Wert von a0; b aus D 44 in D 48 einträgt.
Es ist also L = R, oder L ⋹ R und R ⋹ L zu zeigen.
Nach der Definition der Gleichheit ist nun:
[Formel] , und nach bekanntem, auf voriger Seite unter D 45 schon angezogenem Aussagenschema kann man schreiben:
[Formel] , indem man nämlich erlaubtermaassen die Erstreckungsbedingung NB, = (a; u + b ⋹ u), als eine von u zu erfüllende Voraussetzung hinter (anstatt unterhalb) dem Π-zeichen anmerkt, was eben angängig, sobald als Faktor hinter dem Π nicht ein Relativ, sondern eine Aussage steht.
Es ist also erkannt, dass [Formel] .
Als Folgerung aus R (D 44) hatten wir aber bereits die Sätze D 45: b ⋹ x und D 46: a; x ⋹ x bewiesen, welche zusammengezogen die in R⋹ (a; x + b ⋹ x) notirte Konklusion liefern.
Zusammenziehung dieser mit der darüberstehenden Aussagensubsumtion gibt: R ⋹ L (womit das Theorem D 48 als Subsumtion von rechts nach links aus D 44 abgeleitet erscheint).
Andrerseits ist aber auch konform mit D 47:
[Formel] , welches man aber jetzt nicht als Konsequenz aus D 44, sondern als daraus ersichtlich hinzustellen hat, dass laut der Prämisse links x als ein die Erstreckungsbedingung „NB“ erfüllender Wert des u ein effektiver Faktor dieses Πu sein muss, weshalb ihm dieses eingeordnet.
Letztre Subsumtion nun, mit oben gefundenem [Formel] übermultiplizirt, liefert dazu noch die Konklusion: L ⋹ R, womit im Ganzen L = R bewiesen ist.
D 49. a; b ⋹ a; (a0; b) versteht sich durch beiderseitiges relatives Vormultipliziren mit a aus D 45 und sollte als ein so unmittelbares Korollar hiezu — wie schon gesagt — gar nicht registrirt sein — so wenig man z. B. in der Geometrie den Satz c2n = (a2 + b2)n — um nicht zu sagen nc2 = na2 + nb2 — neben dem Pythagoreischen aufführen wird.
D 50. a; b ⋹ a0; b.
Das a-Bild von b ist Teil der a-Kette von b.
Beweis a fortiori aus dem (hier erstmals zu erwähnenden) Korollar a; b ⋹ a; a0; b (D 49) zu D 45 in Verbindung mit D 46.
D 51. (a; b ⋹ b) = (a0; b = b).
Ist b Kette inbezug auf a, so ist auch b die a-Kette von sich selber, und umgekehrt.
Beweis. D 47 gibt (a; b + b ⋹ b), = (a; b ⋹ b), ⋹ (a0; b ⋹ b), was mit D 45 zur Gleichung a0; b = b verschmilzt.
Die Umkehrung folgt aus D 50.
Man entschuldige diese Wiederholung aus dem „Herwege“.
D 52, 53 … (b ⋹ c) ⋹ (b ⋹ a0; c) ⋹ (a0; b ⋹ a0; c).
Der Teil gleichwie seine a-Kette ist auch in der a-Kette des Ganzen enthalten.
Beweis.
Nach D 45 ist c ⋹ a0; c, mithin folgt aus b ⋹ c a fortiori auch b ⋹ a0; c.
Sei nun b ⋹ a0; c (wenn auch vielleicht nicht b ⋹ c), so kann dies mit dem nach D 46 geltenden a; (a0; c) ⋹ a0; c zusammengezogen werden zu: a; (a0; c) + b ⋹ a0; c und liefert nach D 47 (a0; c für c gesagt) die Folgerung a0; b ⋹ a0; c, q. e. d.
D 55. (b ⋹ a0; c) ⋹ (a; b ⋹ a0; c).
[Wortlaut siehe unter 10).]
Hiefür gibt Dedekind zwei Beweise an.
Beweis 1. Nach D 53 haben wir aus der Prämisse bereits gefolgert: a0; b ⋹ a0; c, und dies mit D 50 zusammengehalten liefert a fortiori die Konklusion.
Beweis 2. Aus der Prämisse folgt a; b ⋹ a; a0; c, letztres aber ist ⋹ a0; c nach D 46. Oder, nur etwas anders gewendet:
Laut Prämisse und D 46 haben wir: a; (a0; c) + b ⋹ a0; c, woraus die Konklusion auch nach D 40 fliesst.
Wollte man die Zahl der kleinen Sätze noch vermehren, so könnte man als Zusatz zu D 55 den aus letzterm und D 52 a fortiori folgenden Satz anfügen: (b ⋹ c) ⋹ (a; b ⋹ a0; c).
An dieser Stelle kann jetzt schon der aus S. 366 zu wiederholende Beweis des Satzes D 59 geliefert werden — wenngleich die Bedeutung des letzteren als Grundlage des Satzes der vollständigen Induktion erst etwas später verständlich wird.
Der Satz ist damit erstmals strenge, nämlich ohne den oben gerügten Zirkel, bewiesen und dürfte fortan überall angewendet werden.
Inzwischen müssen wir unsern „Hinweg“ noch vollends zu Ende gehen.
D 57. Satz und Erklärung.
Es ist: a; (a0; b) = a0; (a; b), d. h. das a-Bild der a-Kette von einem Relativ b ist zugleich die a-Kette vom a-Bilde dieses Relativs b.
Man kann daher solches Relativ kurz durch a00; b (mit demselben Vorbehalt wie S. 370 — vorgreifend!) bezeichnen und nach Belieben das a-Kettenbild oder die a-Bildkette von b nennen.
Beweis.
Auf a; b statt b angewendet sind D 45 und D 46 leicht einzeln hinzuschreiben, lassen sich aber sogleich zusammenfassen zu: a; {b + a0; (a; b)} ⋹ a0; (a; b).
Diese Folgerung hat nun die Form der Prämisse von D 41, worin nur c durch den Ausdruck rechterhand vertreten erscheint.
Nach diesem Satze gibt es nun ein u — nebenbei gesagt wäre der Ausdruck in der geschweiften Klammer linkerhand ein solches —, welches die nachstehend hinter dem Summenzeichen angegebnen Eigenschaften besitzt — oder, um ganz aussagenrechnerisch vorzugehen, es gilt die Konklusion:
[Formel] — wie man durch die ersichtlichen Folgerungen aus dem ersten Aussagenfaktor, sodann durch den Subsumtionsschluss successive ersieht [und nach dem Tautologiegesetze der Aussagenaddition ist das Summenzeichen unterdrückbar gewesen, sobald der allgemeine Summand konstant in Hinsicht der Summationsvariabeln u wurde — wodurch der Eindruck entsteht, als ob man beim Folgern die Summe ⋹ ihrem Gliede verkehrterweise gesetzt hätte!].
Mithin ist die zuletzt gefolgerte Subsumtion bewiesen.
Andrerseits gibt D 46, mit a beiderseits relativ vormultiplizirt eine Folgerung, welche mit D 50 vereinigt lautet: a; {a; (a0; b)} + a; b ⋹ a; (a0; b) und wiederum die Form der Prämisse von D 47 zeigt, indem nur das dortige b hier durch a; b, das c durch die rechte Seite vertreten erscheint.
Nach dem Schema der Konklusion jenes Satzes muss also sein: a0; (a; b) ⋹ a; (a0; b), was die umgekehrte Subsumtion der vorhin bewiesenen ist.
Damit ist also nunmehr die Gleichung gerechtfertigt, welche uns zu beweisen oblag.
D 58. a0; b = b + a00; b, d. h. die a-Kette eines Relativs b setzt sich zusammen aus diesem Relativ selbst und seiner a-Bildkette.
Beweis.
Die fortan einfacher als a00; b ⋹ a; b zu schreibende Subsumtion D 46 zieht sich mit der D 45 zusammen zu: b + a00; b ⋹ a0; b.
Sonach bleibt nur noch die rückwärtige Subsumtion darzuthun.
Zu dem Ende mögen wir die vorletzte Subsumtion des vorhin bei D 57 gegebnen Beweises jetzt kürzer schreiben als: a; (a00; b + b) ⋹ a00; b, was seinerseits ⋹ a00; b + b, und mögen sie mit der selbstverständlichen b ⋹ a00; b + b zusammenziehen zu: a; (a00; b + b) + b ⋹ a00; b + b, was nach dem Schema des D 47, worin nur c durch die rechte Seite vertreten erscheint, die Konklusion liefert: a0; b ⋹ a00; b + b, deren Nachweis allein noch zu erbringen gewesen, q. e. d.
Aufgrund dieses Satzes D 58 könnte jetzt, wie S. 361 unter 0) gezeigt, die Zusammensetzungsweise der Namen a0; b und a00; b nachträglich gerechtfertigt, es könnten a0 und a00 selbst als Relative erklärt werden — freilich in Gestalt von unendlichen Reihen, deren Bildungsgesetz nur mittelst Schlusses von n auf n + 1 gerechtfertigt werden kann, welcher Schluss ja aber nun das volle Bürgerrecht in unsrer Disziplin erlangt hat.
Damit hätte unser „Hinweg“ im Wesentlichen sein Ende erreicht.
Interessant ist es aber noch, zu sehen, wie sich auch bevor man noch das mit dem Namen „a0; b“ provisorisch (oder vorgreifend) bezeichnete Relativ als ein relatives Produkt aus a0 in b erkannt und nachgewiesen hat, die beiden Sätze D 61 und 62 nach Dedekind doch aus dessen Theorie beweisen lassen.
Zu D 61. a0; (b + c + …) = a0; b + a0; c + … hat man: a; (a0; b + a0; c + …) + (b + c + …) ⋹ a0; b + a0; c + … — als Zusammenfassung der in D 46 und 45 enthaltenen auf b, c, … (statt b) angewandten Einzelsätze, wobei sich für die Einordnung des ersten Gliedes linkerhand auch D 42 anziehen lässt.
Und nach dem Schema von D 47 folgt daraus der Schluss: a0; (b + c + …) ⋹ a0; b + a0; c + ….
Andrerseits ist wegen b ⋹ b + c + …, c ⋹ b + c + …, … gemäss dem in D 52, 53 a fortiori mitenthaltnen Schema D 54: a0; b ⋹ a0; (b + c + …), a0; c ⋹ a0; (b + c + …), … was sich zusammenzieht zu: a0; b + a0; c + … ⋹ a0; (b + c + …) — womit denn die im Theorem behauptete Gleichung als Subsumtion vor- und rückwärts bewiesen ist.
Zu D 62. a0; (bc …) ⋹ a0; b · a0; c … ist: a; (a0; b · a0; c …) ⋹ a; (a0; b) · a; (a0; c) … ⋹ a0; b · a0; c …, wo die letzte Subsumtion sich durch überschiebendes Multipliziren der in D 46 enthaltnen Sätze rechtfertigt, der Zwischenschluss aber auch durch Berufung auf D 43 (wonach das Produkt von Ketten eine Kette sein muss) ersetzbar wäre.
Andrerseits folgt durch überschiebendes Multipliziren der mit D 45 gegebnen Sätze: b⋹a0; b, c ⋹ a0; c, … dass bc … ⋹ a0; b · a0; c … sein muss.
Dies mit dem vorigen vereinigt gibt: a; (a0; b · a0; c …) + bc … ⋹ a0; b · a0; c …, woraus die Behauptung unmittelbar nach dem Schema von D 47 fliesst, q. e. d.
Wir sind am Ziele, und wollen uns nun über dieses und den zurückgelegten Weg noch des weitern unterhalten.
Die Art wie die fatale Klippe des Zirkels beim Beweis des Satzes der vollständigen Induktion vorstehend umgangen erscheint, hat unverkennbar etwas Grossartiges.
Der entfaltete Scharfsinn, die Sorgfalt und der den Erfolg anbahnende geniale Blick dürften um so bewundernswerter sein, als der Urheber dieser Theorie keine Kenntniss oder auch nur Ahnung von der Existenz unsrer aus allgemeinrer Grundlage hervorwachsenden Disziplin besass, die — bislang teils in schwer zugänglichen amerikanischen Schriften, teils in noch schwerer verständlichen, ungenügend erläuterten Noten der jenseitigen Literatur zerstreut — sehr wohl der Beachtung, die sie eigentlich verdient, diesseits entgehen konnte — zu geschweigen von De Morgan’s Anläufen, denen unbeschadet ihres bahnbrechenden Pionir-Verdienstes kaum ein Gebrauchswert zukommt.
Gleichwohl erscheint der Wunsch gerechtfertigt: dasselbe Ziel auf minder kunstvolle Weise und auf kürzerm Weg zu erreichen.
Vor allem drängt sich die Frage auf, ob es denn unerlässlich ist, die Kettentheorie mit D 44 auf die Definition eines so zusammengesetzten Relativs wie a0; b zu gründen?
Einfacher scheint es doch, eine Definition von a0 selbst zugrunde zu legen, und diesem gegenüber müsste jenes wol ein Umweg genannt werden.
Wenn es uns in der That alsbald gelingen wird, die Kettentheorie in diesem Sinne recht erheblich zu vereinfachen, so muss ich der Frage begegnen, weshalb ich dann den Leser erst den weiten Weg geführt und nicht sogleich mit meiner vereinfachten Darstellung hervorgetreten?
Das geschah aus mehrern Gründen.
Gegen einen Vorwurf glaube ich indess in jedem Falle — mögen die Gründe Billigung finden oder nicht — gedeckt zu sein dadurch, dass ja diejenigen Studirenden, denen das historische Werden dieser Theorie gleichgültig sein sollte und die so rasch als möglich nur das Unentbehrliche — in einfachster Gestalt — absolviren möchten, sich durch die dem Paragraphen gegebne Überschrift dahin avertirt finden werden, dass hier der Anfang überblättert und dem die Vereinfachung verheissenden Schlusse desselben zugeeilt werden kann.
Vor allem wünschte ich Dedekind’s Theorie selbst erst einmal als solche in einer mir zusagenden Symbolik — und in ihrer vollen, die von Dedekind in Anspruch genommene weit überragenden Allgemeinheit — dargestellt und fixirt zu sehen.
Dabei sollten einerseits die Vorzüge unsres so viel ausdrucksvolleren und weiter tragenden Bezeichnungsystems recht in die Augen springen, von dem allein ich überzeugt bin, dass es sich die Herrschaft auf dem wissenschaftlichen Weltmarkte erringen und diese dauernd behaupten wird.
Andrerseits sollte die Schönheit ebenjener Theorie besser hervortreten, als es mir bei der Symbolik ihres Urhebers möglich erscheint.
Auch denjenigen Lesern gegenüber, welche etwa sich nur in dieses Buch einlesen ohne daneben auch Dedekind’s Schrift zu studiren, wollte ich der Dedekind’schen Leistung zu ihrem Rechte verhelfen und sie ihnen mit zugänglich machen:
es muss ersichtlich sein, wie viel durch sie meiner Vereinfachung der Theorie schon vorgearbeitet ist.
Desgleichen sollte den Mathematikern — und diese sind zahlreich — welche sich mehr oder weniger vollständig durch die Dedekind’sche Schrift „hindurchgewunden haben, im Vorstehenden eine Art von „Interlinearübersetzung“ eines wichtigen Abschnitts derselben an die Hand gegeben werden, vermöge deren sie rasch mit der ihnen ungewohnten, gleichsam fremdsprachigen Symbolik der Peirce’schen Disziplin Vertrautheit erwerben können.
Nebenbei wollte ich auch einige Kritik üben und Material zusammentragen, aus welchem die Hinfälligkeit der Ausstellungen in Hoppe’s Kritik ersichtlich werden muss.
Endlich aber bestimmt mich diese Erwägung.
Wird auch bald eine einfache Kettentheorie — gleichviel ob die unten von mir vorgetragne, oder eine andre — die Dedekind’sche wol endgültig verdrängen, so bleibt an dieser doch Vieles von mehr als blos historischem Werte.
So vor allem, was die Hauptsache: Formulirung und Beweis von D 59 (u. 60), wie sie unter 16) S. 366 dargestellt sind, werden unverändert bestehen bleiben.
Für jene, die „Formulirung“ des Satzes der Induktion, ist eine weitre Vereinfachung gar nicht mehr denkbar, und dieser, der — solchergestalt abgegrenzte — „Beweis“, lässt eine Steigerung der Einfachheit, die er bereits besitzt, weder geboten noch realisirbar erscheinen.
Die „Hauptsache“ also bleibt von der Vereinfachung unberührt, und letztre kann sich nur in der Abkürzung des langen und mühsamen Weges bethätigen, der von den grundlegenden Definitionen bei Dedekind führte zur Sicherstellung der drei Hülfssätze D 45, 47 und 55, auf denen der Beweis von D 59 beruht, und der von da noch bis ans Ende der Theorie zurückzulegen blieb.
Und wenn wir allerdings mit wenigern und mit viel einfachern Sätzen auskommen, wenn wir mit Sätzen, die — statt 2 oder 3 — meist nur 1 oder 2 Relative betreffen, nun rascher und leichter zum Ziele gelangen werden, so behält Dedekind’s Theorie dafür den Vorzug, mit zumeist allgemeineren Sätzen operirt und solche aufgestellt zu haben — Sätze, die, wenn sie auch für unser gegenwärtiges Ziel entbehrlich gemacht sein werden, dafür vielleicht andern Zwecken sich noch dienstbar erweisen mögen.
Diese freilich würden jederzeit auch uns, falls uns Veranlassung würde sie herbeizuziehn, rasch und leicht zugänglich sein.
Als ein bleibender Gewinn aus Dedekind’s Theorie ist namentlich hervorzuheben, dass uns durch sie in D 44 eine Gruppe von Sätzen erschlossen und im Hinblick auf die Prinzipien des Dualismus und der Konjugation mit einem Schlage gesichert ist, die — schon einzeln gar nicht leicht einleuchtend zu finden — durch ihr Zusammenbestehen vollends merkwürdig erscheinen.
Ich meine die folgenden Sätze, denen ich noch ein paar ohnehin ersichtliche, aber zu der Gruppe gehörende vorangestellt habe: 17) 18) [Formel] 19) 20)
[Formel] [Formel] [Formel] [Formel] NB1 = (a; u ⋹ u) NB2 = (b ⋹ u) NB1 = (u ⋹ a ɟ u) NB2 = (u ⋹ b) vel (u; a ⋹ u) vel (u ⋹ u ɟ a) vel(a; u + u; a ⋹ u) vel{u ⋹ (a ɟ u)(u ɟ a)}
„vel“
= „oder auch“
= „oder wenn man will“ — aber ja nicht „sive“ = oder mit andern Worten“!
[Formel] [Formel] NB5 = (1' + a; u ⋹ u) NB5 = {u ⋹ 0'(a ɟ u)} vel (u; a + 1' ⋹ u) vel {u ⋹ (u ɟ a)0'} vel (a; u + 1' + u; a ⋹ u) vel {u ⋹ (a ɟ u)0'(u ɟ a)}
[Formel] [Formel] NB6 = (a; u + a ⋹ u) NB6 = {u ⋹ (a ɟ u)a} vel (a + u; a ⋹ u) vel {u ⋹ a(u ɟ a)} vel (a; u + a + u; a ⋹ u) vel {u ⋹ (a ɟ u)a(u ɟ a)}.
Von diesen Formeln sind alle übrigen blos Sonderfälle von 18), das ist vom Gespann zu D 44.
Vereinfachte Kettentheorie.
Als Definition der „a-Kette“, a0, oder der Kette eines Relativs a gelte: 21) [Formel] , wo die Erstreckungsbedingung „NB“ des Produktes [Formel] laute: 22) NB, = (1' + a; u ⋹ u).
Die „Kette von a“ ist damit erklärt als das identische Produkt — oder um es anschaulicher zu sagen: als das umfassendste oder maximale, „grösste“ gemeinsame Gebiet, der grösste Gemeinteil — aller der Relative x, welche die Forderung 1' + a; x ⋹ x erfüllen; das ist also derjenige Gemeinteil, welcher jeden Gemeinteil der sämtlichen genannten Relative in sich begreift, aus allen diesen sich additiv zusammensetzen wird. —
Der Begriff, die Bezeichnung als „grösser“ ist in dieser Theorie nur auf solche Relative anwendbar, die im Verhältniss des Ganzen zu seinem Teile stehen.
In der Hereinziehung des Gliedes 1' zur Erstreckungsbedingung scheint eine gewisse Willkür zu liegen.
Das Befremden über diese mag etwas gemildert werden durch die Bemerkung, dass neben 0 sich 1' unter den Moduln dadurch auszeichnet, dass inbezug auf ihn ein jedes Relativ eine Kette sein muss.
Darnach wird es nicht so unerhört erscheinen, dass man nach denjenigen Ketten inbezug auf a frage, die als Aliorelativnegate jenen Modul 1' in sich schliessen — um alsdann deren Produkt zu bilden.
Da die Erstreckungsbedingung zerfällt in 22)α 1' ⋹ u, und 22)β a; u ⋹ u, so sind die Schemata anwendbar: Π(1' ⋹u) = (1' ⋹Πu), a; Πu ⋹ Π(a; u) ⋹ Πu, wovon die letzte Subsumtion nicht als allgemeine Formel gilt, sondern blos mit Rücksicht auf den zweiten Teil 22)β der Erstreckungsbedingung gelten muss, aus dem sie durch beiderseitiges Produktiren folgte.
Damit ist aber gefunden: 23)α 1' ⋹ a0 und 23)β a; a0 ⋹ a0, was auch zusammenziehbar zu 23) 1' + a; a0 ⋹ a0.
Die beiden Teile von 23) erscheinen als die vereinfachten D 45 und 46, beziehungsweise als deren Unterfälle für b = 1'.
Aus 23)α folgt sogleich:
1'; b ⋹ a0; b, also 9) b⋹a0; b, womit der Satz D 45 bewiesen ist, der nebenbei auch die Sätzchen: a⋹a0; a und a0 ⋹ a0; a0 unter sich begreift.
Aus Früherem wiederholt.
Und ferner folgt im Hinblick auf 23)β: (b ⋹ a0; c) ⋹ (a; b ⋹ a; a0; c ⋹ a0; c), womit 10) (b ⋹ a0; c) ⋹ (a; b ⋹ a0; c), mithin der Satz D 55 gewonnen ist.
Von den drei zum Beweise von D 59 unentbehrlichen Sätzen verfügen wir also schon über zweie.
Aus Früherem wiederholt.
Ebensoleicht würden sich auch noch einige andre Sätze gewinnen lassen, die teils selbst der Dedekind’schen Kettentheorie angehören, teils die entsprechenden Vereinfachungen von Sätzen dieser sind, deren wir aber hier zu entraten vermögen.
So folgt aus 23)α auch b; 1' ⋹ b; a0, oder der Satz b ⋹ b; a0, welcher auch a ⋹ a; a0 und im Hinblick auf 23)β dann a ⋹ a0 a fortiori involvirt — letztre beiden die Vereinfachungen zu D 49 und 50.
Namentlich ist noch mit folgenden beiden Varianten der Überlegung: (b ⋹ c) = (1' ⋹ a0)(b ⋹ c) ⋹ (1'; b ⋹ a0; c) = (b ⋹ a0; c) (b ⋹ c) ⋹ (a0; b ⋹ a0; c) = (b ⋹ a0; b)(a0; b ⋹ a0; c) ⋹ (b ⋹ a0; c) der Satz D 52: (b ⋹ c) ⋹ (b ⋹ a0; c) aus 23)α oder D 45 leicht erweisbar.
Allein wenn wir bisher in Parallelismus zur Dedekind’schen Theorie auf das Leichteste vordringen konnten mit Überlegungen, die imgrunde nur darauf hinausliefen, die Überlegungen dieses Autors für einen einfachern Sonderfall zu wiederholen (indem allerdings auch nur für diesen sie ausgeführt werden müssen), so findet dies Verfahren nunmehr eine Grenze.
Bei D 47, 51, 53 versagen uns Dedekind’s Beweise, weil sie wesentlich auf der allgemeinern (und komplizirtern) von diesem Autor zugrunde gelegten Definition D 44 beruhen, und wenn wir etwa zum Beweise der entsprechenden Vereinfachungen dieser Sätze mit Parallelüberlegungen zu den Dedekind’schen auszukommen versuchen, so gelangen wir lediglich zu einem Zirkel zwischen den genannten drei Sätzen, aus deren jedem in der That auch leicht die beiden andern ableitbar wären.
Um hier nun weiter zu kommen, bedarf es eines ganz neuen Gedankens.
Für den noch ausstehenden Beweis des dritten und letzten der unentbehrlichen Sätze, D 47, muss ich die Kettentheorie um einen Hülfssatz bereichern.
Dieser lautet: 24) [Formel] — in Worten: Wenn b Kette ist inbezug auf a, so ist auch b ɟ b̄̆ Kette inbezug auf a, und umgekehrt.
Beweis.
Sei a; b ⋹ b.
Weil nach 9) des § 17: b = (b ɟ b̄̆); b ist, haben wir dann: a; b = a; (b ɟ b̄̆); b ⋹ b, und aus der letzten Subsumtion folgt durch Transponiren des letzten relativen Faktors — b — nach dem ersten Inversionstheoreme 4) des § 17 in der That: a; (b ɟ b̄̆) ⋹ b ɟ b̄̆.
Umgekehrt kann letztre Subsumtion äquivalent in die vorhergehende und diese in die erste umgeschrieben werden, d. h. die Schlussreihe ist ohne weitres umkehrbar, q. e. d.
Daraufhin kann man nunmehr — in Analogie zu D 41 — noch einen weitern Hülfssatz aufstellen; doch ist es nicht gerade unerlässlich, ihn als solchen formulirt zu haben oder gar zu memoriren; vielmehr würde es genügen, seinen Beweis mit demjenigen des folgenden Hauptsatzes (D 51) zu verschmelzen.
Er lautet: 25) [Formel] , in Worten: Wenn b Kette ist inbezug auf a, so gibt es eine Kette u inbezug auf a, die alle individuellen Selbstrelative in sich schliesst und inbezug auf welche b eine Kette ist.
Und zwar ist:
(Beweis) u = b ɟ b̄̆ eine solche Kette.
Denn diese erfüllt erstlich wegen 3) des § 8, nämlich 1' ⋹ b ɟ b̄̆ die Forderung 1' ⋹ u, zweitens nach dem vorigen Hülfssatze 24) auch die Forderung a; u ⋹ u, und drittens nach 9) des § 17 auch diese: u; b ⋹ b, indem ja zwischen (b ɟ b̄̆); b und b sogar Gleichheit besteht.
Dementsprechend konnte auch in 25) das letzte Einordnungszeichen als ein Gleichheitszeichen angesetzt werden.
Man kann dem Satze 25) noch eine hübschere Gestalt geben.
Der Forderung 1' ⋹ u wird nämlich mittelst des Ansatzes u = 1' + v auf die allgemeinste Weise genügt, und entsteht:
[Formel] , indem bei der letzten Teilforderung der Term 1'; b oder b, als schon selbstverständlich im Prädikat b enthalten, wegfiel.
Der Bedingung v; b ⋹ b oder v ⋹ b ɟ b̄̆ ist nun wiederum auf die allgemeinste Weise mittelst v = (b ɟ b̄̆)w zu genügen, wonach bleibt: 26) [Formel] .
Das heisst: falls b Kette, so gibt es auch ein Relativ w derart, dass auch 1' + (b ɟ b̄̆)w Kette ist — inbezug auf a. Ein solches ist in der That w = b ɟ b̄̆, wofür 1' + (b ɟ b̄̆)w = b ɟ b̄̆ ebenfalls wird und wir auf 24) zurückkommen.
Nun führt unser Weg über D 51 nach D 47.
Um den Satz D 51 oder 27) [Formel] zu beweisen ist es wesentlich, aus der Voraussetzung a; b ⋹ b die Folgerung a0; b ⋹ b zu ziehen, wo [Formel] bedeutet, erstreckt über die Werte von u, die der Bedingung „NB“ genügen.
Nun ist gewiss:
[Formel] und zwar welches der Erstreckungsbedingung genügende Relativ unter dem letzten u auch immer verstanden werden möge.
Dies aufgrund des Satzes 5) des § 6 und weil das Produkt eingeordnet sein muss einem jeden von seinen Faktoren.
Nun ist beim vorigen Hülfssatz — unter 25) — gezeigt, dass unter diesen Faktoren sich wenigstens einer befindet, welcher Teil ist von b, dass es nämlich ein der NB genügendes u gibt — in Gestalt von b ɟ b̄̆ — für welches u; b ⋹ b ist, und sonach muss also in der That auch a0; b ⋹ b a fortiori sein.
Diese Subsumtion kann dann sofort mit D45 oder 9) zur Gleichung a0; b = b zusammengezogen werden, womit die Aussagensubsumtion (a; b ⋹ b) ⋹ (a0; b = b) gerechtfertigt ist.
Behufs Rechtfertigung der umgekehrten Aussagensubsumtion — die für unsern Hauptzweck nebensächlich ist und sogar schon mit der abgeschwächten Prämisse als (a0; b ⋹ b) ⋹ (a; b ⋹ b) gelten muss — braucht man sich blos auf das im Kontext S. 380 schon gerechtfertigte a ⋹ a0, ergo a; b ⋹ a0; b, zu berufen.
Der Beweis von D 47 oder 11) (a; c + b ⋹ c) ⋹ (a0; b ⋹ c) ist nun endlich ganz leicht so zu leisten: (a; c + b ⋹ c) = (b ⋹ c)(a; c ⋹ c) ⋹ (a0; b ⋹ a0; c)(a0; c ⋹ c) ⋹ (a0; b ⋹ c) — aufgrund von 27) oder D 51.
Aus Früherem wiederholt.
Somit sind jetzt alle Vorbedingungen des zirkelfreinen Beweises von D 59, 60 gewonnen.
Es erübrigt jetzt nur noch die Vereinfachung zu D 58, oder den Satz zu gewinnen: 28) a0 = 1' + a; a0 — eine Rekursion, aus welcher ja die Potenzreihe für a0 leicht ableitbar ist.
Dies gelingt unschwer wie folgt.
Nach 23) haben wir: 1' + a; a0 ⋹ a0 = Πu ⋹ u, somit 1' + a; a0 ⋹ u für jedes der NB genügende u. Mithin ist u jedenfalls von der Form: u = 1' + a; a0 + v, und erhalten wir durch Einsetzung in 22) für v die Erstreckungsbedingung:
1' + a + a; a; a0 + a; v ⋹ 1' + a; a0 + v, welche sich jedoch sofort vereinfacht zu NB0 =) a; v ⋹ 1' + a; a0 + v, indem die drei ersten Glieder des Subjektes als schon bekanntermaassen im Prädikate enthaltene unterdrückbar sind; es folgt ja a ⋹ a; a0 sofort (als a; 1' ⋹ a; a0) aus 23)α und a; a; a0 = a; (a; a0) ⋹ a; a0 aus 21)β.
Darnach ist gefunden:
[Formel] , sintemal v = 0 der NB0 genügt, somit Πv = 0 ist, q. e. d.
Zum Überfluss wollen wir — ohne Benutzung der Potenzreihe für a0 — auch noch die beiden Sätze beweisen: 7) a0; a0 = a und 6) a; a0 = a0; a (was = a00 zu definiren).
Aus Früherem wiederholt.
Aus Früherem wiederholt.
Der erstre 7) ergibt sich als Konklusion aus 23)β nach dem Schema von 27) oder D 51, dieses für b = a0 in Anspruch genommen.
Er ist sozusagen der Kern des Satzes D 53: (b ⋹ a0; c) ⋹ (a0; b ⋹ a0; c), aus welchem er für b = a0, c = 1' hervorginge, wo dann, weil die Prämisse gilt, auch die Konklusion gelten muss.
Umgekehrt folgt aus ihm leicht D 53 mit: (b ⋹ a0; c) ⋹ (a0; b ⋹ a0; a0; c = a0; c).
Behufs Beweises des letztern 6) verfügen wir bereits über: a; a0 ⋹ a0 und a0; a ⋹ a0.
[Jenes war 23)β und dieses folgt etwa für b = a0 wegen 7) aus dem zweiten Satze links in 27) rückwärts.]
Darnach haben wir auch a; (a; a0) ⋹ a; a0, (a0; a); a ⋹ a0; a.
Nach den Schemata links in 27) schreibt nun dies sich äquivalent um in: a0; (a; a0) = a; a0, (a0; a); a0 = a0; a, wonach wegen der Übereinstimmung der linkseitigen Ausdrücke (miteinander und mit a0; a; a0) auch die rechten Seiten einander gleich sein müssen, q. e. d.
Hiermit ist nun auch der Satz: 5) a00; a00 ⋹ a00, den ich als den Angelpunkt der ganzen Kettentheorie bezeichnen möchte, ohne Benutzung von Reihenentwicklungen beweisbar wie folgt: a00; a00 = a; a0; a0; a = a; a0; a ⋹ a0; a = a00.
Aus Früherem wiederholt.
Wer endlich Gewicht darauf legt, von unserm einfachern Ausgangspunkte 21) aus auch noch die allgemeinere Erklärung D 44 nun als Theorem zu gewinnen, wird am besten den unter 11) des § 24 folgenden Überlegungen sich zuwenden, d. h. er braucht blos die von uns für die Proposition a; x + b ⋹ x gegebne allgemeine Lösung als solche zu verifiziren (was wiederum ohne Reihenbenutzung aufgrund schon etablirter Sätze angängig — siehe dort) und von ihr das Produkt Π zu nehmen.
Von jetzt an aber mögen die aus 28) fliessenden Reihenentwickelungen: 29) a0 = 1' + a + a2 + a3 + …, a00 = a + a2 + a3 + … flott benutzt werden.
Es mögen schliesslich die Begriffe der a-Kette und der a-Bildkette von b noch durch ein paar Figuren veranschaulicht werden.
Schon im Hinblick auf Bemerkungen, wie die von Hoppe1 p. 30:
„Im Gegenteil würde man die gegebnen leeren Rahmen, um doch etwas dabei zu denken, kaum anders auszufüllen wissen als durch die bekannten Zahlen“ dürfe solches nicht ganz überflüssig erscheinen.
In Dedekind’s Schrift1.
Ich hatte aber diese Figuren 22 und 23 schon anfertigen lassen, als ich mich noch der Dedekind’schen Bezeichnungsweisen bediente, und muss demgemäss bitten, die Buchstaben darin etwas abgeändert zu denken, nämlich die kleinen a, a', b, b', c, c' durch gleichnamige grosse:
A, A', B, B', C, C' ersetzt zu erachten, für die Zeichen A, A', A'', A''' und B der Figuren aber b, b', b'', b''' und c zu nehmen, damit der Buchstabe a für das als Abbildungsprinzip zu wählende Relativ frei bleibe.
Die Accente werden dabei nach dem Schema b' = a; b, b'' = a; b' = a; a; b = a2; b, b''' = a; b'' = a3; b, als Abkürzungen aufzufassen sein, die behufs Vereinfachung der in die Figur zu machenden Einträge ad hoc gewählt sind.
Es dürfte keinen Anstoss erregen, vielmehr noch obendrein instruktiv sein, dass wir ferner einer andern Methode geometrischer Veranschaulichung als der im § 4 geschilderten uns bedienen.
Als ersten Denkbereich 11 fassen wir diesmal die Gesamtheit der Punkte eines Kreissektors in’s Auge, oder auch des zugehörigen Winkelraumes, wenn man will auch die der Punkte der ganzen Ebene.
Irgend eine Figur in dieser, z. B. ein schraffirtes Flächenstück, wird uns dann also ein „System“ vorstellen, und jeder Punkt ein „Element solchen Systems (und nicht, wie in § 4, ein Elementepaar!).
Als „Relativ“ a, bezüglich dessen Kettenbildung illustrirt werde, wähle ich eine „eindeutige Zuordnung“, eine wirkliche „Abbildung“ aus dem unsrer Theorie gegenüber beschränkteren Ideenkreise der Dedekind’schen Schrift — mit Absicht, gerade um zu zeigen, dass schon diese ein weit über das Zahlensystem hinausragendes Substrat besitzt.
Diese Abbildung ist bei den drei in Fig. 22 zu erblickenden Sektoren eine auch eindeutig umkehrbare, somit in D’s Terminologie „ähnliche (oder „deutliche“) — bei dem nach links gehenden Sektor aber eine andere, als bei den zwei nach rechts gehenden Sektoren.
Fig. 22.
Bei letztern gilt als a-Bild eines (ein Element repräsentirenden) Punktes A der Punkt A' = a; A, welcher halb so wiet vom Kreiszentrum entfernt auf dem Fahrstrahl von A liegt, bei ersterm aber der in der doppelten Entfernung auf dem gleichen Fahrstrahl gelegene Punkt.
Als System b (in der Figur: A) ist nun das in den Sektor fallende Stück eines konzentrischen Kreisringes genommen, und erblickt man bei dem nach rechts oben gehenden Sektor in der unbegrenzten Folge der nach dem Mittelpunkt zu sich immerfort verjüngenden schraffirten „Vierecke die a-Kette a0; b solchen Systemes b, zugleich auch vom äussersten Viereck b ab nach innen fortschreitend die a-Bildkette a00; b desselben.
Die Dimensionen des b sind hier so gewählt, dass jedes der Objekte mit seinem Bilde disjunkt erscheint.
Bei dem nach rechts unten gehenden Sektor ist b so gewählt, dass das Bild sich unmittelbar an das Objekt anschliesst.
Die a-Kette von b ist hier der ganze schraffirte Sektor, und seine radial gemessen innere Hälfte muss die a-Bildkette von b (gleichwie dessen Kettenbild) veranschaulichen.
Bei Übergreifen eines Objektes über sein Bild würde der Erfolg ein ähnlicher sein.
Bei dem nach links gehenden Sektor oder Winkelraum ist a0; b der Inbegriff der nach aussen unbegrenzten Folge von sich fortgesetzt vergrössernden schraffirten Vierecken, und a00; b ebendiese jedoch ohne das innerste derselben — wobei es belanglos bleibt, dass hier Divergenz bei der Reihe der Maasszahlen dieser schraffirten F;ächen vorliegen würde.
Fig. 23.
In Fig. 23 ist eine zwar eindeutige aber nicht eindeutig umkehrbare Zuordnung als Abbildungsprinzip a gewählt.
Als Denkbereich 11 (oder Dedekind’s System) erblickt man hier das Punktsystem eines Kreisausschnittes, der aus zwei Sechstelkreisen oder Sextanten I und II und einem halben solchen III zusammengesetzt ist.
Als Abbildungsprinzip a gelte folgendes.
Bild eines Punktes A (a der Fig.) in I sei allemal der Punkt A' = a; A (a' der Fig.), auf welchen A zu liegen kommt, wenn man den Sextanten I (ohne umzuklappen) einfach über die „Rutschkante“ MR hinüberschiebt, bis er mit II sich deckt.
Bild eines Punktes C (c der Fig.) in III sei der Punkt C' = a; C (c' der Fig.), auf welchen C zu liegen kommt, wenn man die Sextantenhälfte III über die „Falzkante“ MF umklappt, bis sie mit der benachbarten Hälfte von II sich deckt.
Das Bild B' = a; B eines Punktes B in II (resp. b' von b der Fig.) dagegen werde ähnlich wie oben bestimmt als derjenige Punkt, welcher in der halben Entfernung vom Mittelpunkte auf demselben Strahle mit B gelegen ist.
Alsdann ist einleuchtend, dass wir mit einer Abbildung des ganzen Denkbereichs oder Systems 11 in sich selbst zu thun haben.
In Fig. 23 findet sich alsdann durch Schraffur versinnlicht die a-Kette a0; (b + c) des Systems b + c der Punkte, welche die Fläche der beiden Kreise b und c (A und B der Fig.) ausfüllen, und empfehlen wir dem Leser, die Bilder der vier Segmente, in welche die erwähnten „Kanten MF, MR die Flächen dieser Kreise zerlegen, und darnach wiederum deren Bilder, etc. mit der Anschauung aufzusuchen und zu verfolgen.
Leicht wird man auch, indem man sich in die Flächen b oder c (A, B der Fig.) oder in deren Bilder resp. Ketten oder Bildketten ein irgendwie begrenztes Punktgebiet im Geiste einzeichnet, daran die Gültigkeit noch andrer von den Sätzen, wie D 45 ‥ D 56, mit der Anschauung zu kontroliren vermögen.
§ 24. Nebenstudien zur Kettentheorie.
Durch die Einführung des Begriffs der „Kette inbezug auf ein Relativ“ mittelst D 37 sind folgende zwei Aufgaben nahe gelegt.
Aufgabe 1. Das allgemeinste Relativ zu bestimmen, inbezug auf welches ein gegebnes b eine Kette ist, d. h. die Subsumtion aufzulösen: x; b ⋹ b.
Diese Aufgabe ist nur ein Spezialfall der in § 17 durch das erste Inversionstheorem gelösten.
Als Lösung hat man darnach augenblicklich: x ⋹ b ɟ b̄̆ oder x = u(b ɟ b̄̆) für ein unbestimmtes oder arbiträres u, d. h. es mag der Satz notirt werden: 1)
[Formel] .
Partikulare Wurzeln sind x = 0 sowie x = 1', also: inbezug auf die Moduln 0 und 1' ist jedes Relativ Kette.
Aufgabe 2. Das allgemeinste Relativ zu bestimmen, welches inbezug auf ein gegebnes a eine Kette ist, d. h. nach x die Subsumtion aufzulösen: a; x ⋹ x.
Die Lösung dieser Aufgabe haben wir bereits in 5) des § 22 S. 325 gegeben und als die allgemeine Wurzel zwei Ausdrücke gefunden: x = a0; u und x = ā̆1 ɟ u, welche leicht als wesentlich verschieden zu erkennen sind, nämlich ob sie zwar für u gleich einer Wurzel x mit dieser selbst und miteinander zusammenfallen, doch sonst, bei beliebigem u, verschiedene Wurzelwerte darstellen können.
Denn andernfalles müsste auch für u = 1' bei beliebigem a gelten: a0; 1' = a0 = 1' + a + a2 + a3 + … = ā̆1 ɟ 1' = 1'(ā̆ ɟ 1')(ā̆ ɟ ā̆ ɟ 1') …, was offenbar falsch, da das bestimmungslose a nicht ⋹ 1' zu sein braucht.
Sofern es gestattet ist, aus jenem Gespanne 5) § 22 das für uns Wichtigste hier wiederholend hervorzuheben, notiren wir den Satz: 2)
[Formel] .
Diese Aufgabe gab wol den natürlichsten Anlass zur Einführung des Begriffes a0 der a-Kette, sowie des a-Geketts: die Unbekannte muss die a-Kette von irgendwelchem Relative u sein — desgleichen das a-strichkonvers-Gekett piu einem solchen unbestimmten Relative.
Als partikulare Wurzeln sind aus der Gruppe der Moduln bei beliebigem a nur x = 0 und x = 1 angebbar, d. h. es ist (konform mit D 38) zu sagen, dass der ganz leere, sowie der volle (ganze) Denkbereich inbezug auf jedes Relativ eine Kette ist, ein jedes ihn nur „in sich selbst abbilden“ kann.
Bei der Wahl von u = a0 resp. a erhalten wir ausserdem aus der ersten Lösungsform x = a0 sowie x = a00 als partikulare Wurzeln, dergleichen sich noch unbegrenzt viele weitre als x = a000, etc. allgemein angeben liessen — falls wir mit diesem Symbol die Summe der Reihe 6) S. 325 für a0 ohne die zwei ersten Glieder bezeichneten, etc. Etc. dual entsprechend.
Die a-Kette oder Kette von a, desgleichen die a-Bildkette ist demnach auch immer „Kette inbezug auf a“.
Etc.
Mit beiden Lösungsformen 2) haben wir bereits S. 331 die zwei Proben gemacht; mit der ersten lief die Probe 1 hinaus auf den Satz a; a0 ⋹ a, dessen Gespann auch schon in 6) S. 361 gebucht ist.
Mit der zweiten Lösungsform wurde zwar auch auf S. 331 unten schon die Probe 1 gemacht; dagegen ist noch nicht als Satz gebucht die Thatsache, dass auch sie stimmt — und verdient es noch zu werden.
Sagt man b für das dortige u, so ist daselbst der Satz erwiesen: 3)
[Formel] und insbesondre für b = 0', etc.: 4)
[Formel]
Um die dual entsprechenden Formeln auseinander abzuleiten muss man kontraponiren, wie sonst die Buchstaben durch ihre Negate, zugleich aber a durch ă (etc.) ersetzen. —
Wie die Spezies der Negation an einem Symbol der Form a0, a00, a1, a11, etc. auszuführen ist, haben wir bereits in 9) S. 326 statuirt.
Dagegen wird es für das Folgende nützlich sein, auch noch die Wirkung der Konversion an einem Symbole dieser Reihe vorweg zu erledigen.
Zu dem Ende ist blos zu beachten, dass nach den Regeln des Konvertirens S. 85 und im Hinblick auf den Bau 7) S. 326 von a0, etc. sein muss: 5)
[Formel]
Die Reihenfolge der beiden Operationen des Konvertirens und des Kette- (resp. Bildkette, Gekett, etc.)Nehmens von einem Relative muss somit gleichgültig sein: das Konverse von der Kette ist die Kette vom Konversen, etc. — wogegen, wie wir bei 9) S. 326 gesehen haben, solches bei den Operationen des Negirens und der Ketten(etc.)bildung nicht der Fall ist.
Soll vielmehr einer Kette a0 das Strich- oder Strichkonverszeichen übergesetzt werden, und man will diese letztern Operationen an der Kette ausführen, d. h. das Zeichen dem Buchstaben a selbst zuteilen, so müssen zugleich die Suffixe 0 und 1, resp.
00 und 11 ausgetauscht werden!
Man wird deshalb auch ā0, ā̆11 als astrichnull, astrichkonvers einseins (und nicht als anullstrich, etc.) zu lesen haben.
Nach dem ersten Inversionstheoreme kann nun übrigens von den vier relativen Termen in 3) jeder transponirt werden.
Es entstehen dadurch die Formelgespanne — wofern wir die konjugirten unerwähnt lassen: 3a) 3b) 3c) 3d) — worin, da sie wie 3a) rechts aus a; a0 ⋹ a0 teilweise auch schon bekannt sind, ein direktester Beweis der Formeln zu erblicken ist.
ā̆1 ɟ b ⋹ ā̆ ɟ ā̆1 ɟ b a; a0; b ⋹ a0; b
a⋹ā̆1 ɟ b ɟ b̄̆; a0 a0; b; (b̄̆ ɟ ā̆1) ⋹ ā̆
a0; a; (ā̆1 ɟ b) ⋹ b b⋹ā̆1 ɟ ā̆ ɟ a0; b
a; (ā̆1 ɟ b); b̄̆ ⋹ ā̆1 a0⋹ā̆ ɟ a0; b ɟ b̄̆
Ersetzt man noch in 3c) das a0; a durch a; a0 (wonicht a00) und transponirt abermals (das a), so kommt hinzu: a0; (ā̆1 ɟ b) ⋹ ā̆ ɟ b oder ā̆0; (a1 ɟ b) ⋹ a ɟ b | a; b ⋹ ā̆1 ɟ a0; b und andres mehr.
Nunmehr treten wir noch in etliche freie Forschungen ein.
Die Ergebnisse der Untersuchung nach den Prinzipien des Dualismus und der Konjugation zu „Gespannen“ zu ergänzen, sei zumeist dem Leser überlassen.
Nachdem mit den Suffixen 0, 00, 1, 11 äusserst konzise Namen herstellbar gemacht und eingeführt sind für Ausdrücke, die allerdings die Form von unendlichen Entwickelungen aufweisen, als solche jedoch das allereinfachste und durchsichtigste Bildungsgesetz zeigen, wollen wir kürzehalber übereinkommen, von der Lösung einer Aufgabe zu sagen, dass sie sich „in halbgeschlossener Form“ (genauer vielleicht, statt semi-, quasi-geschlossen) präsentire, sobald sich ihr Ausdruck mittelst endlicher Menge von Operationen der 6 Spezies und solcher Suffixerteilungen aufbaut.
Unsre der Kürze halber als „halbgeschlossen bezeichnete Formen sind also wesentlich solche, die im Operationskreis der 6 Spezies zwar als unendliche Entwickelungen sich präsentiren, dagegen nach Adjungirung des Begriffs der a-Kette sich als geschlossene Formen darstellen.
Wir schreiten zunächst dazu, die letzte Aufgabe zu verallgemeinern.
Augabe 3. Nach x die Subsumtion aufzulösen: 6) a; x + b ⋹ x.
Diese spielt ja obendrein in verschiednen der Dedekind’schen Sätze — D 40, 41, 44, 47, 48 — eine so hervorragende Rolle, dass schon dadurch die Aufgabe nahe gelegt erscheint.
Ihre Lösung kann auf mehreren Wegen erfolgen, die wir sämtlich aus-gehen wollen, sintemal sie zu interessanten Ergebnissen führen und ihre Vergleichung methodologisch lehrreich erscheint. Dieselben führen uns zu folgenden vier getrennt zu chiffrirenden
Formen der Lösung. 7)
[Formel] 8)
[Formel] 9)
[Formel] 10) [Formel] , deren erste „die beste“ zu nennen.
Zur Herleitung.
Da x = 1 der Forderung der Aufgabe genügt, so haben wir keine Resultante.
In Anbetracht, dass in 3) rechts x als Prädikat bereits isolirt erscheint, kann man eine erste Lösungsform augenblicklich nach dem Satz 1) des § 13 hinschreiben in der Gestalt:
[Formel] .
Mit diesem f(u) = b + (1' + a); u beweist man aber leicht durch Schluss von r auf r + 1 das Bildungsgesetz der iterirten Funktion: fr(u) = (1' + a)r; u + (1' + a)r — 1; b = (1' + a)r — 1; f(u) in Anbetracht, dass (1' + a)r — 1 ⋹ (1' + a)r = (1' + a); (1' + a)r — 1 sein muss.
Damit ist dann f∞(u) = (1' + a)∞; u + (1' + a)∞; b = a0; b + a0; u = a0; (b + u) gefunden, d. h. es ist die Lösungsform 7) heuristisch gewonnen.
Es wird uns nachher auch noch ein andrer Weg zu ebendieser führen.
Zum Überfluss soll sie auch direkt verifizirt werden.
Dass die Probe 1 stimmt, beruht lediglich auf den Sätzen 1' ⋹ a0 und a; a0 ⋹ a0.
Die Probe 2 fällt zusammen mit dem Nachweis des Satzes: 11) (a; x + b ⋹ x) = {x = a0; (b + x)} = {a0; (b + x) ⋹ x}, dessen letzter Teil sich daraus versteht, dass die letzte Subsumtion rückwärtig (wegen D 45) ohnehin gilt, wogegen vom ersten Teile die vorwärtige Aussagensubsumtion darnach aus 13) des § 23 (resp. aus D 40) gerechtfertigt werden kann, indem (a; x + b ⋹ x) ⋹ {a; (b + x) ⋹ x} ⋹ {a; (b + x) ⋹ b + x} = {a0; (b + x) = b + x = x} nach D 51 und wegen b ⋹ x sein muss, die rückwärtige durch Probe 1 (diese für u = x in Anspruch genommen) bereits sich erwiesen findet, q. e. d.
Die hiermit gerechtfertigte Lösung 7) setzt uns in den Stand, nun auf die eleganteste Weise für den rückwärtigen Gang der Untersuchung im § 23 den noch ausstehenden letzten Schritt zu vollziehen, nämlich zur Dedekind’schen Definition D 44 der a-Kette von b heuristisch zu gelangen.
Es folgt:
[Formel] , indem offenbar [Formel] sein muss, als den Faktor a0; 0 (= 0) aufweisend.
Damit sind wir nun erst den im § 23 so genannten „Rückweg völlig zu Ende gegangen.
Sehn wir vorgreifend auch die drei andern Lösungsformen 8, 9, 10) als schon erwiesen an und wenden, um es sogleich abzumachen, auch auf sie den eben neu gerechtfertigten Satz D 44 an, so wird das zum Teil recht lehrreich, und findet der Satz auch dadurch seine Bestätigung.
Anwendung von D 44 auf Lösungsform 8) liefert das neue Ergebniss: 12) [Formel] dessen drei letzte Thesen als Sonderfälle mit den Annahmen b = a, 1', a0 aus der ersten fliessen.
Diese ist von ziemlich verwickelter Natur, und werden wir erst im § 29 in den Stand gelangen, sie auch ohne Vermittelung von D 44 direkt zu beweisen.
Um nicht nochmals darauf zurückkommen zu müssen, sei wiederum vorgreifend bemerkt, dass in der That nach Auswertung des Π gemäss dem zweiten Schema 110) des § 29 der erste Satz 13) sich in der Form bewahrheiten wird: a0; b = (a0 ɟ ā̆1)(a0; ă0); b, indem man nur das a, b, c, d, e jenes Schema’s durch resp. ă0, 1, a0; ă0, ā1, b zu ersetzen hat.
Dass aber dieses richtig, sieht man so.
Nach einer gleich nachher begründeten Formel 14) wird der erste relative Faktor rechts sich zu a0(a0; ă0) vereinfachen, und da wegen 1' ⋹ ă0 auch a0 = a0; 1' ⋹ a0; ă0 ist, so muss derselbe in der That a0 selbst sein. —
Zur Lösungsform 9) wird: [Formel] , weil der für u = 0 sich ergebende Faktor des Π in allen andern enthalten ist.
Wogegen die Lösungsform 10) den Satz D 44 nur einfach bestätigt: indem das Π des letzten Gliedes von x, als den auch einmal Nullwert annehmenden Faktor u enthaltend, verschwinden muss.
Nach jenem Resultat jedoch wird das Gespann gelten müssen: 13) [Formel] mithin auch: ā̆1 ɟ b = a0; (ā̆1 ɟ b) = a0; ā̆1 ɟ b.
Der dritte Ausdruck folgt aus dem zweiten so hinzu, dass man die erste Gleichung für b = 1' in Anspruch nimmt, wo sie zusammen mit der konjugirten liefert: 14) [Formel]
Ich will noch Anleitung geben, wie man die erstmals so gewonnenen Sätze auch direkt beweisen kann, speziell die erste Gleichung 13).
Hievon kommt die vorwärtige Subsumtion a0; b ⋹ ā̆1 ɟ a0; b nach dem ersten Inversionstheoreme auf a0; a0; b ⋹ a0; b somit a0; a0 ⋹ (sogar =) a0 hinaus.
Die rückwärtige versteht sich mit ā̆1 ⋹ 0' — cf. 3) S. 361 — aus ā̆1 ɟ a0; b ⋹ 0' ɟ a0; b = a0; b, q. e. d.
Auch so:
Schreibt man nach dem S. 331, Z. 6 v. u. gegebnen Vorbild die rechte Seite der fraglichen Gleichung 13) ausführlich hin, so lautet die Gleichung: a0; b = a0; b · (ā̆ ɟ a0; b)(ā̆ ɟ ā̆ ɟ a0; b) …, läuft also hinaus auf die Einordnung der linken Seite unter das Produkt der Faktoren rechterhand vom ersten ab.
Dass dann in der That unser Subjekt jedem von diesen Faktoren eingeordnet sein muss, folgt wegen a; a0 ⋹ a0 nach dem ersten Inversionstheoreme, indem z. B. die Einordnung a0; b ⋹ ā̆ ɟ ā̆ ɟ a0; b äquivalent ist mit: a; a; a0; b ⋹ a0; b. Etc.
Zum Überfluss kann man zeigen, dass jedes Glied aλ; b des Subjektes a0; b in jedem Faktor (ā̆ ɟ)ϰ ɟ a0; b des Prädikates enthalten ist, indem in letzterem steckt: (ā̆ ɟ)ϰ ɟ aϰ + λ; b und die Einordnung aλ; b ⋹ (ā̆ ɟ)ϰ ɟ aϰ + λ; b nach dem ersten Inversionstheorem äquivalent ist mit der als Gleichung selbstverständlich geltenden aϰ; aλ; b ⋹ aϰ + λ; b. —
Treten wir nach dieser Digression jetzt wieder an die systematische Auflösung unsrer Subsumtion 6) heran.
Als Subjekt lässt sich x in ihr nicht isoliren in Anbetracht, dass die Subsumtion 6) zerfällt in: 15) a; x ⋹ x und b ⋹ x.
Wenn dann auch aus der ersten Teilsubsumtion allerdings x als Subjekt isolirt werden kann zu: x ⋹ ā̆1 ɟ x, so ist das doch nur ein abgeschwächter Schluss und würden wir als äquivalente Transformation von 6) vielmehr eine Doppelsubsumtion behalten: b ⋹ x ⋹ ā̆1 ɟ x. Der Satz 1) des § 13 liefert uns folglich keine zweite Lösung.
Zwecks Entdeckung von Lösungen scheint es vielmehr naturgemäss geboten, dass wir den beiden Teilsubsumtionen 15) nacheinander zu genügen suchen.
Je nach der Reihenfolge, für die man sich dabei entscheidet, gestaltet sich dies aber verschieden.
Erstes (eigentlich schon zweites) Lösungsverfahren.
Wir erfüllen zuerst die erste Forderung 15).
Nach 2) ist dies bereits auf zwei Arten möglich.
Einmal wird jener Fordrung auf die allgemeinste Weise genügt durch den Ansatz: x = a0; v für ein unbestimmtes v. Letztres wird jedoch in seiner Unbestimmtheit noch weiter eingeschränkt durch die Forderung, dass unser x auch der zweiten Subsumtion 15) genüge, d. h. dass b ⋹ a0; v werde.
Hieraus fliesst zunächst b ⋹ a0; 1 als Resultante nach v.
Diese ist aber von selbst erfüllt, indem der Satz gilt: 16) wie sich links daraus versteht, dass 1' ⋹ a0 also 1'; 1 = 1 ⋹ a0; 1 sein muss.
In der That kann (somit) eine a-Kette weder Leerzeilen noch Leerkolonnen haben, ein Gekett aber keine Vollreihen.
a0; 1 = 1 = 1; a0 a1 ɟ 0 = 0 = 0 ɟ a1,
Darnach bestimmt sich denn v ohne weitres nach dem zweiten Inversionstheoreme 11) S. 249 zu v = u + ă0; (ā1 ɟ ū)b mit Rücksicht auf 9) S. 326 und 5).
Durch Einsetzung ist hernach die zweite Lösungsform 8) gewonnen.
Nach der zweiten Art wird der ersten Subsumtion 15) auch auf die allgemeinste Weise zu genügen sein mittelst des Ansatzes: x = ā̆1 ɟ w.
Soll dieses x nun auch die zweite erfüllen, so müssen wir w aus b ⋹ ā̆1 ɟ w berechnen.
Dies gelingt sofort nach dem ersten Inversionstheoreme, welches uns a0; b ⋹ w, also w = a0; b + u liefert.
Damit ist die dritte Lösungsform 9) gefunden.
Es ist instruktiv, auch mit dieser die beiden Proben zu machen.
Probe 1 erfordert zu zeigen, dass für w = a0; b + u sowol a; (ā̆ ɟ w) ⋹ ā̆1 ɟ w — was wir bereits S. 331 unten für jedes w gethan — als auch, dass b ⋹ ā̆1 ɟ w = ā̆1 ɟ (a0; b + u) sein muss.
Letzteres geht auf zwei Arten: erstens kommt die Subsumtion nach dem ersten Inversionstheoreme äquivalent hinaus auf die evidente a0; b ⋹ a0; b + u, und zweitens folgt dieselbe a fortiori, falls sie für u = 0 zutrifft.
Dass aber b⋹ā̆1 ɟ a0; b = a0; b · (ā̆ ɟ a0; b)(ā̆ ɟ ā̆ ɟ a0; b) … kann auch gezeigt werden, indem man darthut, dass b in jedem Faktor der rechten Seite enthalten sein muss.
Dies folgt wieder durch Umwandlung der bezüglichen Subsumtionen nach dem ersten Inversionstheorem in diese aus dem Bau von a0; b selbstverständlichen: b⋹a0; b, a; b ⋹ a0; b, a; a; b ⋹ a0; b, … kann aber endlich auch ohne dies Theorem auf eine Weise dargethan werden, die ich beispielsweise für den dritten Faktor darlegen will.
Wegen 1' ⋹ ā̆ + a ist auch b = 1'; b ⋹ (ā̆ ɟ a); b ⋹ ā̆ ɟ a; b und ā̆ ɟ a; b = ā̆ ɟ 1'; a; b ⋹ ā̆ ɟ (ā̆ ɟ a); a; b ⋹ ā̆ ɟ ā̆ ɟ a; a; b.
Es ist also b ⋹ ā̆ ɟ ā̆ ɟ a2; b erwiesen, und weil nun a2; b ⋹ a0; b, so folgt a fortiori: b ⋹ ā̆ ɟ ā̆ ɟ a0; b wie behauptet.
Probe 2, d. h. der (als Äquivalenz gültige) Satz: (a; x + b ⋹ x) ⋹ {x = ā̆1 ɟ (a0; b + x)} folgt so.
Mit der Prämisse a; x ⋹ x ist nach D 51 auch gegeben: a0; x = x.
Mit b ⋹ x sonach a0; b ⋹ a0; x folgt also auch a0; b ⋹ x oder a0; b + x = x. Dass aber mit a; x ⋹ x auch x = ā̆1 ɟ x sei, geht als vorwärtige Subsumtion nach dem ersten Inversionstheoreme hervor und versteht sich als rückwärtige daraus von selbst, dass ā̆1 ɟ x = x(ā̆ ɟ x)(ā̆ ɟ ā̆ ɟ x) … den Faktor x aufweist, resp. dass ā̆1 ɟ x ⋹ x als duales Gegenstück zum Satze D 45: x ⋹ a0; x gelten muss, nämlich kraft 3) S. 361 aus ā̆1 ⋹ 0' mit ā̆1 ɟ x ⋹ 0' ɟ x = x folgt.
Damit ist auch der Leistung der beiden Proben bei der vierten, erst noch abzuleitenden Lösungsform 10) dermaassen vorgearbeitet, dass dieselbe dem Leser wird überlassen werden können.
Zweites Lösungsverfahren.
Anstatt der ersten kann man jedoch auch der zweiten Subsumtion 4) zuerst zu genügen suchen.
Dies geschieht, indem man setzt: x = x1, = b + u1, unter u1 hier ad hoc nicht das u-Gekett, sondern blos ein unbestimmtes Relativ verstanden.
Dann wird von u1 noch die erste Subsumtion zu erfüllen sein, nämlich die Forderung: a; b + a; u1 ⋹ b + u1.
Diese zerfällt aber in die beiden Teilforderungen: a; b ⋹ b + u1 oder b̄ · a; b ⋹ u1 und a; u1 ⋹ b + u1.
Der erstern ist auf die allgemeinste Weise zu genügen durch: u1 = b̄ · a; b + u2 und damit wird: x = x2, = b + b̄ · a; b + u2 = b + a; b + u2.
Setzt man zur Abkürzung: 17) f(y) = b + a; y und definirt die Iterationen dieser Funktion wie üblich rekurrirend durch: f0(y) = y, f1(y) = f(y), fr + 1(y) = f{fr(y)} = b + a; fr(y), so müssen wir uns zur Vereinfachung des Folgenden zunächst überzeugen, dass für fr + 1(y) beim Argumente y = b neben der vorigen auch diese Darstellung zutrifft: fr + 1(b) = fr(b) + a; fr(b).
Dies zu beweisen gelingt unschwer so: die Doppelsubsumtion: b⋹fr — 1(b) ⋹fr(b) ist für r = 1 augenscheinlich richtig.
Gilt sie aber für ein bestimmtes r, so folgt weiter: b⋹b + a; fr — 1(b) ⋹ b + a; fr(b) das heisst: b⋹fr(b) ⋹fr + 1(b), d. h. sie gilt dann auch für r + 1 und somit allgemein.
Nunmehr muss nach R. Grassmann’s Theoreme 20+) des Bd. 1, oder vorletzte Zeile von 3) unsres § 6 S. 79 sein: fr(b) + a; fr(b) = fr(b) + b + a; fr(b) = fr(b) + fr + 1(b) = fr + 1(b), wie zu zeigen gewesen.
Nach dieser Vorbereitung lässt sich darthun, dass, wenn für ein bestimmtes r gefunden ist, dass die allgemeine Wurzel x der aufzulösenden Subsumtion 3) in der Form existirt: 18) x = xr, = fr — 1(b) + ur, wo ur noch weiterer Bestimmung harrt — und dies war ja für r = 1 und 2 der Fall — alsdann das Entsprechende auch für den nächst höheren Wert von r folgt.
Da nämlich wegen b ⋹ fr — 1(b) die Forderung b ⋹ xr bereits erfüllt ist, so wird nur noch zu erfüllen sein: a; xr ⋹ xr, und dies zerfällt bei Einsetzung von xr in zwei Forderungen, deren erste lautet: a; fr — 1(b) ⋹ fr — 1(b) + ur oder fr — 1(b)͞ · a; fr — 1(b) ⋹ ur.
Der aber ist vermittelst des Ansatzes:
ur = fr — 1(b)͞ · a; fr — 1(b) + ur + 1 auf die allgemeinste Weise Genüge zu leisten und damit wird: x = fr — 1(b) + a; fr — 1(b) + ur + 1, indem nach Th. 33+) Zusatz des Bd. 1 die Negation des ersten Gliedes als Faktor beim zweiten Gliede unterdrückt werden durfte.
Nach dem Obigen läuft dies nun hinaus auf: x = xr + 1 = fr(b) + ur + 1, q. e. d.
Die Formel 18) ist sonach für jede noch so grosse Zahl r als gültig erwiesen, und mögen wir in ihr r auch unendlich anwachsen lassen.
Dann ist gefunden: 19) x = f∞(b) + v, wo das Relativ v, mit dessen Namen wir den von u∞ abkürzten, immer noch einer weitern Bestimmung harrt, die wir erst weiter unten statuiren und zu erfüllen suchen.
Es besitzen aber die Iterationen der Funktion f(y) einen äusserst übersichtlichen Bau und ist sowol independent einleuchtend als rekurrirend leicht beweisbar, dass wir haben:
[Formel] , insbesondre: f(b) = (1' + a); b, fr(b) = (1' + a)r; b, und endlich 20) f∞(b) = (1' + a)∞; b = a0; b.
Anmerkung.
Hätte man sich enthalten, die Ausdrücke für die xr so wie es oben geschah jeweils durch Anwendung jenes Th. 33+) Zusatz: a + āb = a + b zu reduziren, so würde man zu einem sehr viel komplizirteren Ausdruck für xr gelangt sein, von dem es aber bemerkt zu werden verdient, dass er sich eben zu dem obigen einfachern Ergebnisse 18) reduziren lässt.
Darum sei auch ihm noch einige Beachtung geschenkt.
Nennen wir:
F(y) = ȳ · a; y und definiren die Iterationen auch dieser Funktion in der üblichen Weise, so ergibt sich für xr die folgende Darstellung: x = xr = F0(b) + F1(b) + F2(b) + … + Fr — 1(b) + ur, von der wir uns begnügen wollen nachzuweisen, dass sie mit der vorigen zusammenfällt, indem sich die Summe rechterhand reduzirt nach dem Schema:
Fr — 1(b) =, F0(b) + F1(b) + F2(b) + F3(b) + … + Fr — 1(b) = fr — 1(b).
Letzteres ist in der That zunächst evident für r = 1 sowie 2 und kann von da durch Schluss von r auf r + 1 bewiesen werden.
Zu dem Ende beachte man, dass laut vorstehender Definition von Fr(b) allgemein sein muss:
Fr(b) = Fr — 1(b) + Fr(b) = Fr — 1(b) + Fr — 1(b)͞ · a; Fr — 1(b) = = Fr — 1(b) + a; Fr — 1(b), weil nämlich der zuletzt unterdrückte Faktor gerade die Negation des letzten Summanden im vorhergehenden Gliede und darum nach dem Satze a + āb = a + b unterdrückbar war.
Wendet man diese Rekursion auch auf die vorhergehenden Werte r — 1, r — 2, … 2, 1 von r an und setzt rechterhand rückwärts ein, so ergibt sich leicht, weil ja F0(b) = F0(b) = b ist: Fr(b) = F0(b) + a; {F0(b) + F1(b) + … + Fr — 1(b)} = b + a; Fr — 1(b).
Wenn nun oben die zu beweisende Reduktionsformel für ein bestimmtes r gültig ist, so wird aus ihr folgen, dass: Fr(b) = b + a; fr — 1(b) = fr(b) sein, d. h. dass sie auch für r + 1 gelten muss — womit sie denn in der That durch den Schluss der vollständigen Induktion bewiesen erscheint.
Unser Ergebniss war, dass 21a) x = a0; b + v sein muss, wobei wegen b ⋹ a0; b nunmehr a fortiori auch b ⋹ x sein wird, mithin die zweite Subsumtion 15) erfüllt ist, aber die erste a; x ⋹ x noch zu erfüllen bleibt.
Diese zerfällt in a; a0; b = a00; b ⋹ a0; b + v, was wegen a00 ⋹ a0 schon bei v = 0 mithin umsomehr bei beliebigem v identisch erfüllt ist, und in: 21b) a; v ⋹ a0; b + v, welcher Bedingung wir noch fernerhin durch geeignete Bestimmung von v zu genügen haben werden.
Noch bevor letzteres ausgeführt ist, können wir aber wiederum, auch von dem hier gewonnenen Standpunkte, den Dedekind’schen Ausdruck D 44 für die a-Kette von b (für den rückwärtigen Gang der Untersuchung im § 23) beweisen wie folgt.
Es ist mit dem Vorstehenden erwiesen, dass 21) [Formel] .
Darnach muss also sein:
[Formel] , sintemal zu den Relativen, welche die Erstreckungsbedingung von v erfüllen, augenscheinlich auch der Wert 0 gehört, wonach also das Πv = 0 sein muss, q. e. d. —
Inzwischen sind wir aber mit unsrer zweiten Lösungsart der Aufgabe 3 noch nicht zu Ende gekommen.
Dieselbe ist vielmehr erst blos zurückgeführt auf die Auflösung einer Hülfsaufgabe, nämlich der nach der Unbekannten v der Subsumtion 21b).
Statt dieser nehmen wir lieber sogleich vor die allgemeinere
Aufgabe 4. Nach x die Subsumtion aufzulösen: 22) a; x ⋹ b + x.
Da x = 0 der Forderung genügt, so haben wir keine Resultante.
Weil sich in äquivalenter Transformation von 22) sowol als Prädikat wie als Subjekt x isoliren lässt zu: 23a) b̄ · a; x ⋹ x, x ⋹ ā̆ ɟ (b + x), so verfügen wir nach meinem Theorem 1) des § 13 sofort über die zwei Lösungsformen: 23) [Formel] , mithin für φ(u) = b̄ · a; u, ψ(u) = ā̆ ɟ (b + u) auch x = f∞(u) = u + φ(u) + φ2(u) + … resp. uψ(u)ψ2(u) … sein wird.
Das Bildungsgesetz der iterirten Funktionen φ und ψ ist dabei ein leidlich durchsichtiges; auch zeigt man leicht, dass φr inbezug auf Summen, ψr inbezug auf Produkte distributiv ist, nämlich: φr(u + v) = φr(u) + φr(v), ψr(uv) = ψr(u)ψr(v) allgemein sein muss.
Darnach wird dann z. B.: φ(x) = φ{u + φ(u) + φ2(u) + …} = φ(u) + φ2(u) + φ3(u) + … ⋹ u + φ(u) + φ2(u) + φ3(u) + … = x und stimmt die Probe 1 sofort.
Etc.
Invariant sind die beiden Funktionen f im allgemeinen nicht, indem weder a; u + a; b̄(a; u) ⋹ b + u + b̄ · a; u noch a; u{ā̆ ɟ (b + u)} ⋹ b + u{ā̆ ɟ (b + u)}, 24) d. h. a; b̄(a; u) ⋹ b + u + a; u resp.
„ „ „ ⋹ b + ā̆ ɟ (b + u) zu gelten braucht.
Was nämlich die zweite Subsumtion betrifft, deren Prädikat in (b + u) mal dem zuletzt angegebnen zerfällt, so lässt sich allerdings zeigen, dass ihr Subjekt L⋹a; u · a; {ā̆ ɟ (b + u)} ⋹ a; ā̆ ɟ (b + u) ⋹ 0' ɟ (b + u) = b + u ist, weshalb dieser Faktor beim Prädikate unterdrückbar war.
Immerhin gibt es ausgedehnte Klassen von Fällen, worin die Beziehungen 24) zutreffen und dann statt 23) der Ausdruck x = f(u) selbst die Wurzel vorstellt, dazu auch andre, wo wenigstens in halbgeschlossener Form eine Lösung möglich.
Ein bemerkenswertester Fall jener Art liegt vor, wenn in unserm Probleme 23) a Kette, somit durch a0 vertreten ist.
Die linke Seite L = a0; b̄(a0; u) der ersten Subsumtion 24) ist dann nämlich ⋹ a0; a0; u = a0; u, somit L ⋹ R, und die L der zweiten Subsumtion 24) ist ⋹ a0; {ā̆1 ɟ (b + u)} ⋹ a0; ā̆1 ɟ (b + u) = ā̆1 ɟ (b + u) nach 14) rechts, somit auch hier L ⋹ R.
Sonach müssen wir haben: 25) [Formel] , — womit zum Überfluss auch beide Proben zu leisten nach Bisherigem ein Leichtes ist.
Auf dieses Schema lassen sich auch noch andre Partikularfälle der Aufgabe 4 zurückführen, darunter zum Glück gerade derjenige, der für die völlige Lösung unsrer Aufg. 3 (im zweiten Lösungsverfahren) unentbehrlich gewesen.
Es gilt nämlich der Satz: 26) (a; x ⋹ x + b) ⋹ (a; x ⋹ x + a0; b) = (a0; x ⋹ x + a0; b), dessen erster Teil sich aus D 45 (b ⋹ a0; b) a fortiori versteht.
Die so als Konklusion gewonnene zweite Subsumtion kann man von da weiter schliessend mit der selbstverständlichen a; a0; b ⋹ a0; b ⋹ x + a0; b zusammenziehen zu: a; (x + a0; b) ⋹ x + a0; b, was sich nach D 51 äquivalent umschreibt in a0; (x + a0; b) = x + a0; b oder wegen a0; a0 = a0 in a0; x + a0; b = x + a0; b und die Folgerung involvirt: a0; x ⋹ x + a0; b, womit die dritte Subsumtion 26) gewonnen ist.
Aus dieser fliesst aber auch umgekehrt wegen a; x ⋹ a0; x a fortiori die zweite, sodass die beiden als äquivalent erkannt sind, q. e. d.
Die Einordnung der ersten Subsumtion 26) unter die dritte kann als eine Ausdehnung von Dedekind’s Satz D 51 hingestellt werden, in den sie für b = 0 (dann b für x gesagt) übergeht.
Natürlich konnte man diesen Satz auch leicht mittelst überschiebenden Addirens einer unbegrenzten Reihe von Folgerungen aus der ersten Subsumtion 26): 1'; x ⋹ x + b, a; x ⋹ x + b, a; a; x ⋹ a; x + a; b ⋹ x + b + a; b, etc. gewinnen.
Durch den zweiten Teil von 26) erscheint aber das mittlere Problem dieser Zeile auf das Schema 25) zurückgeführt und können wir darnach sogleich auch die Aufgabe mit zwei Lösungsformen hinschreiben: 27) [Formel] .
Nimmt man dies für v statt x in Anspruch und setzt dessen der letzten Subsumtion in 21) auf allgemeinste Weise genügenden Wert in die vorletzte ein, so ergeben sich zwei Lösungsformen unsrer Aufgabe 3, und zwar kommt man mit der ersten Lösungsform 27) durch die kleine Reduktion: a0; b + u + (ā1 ɟ b̄) · a0; u = u + a0; b + a0; u = a0; (b + u) — weil u ⋹ a0; u, auf die schon früher gefundene Lösungsform 7) zurück.
Mit der zweiten Lösungsform 27) aber ergibt sich unmittelbar die letzte Lösungsform 10), die wir noch heuristisch abzuleiten schuldig gewesen. —
Den Aufgaben 27) reiht sich ferner noch an: 28) [Formel] , indem die erste Äquivalenz wieder die Aufgabe auf das Schema 25) zurückführt.
Um sie, die als rückwärtige Aussagensubsumtion evident ist, auch als vorwärtige einzusehen, hat man gemäss 26) nur den Satz zu beachten: 29) [Formel] der sich nach bekannten Sätzen aus 16) versteht.
Bei den zweiten Lösungsformen 28) ist sodann blos noch eine Reduktion vonnöten mit Berücksichtigung der Sätze 5 und 24) des § 18 und von 9) S. 362. —
Sobald also b „Systemkonvers“ ist (cf. § 27), vermögen wir die Aufgabe 4 wenigstens in halbgeschlossner Form zu lösen.
Bemerkenswert ist, dass bei diesen 28) gleichwie bei den Aufgaben 27) die Funktion f(u) der allgemeinen Lösungen 23) gleichwol nicht invariant ist (es müsste ja sonst auch a; u an Stelle von a0; u im ersten Wurzelausdruck stehen und ā̆ ɟ etc. an Stelle von ā̆1 ɟ etc. im zweiten!).
Ähnlich wie in diesen beiden Partikularfällen derselben auch für die allgemeine Aufgabe 4 eine Lösung in halbgeschlossener Form zu ermitteln, ist mir nicht gelungen.
[Ich hatte, nebenbei bemerkt, je die ersten Resultate 25, 27, 28) auf einem ganz andern und viel mühsameren Wege gefunden, indem ich nämlich der Koeffizientenbedingung bei der allgemeinen Aufgabe 4 symmetrisch allgemein zu genügen suchte; auch dies Verfahren — weil vielleicht noch nicht hinlänglich vervollkommnet — liefert(e) nur die partikularen Ergebnisse.]
Zum vorstehenden Problemcyklus scheint auch noch zu gehören die
Aufgabe 5. Nach x die Subsumtion aufzulösen: 30) a; x ⋹ bx.
Auch hier ist keine Resultante, und zerfällt wie bei Aufg. 3 die Subsumtion in zweie: 31) a; x ⋹ b und a; x ⋹ x, deren erstrer für sich man nach dem ersten Inversionstheorem, der zweiten auf zwei Arten gemäss Aufg. 2 genügen kann.
Je nach der Reihenfolge in der man die Forderungen 31) successive erfüllt, wird man also zwei verschiedne Lösungsverfahren haben.
Und noch mehr:
denn es ist auch in 30) mit x ⋹ ā̆ ɟ bx = (ā̆ ɟ b)(ā̆ ɟ x) die Unbekannte sofort als Prädikat isolirbar, wonach mein Satz 1) des § 13 sich anwenden lässt.
Alle diese Wege auszugehen will ich diesmal teilweise dem Studirenden überlassen und mich mit der Angabe der folgenden Lösungsformen begnügen: 32) [Formel] , für welche die beiden Proben auch unschwer zu leisten sind.
Damit gelangt unser Aufgabencyklus zu einem gewissen Abschlusse.
Als nächste Verallgemeinerungen des Kettenproblemes a; x ⋹ x bieten nämlich auf den ersten Blick sich folgende vier Probleme dar:
Nach x (womöglich doch in halbgeschlossner Form) aufzulösen die Subsumtion: 33) [Formel] . Von diesen vier Problemen sind aber die beiden mittleren der Art nach nicht verschieden, weil von ihnen das eine, b̄ für b gesetzt, mit dem andern zusammenfällt.
Sonach repräsentiren uns die vier Subsumtionen blos drei Probleme, die mit den Aufgaben 3, 4 und 5 behandelt worden, und von denen die beiden äussersten als (a; x ⋹ x)(b ⋹ x) resp. (a; x ⋹ b)(a; x ⋹ x) zerfallen, keines aber eine Resultante involvirt.
Von diesen Problemen also würden nun die Lösungen erreicht sein.
Zugleich erscheint das identische Produkt [Formel] — Dedekind’s „Gemeinheit“ — ihrer sämtlichen Wurzeln ermittelt, und dual entsprechend auch deren identische Summe [Formel] , sofern deren Wert nicht ohnehin ersichtlich.
In der That ist nämlich 34) [Formel] — welch letztres Ergebniss leicht aus 32) zu folgern ist, indem die [Formel] , erstreckt über alle Wurzeln x der vierten Subsumtion 33), gleich [Formel] und die mit der „absoluten Erstreckung“ (über den ganzen Denkbereich 12) versehen zu denkende [Formel] gleich 1 sein wird.
Der andre Ausdruck fliesst ähnlich aus der letzten Lösungsform von 32).
Jedenfalls lassen unsre Nebenstudien doch schon erkennen, wie auch komplizirtere und mehrere Parameter aufweisende Probleme unsrer Disziplin allmälig in stufenweisem Fortschritte zu eleganter Lösung gebracht werden können.
Wie schon aus dem Anblick der Gespanne 5) bis 5''') des § 22 erhellt, müssen zu den aufgestellten Sätzen nicht nur die dual und konjugirt verwandten gelten, welche uns die Lösungen der zum Gespann des Kettenproblemes gehörigen verwandten Probleme mit darstellen, sondern es muss auch für das Kettenproblem selbst gestattet sein, indem man nur a durch ā̆ ersetzt, die zu den gegebnen dual entsprechenden Formeln aufzustellen — eine Bemerkung, durch welche die Fülle der bisherigen Ergebnisse nochmals verdoppelt wird.
Ob diese Bemerkung schon weit genug in ihre Konsequenzen verfolgt, der Umstand genügend ausgebeutet wurde, muss ich noch dahingestellt sein lassen.
Wenn nun die an die Probleme 29) sich knüpfenden Untersuchungen als so belangreiche sich erwiesen haben, so drängt sich die Vermutung auf, es möchte Ähnliches auch zutreffen hinsichtlich der Probleme, welche durch die rückwärtigen Subsumtionen zu denen 33) statuirt werden: 35) die ebenfalls nur drei Probleme repräsentiren und als nächstliegende Verallgemeinerungen des „rückwärtigen Kettenproblems“ x ⋹ a; x erscheinen.
Das erste von diesen 35) involvirt hier eine Resultante b ⋹ a; 1, die übrigen, weil x = 0 genügt, wiederum keine.
x + b ⋹ a; x, [Formel] x⋹a; x · b oder (x ⋹ a; x)(b ⋹ a; x) oder (x ⋹ a; x)(x ⋹ b),
Bei Festhaltung derselben Reihenfolge wie in 33) würden es die beiden äussersten Subsumtionen gewesen sein, die rückwärtig in ein Problem zusammenfallen, die beiden mittleren, welche, diesmal grundverschiedene Probleme darstellend, zerfallen.
Wir haben darum in 35) die Reihenfolge umgestülpt.
Welche Werte haben nun die Πx und Σx erstreckt über alle Wurzeln einer dieser Subsumtionen?
Ich habe diese Probleme noch nicht allzuweit verfolgt und empfehle sie Forschern zur Bethätigung.
Dass sie mit dem Kettenprobleme zusammenhängen werden, zeigt sich schon darin, dass, wenn ein x der Forderung x ⋹ a; x genügt, auch a0; x derselben leichterweislichermaassen genügen und zwar die Subsumtion als Gleichung erfüllen muss, sodass 36) (x ⋹ a; x) ⋹ (a0; x = a; a0; x) = (x ⋹ a; a0; x).
Zum Schlusse noch ein Wort
Zu D 63.
Dieser ohne Beweis gegebene „Satz“ des Herrn Dedekind enthält mehrere Behauptungen, bei deren einigen auch von „echten“ Teilen die Rede ist, und wir also zu deren Wiedergabe das Unterordnungszeichen ⊂ gebrauchen müssten.
Man kann jedoch unbeschadet der Richtigkeit das letztere auch durch ⋹ ersetzen und sich begnügen die entsprechenden Behauptungen blos für „Teile“ schlechtweg zu beweisen, was wir zunächst thun wollen.
Dann gelten die ersten derselben nicht blos für eindeutige Abbildungen und Systeme, sondern wiederum für beliebige Relative.
Die erste Behauptung des Satzes (noch unmodifizirbedürftig) lautet: (a; c ⋹ b ⋹ c) ⋹ (a; b ⋹ b) 37) oder (a; c ⋹ b)(b ⋹ c) ⋹ (a; b ⋹ b), besagend, dass jeder Teil b einer Kette c (bezüglich a) welcher das a-Bild derselben enthält, selbst Kette (bezüglich a) sein muss — sintemal ja auch a; c ⋹ c gilt, also c Kette sein wird.
Dies folgt mittelst a; b ⋹ a; c (aus der zweiten Prämisse: b ⋹ c) wegen der ersten a; c ⋹ b a fortiori mit grösster Leichtigkeit.
Weniger naheliegend ist der Beweis der folgenden Behauptungen Dedekind’s.
Eine zweite besagt, dass unter den obigen Voraussetzungen: 38) a0; b̄c ⋹ c sein müsse.
[Genauer, falls sogar b ⊂ c, dass a0; b̄c ⊂ c sei; das b̄c ist Dedekind’s U.]
Wir bringen uns zum Bewusstsein, dass wir über folgende Propositionen verfügen: (a; c ⋹ c)(a; c ⋹ b)(b ⋹ c)(a; b ⋹ b)(a0; b = b)(a0; c = c), deren letzte beiden nach D 51 aus vorhergehenden fliessen.
Nun ist: a0; c = a0; (b + b̄)c = a0; bc + a0; b̄c, mithin a0; b̄c ⋹ a0; c, welches = c, und damit die zweite Behauptung erwiesen.
Eine dritte Behauptung ist blosse Wiederholung der zweiten.
Wenn nämlich hier zur Abkürzung a0; b̄c = d genannt wird, so lautet sie: c = d + cd̄ (indem cd̄ zusammenfällt mit Dedekind’s V).
Dies heisst aber einfacher: c = d + c und läuft auf d ⋹ c hinaus, was die zweite Behauptung ausmachte.
[Eine vierte Behauptung sagt, es sei b = a; d + cd̄ und eine fünfte (die letzte) fügt hinzu, dass, falls obendrein b = a; c ist, auch sein müsse cd̄⋹a; cd̄.
Diese beiden Behauptungen gelten jedenfalls nicht mit der gleichen Allgemeinheit wie die übrigen schon für beliebige binäre Relative.
Sie wären vom „zweiten Teile“ der Dedekind’schen Schrift — nach meiner Abgrenzung desselben — eigentlich auszuschliessen gewesen.
Und es ist hier nicht der Ort, ihre Geltung für eindeutige Abbildungen a und Systeme b, c zu prüfen.] —
Zu allerletzt — die Wissenschaft ist ja unendlich! — noch etwas Neues:
Für die Ketten gelten auch die Sätze: 39) [Formel] welche äusserst leicht aus ihrem Bildungsgesetze zu beweisen sind — vergl. 6) des § 22 S. 325.
Ist a ⋹ 1', so auch a; a ⋹ 1'; 1' = 1', etc.
Dazu: 40) [Formel]
Die Kette von a ist mithin einerlei mit der Kette von 0'a, d. i. des Alioteils von a.
Beweis auf verschiedne Arten möglich; am einfachsten aufgrund von 15) S. 365 mit a0 = (1' + a)∞ = (1' + 0'a)∞ = (0'a)0.
Mit den gelösten Auflösungsproblemen haben natürlich — im Einklang mit S. 174 sq. — auch einige Eliminationsprobleme ihre Lösung gefunden.
Namentlich muss in den folgenden Aussagensubsumtionen: 41) (x00 = a) ⋹ (a; a ⋹ a) = (a00 = a), 42) (x0 = a) ⋹ (a0 = a), (a = 1' + y)(y; y ⋹ y) ⋹ (a0 = a) die rechte Seite uns die volle Resultante der Elimination von x resp. y aus der linken vorstellen.
Beweis auch direkt leicht zu führen:
Da nach 5) S. 361: x00; x00 ⋹ x00, so folgt durch Einsetzung aus der Prämisse von 41) zunächst die Behauptung a; a ⋹ a als „eine“ Resultante.
Diese ist nach D 51 äquivalent mit der a0; a = a, d. h. mit der letzten Gleichung in 41), und letztre lässt erkennen, dass, wenn sie erfüllt, auch x = a eine Wurzel der Gleichung x00 = a sein wird, dass unsre Resultante mithin die volle gewesen.
Hienach deckt sich überhaupt der Begriff einer Bildkette mit dem eines transitiven Relativs.
Ebenso folgt zur Prämisse der ersten Subsumtion 42) die Resultante zunächst als Konklusion aus (x0)0 = x0 kraft 8) S. 362, und gibt sich auf den ersten Blick als die volle zu erkennen, weil dann x = a genügt.
Die zweite Subsumtion 42) betreffend mag man deren zweite Prämisse nach dem Schema 41) äquivalent in y00 = y umschreiben, was sich benutzen lässt, um die erste zu a = 1' + y00 = y0 zu reduziren.
Etc. q. e. d.
Zur Darstellung aller transitiven Relative verfügen wir in Gestalt von 34) S. 339 auch über geschlossene Ausdrücke, und frägt es sich inwieweit letztere zur Berechnung von Bildketten sich verwerten lassen.
Zwar um die Bildkette a00 zu einem gegebnen Relativ a zu ermitteln, scheint solches bis jetzt nicht möglich zu sein.
Handelt es sich jedoch etwa nur darum, aus den binären Relativen alle diejenigen hervorzuheben, welche überhaupt Bildketten resp. Ketten sind, so würden sich dieselben gemäss der in Form unendlicher Entwicklung bekannten Darstellung: u00 = u + u2 + u3 + …, u0 = 1' + u00 nur äusserst mühsam für andre und andre u berechnen, herstellen lassen.
Ein Leichtes wird dies aber, wenn man für u00 den nach citirtem Schema gebildeten Ausdruck v(v̄̆ ɟ v) nimmt und diesen, der ja geschlossene Form hat, für andre und andre v evaluirt.
Zehnte Vorlesung.
Individuen im ersten und im zweiten Denkbereich.
Die Theorie der uninären Relative.
§ 25.
Das Element als Einzeiler und der Einkolonner.
Charakteristik und Knüpfungsgesetze beider.
Die Buchstaben derjenigen Gruppe i, j, h, k, l, …, welche wir in unsrer Theorie für die Verwendung als Indizes reservirt hatten, wurden schon im § 3 vermöge einer fundamentalen Festsetzung 8) auch zu binären Relativen gestempelt, und zwar lautete — für i als Repräsentanten irgend eines Index gesagt — die Festsetzung:
1) ih k = 1'i h, welche als eine für alle i, h, k gültige verstanden werden sollte.
Es wird hienach ih k = ih j = ih l = … vom zweiten Suffixe unabhängig sein; oder wenn das Relativ i an einer Stelle einer bestimmten Zeile ein Auge besitzt (indem ein gewisses ih k = 1 ist), so muss es an jeder Stelle ebendieser Zeile ein Auge, diese Zeile somit zur Vollzeile haben (indem dann auch für jedes, von k eventuell verschiedne l wird ih l = 1 sein müssen).
Und wenn das Relativ i eine Stelle einer bestimmten Zeile zur Leerstelle hat, so hat es jede Stelle ebendieser Zeile zur Leerstelle, die ganze Zeile zur Leerzeile (indem für ein ih k = 0 auch jedes ih l = 0 sein muss).
Das Relativ i kann also nur aus Voll- und Leerzeilen bestehen.
Nun ist 1'i h = 1 ausschliesslich für h = i, dagegen 1'i h = 0 für jedes h ≠ i.
Sonach hat i nur eine und zwar die ite Zeile zur Vollzeile und alle übrigen Zeilen zu Leerzeilen.
Das Relativ i ist ein „sonst leerer Einvollzeiler“, was wir kurz einen Einzeiler nennen.
Ebenso ist ĭ ein sonst leerer Einvollkolonner oder kurz ein Einkolonner, hat nämlich die ite Kolonne zur vollen, alle übrigen zu Leerkolonnen.
Mit dem Studium der Eigenschaften dieser hochwichtigen Relative, der Einzeiler und Einkolonner, wollen wir uns hiernächst beschäftigen.
Als eine Frucht dieses Studiums wird namentlich die Erkenntniss zu gewinnen sein, dass man berechtigt ist, den Einzeiler i auch als (das) Element (i) des ersten Denkbereiches in der Theorie der Relative hinzustellen.
Verwandte (von i) sind die Relative i, ī, ĭ und ī̆.
Was zunächst die Modulknüpfungen dieser Relative betrifft, so bieten die identischen nur ein geringeres Interesse; auch wird inbezug auf sie der Leser sich leicht selbst — schon aus der geometrischen Evidenz — orientiren.
Dagegen haben die relativen Modulknüpfungen die bemerkenswerte Eigenschaft, dass inbezug auf sie die vier Verwandten mit den Moduln zusammen eine „Gruppe“ bilden, derart dass aus den vier gedachten Relativen durch irgendwelche (auch successive) relative Modulknüpfungen immer nur 1 oder 0 oder eines der vier Relative selbst hervorgehen kann.
Dies erhellt sogleich aus dem Anblick der primären von diesen relativen Modulknüpfungen, welche sich in vollständiger Zusammenstellung darstellen wie folgt: 2)
[Formel] 3)
[Formel] 4) und wovon die zweite (untere) Hälfte aus der ersten durch beiderseitiges Konvertiren hervorgeht, die rechte Hälfte aus der linken durch beiderseitiges Negiren (Kontraposition).
Die 8 Formeln des ersten Viertels oder Quadranten aber sind so leicht zu rechtfertigen — sei es aus 1) eventuell unter Anwendung der Schemata 12) des § 8, sei es auch durch zeilen- oder kolonnenschematisches Rechnen — dass wir glauben kaum länger dabei verweilen zu sollen.
ĭ; 1 = 1 ĭ ɟ 0 = 0 ī̆; 1 = 1 ī̆ ɟ 0 = 0 1; ĭ = ĭ 0 ɟ ĭ = ĭ 1; ī̆ = ī̆ 0 ɟ ī̆ = ī̆ ĭ; 0' = ī̆ *ĭ ɟ 1' = 0 *ī̆; 0' = 1 ī̆ ɟ 1' = ĭ 0'; ĭ = ĭ 1' ɟ ĭ = ĭ 0; ī̆ = ī̆ 1' ɟ ī̆ = ī̆
Die letztre Beweismanier in der That dem Leser überlassend, wollen wir doch (bei der grossen Wichtigkeit der Sätze) nach jener erstern wenigstens die Rechtfertigung durch Koeffizientenevidenz hier geben:
Zu 2).
[Formel] Zu 3). [Formel]
Von den bisherigen (jenen 8)
Formeln ist — wie leicht zu sehn — noch keine fähig, das Relativ i etwa als einen Einzeiler zu charakterisiren.
Will man letzteres erreichen, so muss man auch höhere Modulknüpfungen von i in’s Auge fassen, und zwar wird am einfachsten schon mit Hülfe von sekundären sich unser Ziel verwirklichen lassen.
Jede höhere Modulknüpfung von i (oder einem seiner Verwandten) lässt sich natürlich mittelst successiver Anwendung von Formeln der obigen Tafel nun mit Leichtigkeit ausrechnen.
Dem Leser, welcher etwa heuristisch vorgehn will, empfehlen wir, dies mit den 32 sekundären Knüpfungen — wie sie sich für ein allgemeines Relativ in einer spätern Vorlesung zusammengestellt finden — wirklich zu thun.
Diejenigen Formeln, welche eine Reduktion der Knüpfung zu 0 oder 1 statuiren, wie 0'; (1' ɟ i) = 0 oder 1; (i ɟ 0) = 1, sind natürlich unfähig i als einen Einzeiler zu charakterisiren, schon aus dem Grunde weil sie auch für i = 0, oder aber für i = 1, erfüllt sein würden.
Solches kann daher höchstens durch Formeln, die rechterhand ī selbst, oder auch i zeigen, geleistet werden.
Doch thun es von diesen nicht alle.
Einige vielmehr, wie (i ɟ 1'); 1 = i, i; 0' ɟ 0 = i, (i ɟ 1'); 0' = i, i; 0' ɟ 1' = i, 1' ɟ 0'; i = i sind auch für i = 0 schon erfüllt, könnten also höchstens dienen (was obendrein nicht zutrifft), i als „Einzeiler oder Leerzeiler (0)“ charakterisiren zu helfen.
Eine andre von den Formeln:
0'; i; 0' = ī ist, ausser durch i, augenscheinlich auch durch ĭ erfüllt.
Und so verbleiben in der That als (möglicherweise) charakteristisch nur die nachher angeführten Formeln 6).
Der Umstand, dass sich 1; i; 1 = 1 herausstellt, kann im Hinblick auf § 10 nebenbei als Beweis dafür hingestellt werden, dass 5) i ≠ 0 sein muss.
Und ferner gelangt man durch die Prüfung der sekundären Knüpfungen zu dem bemerkenswerten
Satze, dass die Charakteristik des Einzeilers in folgenden sechs äquivalenten Formen — wol auf die einfachste Weise — kann ausgesprochen werden: 6)
[Formel] von denen die drei in einer Zeile aus denen der andern durch Kontraposition hervorgehen, und die natürlich auch noch mittelst Konvertirens vervielfältigt werden könnten.
Behauptet ist also, dass, wenn ein Relativ x beispielsweise die Gleichung erfüllt: 0'; x; 1 = x̄, dasselbe notwendig ein Einzeiler sein müsse — und ähnlich bei den andern Formen.
Und ferner ist — auch für ein nicht näher bekanntes Relativ x — die Äquivalenz der drei nachstehend einander gleichgesetzten Aussagen: 7)
(1' ɟ x̄; 1 = x) = (1' ɟ x̄ ɟ 0 = x) = {(1' ɟ x̄); 1 = x} als eine allgemein und denknotwendig bestehende behauptet.
Diese Äquivalenz wollen wir zuerst beweisen.
Die Gleichheit der ersten und zweiten, sowie die der zweiten und dritten Aussage als vor- und rückwärtige Subsumtion darzuthun würde vier Nachweise erheischen.
Von diesen können wir einen sparen.
Zeigen wir nämlich, dass aus der ersten Gleichung oder Aussage die zweite, aus dieser die dritte und aus der dritten wieder die erste folgt, so werden — entweder direkt oder mittelst Subsumtionsschlusses — aus jeder von den drei Gleichungen die beiden andern folgen und alle drei in der That äquivalent sein müssen.
Indem wir also die erste Gleichung zur Voraussetzung erheben, werden wir schliessen können:
Sei 1' ɟ x̄; 1 = x, so ist 0'; (x ɟ 0) = x̄, und folgt: 0'; (x ɟ 0); 1 = x̄; 1, da (x ɟ 0); 1 = x ɟ 0 ist, also: 0'; (x ɟ 0) = x̄; 1, was kontraponirt: 1' ɟ x̄; 1 = x ɟ 0, also x = x ɟ 0.
In die Hypothesis x̄ eingesetzt gibt: 1' ɟ 0'; (x ɟ 0); 1 = x, was sich wie vorhin vereinfacht zu: 1' ɟ 0'; (x ɟ 0) = x.
Aber nach der zweiten Gleichung ist: 1' ɟ x̄ ɟ 0 = 1' ɟ 0'; (x ɟ 0) ɟ 0, worein das vorige Ergebniss eingesetzt: 1' ɟ x̄ ɟ 0 = x ɟ 0, was wegen des ersten Ergebnisses wird: 1' ɟ x̄ ɟ 0 = x.
Somit ist also die zweite Gleichung aus der ersten abgeleitet.
Nun gelte blos diese, d. h. es
Sei 1' ɟ x̄ ɟ 0 = x, also 0'; x; 1 = x̄, so folgt: (1' ɟ x̄ ɟ 0); 1 = x; 1, 1' ɟ x̄ ɟ 0 = x; 1 — weil (a ɟ 0); 1 = a ɟ 0 ist, somit x; 1 = x, x̄ ɟ 0 = x̄, 1' ɟ x̄ ɟ 0 = 1' ɟ x̄, 1' ɟ x̄ = x, (1' ɟ x̄); 1 = x; 1, also (1' ɟ x̄); 1 = x, — womit die dritte Gleichung aus der zweiten abgeleitet ist.
Sei endlich: (1' ɟ x̄); 1 = x, also 0'; x ɟ 0 = x̄, so folgt: (0'; x ɟ 0); 1 = x̄; 1, 0'; x ɟ 0 = x̄; 1, x̄; 1 = x̄, 1' ɟ x̄; 1 = 1' ɟ x̄.
Aber laut Hyp. ist einerseits: 0'; (1' ɟ x̄); 1 ɟ 0 = x̄, also 0'; (1' ɟ x̄); 1 = x̄, andrerseits 0'; (1' ɟ x̄); 1 = 0'; x, somit 0'; x = x̄, 1' ɟ x̄ = x, mithin oben 1' ɟ x̄; 1 = x, — womit auch die erste Gleichung aus der dritten abgeleitet ist, q. e. d.
Zur Übung wolle der Leser die Sätze auch in der umgekehrten Ringfolge auseinander ableiten.
Nebenher sei hier konstatirt — was wir teilweise schon unterweges sahen — dass die Gesetze 2), 3) aller Modulknüpfungen von x = i auch aus unsrer Charakteristik 7) rein analytisch-rechnerisch folgen.
Und zwar die der ersten Zeilen x; 1 = x = x ɟ 0, x; 0' = x = x ɟ 1' schon nach dem Abacus bei Benutzung einer geeigneten (der zweiten oder dritten) von den drei als äquivalent nachgewiesnen Formen.
Um 1; x = 1 zu gewinnen verhilft die Überlegung:
1; x = 1; x; 1 = 1'; x; 1 + 0'; x; 1 = x; 1 + x̄ = x + x̄ = 1, weil 0'; x; 1 = x̄ nach einer von den drei Charakteristikformen.
Damit ist dann auch die Konsequenz 5) oder 1; x; 1 = 1 also x ≠ 0 gezogen.
Weiter ist sodann: 0 ɟ x = 0 ɟ 1' ɟ x̄ ɟ 0 = 0 ɟ x̄ ɟ 0 = 0, 0'; x = 0'; (x ɟ 0) = x̄, 1' ɟ x = 1' ɟ 1' ɟ x̄; 1 = 0 ɟ x̄; 1 = 0 ɟ x̄ = 0 gefunden.
Nunmehr braucht blos noch von einer der drei Gleichungen 7), z. B. von der ersten, gezeigt zu werden, dass, wie sie einerseits mittelst 2) und 3) als für x = i gültig aus 1) floss, sie andrerseits generell auch 1) bedingt, nämlich dass sie ausreicht, x zum Einzeiler zu stempeln, also dass das ihr genügende Relativ x notwendig ein solcher — irgend ein Einzeiler, mag man ihn i oder anders (j, h, …) nennen — sein muss. M. a. W. nachdem erkannt ist, dass der Gleichung 1' ɟ x̄; 1 = x jeder Einzeiler genügt, muss auch noch gezeigt werden, dass ihr nur Einzeiler genügen können.
Dies gelingt unschwer wie folgt.
Es ist xi j = Πh(1'i h + Σkx̄h k) augenscheinlich vom zweiten Suffixe j unabhängig, somit xi j = xi l für jedes l, und folgt wie oben unter 1), dass das Relativ x nur aus Voll- und Leerzeilen bestehen kann.
Hätte es nun keine Vollzeile, so müsste es lauter Leerzeilen haben und x = 0 sein.
Dieser Wert genügt aber der fraglichen Charakteristik nicht, verwandelt sie vielmehr in die absurde Gleichung 1 = 0. Folglich muss x mindestens eine Vollzeile haben.
Sei durch i solche markirt, mithin xi k = 1 für jedes k, so ist leicht zu zeigen, dass x keine zweite Vollzeile haben kann, vielmehr alle übrigen Zeilen von x ausser der iten dann Leerzeilen sein müssen.
Denn markirt l ≠ i irgend eine andre Zeile, so werden wir haben: xl j = Πh(1'l h + Σkx̄h k) — worin nur der dem Werte h = l entsprechende Faktor des Produktes Π wegen 1'l l = 1 ineffektiv ist, für jedes h ≠ l dagegen ein nicht zu vernachlässigender Faktor hervorspringt.
Ein solches h ≠ l ist aber (wegen i ≠ l) unfehlbar der Wert h = i. D. h. unser xl j repräsentirendes Produkt hat jedenfalls zum Faktor 1'l i + Σkx̄i k, welches = 0, weil 1'l i = 0 für l ≠ i und jedes x̄i k = 0 sein muss, als Negation des oben = 1 statuirten xi k. Mithin verschwindet auch das ganze Produkt und haben wir bei beliebigem j neben xi j = 1 auch xl j = 0 für jedes l ≠ i; d. h. x ist (= i) ein Einzeiler, wie behauptet worden.
Man kann den Satz auch durch die Formel darstellen: 8)
(1' ɟ x̄; 1 = x) = Σi(x = i), und wird er auch in dieser Fassung als rückwärtige Aussagensubsumtion durch das Frühere, als vorwärtige durch die Überlegung des letzten Kontextes für bewiesen zu erachten sein.
Selbstverständlich kann in jedem Falle nur ein Glied der Alternative rechterhand den Wahrheitswert 1 haben.
Will man x = i als einen Einzeiler, anstatt durch eine der etwas komplizirten Gleichungen 7), lieber durch zwei zusammenbestehende einfachere Gleichungen charakterisiren, so braucht man nur von den 2 + 4 = 6 folgenden eine links vom Striche zu nehmen und mit irgend einer rechts davon zu verbinden:
x; 1 = x 1' ɟ x̄ = x x ɟ 0 = x 0'; x = x̄ x̄; 1 = x̄ x̄ ɟ 0 = x̄.
Denn durch Einsetzung des Wertes von x oder x̄ aus der einen in die andre Gleichung ergibt sich allemal eine der Gleichungsformen 6) — x für i gesagt — und ferner sind die vorstehenden für x = i erfüllt.
Beispielsweise charakterisirt also auch die Doppelgleichung:
1' ɟ x̄ = = x = x; 1, ebenso die Gleichung x · 0'; x = 0 nebst der Subsumtion x; 1 + 1' ɟ x̄ ⋹ x, etc. das x als einen Einzeiler. —
Als von Interesse sei noch angeführt, dass auch unter den tertiären irreduziblen relativen Modulknüpfungen eines allgemeinen Relativs a sich eine findet, welche, sofern sie nicht 0 oder 1 wird, nur einen Einzeiler vorstellen kann.
Diese ist: 1' ɟ 0'; (a ɟ 0).
Es wird also die Gleichung 9) 1' ɟ 0'; (x ɟ 0) = x stipuliren, dass x entweder 0 oder 1 oder ein Einzeiler i sein müsse.
Dass sie in der That für diese drei Werte erfüllt wird, indem auch: 1' ɟ 0'; (i ɟ 0) = i, 0'; (1' ɟ ī; 1) = ī, ist leicht nachzusehen.
Für das Umgekehrte, dass jedes der Gleichung 9) genügende von 0 und 1 verschiedene x ein Einzeiler sein müsse, sich den Beweis zu konstruiren sei einstweilen dem Leser überlassen.
— Noch eine Bemerkung hiezu:
In § 14 hatten wir in Gestalt des Ausdrucks: f(u) = u · 1; ū; 1 + ū(0 ɟ ū ɟ 0) eine Funktion konstruirt, welche immer gleich u selbst ist, ausgenommen für u = 0 oder 1, wo sie diese beiden Werte vertauscht, sodass also f(0) = 1, f(1) = 0 und sonst immer f(u) = u ist.
Nimmt man u = 1' ɟ 0'; (x ɟ 0) und v = 1' ɟ x̄ ɟ 0 oder 1' ɟ x̄; 1 oder (1' ɟ x̄); 1, so wird die Gleichung f(u) = x nur noch für x = i erfüllt sein, aber nicht mehr für x = 0 oder 1, wofür sie vielmehr in 1 = 0 resp. 0 = 1 überginge.
Sie wird demnach ebenfalls x als Einzeiler charakterisiren.
Ferner wird für jeden Einzeiler x = i natürlich f(u) = v = u = f(v) sein müssen.
Eine Charakteristik des Einzeilers würde sich also auch mit Hülfe des genannten tertiären Relativs gewinnen lassen, falls dieses Ziel nicht schon einfacher durch die sekundären Relative erreicht worden wäre.
Mit der im Bd. 2 für den identischen Kalkul aufgestellten Individuumsdefinition werden wir die gegenwärtige Charakteristik des Einzeilers, als die Definition des „Elementes“ oder „Individuums im ersten Denkbereiche für die Algebra der Relative, weiter unten (§ 27) in Zusammenhang bringen.
In der grössern Einfachheit der letztern gegenüber jener dokumentirt sich indess schon ein Vorzug unsrer so viel weiteren Disziplin.
Nachdem die Modulknüpfungen des Einzeilers und seiner Verwandten erledigt sind, studiren wir jetzt die relativen Knüpfungen zwischen je zwei Relativen dieser Verwandtschaftsgruppe.
Dieses Studium wird überaus wichtige Aufschlüsse liefern.
Die 32 Knüpfungen zerfallen in drei oder auch vier Gruppen.
Die 16 der ersten Gruppe reduziren sich zu einem Relativ des Verwandtschaftsquadrupels selber gemäss den Schemata: 10) [Formel]
In Worten: Ein Einzeiler von einem Einzeiler ist immer der erste Einzeiler und ein Einkolonner von einem Einkolonner ist immer der letzte Einkolonner — statt eines Terms aber kann hiebei auch auch dessen Negation durchweg eintreten.
Den Beweis durch Herbeiführung der Koeffizientenevidenz zu leisten ist leicht.
Will man diese umgehen, so kann man auch schliessen: i; j = (i; 1); j = i; 1; j = i; 1 · 1; j = i · 1 = i — gemäss 2), und 5) des § 11.
Ganz ebenso ist i; j̄ = i, ī; j̄ = ī, ī; j = ī zu beweisen, woraus dann die übrigen Formeln der ersten Zeile von 10) durch die Kontraposition folgen, und aus dieser die zweite Zeile durch Konvertiren hervorgeht.
Bei den 8 Knüpfungen der zweiten Gruppe stellt sich das Ergebnis der relativen Knüpfung als einerlei heraus mit dem der gleichnamigen identischen Knüpfung: 11) 12) 13)
Beweis. i; j̆ = i; (1; j̆) = i; 1; j̆ = i; 1 · 1; j̆ = i · j̆, u. s. w.
Der Einzeiler von einem Einkolonner ist also der Schnitt beider, d. h. ist immer ein individuelles binäres Relativ, und zwar dasjenige, welches an der Schnittstelle der beiden Vollreihen in der Tafel 12 steht.
Hier sei auf eine Attrape aufmerksam gemacht.
Angesichts des vorstehenden Satzes wird der Anfänger auf die Frage, was nun der Einkolonner von einem Einzeiler sein werde?
leichtlich hereinfallen, meinend, dass dies sich analog verhalten werde.
Solches ist nun aber durchaus nicht der Fall und braucht es nicht zu sein, weil das Konverse von i; j̆ wieder von derselben Form, nämlich j; ĭ, keineswegs jedoch ĭ; j noch auch j̆; i sein wird — gleichwie überhaupt bei a; b̆ (sowie bei ă; b) die Konversion niemals aus dieser Form herausführen kann!
Die Antwort auf die aufgeworfne Frage wird vielmehr ganz anders ausfallen und durch den ersten der folgenden Sätze selbständig gegeben.
Die Formeln rechts vom Mittelstriche in 11) bis 13) müssten als dual den linkseitigen entsprechende eigentlich in der umgekehrten Reihenfolge, von unten nach oben, hingesetzt sein; doch glaubten wir durch die gewählte Stellung die Übersicht und das Behalten der Sätze zu erleichtern.
Die 8 noch übrigen Knüpfungen bilden eigentlich zusammen eine dritte Hauptgruppe, die sich aber in zwei Untergruppen gliedert.
Die dritte Gruppe umfasst sechs von den 8 Knüpfungen, nämlich diejenigen, welche lediglich der Werte 0 und 1 fähig sind, von denen sie den einen oder andern annehmen, je nachdem i gleich oder ungleich j ist, — Knüpfungen also, deren Ergebnisse als „ausgezeichnete Relative bezeichnet werden könnten.
Sie sind: 14) [Formel]
Endlich die vierte Gruppe enthält die beiden noch übrigen Knüpfungen, und diese sind absolut bestimmt, nämlich: 15)* wobei der Stern wie früher darauf hinweist, dass für die Geltung der Formeln die Voraussetzung wesentlich ist, dass der Denkbereich 11 mindestens drei Elemente enthalte.
ī̆; j̄ = 1 ĭ ɟ j = 0,
Hienach ist der Einkolonner von einem Einzeiler gleich 1 falls sich beider Vollreihen auf der Hauptdiagonale schneiden, dagegen gleich 0 in jedem andern Falle.
Umgekehrt, falls für den einen relativen Faktor dessen Negat eintritt.
Gleich 1 aber ist das Einkolonnernegat vom Einzeilernegate.
Die Relative in 14) verhalten sich wie die Aussagen i = j resp. i ≠ j, und können auch in die Formen gesetzt werden — die wir nur für die vorkommenden relativen Produkte angeben wollen: 14a) [Formel] und analog ist endlich: 15a)* wobei die Konvertirung noch weitre äquivalente Formen liefert, wie 14b) [Formel] 15b)*
ī̆; j̄ = 1; īj̄ = 1 0 ɟ (i + j) = 0,
ī̆j̄̆; 1 = 1 (ĭ + j̆) ɟ 0 = 0.
Während die beiden letzten Formeln wegen 1'i j = 1'j i oder (i = j) = = (ĭ = j̆) — wie schon (a = b) = (ă = b̆) — aus den vorhergehenden beiden folgen, bleiben von diesen die auf die relativen Produkte bezüglichen Angaben noch zu beweisen, aus denen die übrigen durch Kontraposition folgen.
Dies wäre aus der Koeffizientenevidenz zu leisten ein Leichtes, kann jedoch in allen vier Fällen — eleganter — auch mittelbar geleistet werden nach dem Vorbilde:
ĭ; j = (1; ĭ); j = 1; ĭ; j = 1; (i; 1)j = 1; ij, wobei von dem Satze 6) des § 18 — vergleiche auch 21) der Formelsammlung des übernächsten Paragraphen — Gebrauch gemacht wurde.
Nunmehr ist also blos noch die Äquivalenz der Relative mit den Aussagen zu erhärten.
Auf den ersten Blick ist klar, dass für j = i auch sein muss: 1; ij = 1; i = 1, 1; ij̄ = 1; iī = 1; 0 = 0 = 1; īj.
Und dass für j ≠ i umgekehrt: 1; ij = 0, 1; ij̄ = 1 = 1; īj sein muss, beruht auf dem Hülfssatze: 16) (i ≠ j) = (ij = 0) = (ij̄ = i) = (īj = j) = (i ⋹ j̄) = (j ⋹ ī) = = (ī + j̄ = 1) = (ī + j = ī) = (i + j̄ = j̄), dessen sämtliche Formen aus der ersten Äquivalenz schon durch identische Umformungen sich ergeben.
Zum Beweise jener haben wir vorwärts: (ij)h k = ih kjh k = 1'i h1'j h = 0, weil nach der Voraussetzung i ≠ j das h nicht mit i sowol als j zusammenfallen kann, folglich von den beiden 1'-Koeffizienten, deren Produkt in Betracht kommt, mindestens einer verschwindet.
Dass umgekehrt aus ij = 0 auch rückwärts i ≠ j folgt, ergibt sich indirekt, weil die gegenteilige Annahme zu dem Widerspruch i = 0 mit 5) führen würde. —
Nunmehr kann auch für 1; ij = 1 nur j = i sein, wie leicht apagogisch zu zeigen, weil für j ≠ i bewiesen erscheint, dass 1; ij = 1; 0 = 0 sein muss.
Endlich dass stets 1; īj̄ = 1 sein muss, folgt für j = i schon als 1; ī = 1 nach 2), überhaupt aber aus der Koeffizienteneviden wegen: (1; īj̄)h k = Σlīl kj̄l k = Σl0'i l0'j l = 1*, sobald der Denkbereich mindestens drei Elemente enthält, weil es dann auch ein von i und j verschiedenes l geben wird, für welches der zugehörige Summand der Σl gleich 1 ist.
Hiemit sind denn also sämtliche Formeln 14) und 15) bewiesen.
Zugleich sind mit 14, 15a & b) für eine Anzahl der identischen Knüpfungsergebnisse zwischen i, j und deren Verwandten die primären relativen Knüpfungen mit den absoluten Moduln ermittelt — wozu die übrigen, nebenbei gesagt, weiter unten ihre Erledigung finden.
Bisher haben wir i lediglich als den „Einzeiler“ in’s Auge gefasst, und von ihm und seinen Verwandten die relativen Knüpfungen studirt mit den Moduln sowol als mit ihres(jener)gleichen.
Nunmehr sind wir auch in der Lage diejenigen Sätze zu begründen, auf welchen es beruht, dass solch ein „Einzeiler“ in unsrer Theorie der binären Relative gedeutet werden kann als „Element“ i des ersten Denkbereiches, dass er jederzeit hingestellt werden darf als der Repräsentant dieses Elementes.
Um als zulässig zu erscheinen, muss solche Deutung des Einzeilers sich in allen Stücken als mit der „rhetorischen Evidenz“ (cf.
§ 4) vereinbar, im Einklange erweisen — wozu ein Mehreres gehört.
Zuvörderst müssen gleichwie die Elemente, so auch die Einzeiler sämtlich vom Nichts verschieden, verschiedene auch unter sich disjunkt sein.
Dies ist in der That für die Einzeiler bereits mit 5) und 16) erwiesen.
Weiter aber müssen die drei Möglichkeiten, über welche unsre Theorie Verfügung gewann, um auszudrücken, dass i ein a von j sei, sich für die Einzeiler i, j als äquivalent erweisen zu lassen.
Die drei Möglichkeiten rekapitulirt und ihre Äquivalenz statuirt der (fundamentale) Satz: 17) (ai j = 1), = ai j = (i ⋹ a; j) = (i : j ⋹ a).
Über die erste von diesen drei Gleichungen als eine ja schon durch den Aussagenkalkul gegebene brauchen wir kein Wort zu verlieren.
Die zweite beweist sich wie folgt.
Es ist: (i ⋹ a; j) = Πh k(ih k ⋹ Σlah ljl k) = Πh k(1'i h ⋹ Σlah l1'j l) = = Πh(1'i h ⋹ ah j) = (1'i i ⋹ ai j) = (1 ⋹ ai j) = ai j.
Dem Beweise der dritten Äquivalenz wollen wir einen wichtigen Satz voranschicken: 18) i : j = i; j̆ = ij̆.
Beweis.
Nach der fundamentalen Festsetzung 9) des § 3 ist: (i : j)h k = 1'i h1'j k und dies = ih kjk h = (ij̆)h k. Somit ist i : j = ij̆ bewiesen, und dass das identische Produkt von i und j̆ mit dem relativen i; j̆ übereinstimmt sahen wir bereits mit Satz 11) ein.
Nach diesem merkwürdigen Satze lässt sich das individuelle binäre Relativ i : j auch mittelst der 6 Spezies unsrer Theorie durch i und j ausdrücken; es wird der Doppelpunkt als apartes Knüpfungszeichen — nachträglich — entbehrlich, nämlich in der That entbehrlich gemacht schon durch die beiden Spezies: der Konversion und der sei es relativen, sei es identischen Multiplikation.
Um 18) zu einem Gespann zu ergänzen, müsste noch hinter einem Mittelstriche angefügt werden: i̅ :̅ j̅ = ī ɟ j̄̆ = ī + j̄̆.
Als Beweis der letzten Äquivalenz 17) haben wir nun ähnlich: (i : j ⋹ a) = Πh k(1'i h1'k j ⋹ ah k) = (1'i i1'j j ⋹ ai j) = (1 ⋹ ai j) = ai j, indem wieder diejenigen Faktorenaussagen des Πh k, welche sich bei h ≠ i oder k ≠ j ergeben, als auf (0 ⋹ ah k), = 1 hinauslaufende unterdrückt werden durften — q. e. d.
Ferner wird nun die rhetorische Evidenz gebieterisch erheischen, dass auch folgender Satz für die Einzeiler i und j erweisbar sei: 19) (i ⋹ a; j) = (j ⋹ ă; i).
Sooft nämlich i ein Liebender (a, = amans) ist von j, muss j ein Geliebter (ă, = amatus, -a, -um) sein von i, und umgekehrt.
Beweis.
Denn die behauptete Gleichung kommt nach dem Satze 17) auf die laut fundamentaler Festsetzung geltende Identität hinaus: ai j = ăj i.
Bei diesen Nachweisen hinsichtlich des Einklangs unsrer Theorie mit der rhetorischen Evidenz in der (ohnehin nirgends systematisch nennenswert entwickelten) verbalen Logik relativer Begriffe wollen wir uns vorläufig beruhigen, und an dieser Stelle nicht die Frage zum Austrag bringen, ob die bereits gegebnen Nachweise auch schon genügen, jene Übereinstimmung als eine durchgängig bestehende zu begründen oder wenigstens die Interpretation des „Einzeilers“ als eines Elements“ des ersten Denkbereichs vollends zu rechtfertigen, die fundamentale Festsetzung 8) des § 3 aus den Bedürfnissen der Logik selbst zu motiviren.
Wir werden fortan, wie früher schon, die beiden Namen „Einzeiler“ und „Element“ als synonyme gebrauchen.
Wir haben noch zu viel zu thun mit der Durchführung von Untersuchungen und der Beantwortung von Fragen, die sich als solche der reinen Algebra (der Relative) an unsre letzten Betrachtungen knüpfen.
Das Theorem 19), welches, zu einem Gespann ergänzt, lautet: 19) [Formel] hebt einen Sonderfall des zweiten Inversionstheorems hervor, in dem es — ausnahmsweise — möglich ist, einen relativen Faktor auch aus dem Prädikate einer Subsumtion zu isoliren, so, wie es uns das erste Inversionstheorem aus dem Subjekte stets gestattet.
Dieser Fall liegt hinsichtlich des zweiten relativen Faktors sicher vor, wenn derselbe sowie auch das Subjekt der Subsumtion ein Element ist; beim ersten relativen Faktor liegt er vor, wenn dieser sowie das Subjekt ein Elementkonvers ist.
Die Frage, inwiefern diese Wahrnehmung sich verallgemeinern lässt, ist eine wichtige und wird uns nochmals beschäftigen.
Bei der ofterwähnten Vielförmigkeit unsrer Disziplin erscheint es fast unthunlich, die Sätze jeweils in allen ihren gleichberechtigten, äquivalenten und gleich einfachen Formen aufzuführen.
Und doch kann gelegentlich irgend eine dieser Formen belangreich werden!
So sind — wenn wir es diesmal noch versuchen — im Hinblick auf den mit unter 22) gegebenen Satz a; i = a ɟ ī, den man (mit seinen Verwandten) eben auswendig behalten muss(!) — auch folgendes noch die mit ihm gleichberechtigten Formen unsres Satzes 19): 20) .
Zu 17) die verwandten Formen aufzustellen überlassen wir dem Leser. —
Um in unsrer Theorie keine Lücke zu lassen, müssen wir auch die den Sätzen 6) und 7) des § 2 zugrunde liegenden Behauptungen irgendwo beweisen.
Dies ist an gegenwärtiger Stelle ein Leichtes.
Um jenen Satz 7)
i : j ≠ 0 zu beweisen, hat man blos nachzusehn, dass 1; (i : j); 1 = 1; i; j̆; 1 = 1; 1 = 1 ist.
Und um — was jenem Satze 6) zugrunde liegt — die Verschiedenheit von i : j und j : i bei der Annahme i ≠ j darzuthun, braucht man blos zu zeigen, dass ij̆ und ĭj in wenigstens einem Koeffizienten nicht übereinstimmen.
Nun ist der allgemeine Koeffizient des einen (ij̆)h k = ih kjk h = 1'i h1'j k gleich 1 für h = i und k = j, gleich 0 aber in jedem andern Falle; der des andern ist (ĭj)h k = ik hjh k = 1'i k1'j h gleich 1 für h = j und k = i, andernfalles gleich 0.
Also gibt es zwei Suffixe (ij und ji), wo die beiden Koeffizienten verschieden, der eine nämlich 1 und der andre 0 ist, q. e. d.
Die Formeln und Sätze über die relativen Knüpfungen zwischen einem Einzeiler i oder einem Einkolonner ĭ oder deren Negaten und einem allgemeinen Relativ a brauchen nicht besonders aufgestellt und begründet zu werden, weil sie sich sogleich als spezielle Fälle ergeben aus den allgemeineren Formeln für die Knüpfung eines Systems überhaupt, oder von dessen Verwandten, mit solchem allgemeinen Relative, wie sie im nächsten Paragraphen abgehandelt werden — cf. 42 & 43) des § 22.
Zur Bequemlichkeit des Studirenden stellen wir sie indessen vorweg hier zusammen.
Sie lauten: 21) [Formel] 22) [Formel] 23) [Formel]
Ihre Rechtfertigung durch die Koeffizientenevidenz bildet übrigens nur eine leichte Übung.
Für die letzten Knüpfungen 23) gibt es zudem auch die komplizirtern Darstellungen: 24) [Formel] deren Beweis ebenfalls als Übung empfohlen sei.
Zum Beweise der ersten Formel jedes der Gespanne 21) bis 23) bedarf es übrigens des Rekurses auf die Koeffizientenevidenz nicht; vielmehr genügt dazu, wegen i = i; 1, ī = ī; 1, der Hinweis auf das Theorem 5) des § 11, = 16) des § 27, sowie (für b = ĭ oder ī̆) auf das 6) des § 18, = 21) des § 27. Darnach wird nur noch die Formel unter 22) a; i = a ɟ ī unmittelbar zu beweisen bleiben, und beruht deren Koeffizientenevidenz (a; i)h k = (a ɟ i)h k auf dem Satze 12) des § 8, wonach: Σlah l1'i l = ah i = Πl(ah l + 0'i l) in der That sein muss; q. e. d.
Hiezu scheint behufs Aussöhnung der „rhetorischen Evidenz“ wenigstens eine Bemerkung nötig.
Dass wie in 22) angegeben: a; i = a ɟ ī, erscheint ohne weitres vor- und rückwärts einleuchtend.
Stellt nämlich i eine bestimmte Person vor, so ist ein Liebender von i gewiss auch ein Liebender von allen ausser den nicht-i, und umgekehrt.
Man könnte nun wähnen, es müsse auch geradeso a; ī = a ɟ i sein; bei genauerem Zusehen stellt sich dies jedoch als ein Irrtum heraus.
Es gilt blos der Satz: 25) [Formel] d. h. ein Liebender von allen ausser i ist gewiss auch ein Liebender von nicht-i’s.
Dagegen braucht das Umgekehrte keineswegs zuzutreffen: ein Liebender von nicht-i’s braucht nur einige aber nicht alle Personen ausser i zu lieben.
Koeffizientenvergleichung für das Suffix hk lehrt auch in der That, dass nur mit ⋹ aber nicht mit = zu gelten braucht: Πl(ah l + 1'i l) ⋹ Σlah l0'i l, d. h. ah Aah B … (ohne ah i) ⋹ ah A + ah B + … (ohne ah i).
Zu den Konsequenzen der Formeln 21) bis 23) — die vielleicht noch lange nicht erschöpfend gezogen sind — gehört unter anderm das bemerkenswerte Sätzegespann: 26) [Formel] dessen ersten man auch ohne Zuhülfenahme der Koeffizientenevidenz mit (a ɟ ī)(b ɟ ī) = ab ɟ ī gemäss 22) und 4) des § 6 beweisen kann.
Stellte i nicht ein Element, sondern irgend ein andres Relativ vor, so würde sich blos die Einordnung ab; i ⋹ a; i · b; i behaupten lassen.
Natürlich kann man den Satz 26) auch von zweien auf beliebig und unbegrenzt viele identische Faktoren (resp. Terme) ausdehnen, und muss — falls die Zeichen Π, Σ sich auf ein allgemeines oder irgendwie variables Relativ a beziehen — auch gelten: Πa; i = (Πa); i, Πĭ; a = ĭ; Πa, Σ(a ɟ ī) = Σa ɟ ī, Σ(ī̆ ɟ a) = ī̆ ɟ Σa.
Ebenso ist beachtenswert, dass der Satz gelten muss: 27) [Formel] — während, wenn i ein beliebiges Relativ vorstellte, sich blos (a ɟ b); i ⋹ a ɟ b; i behaupten lassen würde.
Dies zu berücksichtigen ist besonders behufs Ausführung von Summationen und Produktermittelungen wichtig.
Der Beweis ergibt sich nach 22) aufgrund der Assoziativität der relativen Addition mit: a ɟ b; i = a ɟ (b ɟ ī) = (a ɟ b) ɟ ī = (a ɟ b); i.
Keineswegs dagegen dürfte auch a; (b ɟ i) gleich a; b ɟ i gesetzt werden — eine Verwechselung, vor der man sich hüten muss.
Vielmehr ist, wie wir in § 29 sehen werden, das erstre = a; (b ɟ 1'); i, das letztere = (a; b ɟ 1'); i — davon verschieden.
Nach 23) muss das Relativ a ɟ i aus lauter Voll- und Leerzeilen, nämlich aus jenen von ĭ + a bestehen.
Zu denselben müssen erstens die Vollzeilen von a selbst, das ist a ɟ 0, gehören, zweitens aber müssen dazu Vollzeilen beisteuern: diejenigen Einlückzeilen von a, deren Lücke gerade auf die Kolonne ĭ zu liegen kommt, mithin durch das in sie hineinfallende Auge von ĭ zur Vollzeile ergänzt wird.
Bringt man dies in Formeln, so kann man sich von der geometrischen Evidenz ausgehend (auf einigen Umwegen) zur Entdeckung des folgenden Gespanns von Sätzen führen lassen: 28) [Formel] deren erste Zeile man auch zu der Skala ergänzen könnte: a ɟ 0 ⋹ a ɟ i ⋹ (a ɟ 1'); 1 ⋹ a; 0' ɟ 0 ⋹ a; ī ⋹ a; 1 etc.
Statt obigen Entdeckungsweg genauer darzulegen, ziehe ich vor, die erste Formel 28) hier einfach durch die Koeffizientenevidenz zu beweisen:
Es ist Lh k = (a; 0' ɟ 0)h k = ΠmΣlah l0'l m und Rh k = (a; ī)h k = Σlah līl k = Σlah l0'i l, welch letzteres in Lh k bei m = i als Faktor auftritt, sodass Lh k ⋹ Rh k, q. e. d.
Gelegentlich von Nutzen ist auch noch das folgende Doppelgespann von Sätzen: 29) [Formel] deren erster auch als a; i · ĭ ⋹ a, (etc.) hätte gebucht werden können.
Der Beweis desselben mittelst der Koeffizientenevidenz, wobei Lh k = Σlah lil k · ik h = 1'i kΣlah l1'i l = 1'i kah i, beruht auf der bemerkenswerten Gleichung:
1'i kah i = 1'i kah k(= Rh k), welche für k ≠ i in 0 = 0, für k = i in ah i = ah k übergeht.
Die nächste Gleichung des linkseitigen Quadrupels folgt dann gemäss 22), etc. und die erste Gleichung des rechtseitigen Quadrupels mittelst identischer Rechnung als a; i · ĭ + ī̆ = aĭ + ī̆, etc.
Ein gleiches gilt von den beiden Sätzegespannen: 30) [Formel] 31) .
Behufs Beweises des ersten haben wir Lh k = Σlah līl k · ik h = 1'i kΣlah l0'i l und Rh k = 1'i kΣlah l0'l k, mithin Lh k = Rh k; denn für k ≠ i kommt diese Gleichung auf 0 = 0, für k = i aber auf die Identität Σlah l0'i l = Σlah l0'l i hinaus, q. e. d. —
Der erste Satz 31) des zweiten Gespannes beweist sich schon ohne Zuhülfenahme der Koeffizientenevidenz vor- oder rückwärts so: 0'a; i = 0'a ɟ ī = (0' ɟ ī)(a ɟ ī) = (a ɟ ī)ī = a; i · ī, mit derselben so: (a; i · ī)h k = Σlah lil kīh k = Σlah l1'i l0'i h = ah i0'h i = = Σl(0'a)h l1'i l = Σl(0'a)h lil k = (0'a; i)h k.
Man bemerkt schon im Hinblick auf die vorige (mittelbare) Herleitung, dass dieser Satz 31), als zu nahe liegend, kaum noch registrirt zu werden verdiente.
Und so wollen wir auch inbezug auf eine Reihe noch anführbarer ähnlicher Sätze — wie a; i · i = 1'a; i, was mit a; i · 1'; i nach 26) folgt, etc. — hier nicht nach Vollständigkeit streben.
Hierher gehören auch noch die ganz leicht erweislichen Sätzchen: oder und andre mehr.
aī̆⋹a; ī a ɟ i ⋹ a + ĭ īa⋹ī̆; a ĭ ɟ a ⋹ i + a
a⋹a; ī + ĭ (a ɟ i)ī̆ ⋹ a a⋹i + ī̆; a ī(ĭ ɟ a) ⋹ a
Von sehr häufiger Anwendung werden endlich auch diese beiden Gruppen von Sätzen sein: 32) [Formel] 33)
[Formel]
Hievon verstehen sich die Gleichsetzungen der ersten Zeile in beiden Chiffren wegen ĭ = 1; ĭ, i = i; 1 etc. zwar aus einem allgemeineren Satze, welchen wir unter 9) im § 27 der Theorie einfügen werden; da man behufs Übergangs zur zweiten Zeile doch ohnehin an die Koeffizientenevidenz appelliren muss, mögen sie hiernächst durch diese sogleich mit gerechtfertigt werden.
Man hat zu 32) linkerhand:
Lh k = Σlil hah lil kbl k = Σlah l1'i lbl k = ah ibi k und Rh k = Σlah lil k · Σmim hbm k = Σlah l1'i l · Σm1'i mbm k = ah ibi k, q. e. d.
Zu 33) jedoch:
Lh k = Σlīl hah līl kbl k = Σlah l0'i lbl k, was nur ⋹ ist dem Rh k = Σlah līl k · Σmīm hbm k = Σlah l0'i lΣm0'i mbm k.
Wenn ein i oder ī als identischer Faktor beim Vorfaktor eines relativen Produktes auftritt, desgleichen wenn ein ĭ oder ī̆ in einen relativen Nachfaktor multiplizirt erscheint, so kann man jedes nach 5) des § 18, = 7) des § 27, bekanntlich als identischen Faktor absondern, indem ai; b = i · a; b, a; ĭb = a; b · ĭ, aī; b = ī · a; b, a; ī̆b = a; b · ī̆ sein muss; und ähnlich ist, für diese Elementverwandten als identische Summanden in den Termen einer relativen Summe, zu konstatiren dass: (a + i) ɟ b = i + a ɟ b, a ɟ (ĭ + b) = a ɟ b + ĭ, (a + ī) ɟ b = ī + a ɟ b, a ɟ (ī̆ + b) = a ɟ b + ī̆.
Wenn dagegen umgekehrt ein i oder ī als gleichnamiger identischer Term beim zweiten Operationsgliede, desgleichen wenn ein ĭ oder ī̆ beim ersten Operationsgliede eines relativen Knüpfungsergebnisses auftritt, so konvenirt es nicht selten, dieselben konvertirt zum andern Operationsgliede zu schlagen, und verbürgen uns die Formeln 32) und 33) mit ihrer ersten Zeile die Berechtigung zu diesem Verfahren.
Und der Satz 32) lehrt noch ausserdem (mit seiner folgenden Zeile), dass man solchen Ausdruck a; ib resp. (a + ĭ) ɟ b, etc. in ein identisches Knüpfungsergebniss äquivalent aufzubrechen vermag, was bei den Ausdrücken a; īb, etc. in 33) nicht der Fall ist.
Hieraus werden wir — in § 29 — noch wichtige Folgerungen ziehen.
Als eine eminent wichtige Konsequenz unsrer Studien über das „Element“ (als binäres Relativ) und seine Knüpfungen stellen wir schliesslich eine Gruppe von Sätzen zusammen, die man als die
Sätze über den Wechsel (die Vertauschung, Abänderung) der Suffixe bezeichnen könnte.
Gehörte zu diesen in erster Linie der Satz aj i = ăi j, der sich schon unter den fundamentalen Festsetzungen vorfindet, und konnte demselben aus Anlass gelegentlicher Sätze 24, 25) des § 22 das Sätzepaar: 34) ai i = (1'a; 1)i j, aj j = (1; a1')i j als ein aus der Koeffizientenevidenz leicht zu rechtfertigendes vielleicht schon früher angereiht werden, so tritt nunmehr auch noch das Sätzepaar hinzu: 35) ai k = (ĭ; a)h k, ah j = (a; j)h k und als der umfassendste Satz der ganzen Gruppe: 36) ai j = (ĭ; a; j)h k.
Beweis des letztern: (ĭ; a; j)h k = Σl mil hal mjm k = Σl m1'i lal m1'j m = ai j, q. e. d.
Und ähnlich für die vorhergehenden Sätze.
Der zahlreichen Varianten ihrer Ausdrucksform, deren die Sätze, wegen 1'a; 1 = (0' + a) ɟ 0, und a; j = a ɟ j̄, etc. noch fähig sind, sei nur ganz beiläufig hiermit Erwähnung gethan.
Der letzte Satz setzt uns nun bei jedem Relativkoeffizienten in den Stand, irgend ein gegebenes Suffix ij in irgend ein gewünschtes hk zu verwandeln.
Aber noch mehr als das.
Weil nämlich das Relativ ĭ; a; j = 1; ĭ; a; j; 1 „ein ausgezeichnetes“ und als solches lediglich der Werte 0 und 1 fähig ist, so wird es seinem allgemeinen Koeffizienten (zu beliebigem Suffixe hk) gleich sein, und kann man auch schreiben: 37) ai j = ĭ; a; j, d. h. jeder Relativkoeffizient lässt sich selber als ein binäres Relativ ansehen und darstellen.
Speziell wird — vergl. 3), 4): 38) [Formel]
Im vorgeschrittensten der Peirce’schen Bezeichnungssysteme, als welches ich dasjenige in 9c hinstellen muss, würde die Gleichung 37) nur für den Fall ai j = 0 zutreffen, im andern Falle dagegen als linke Seite 1, als rechte ∞ auftreten.
Es würde unsre Theorie dadurch zwecklos einer Einfachheit, Symmetrie und Schönheit beraubt, und scheint mir dies der unabweislichste von allen Gründen, welche mich bestimmten, die Peirce’sche ∞ zu verwerfen und für sie der Boole’schen 1 den Vorzug zu geben.
Mit dieser Modifikation, die doch wol nicht so unwesentlich sein dürfte, sowie mit der Einführung der Zeichen 1', 0', des; und der Gestaltung des ɟ Zeichens, wage ich zu hoffen, „die letzte Hand“, den coup d’épingle oder finishing touch an die Vervollkommnung des fundamentalen Bezeichnungssystems der relativen Logik haben legen zu dürfen — das von den rudimentären „spiculae“ De Morgan’s an einen so weiten und schweren Weg bis hier zurückzulegen hatte!
Wird hiermit zusammengehalten, dass nach unserm Satze 18) auch der Doppelpunkt entbehrlich geworden, die Elementepaare i; j nämlich auch als identische sowol wie relative Produkte von i und j̆ darstellbar nachgewiesen sind, so erhellt, dass in unsrer Disziplin wesentlich keine andern Symbole und Operationen als wie: binäre Relative und die sechs Spezies (inclusive Π- und Σ-bildung) vorkommen.
Die Disziplin würde sich rein als eine solche darstellen lassen, die sich blos auf diesem Gebiete und in diesem Operationskreise bewegt.
§ 26.
Das Einauge, dessen Charakteristik und Knüpfungen.
Das „Elementepaar“ oder „individuelle binäre Relativ“ i; j entspricht dem „Punkt“ in der Geometrie der Ebene und könnte auch schlechtweg als ein solcher, als „Individuum des zweiten Denkbereichs“ bezeichnet werden.
Die Matrix dieses Relativs besitzt nämlich stets und nur ein Auge, und zwar an der Schnittstelle der iten Zeile mit der jten Kolonne — oder, wie wir jetzt auch sagen dürfen: mit der „Kolonne j̆“.
Darum nennen wir solches Relativ auch ein „Einauge“.
Es möge i; j vorerst z heissen.
Wir wollen uns nunmehr mit der Charakteristik und den fundamentalen Eigenschaften des Einauges beschäftigen.
Die Charakteristik des binären individuellen Relativs, Elementepaars, Punktes oder Einauges muss sich ergeben, indem man aus den drei Gleichungen: 1)
[Formel] die beiden Symbole i und j (welches, wenn man will, nur als j̆ vorkommt) regelrecht eliminirt.
Leider aber haben wir dafür noch keine bequeme Regel von allgemeiner Anwendbarkeit.
Für i etwa x und y für j̆ sagend mag man auch schreiben: 2) z = xy, 1' ɟ x̄; 1 = x, 1; ȳ ɟ 1' = y, woraus x und y zu eliminiren.
Ich gewinne die gesuchte Resultante, indem ich aus diesen drei Gleichungen durch besondre Kunstgriffe eine Reihe von Schlüssen — z betreffend — ziehe, hernach zeige, dass die Vereinigung dieser Konklusionen oder partiellen Resultanten die volle Resultante ausmacht.
Zur Aufstellung partieller Resultanten, für die dann nur noch die rechnerische Begründung beizubringen ist, wird man leicht heuristisch durch die geometrische Evidenz geführt.
Zur Resultante gehört jedenfalls, dass z; 1 · 1; z oder z; 1; z = z ist, und ferner dass z ⋹ (z̄ ɟ 1')(1' ɟ z̄) sein muss — letztres, weil das Einauge als eine „nie mehrdeutige Abbildung“ (cf. § 30), und zugleich als das konverse einer solchen auch, erscheint.
Endlich muss z ≠ 0 sein.
Jenes zunächst lässt sich so ableiten:
Aus der zweiten und dritten Prämisse dürfen wir die früher gezognen Folgerungen benutzen: x; 1 = x, 1; y = y.
Nun ist: z; 1 = xy; 1 ⋹ x; 1 · y; 1 = y; 1 · x 1; z = 1; xy ⋹ 1; x · 1; y = y · 1; x, woraus: z; 1 · 1; z ⋹ y; 1 · xy · 1; x = xy = z, also z; 1; z ⋹ z folgt, und da die umgekehrte Subsumtion als allgemeine Formel gilt — vergl. 5) des § 11 und 8) des § 15, so muss in der That gelten: 3) z; 1; z = z als „eine“ (und zwar eine partielle) Resultante.
Um eine (die im Kontext genannte) zweite zu gewinnen, bemerken wir, dass nach bekanntem Satze 5) des § 6 allgemein gilt: x̄ ɟ 1' + ȳ ɟ 1' ⋹ (x̄ + ȳ) ɟ 1', 1' ɟ x̄ + 1' ɟ ȳ ⋹ 1' ɟ (x̄ + ȳ).
Aber für x, y hatten wir einzeln schon die Konklusionen gewonnen — vergl. 3), 4) des § 25: x̄ ɟ 1' = x̄, ȳ ɟ 1' = y, 1' ɟ x̄ = x, 1' ɟ ȳ = ȳ und zudem ist: x̄ + ȳ = z̄, also: x̄ + y ⋹ z̄ ɟ 1', x + ȳ ⋹ 1' ɟ z̄, woraus durch überschiebendes Multipliziren:
xy + x̄ȳ ⋹ (z̄ ɟ 1')(1' ɟ z̄) oder z + x̄ȳ ⋹ (z̄ ɟ 1')(1' ɟ z̄), mithin a fortiori folgt: 4) z⋹ (z̄ ɟ 1')(1' ɟ z̄), was die zweite partielle Resultante ist.
Die bisherigen beiden sind auch für z = 0 erfüllt und können darum vereinigt noch nicht die volle Resultante geben, vielmehr wird als dritte partielle Resultante noch die Bedingung 5) z ≠ 0 oder 1; z; 1 = 1 oder 0 ɟ z̄ ɟ 0 = 0 hinzuzutreten haben, welche aus den Prämissen 2) rechnerisch auch wie folgt sich ableiten lässt.
Wegen y = 1; y ist 1; z = 1; xy = 1; x(1; y) = 1; x · 1; y nach 5) des § 18, somit 1; z = y · 1; x und 1; z; 1 = y(1; x); 1 = y; x̆; 1 nach 6) des § 18.
Aber gemäss 3), 4) des § 25 sind aus den beiden letzten Prämissen auch schon die Konklusionen verfügbar: x̆; 1 = 1 und y; 1 = 1, womit denn in der That 1; z; 1 = 1 gewonnen ist.
Bedeutend einfacher wird freilich der Beweis dieser dritten Resultante, falls man die erste Prämisse in der Gestalt z = x; y zugrunde legt.
Hier folgt — wie auf S. 417 — sogleich: 1; z; 1 = 1; x; y; 1 = 1; 1 = 1 wegen 1; x = 1 = y; 1. Und auch die beiden andern Einzelresultanten beweisen sich unschwer so: z; 1; z = z; 1; 1; z = x; y; 1; 1; x; y = x; 1; 1; y = x; y = z, wegen y; 1 = 1 = 1; x und x; 1 = x, 1; y = y.
Endlich: (z̄ ɟ 1')(1' ɟ z̄) = (x̄ ɟ ȳ ɟ 1')(1' ɟ x̄ ɟ ȳ) = (x̄ ɟ y)(x ɟ ȳ) = (x̄; 1 ɟ 1; ȳ)(x; 1 ɟ 1; ȳ) = = (x̄; 1 + 1; y)(x; 1 + 1; ȳ) = (x̄ + y)(x + ȳ) = xy + x̄ȳ = x; 1 · 1; y + x̄; 1 · 1; ȳ = = x; 1; y + x̄; 1; ȳ = x; 1; 1; y + x̄; 1; 1; ȳ = x; y + x̄; ȳ = z + x̄; ȳ, womit die Einordnung von z unter die linke Seite bewiesen ist.
Es kamen hierbei ausser vorerwähnten nur die Gleichungen x̄; 1 = x̄, 1; ȳ = ȳ aus 3), 4) des § 25 und das Theorem 24) des § 20 in Anwendung.
Die Herleitung der drei Einzelresultanten bei Zugrundelegung andrer Formen der Charakteristik von i resp. x bietet hübsche Übungsaufgaben für Anfänger.
Die vereinigte Gleichung der drei gefundnen Einzelresultanten ist: 6) z̄ · z; 1; z + z(z; 0' + 0'; z) + 0 ɟ z̄ ɟ 0 = 0.
Dass diese aber in der That die volle Resultante ist, lässt sich wie folgt beweisen.
Wegen des mittleren Terms ist das Relativ z = (z̄ ɟ 1')z(1' ɟ z̄) jedenfalls eine „auch umgekehrt niemals mehrdeutige Abbildung“, d. h. die Augen seiner Matrix sind lauter Kreuzreiter — vergleiche etwa § 30 — oder, um uns hier lediglich auf die bekannten Parallelreihensätze zu berufen: wegen z ⋹ z̄ ɟ 1' und z ⋹ 1' ɟ z̄ hat z höchstens einbesetzte Zeilen sowol als Kolonnen (neben etwaigen Leerreihen).
Wegen des dritten Terms ist z ≠ 0 und enthält mindestens ein Auge; das einäugige z erfüllt die Forderung 6).
Sobald aber z mehr als einen Kreuzreiter zu Augen hat, verschwindet der erste Term nicht mehr, indem z; 1; z alsdann von z notwendig verschieden wird, nämlich mehr Augen als dieses enthält.
Irgend zwei (als Kreuzreiter) etwa vorhandene Augen des z steuern nämlich zu dem Relative z; 1; z = z; 1 · 1; z auch die beiden Augen bei, welche die beiden andern Ecken des von jenen beiden bestimmten Reihenrechtecks (oder der zugehörigen Gittermasche) sind und die wir in beistehender Figur durch hohle Ringe markirt haben.
Diese konnten jedenfalls dem z nicht angehören, weil dasselbe sonst mehrbesetzte Reihen hätte.
Es greift dann also in der That z; 1; z über z hinaus.
Somit kann ein Relativ z, welches die Forderung 6) erfüllt, auch nicht mehr als ein Auge haben; es muss Einauge sein, q. e. d. [Der vorstehenden Überlegung würde sich auch leicht eine mehr analytische, rechnerisch zuwerkegehende Fassung geben lassen.]
Es ist also 6) die gesuchte Charakteristik des Einauges.
Dieselbe lässt sich noch auf elegantere Formen bringen.
Nach 5) des § 11 und 14) des § 15 kann umgeformt werden: z̄ · z; 1; z = z̄ · z; 1 · 1; z = z; 1 · z̄ · z̄ · 1; z = z; 0' · z̄ · z̄ · 0'; z = z; 0' · z̄ · 0'; z. Setzt man dies ein, so kann ferner nach dem Schema: abz̄ + (a + b)z = ab + (a + b)z der Faktor z̄ im ersten Term auch unterdrückt werden und entsteht: 7) z; 0' · 0'; z + z(z; 0' + 0'; z) + 0 ɟ z̄ ɟ 0 = 0.
Fig. 24.
Die beiden ersten Terme sind aber einerlei mit z; 0' · (z + 0'; z) + (z; 0' + z) · 0'; z und reduzirt sich dies nach 13) des § 15 so, dass wir erhalten: 8) 0 ɟ z̄ ɟ 0 + z; 1 · 0'; z + z; 0' · 1; z = 0, was mit Aufwand von nur zwölf Termen unsre Charakteristik darstellt; dieselbe kann hienach aber auch mit nur zehn Termen gegeben werden in einer der beiden Formen: 9)
[Formel]
Immer noch ist dies aber nicht die einfachste Gestalt unsrer Resultante oder Charakteristik des Einauges.
Dieselbe kann vielmehr auch mit Aufwand von nur sieben Termen gegeben werden in — gleichviel welcher der vier Formen: 10) 0'; z; 0' = (z̄ ɟ 0)(0 ɟ z̄), 1' ɟ z̄ ɟ 1' = z; 1 + 1; z, 11) 0'; z; 0' = (z̄ ɟ 0); (0 ɟ z̄), 1' ɟ z̄ ɟ 1' = z; 1 ɟ 1; z, deren Äquivalenz unter sich durch Kontraposition und aus 24) des § 20 erhellt.
Zu diesen werden wir nachher beim Studium der Modulknüpfungen von z heuristisch gelangen und dort auch ihre Äquivalenz mit 6) bis 9) analytisch beweisen.
Die vier Formen 10), 11) können wesentlich als eine Ausdrucksform unsrer Charakteristik bezeichnet werden.
Wir haben nun inbezug auf das Elementepaar oder individuelle binäre Relativ eine Reihe von Fragen zu erledigen, als da sind:
die Frage nach den Verwandten desselben,
die Frage nach seinen und deren relativen Modulknüpfungen (sintemal die identischen jederzeit sich ohne weiteres durchschauen lassen), sodann die Frage nach den identischen und relativen Knüpfungen zwischen Elementepaaren oder ihren Verwandten, weiter die Frage nach den Knüpfungen zwischen letztern und Elementen oder deren Verwandten, endlich die Frage nach den Knüpfungen jener (d. i. des Elementepaares nebst Verwandten) mit einem allgemeinen Relative.
Verwandte von i : j sind (nächst i : j selbst, was wir immer einbegreifen): 12) i : j͝ = j : i.
Beweis. i : j͝ = ij̆͝ = jĭ = j : i.
Das Konverse eines Elementepaars ist also so, wie es vorgreifend schon in § 1 erklärt worden, immer wieder ein Elementepaar, und zwar das ihm symmetrisch zur Hauptdiagonale gegenüber stehende, in das es übergeht durch Vertauschung der Zeilen mit den Kolonnen.
Es fällt mit ihm selbst zusammen lediglich dann, wenn j = i ist, d. h. falls i : j = i : i zu den Selbstrelativen gehörte.
Aufgrund obiger Bemerkung braucht beim Studium der Knüpfungen, die Relative der Verwandtengruppe von i : j mit irgend welchen Relativen eingehen, nur i : j selbst und sein Negat berücksichtigt zu werden, von seinem Konversen und Strichkonversen kann abgesehen werden, was die Arbeit auf die Hälfte reduzirt.
Die übrigen Verwandten sind: 13) i : j͞ = ī + j̄̆, i : j͞͝ = ī̆ + j̄ = j : i͞.
Ein solches Relativ nennen wir einen „Einleersteller“ oder „Einlücker“ demselben fehlt blos ein Auge, um zum „Allauge“ oder Modul 1 zu werden.
Zum Studium der Modulknüpfungen wollen wir für i : j wieder den Namen z gebrauchen, sodass uns hiernächst: 14) z = i : j = i; j̆ = ij̆, z̄ = i : j͞ = ī ɟ j̄̆ = ī + j̄̆ bedeutet.
Die primären relativen Modulknüpfungen von z und z̄ gibt alsdann die Tafel an: 15) , 16) , deren Formeln durch die Koeffizientenevidenz im Hinblick auf zh k = ih kjk h = 1'i h1'j k äusserst leicht zu rechtfertigen wären.
Dieselben lassen sich jedoch auch unschwer mittelbar beweisen wie folgt.
Es ist: z; 1 = ij̆; 1 = (i; 1)j̆; 1 = i; 1 · j̆; 1 = i · 1 = i, 1; z = 1; i(1; j̆) = 1; i · 1; j̆ = 1 · j̆ = j̆ im Hinblick auf 5) des § 18, und 2) des § 25; ferner: z ɟ 0 = ij̆ ɟ 0 = (i ɟ 0)(j̆ ɟ 0) = i · 0 = 0, 0 ɟ z = (0 ɟ i)(0 ɟ j̆) = 0 · j̆ = 0, z; 0' = ij̆; 0' = (i; 1)j̆; 0' = i; 1 · j̆; 0' = ij̄̆, 0'; z = 0'; i(1; j̆) = 0'; i · 1; j̆ = īj̆ wegen 5) des § 18; endlich: z ɟ 1' = ij̆ ɟ 1' = (i ɟ 1')(j̆ ɟ 1') = i · 0 = 0, 1' ɟ z = (1' ɟ i)(1' ɟ j̆) = 0 · j̆ = 0, , q. e. d.
Die, sofern sie sich nicht schon aus dem Abacus ergeben, nun unschwer ähnlich zu gewinnenden sekundären Modulknüpfungen von z und z̄ seien zur Bequemlichkeit des Studirenden hiernächst vollständig zusammengestellt: 17) .
Fügt man noch hinzu die an die überragende (achte) Zeile sich anspinnenden tertiären Knüpfungen: 18) so können alle (wenn auch noch so hohen) relativen Modulknüpfungen von z und z̄ nunmehr augenblicklich angegeben werden, indem man dieselben von innen heraus unter ev. wiederholter Benutzung dieser Tafeln successive reduzirt. Dieselben führen niemals aus dem Kreise der bisher als rechte Seiten vorgekommnen vierzehn Symbole 0, 1, z, z̄, i, j̆, ī, j̄̆, ij̄̆, īj̆, ī + j̆, i + j̄̆, īj̄̆, i + j̆ heraus.
Insbesondre ist von quartären Modulknüpfungen beachtenswert, dass: 19) 1' ɟ 0'; z; 0' ɟ 1' = z, 0'; (1' ɟ z̄ ɟ 1'); 0' = z̄ gilt.
Diese Formel vermag aber z nicht als Einauge zu charakterisiren, weil sie schon für z = 0 sich erfüllt zeigt.
Ebendies ist für z = 0 oder 1 auch mit der grossen Mehrzahl der übrigen Formeln der Fall, in denen blos z, z̄ neben Moduln vorkommen.
Und es könnten als möglicherweise für das Einauge charakteristisch höchstens noch diese fünf von unsern Formeln in Betracht kommen (die rechterhand sind nur Kontraposition der linkseitigen): 20) [Formel] 21) [Formel] (10) welche — in 6 oder 7 Termen — ein gewisses Relativ charakterisiren.
0'; z; 0' ɟ 0 = 0 (1' ɟ z̄ ɟ 1'); 1 = 1 0 ɟ 0'; z; 0' = 0 1; (1' ɟ z̄ ɟ 1') = 1 0'; z; 0' ɟ 1' = 0'; z (1' ɟ z̄ ɟ 1'); 0' = 1' ɟ z̄ 1' ɟ 0'; z; 0' = z; 0' 0'; (1' ɟ z̄ ɟ 1') = z̄ ɟ 1',
0'; z; 0' = (z̄ ɟ 0)(0 ɟ z̄) 1' ɟ z̄ ɟ 1' = z; 1 + 1; z,
Von diesen fünfen wäre aber die der ersten Zeile auch durch z = ī̆, die der zweiten und dritten durch z = i, der vierten durch z = ĭ erfüllt, somit zur Charakterisirung des Einauges nicht ausreichend.
Anders die Formel der fünften Zeile.
Dass diese (10) hiezu ausreicht, hat mich zuerst in geometrischer Evidenz das Studium der sieben Formen gelehrt, welche unter den sekundären Modulknüpfungen eines allgemeinen Relativs a das Relativ 0'; a; 0' annehmen kann, und deren Vergleichung mit den zugehörigen Werten des Relativs (ā ɟ 0)(0 ɟ ā).
Dieselbe muss also mit 8) äquivalent sein, was analytisch nachzuweisen nicht ganz leicht erscheint und nunmehr geschehen soll.
Wir leiten zuerst 8) aus 10) ab.
Wegen z; 1 + 1; z ⋹ 1' ɟ z̄ ɟ 1' haben wir nach dem ersten Inversionstheoreme: (z; 1 + 1; z); 0' ⋹ 1' ɟ z̄, 0'; (z; 1 + 1; z) ⋹ z̄ ɟ 1', z; 1 + 1; z; 0' ⋹ 1' ɟ z̄, 0'; z; 1 + 1; z ⋹ z̄ ɟ 1', somit a fortiori: z; 1 ⋹ 1' ɟ z̄, 1; z ⋹ z̄ ɟ 1', oder z; 1 · 0'; z + z; 0' · 1; z = 0, womit ein Teil von 8) gewonnen ist und nur noch z ≠ 0 abzuleiten bleibt, was aber schwieriger.
[Da z; 0' ⋹ z; 1, so folgt nebenher auch sogleich z; 0' · 0'; z = 0.]
Wegen a ɟ 0 = (a ɟ 1')a etc. — cf. 13) des § 15 — haben wir allgemein: 0 ɟ z̄ ɟ 0 = {(0 ɟ z̄) ɟ 0}{0 ɟ (z̄ ɟ 0)} = {z̄(1' ɟ z̄) ɟ 0}{0 ɟ (z̄ ɟ 1')z̄} = = (z̄ ɟ 0)(0 ɟ z̄)(1' ɟ z̄ ɟ 0)(0 ɟ z̄ ɟ 1').
Andrerseits ist nach dem Abacus, 10) und 24) des § 18, hier: 1' ɟ z̄ ɟ 0 = 1' ɟ z̄ ɟ 1' ɟ 0 = (z; 1 + 1; z) ɟ 0 = z; 1 + 1; z ɟ 0, also (z̄ ɟ 0)(1' ɟ z̄ ɟ 0) = (z̄ ɟ 0)(1; z ɟ 0), und ebenso zeigt man, dass: (0 ɟ z̄)(0 ɟ z̄ ɟ 1') = (0 ɟ z̄)(0 ɟ z; 1), womit wir haben: 0 ɟ z̄ ɟ 0 = (z̄ ɟ 0)(0 ɟ z; 1)(1; z ɟ 0)(0 ɟ z̄).
Wegen 0 ɟ z; 1 ⋹ z; 1, etc. ist aber das Produkt der beiden ersten Faktoren rechts gleich 0, und ebenso das der beiden letzten, womit denn auch 0 ɟ z̄ ɟ 0 = 0 oder z ≠ 0 gewonnen ist, q. e. d.
Um umgekehrt 10) aus 8) abzuleiten, deduziren wird aus letzterm: 0'; z ⋹ z̄ ɟ 0, z; 0' ⋹ 0 ɟ z̄, somit: 0'; z; 0' ⋹ (z̄ ɟ 0); 0' = z̄ ɟ 0, desgleichen ⋹ 0'; (0 ɟ z̄) = 0 ɟ z̄, also 0'; z; 0' ⋹ (z̄ ɟ 0)(0 ɟ z̄).
Andrerseits haben wir nach der allgemein für 0 ɟ z̄ ɟ 0, welches hier = 0 ist, oben gegebnen Umformung:
(z̄ ɟ 0)(0 ɟ z̄)(1' ɟ z̄ ɟ 0)(0 ɟ z̄ ɟ 1') ⋹ 0, oder (z̄ ɟ 0)(0 ɟ z̄) ⋹ 0'; z; 1 + 1; z; 0'.
Allgemein aber kann man umformen: 0'; a; 1 + 1; a; 0' = 0'; a; (1' + 0') + (0' + 1'); a; 0' = = 0'; a + 0'; a; 0' + a; 0', und hienach wird a fortiori: (z̄ ɟ 0)(0 ɟ z̄) ⋹ z + 0'; z + 0'; z; 0' + z; 0' + z = ⋹ 1; z + 0'; z; 0' + z; 1 wegen 13) des § 15.
Dies reduzirt sich zu: (z̄ ɟ 0)(0 ɟ z̄) ⋹ 0'; z; 0', indem die beiden äussersten Glieder negirt als Faktoren nach links geschlagen mit den dortselbst bereits vorhandenen zusammenfallen.
Hiemit ist 10) als Subsumtion vor- und rückwärts aus 8) abgeleitet, q. e. d.
Die beiden sind also als äquivalent auch rechnerisch bewiesen.
Den unterweges bewiesnen Satz mit seinem dualen Gegenstück zu einem Gespann ergänzt, wollen wir übrigens zu gelegentlicher Anwendung ausdrücklich notiren: 22)
1; a; 1 = a; 1 + 1; a + 0'; a; 1 + 1; a; 0' 0 ɟ a ɟ 0 = (a ɟ 0)(0 ɟ a)(1' ɟ a ɟ 0)(0 ɟ a ɟ 1').
Derselbe ergibt sich linkerhand auch rasch, indem man den ersten und letzten relativen Faktor 1 durch 1' + 0' ersetzt.
Nach alledem muss also die Gleichung 10) 1' ɟ z̄ ɟ 1' = z; 1 + 1; z als die — soweit bekannt — konziseste Definition des „Individuums im zweiten Denkbereiche“ angesehen werden.
Auf dieser fussend wollen wir nun die ganze Theorie des Individuums streng wissenschaftlich aufbauen.
Es würde imposanter gewesen sein, wenn ich jene ohne weitre Motivirung an die Spitze derselben gestellt hätte; instruktiver schien mir’s, dem Leser auch einen Einblick in das Werden, die Heuristik der Theorie zu verschaffen.
Ein erstes Kunststück ist, die Gesetze der Modulknüpfungen 15) bis 21) direkt aus der Gleichung 10) rechnerisch abzuleiten so, wie es schon mit dieser 1; z; 1 = 1 oben geschah.
Dabei dürften wir überhaupt die bereits mit Gleichung 8) deduzirten Ergebnisse benutzen.
Das Kunststück ist trotzdem nicht gerade leicht, und da seine Ausführung bei der grossen Menge zu rechtfertigender Formeln einen erheblichen Druckaufwand erforderte, so will ich mich begnügen, die Aufgabe zur Selbstbethätigung für Vorgerücktere zu empfehlen.
Ihre Lösung mache ich für die nachstehende Theorie dadurch entbehrlich, dass ich von der Gleichung 10) aus möglichst rasch zur Darstellung des z durch ij̆ eile, aus der sich ja oben auf die leichteste Weise alle Modulknüpfungsformeln ergeben haben.
Ein erster Satz dieser Theorie lautet: 23) [Formel] .
Diese Aussagenäquivalenz muss als Subsumtion vor- und rückwärts bewiesen werden.
Die Gleichung 23) rückwärts als Subsumtion zu beweisen läuft darauf hinaus, zu zeigen, dass die Charakteristik linkerhand (als Resultante der Elimination von x, y) aus dem allgemeinen Glied der Doppelsumme rechterhand folgt.
Dies ist auf dem Umwege über 6) ‥ 8) nach 10) implicite bereits geschehen, soll aber nunmehr nochmals auf dem kürzesten Wege geleistet werden.
Dabei dürfen wir die aus den Charakteristiken für x und y bereits S. 408 sq. abgeleiteten Folgerungen x; 1 = x = x ɟ 0, 1; x = 1 = y; 1, 1; y = y = 0 ɟ y, etc. nebst deren Kontraposition benutzen.
Nun ist für z = xy: R = z; 1 + 1; z = xy; 1 + 1; xy, L = 1' ɟ z̄ ɟ 1' = 1' ɟ (x̄ + ȳ) ɟ 1' und soll L = R bewiesen werden.
Aber: R = (x; 1)y; 1 + 1; x(1; y) = x; 1 · y; 1 + 1; x · 1; y = x · 1 + 1 · y = x + y gemäss der linkseitigen Schemata 5) des § 18 für c = 1 in Anspruch genommen.
Ebenso haben wir nach deren rechtseitigen für c = 1' in Anspruch genommnen Schemata: L = {1' ɟ (x̄ + 1; ȳ)} ɟ 1' = (1' ɟ x̄ + 1; ȳ) ɟ 1' = (1' ɟ x̄; 1 + 1; ȳ) ɟ 1' = = (x + 1; ȳ) ɟ 1' = (x; 1 + 1; ȳ) ɟ 1' = x; 1 + 1; ȳ ɟ 1' = x + y, q. e. d.
Noch leichter könnte mit der Annahme z = x; y gezeigt werden, dass: R = x; y; 1 + 1; x; y = x; 1 + 1; y = x; 1 ɟ 1; y = x ɟ y, L = 1' ɟ x̄ ɟ ȳ ɟ 1' = 1' ɟ x̄; 1 ɟ 1; ȳ ɟ 1' = x ɟ y, also L = R sein muss.
Um die Gleichung 23) vorwärts als Subsumtion zu beweisen, muss gezeigt werden, dass, sobald z die Charakteristik links erfüllt, es mindestens ein Wertepaar x, y gibt, welches die Aussage hinter der Doppelsumme rechts wahr macht.
Ein solches ist aber in der That angebbar in Gestalt von: x = z; 1, y = 1; z.
Beweis.
Denn hiefür wird erstens z = z; 1 · 1; z(= z; 1; z) = z; 1; 1; z, also z = xy = x; y erfüllt sein, was wir indirekt schon aus 10) abgeleitet haben, auf wol kürzestem Weg aber so ableiten mögen: z; 1 · 1; z = z; (1' + 0') · (0' + 1'); z = (z + z; 0')(0'; z + z) = z + z; 0' · 0'; z = z + 0 = z, indem das Verschwinden des letzten Gliedes bereits auf S. 431 aus 10) gefolgert wurde.
Es bleibt also nur noch das Erfülltsein der beiden ersten Faktor- Aussagen hinter den Σ in 23) zu beweisen.
Wegen x̄; 1 = (z̄ ɟ 0); 1 = z̄ ɟ 0, 1; ȳ = 1; (0 ɟ z̄) = 0 ɟ z̄ laufen diese aber hinaus auf die Modulknüpfungssätze 21): 1' ɟ z̄ ɟ 0 = z; 1, 0 ɟ z̄ ɟ 1' = 1; z, welche — zum wenigsten also — bewiesen werden müssen.
Indem wir zu unsrer Charakteristik beiderseits 0 relativ (nach- oder vor-)addirten, hatten wir aber bereits S. 431 die Ergebnisse gewonnen: 1' ɟ z̄ ɟ 0 = z; 1 + 1; z ɟ 0, 0 ɟ z̄ ɟ 1' = 0 ɟ z; 1 + 1; z.
Aus unsrer Charakteristik folgt jedoch a fortiori: z; 1 ⋹ 1' ɟ z̄ ɟ 1', somit nach dem ersten Inversionstheorem: z ⋹ 1' ɟ z̄ ɟ 1' ɟ 0 oder z⋹ 1' ɟ z̄ ɟ 0, analog z ⋹ 0 ɟ z̄ ɟ 1'.
Darnach wird 1; z ɟ 0 ⋹ 1; (0 ɟ z̄ ɟ 1') ɟ 0 = 0 ɟ z̄ ɟ 1' ɟ 0 = 0 ɟ z̄ ɟ 0, was als ⋹ 0 mit z ≠ 0 bereits S. 431 erwiesen ist.
Somit gelten also nebenher auch die Modulknüpfungssätze:
1; z ɟ 0 = 0, 0 ɟ z; 1 = 0 und mit diesen bewahrheiten sich auch die vorigen, q. e. d.
Weil das genannte x nun also die Charakteristik des Elementes, y die des Elementkonverses erfüllt, so dürfen wir jenes mit i, dieses mit j bezeichnen, und haben die Darstellung z = ij̆ gewonnen.
Diese ist nebenbei gesagt nur auf eine Weise möglich, oder es kann nicht mehr als ein Glied der Aussagendoppelsumme in 23) wahr sein.
Denn wenn noch auf eine zweite Weise z = hk̆ wäre, so müssten wir auch z = zz = ij̆hk̆ haben, was nach 16) des § 25 wegen ih = 0 oder wegen j̆k̆ = 0, im Widerspruch zu z ≠ 0, verschwinden müsste, sobald das zweite Elementepaar nicht durchaus mit dem ersten zusammenfiele.
Als nächsten Satz der Theorie stellen wir nun diesen auf: 24) [Formel] , wonach unsre Charakteristik äquivalent ist der Individuumsdefinition, wie sie der identische Kalkul (Bd. 2, S. 325) formulirt.
Auch diese Äquivalenz muss als Subsumtion vor- und rückwärts bewiesen werden.
Vorwärts haben wir bereits die Folgerung z ≠ 0 aus der Charakteristik gezogen, bleibt also nur noch darzuthun, dass ein individuelles Relativ z jedem binären Relativ u gegenüber entweder ganz in ihm selbst oder ganz in seinem Negat enthalten ist.
Nun gibt die Alternative der Gleichungen (zū = 0) + (zu = 0) nach den Methoden des § 11 zusammengezogen die vereinigte Gleichung:
1; zū; 1; zu; 1 = 0 oder zū; 1; zu = 0, welche also nur mehr zu beweisen ist.
Dabei kann z = ij̆ eingesetzt werden.
Nennen wir Z den fraglichen Ausdruck, so ist:
Z = zū; 1 · 1; zu = (i; 1)j̆ū; 1 · 1; i(1; j̆)u = i; 1 · j̆ū; 1 · 1; j̆ · 1; iu = = ij̆ · ū(1; j̆); 1 · 1; (i; 1)u = ij̆ · ū; j; 1 · 1; ĭ; u = ij̆ · ū; j · ĭ; u — gemäss 6) des § 18, zu vorletzt.
Dass dieser Ausdruck nun verschwindet ist einerseits daraus ersichtlich, dass nach 29) des § 25:
Z = ū; j · j̆ · i · ĭ; u = ūj̆ · iu ⋹ uū = 0 wird; andrerseits ist es auch durch die Koeffizientenevidenz nachweisbar, indem:
Zh k = ih kjk hΣlūh ljl k · Σmim hum k = = 1'i h1'j kΣlūh l1'j l · Σm1'i mum k = 1'i h1'j kūh jui k, wo das Produkt der beiden ersten Faktoren nur für h = i und j = k nicht verschwinden wird, dafür aber das Produkt der beiden letzten Faktoren als ūi j · ui j verschwindet, q. e. d.
Man hätte den Beweis auch ohne die vorhergehende Reduktion des Ausdrucks mit Z = ij̆ū; 1; ij̆u in Gestalt von Zh k = Σl mih ljl hūh l1l mim kjk mum k = = Σl m1'i h1'j lūh l1'm1'j kum k = ūi jui j = 0 noch rascher führen können.
Rückwärts ist zu zeigen, dass ein nicht verschwindendes binäres Relativ z, welches die Eigenschaft besitzt, jedem binären Relativ u gegenüber entweder in diesem oder in ū enthalten zu sein, notwendig ein Elementepaar i : j sein muss, nämlich die Charakteristik 10) ebendieses erfüllt.
Dies kann ja ganz leicht durch folgende Überlegung geschehen.
Jedes binäre Relativ ist laut Definition eine Summe von Elementepaaren, und seine Matrix besteht dementsprechend aus Augen und Leerstellen.
Nun muss die Matrix des der rechten Seite von 24) genügenden z mindestens ein Auge haben, weil z = 0 ausgeschlossen ist.
Sei i : j das einem solchen Auge entsprechende Elementepaar, so kann z kein zweites Elementepaar h : k enthalten, m. a. W. die Matrix von z kann (auch) nicht mehr als ein Auge haben.
Denn im gegenteiligen Falle würden Relative u existiren und angebbar sein von der Eigenschaft, dass z nachweislich weder in ihnen noch in ihrem Negate enthalten sein kann.
Ein solches Relativ u müsste nämlich dann das Einauge sein, als welches sich das eine (oder andre) der beiden genannten Elementepaare präsentirt.
Das Einauge u = i : j kann, als h : k ausschliessend, auch nicht z enthalten, dessen Teil ja laut Assumtion sowol h : k als i : j ist.
Ebensowenig kann aber auch die Negation ū = i : j͞ unser z als Teil enthalten, obwol es h : k einschliessen wird, weil es den Teil i : j von z ausschliesst.
Dass dies zutrifft, wird ganz strenge eigentlich erst weiter unten — sub 27) — gerechtfertigt.
Damit ist gezeigt, dass jedes durch die rechte Seite von 24) charakterisirte binäre Relativ z gerade ein Auge haben muss, und folglich auch erfüllen muss die schon bekannte „Charakteristik des Einauges“, wie sie linkerhand in 24) sich angegeben findet.
Die Individuumscharakteristiken, entnommen einerseits dem identischen Kalkul als niederer Stufe und andrerseits der Theorie der relativen Modulknüpfungen als höherer Stufe der Algebra der Relative, müssen darnach einander äquivalent sein, q. e. d.
Allein so bündig dieser vorstehende Beweis auch ist, so vermag ich mich doch in methodologischer Hinsicht mit demselben noch nicht ganz zufrieden zu geben.
Als Desideratum schwebt mir noch die Forderung vor, die linke Seite von 24) auch rein analytisch, rechnerisch, aus der rechten abzuleiten, ungefähr wie dies umgekehrt bereits (so ziemlich) geleistet wurde.
Ich bin in dieser Richtung wenigstens bis zu einem bestimmten Punkte vorgedrungen, und bietet mein Weg einige interessante Momente, weshalb die Betrachtungen in Kürze dargelegt seien.
Für jedes u ist entweder z ⋹ u oder z ⋹ ū, aber niemals beides, weil (z ⋹ u)(z ⋹ ū) = (z ⋹ uū) = (z ⋹ 0) = (z = 0) in Widerspruch mit der Stipulation z ≠ 0 treten würde.
Darnach ist entweder z⋹z̄ ɟ 1' oder aber z ⋹ z; 0'.
Um nachzuweisen, dass von diesen beiden Alternativen notwendig die erstere statt hat, kann man versuchen, die letztere ad absurdum zu führen.
Nehmen wir zu dem Ende an, es sei z ⋹ z; 0', so muss also zeilenschematisch sein 1αβγ0 ⋹ 111γ̄0, d. h. es muss die Zeilenkategorie γ entfallen und z = z; 0' · z = 1αβ-0 ohne einbesetzte Zeilen sein.
Weiter muss von vornherein entweder z ⋹ 1' oder z ⋹ 0' sein, von welchen beiden Möglichkeiten die erstere sich refutiren lässt.
Entweder nämlich haben wir z⋹z ɟ 0 (und damit z = z ɟ 0 = 1---0) oder z ⋹ z̄; 1 [und damit (z ɟ 0)z = 0, z ɟ 0 = 0, z = z̄; 1 · z; 0' · z = -αβ-0].
Im „oberen“ Falle müsste für beide darüber erwähnten Möglichkeiten z ɟ 0 = 0 und damit z = 0 sein, was unzulässig.
Man hat nämlich als geometrisch unmittelbar evident die beiden Sätzchen: 25) (z ɟ 0 ⋹ 1') = (z ɟ 0 = 0) = (z ɟ 0 ⋹ 0').
Der Studirende klappe hier das Buch zu, und versuche, dieselben auch analytisch zu beweisen.
Es geht so:
Für das erste Sätzchen schliesst man: z ɟ 0 ɟ 1' ⋹ 1' ɟ 1', also z ɟ 0 ⋹ 0, q. e. d. (die Umkehrung nämlich ist selbstverständlich).
Für das zweite Sätzchen schliesse man: z ɟ 0 ɟ 1' ⋹ 0' ɟ 1', also z ɟ 0 ⋹ 1', wonach dasselbe auf das erste zurückkommt — wofern man nicht lieber das Ergebniss mit der Hypothesis kombiniren will zu z ɟ 0 ⋹ 0' · 1' = 0, q. e. d.
Ergo muss der „untere“ Fall statthaben.
Wegen z = z̄; 1 · z; 0' · z folgt dann bei der ersten Möglichkeit mit z ⋹ 1' a fortiori auch z; 0' · z ⋹ 1' und kann man sich weiter auf das Sätzchen berufen: 26) (z; 0' · z ⋹ 1') = (z; 0' · z = 0), welches geometrisch wiederum einleuchtet und womit wir dann wieder bei der zu verwerfenden Konklusion z = 0 angelangt sind.
Analytisch ist der Beweis des Sätzchens etwas schwieriger.
Man schliesse: (z; 0')z; 0' ⋹ 1'; 0', also z; 0' ɟ 0 ⋹ 0', was mit der Prämisse übermultiplizirt wegen z; 0' ɟ 0 ⋹ z; 0' gibt: (z; 0' ɟ 0)z ⋹ 0' · 1' = 0 oder z; 0' · z = 0, q. e. d.
Somit bleibt nur die zweite Möglichkeit im unteren Falle übrig: z = -αβ-0 = z̄; 1 · z; 0' · z ⋹ 0', während z ɟ 0 = 0 auch hier sein muss.
Dieses z ist nun entweder ⋹u = -αβ̄-0 somit z = -α--0, oder ⋹ ū = -ᾱβ-1 somit z = --β-0, d. h. entweder hat z nur einlückige mehrbesetzte oder nur mehrlückig mehrbesetzte Zeilen neben Leerzeilen.
Sofern es nicht gelingen sollte, auch diese beiden Möglichkeiten gleich den vorhergehenden vollends ad absurdum rechnerisch zu führen, kann man immer auf irgend zwei Augen einer mehrbesetzten Zeile des Räsonnement des vorhergehenden Haupttextes im Notfalle anwenden, um zu dem Schlusse zu gelangen, dass nur z ⋹ z̄ ɟ 1' und konjugirt dazu auch z ⋹ 1' ɟ z̄ bestehen kann, womit dann von den drei Gliedern der Form 6) unsrer Charakteristik das Verschwinden der beiden letzten gesichert ist — das des letzten Gliedes ist es nämlich ohnehin vermöge z ≠ 0.
Dann bliebe noch das Verschwinden des ersten Terms zu rechtfertigen.
— Oder auch, um von der Form 10) das Verschwinden aller drei Terme zu sichern (von denen das des dritten nach dem Konjugationsprinzip mit dem des zweiten sich erledigt), so müsste gezeigt werden, dass nicht nur, wie oben, z ⋹ z̄ ɟ 1', sondern dass sogar 1; z ⋹ z̄ ɟ 1', d. h. z ⋹ 0 ɟ z̄ ɟ 1' sein muss.
Es müsste mithin blos die Annahme z ⋹ 1; z; 0' rechnerisch ad absurdum geführt werden.
Das Theorem 24) erfährt späterhin noch eine eigentümliche Beleuchtung, einerseits wenn bei der Erweiterung des zweiten Denkbereiches 12 zu dem der dritten Ordnung 13 das Elementepaar i : j noch weiter (in Punkte) eingeteilt wird, indem uns der Punkt der Matrixebene nicht blos als Träger sondern als Repräsentant einer in ihm normal zu dieser stehenden Geraden („Applikate“) gelten kann, die dann selber noch unendlich viele Punkte enthalten mag; andrerseits wenn wir eine Zurückdeutung in den ersten Denkbereich 11 vornehmend — schon im nächsten Paragraphen — die Charakteristik des „Elementes“ ebenfalls mit der Individuumsdefinition des identischen Kalkuls in Zusammenhang bringen werden.
Die Äquivalenz 24), wenn in ihr das [Formel] allemal mit der vollen Erstreckung über alle Relative u des betreffenden Denkbereiches genommen wird, versagt für die höheren Denkbereiche.
Die Charakteristik 10) vermag nur das Individuum des zweiten, die 7) des § 25 nur das des ersten Denkbereiches (für den zweiten) zu definiren.
Die Definitionsform des identischen Kalkuls dagegen definirt in übereinstimmender Fassung für jeden Denkbereich gerade diejenige Art von Relativen, welche in ihm als „Individuen“ zu gelten haben. —
Wenden wir uns jetzt programmgemäss zu den identischen Knüpfungen zwischen Elementepaaren oder deren Verwandten, so genügt es, die beiden folgenden Sätze zu etabliren: 27) (i ≠ h) + (j ≠ k) = {(i : j)(h : k) = 0}, 28) (i = h)(j = k) = {(i : j)(h : k) = i : j = h : k} = {(i : j)(h : k) ≠ 0}, was nichts anderes besagt, als: Alle Elementepaare sind unter sich disjunkt.
Das identische Produkt zweier Elementepaare verschwindet, sobald dieselben nicht in den Antezedenten (Relaten) sowol als in den Konsequenten (Korrelaten) übereinstimmen, d. h. völlig einerlei sind.
Natürlich aber ist nach dem Tautologiegesetze das Produkt zweier Elementepaare gleich dem einen und auch gleich dem andern, sobald dieselben identisch sind.
Beweise.
Ist h = i und k = j, so ist auch h : k = hk̆ = ij̆ = i : j, (i : j)(h : k) = ij̆ij̆ = ij̆ = i : j, etc. dem eben Gesagten entsprechend.
Somit ist der erste Teil von 28) als vorwärtige Aussagensubsumtion erwiesen.
Ist i ≠ h oder j ≠ k, so muss (i : j)(h : k) = ij̆hk̆ = 0 sein, weil dann entweder ih oder j̆k̆, nämlich jk nach 16) des § 25 gleich 0 ist.
Somit ist auch die Aussagenäquivalenz 27) als vorwärtige Subsumtion bewiesen.
Die linke Seite von 27) ist die Negation derer von 28).
Würde nun aus der Behauptung der vorhin erwiesenen Aussagensubsumtion 28) nicht auch umgekehrt deren Voraussetzung folgen, so müsste die Negation von dieser, mithin die Hypothesis von 27) gelten.
Dann hätten wir aber (i : j)(h : k) = 0 im Widerspruch zu der Annahme, dass dies Produkt = i : j (= z) somit ≠ 0 sei.
Ebenso zeigt man apagogisch auch die rückwärtige Geltung der für 27) bereits bewiesnen Aussagensubsumtion.
Der letzte Teil des Satzes 28) ergibt sich durch Vergleichung seines ersten Teils mit der Kontraposition von 27).
Als einen partikularen Fall von 27) haben wir insbesondre für k ≠ j: 29) (i : j)(i : k) = 0 und gibt derselbe Veranlassung zu einer sehr wichtigen Bemerkung.
Derselbe thut nämlich meines Erachtens unwiderleglich dar, dass es für die Widerspruchsfreiheit, Konsistenz unsrer Theorie ganz unerlässlich ist, die Denkbereiche der verschiednen Ordnungen — wie von mir betont — scharf von einander zu unterscheiden.
Dies etwa in folgender Weise.
Es seien die Elementepaare i : j und i : k — alle beide — Glieder eines Relativs a = amans = „Liebender von-“.
Wenn dann nach Peirce2 p. 12 sq., 5 p. 44, 6 p. 5 sq. (konnotativ) i : j den i „als Liebenden von j“, ebenso i : k den i „als Liebenden von k“ bedeutet, mithin beide Elementepaare das Relat, den i, bezeichnen, so muss notwendig im Widerspruch zu 29) das identische Produkt: 29̅) (i : j)(i : k) = i selbst sein; und dieses ist es in der That, sobald man vor der Multiplikation der Elementepaare an ihnen den Prozess ausführt, den ich ihre „Zurückdeutung“ in den Denkbereich 11 nannte — ein Prozess, der (wie wir später sehen werden) die Wirkung hat zu verwandeln: das Elementepaar i : j in (i : j); 1 = ij̆; 1 = i; 1 · j̆; 1 = i · 1 = i und ebenso das i : k in i.
Eine ähnliche Bemerkung würde sich auch an die Operation des Negirens anknüpfen lassen, wo es einen grossen Unterschied macht, ob man ein binäres Relativ a erst negirt, und dann (das Negat ā) in den Denkbereich 11 zurückdeutet (womit ā; 1 entsteht), oder ob man umgekehrt a erst zurückdeutet (was a; 1 liefert) und dann negirt (womit a1 = ā ɟ 0 entsteht).
Solange Peirce’s Theorie fortgesetzt nur mit einem einzigen völlig offenen Denkbereiche wirtschaftet(e), in welchen es jederzeit freisteht, die Objekte unsrer verschiednen Denkbereiche mit gleichem Rechte einzubeziehen, kann dieselbe wie mir scheint von einem innern Widerspruche, einer Inkonsistenz nicht wohl ganz freigesprochen werden.
Dieser Umstand hat mir das Eindringen in das Verständniss von Peirce’s herrlicher Schöpfung lange Zeit erschwert — um nicht zu sagen: einer Barrière gleich, verlegt.
Wir gehn nun über zu den relativen Knüpfungen zwischen Elementepaaren und deren Verwandten, nämlich Negaten (da die Konverse eben auch nur Elementepaare sind).
Hier ist von fundamentaler Bedeutung der Satz: 30)
[Formel]
Beweis leicht aus der Koeffizientenevidenz, eleganter nach 5) des § 18, aufgrund welches Satzes wir haben: (i : h); (k : j) = ih̆; kj̆ = (i; 1)h̆; k(1; j̆) = i; 1 · h̆; k · 1; j̆ = = ij̆ · h̆; k = i; j̆ · h̆; k = (i : j) · h̆; k, wo nun nach 14) des § 25 h̆; k gleich 0 ist für k ≠ h und gleich 1 für k = h, q. e. d.
Was die übrigen Knüpfungen der fraglichen Kategorie betrifft, so stellen wir dieselben — unter Wiederholung der soeben bewiesenen — sogleich übersichtlichst in einer Tafel zusammen.
Auf diese lassen wir sodann dem S. 428 aufgestellten Programme gemäss noch andre Tafeln folgen.
Was die Herleitung oder Begründung der in ihnen gegebnen Formeln betrifft, so verschiebe sie der Leser, wofern er sich nicht an zahlreichen Einzelaufgaben üben will, bis zum Schlusse der Aufzählung.
Die erste Tafel umfasst die Formeln: 32) [Formel] . *
Darin ist der Aussagenterm j = h entweder 0 oder 1, und sind darnach in Vorstehendem insbesondere enthalten die Sätze: 33) [Formel]
Die nächste Tafel erledigt die relativen Knüpfungen zwischen den Verwandten eines Elementepaars und denen eines Elementes: 34) [Formel] 35) [Formel] 36) [Formel] 37) [Formel] 38) [Formel] 39) [Formel]
Sie umfasst — die Doppelform der nach der Zeilenmitte zu stehenden Ergebnisse bei 37) ungerechnet — 4 × 8 = 32 Formeln.
Als Sonderfälle von 34), 35) sind hervorzuheben: 40) [Formel] 41)
(i : j); j̄ = 0 = ī̆; (i : j) ĭ ɟ i : j͞ = 1 = i : j͞ ɟ j.
Aus den einseitigen Formeln von 36) geht ferner durch Buchstabenvertauschung und Komparation noch hervor: 42)
i; (h : j) = i : j = (i : h); j̆ i : h͞ ɟ j̄̆ = i : j͞ = ī ɟ h : j͞.
Die letzte Tafel von 8 Formeln endlich erledigt die relativen Knüpfungen zwischen einem Elementepaar oder dessen Negate und einem allgemeinen Relativ a, indem sie zeigt, wie dieselben zunächst zurückkommen auf die Knüpfungen von a mit einem Elementverwandten, in letzter Instanz aber auf identische Operationen und relative Knüpfungen blos mit den absoluten Moduln — was die äusserste Reduktion des Knüpfungsergebnisses vorstellt, die man allgemein auszuführen vermag: 43) [Formel] .
Behufs Beweises der hinzugekommnen Formeln 32) bis 43) dürfte der Studirende, das Allgemeinere zuerst erledigend, die drei Tafeln besser in der umgekehrten Reihenfolge durchnehmen.
— Was die letzte 43) betrifft, so verstehen sich die Gleichungen der ersten Kolumne (links) aus 11) und 13) des § 25, nämlich weil i : j = ij̆, i̅ ̅:̅ ̅j̅ = ī + j̄̆ ist, teils in Anbetracht, dass i = i; 1, j̆ = 1; j̆, ī = ī; 1, j̄̆ = 1; j̄̆ nach 2) und 4) des § 25 gilt, aus dem Theorem 15) des § 18, welches der Leser als 7) des § 27 noch näher zurhand hat, teils ohne weiteres; und die übrigen Ausdrucksformen des Ergebnisses sind davon blosse Umformungen gemäss 21) bis 23) des § 25. —
Indem man sodann in 43) für a spezieller h, oder h : k, etc. setzt und die frühern Relationen nach Bedarf — eventuell die 43) nochmals — berücksichtigt, wird man leicht zur Rechtfertigung der Formeln auch der beiden vorhergehenden Tafeln gelangen, ohne jemals zur Koeffizientenevidenz seine Zuflucht nehmen zu müssen, deren Herbeiführung übrigens ebenfalls auf eine Schwierigkeit nirgends stossen würde.
Anzuführen ist noch, dass von den — nach den einen 43) leicht auf andre 43) zurückzuführenden — Sätzen: 44) [Formel] die beiden rechts vom Striche sich in doppelter Ausfertigung (für ā sowol als für a ausgesprochen) bereits von Peirce5 p. 53, in gänzlich andre Symbolik verhüllt, gegeben finden.
Mit Rücksicht auf 29) des § 25 hat man aus 43) noch speziell: 45) [Formel]
§ 27. Sätze über Knüpfung mit den absoluten Moduln.
Systeme, Klassen oder absolute Terme als binäre und als uninäre Relative.
Bevor wir in die Theorie der „Systeme“ eintreten, empfiehlt es sich — grösstenteils unter Rekapitulation — die wichtigsten Sätze übersichtlich zusammenzustellen, die Bezug nehmen auf die [in erster Instanz natürlich relativen] Knüpfungen zwischen irgend welchen Relativen und den absoluten Moduln 1 und 0 — unter Beiseitelassung aller Sätze, in welchen auch relative Moduln vorkämen.
Jenes sind also diejenigen Sätze, in deren Formelausdruck neben allgemeinen Buchstabenrelativen (und eventuell deren Verwandten) nur Ausdrücke von den 4 Formen:
0) a; 1, 1; a, a ɟ 0, 0 ɟ a figuriren — zwischen derengleichen nebst den Relativen aber noch identische sowohl als relative Knüpfungen in Betracht kommen mögen.
Identische Knüpfungen zwischen 1 oder 0 und irgend einem Relative lassen dieses ja entweder ungeändert, oder verwandeln es sogleich in 0 oder aber 1.
Schon zum öftern, so namentlich in der sechsten, siebenten und in der gegenwärtigen Vorlesung, hat der Leser Gelegenheit gehabt, den Wert von dergleichen Sätzen zu erproben — mochte ihr Formelausdruck auch blos in einer unscheinbaren Subsumtion bestehen und mochte auch der Ausdruck auf der einen Seite solcher Formel ziemlich willkürlich und vielleicht in sehr spezieller Weise aus seinen Elementarsymbolen zusammengesetzt erscheinen.
Der Anwendungswert solcher Formeln zur Förderung der Zwecke einer Untersuchung tritt nicht selten ganz unvermutet zutage — so vor allem dann, wenn eben Sätze von allgemeinerm Charakter nicht zur Verfügung stehen — und rechtfertigt es, dass die Formel nebst andern ihresgleichen in eine Sammlung einregistrirt werde.
Ich hätte den bisherigen Lehrgang vielleicht mannigfach vereinfachen können, wenn ich diese Sammlung vorangenommen hätte; doch liess ich mich durch gute Gründe bestimmen, welche dafür sprachen erst das Bedürfniss nach solcher Sammlung fühlbar werden zu lassen.
Teils auch kompletirte sich die Sammlung erst nach Maassgabe der Fortentwickelung des Werkes im Lauf der Drucklegung.
Die bisher gelegentlich gebrauchten und jeweils ad hoc aufgestellten Sätze solcher Art finden sich jedenfalls zu zerstreut um einen Überblick zu gestatten, und müssen sie darum hiernächst wiederholt werden, wogegen sie nicht mehr bewiesen zu werden brauchen.
So seien denn zuerst die Formeln 8) ‥ 11) und 16) des § 15 — hiernächst als 1) bis 5) — in Erinnerung gebracht, obwol sie reine Parallelreihensätze sind.
Dem letzten Gespanne, das sekundäre Modulknüpfungen reduziren lehrt, stellen wir unter 6) zur Seite ein neues Gespann von Formeln, die für die Reduktion von tertiären Modulknüpfungen maassgebend sind, aber nicht mehr zu den Parallelreihensätzen gehören.
Als 7) ‥ 10) reihen sich drei Paare von sehr wichtigen und allgemeinen Satzgespannen an, die sich auf irgend drei allgemeine Relative beziehen und deren Sätze die Form von Gleichungen haben.
An diese schliesst sich noch ein gewissermassen nur mit sich selbst gepaarter Satz 11) von ebenso allgemeinem Charakter, doch vielleicht minderem Werte.
Die Formeln 12) und 13) heben partikulare Fälle (für c = 1 resp. 0) derer 7) und 8) hervor, und 14) ist dann eine naheliegende Erweiterung von 12), sowie 15) ein selbstverständliches Gegenstück hierzu.
Analog mögliche Erweiterungen von 13), wie {(a ɟ 0)b; 1 · c ɟ 0}d; 1 · e ɟ 0 … = (a ɟ 0) · b; 1 · (c ɟ 0) · d 1 · (e ɟ 0) …, haben wir, weil sie minder einfach aussehen, nicht mit einregistrirt.
Es folgen Formeln, die nur zwei allgemeine Relative — und bei 19), 20) nur ein solches — betreffen.
1) [Formel] 2)
[Formel] 3)
[Formel] 4)
[Formel] 5)
[Formel] 6)
[Formel] 7)
[Formel] 8)
[Formel] 9)
[Formel] 10) [Formel] 11) [Formel] 12) [Formel] 13) [Formel] 14) [Formel] 15) [Formel] 16) [Formel] 17) [Formel] 18) [Formel] 19) [Formel] 20) [Formel] 21) [Formel] 22) [Formel]
Von diesen Sätzen sind zudem bereits vorgekommen (somit auch schon bewiesen) die 7), 8), 16), 18), 19), 20), 21) als 5) des § 18, 24) § 18, 5) § 11, 24) § 20, 21) § 20, 23) § 20, 6) § 18.
Es folgt 17) als spezieller Fall für b = 1 resp. 0 aus 8), ebenso 22) aus 10) für c = 1 resp. 0, und müssen also nur die 6) — vergl. übrigens S. 148 — und 9) ‥ 11) hier noch bewiesen werden.
Man hat:
Zu 6)
Li j = ΠhΣkΠl(1i kak h + 0h l + 0l j) = ΠhΣkΠlak h = ΠhΣkak h = = ΠhΣk(1i kak h + 0h j) = Ri j, Zu 9)
Li j = ΣhΣkai h1i kbk hch j = ΣhΣkai hb̆h k1k jch j = Ri j, Zu 10)
Li j = ΣhΠkai h(0i k + bk h)ch j = ΣhΠkai h(b̆h k + 0k j)ch j = Ri j, Zu 11)
Li j = ΣkΣhai hbh kci k1k j = ΣhΣkci kb̆k hai h1h j = Ri j.
Doch kann man, anstatt 10) solchergestalt unmittelbar zu beweisen, den Satz auch, indem man 1; (b ɟ 0) für b ɟ 0 sagt, auf 9) zurückführen.
Als Ergänzungen zu 21) und 22) hätte man noch: a(1; b) ɟ 0 = (a ɟ 0)(1; b ɟ 0), a(0 ɟ b) ɟ 0 = (a ɟ 0)(0 ɟ b ɟ 0), etc., doch wären diese Sätze, in denen rechts ein ausgezeichnetes Relativ als Faktor hinzutritt, augenscheinlich von anderm Charakter und verdienen sie nicht, mitregistrirt zu werden.
Die vorstehenden Sätze liefern unter anderm grösstenteils die Regeln, nach welchen jeder Ausdruck von einer der vier Formen 0) in a mit einem ebensolchen in b relativ geknüpft werden kann, und ist es vielleicht nicht überflüssig, die 32 Knüpfungsergebnisse einmal mit kombinatorischer Vollständigkeit zusammenzustellen: 23) . Dabei sind auch noch folgende etwas einfachere Darstellungen zulässig: 24)
Man bemerkt, dass die 8 Knüpfungsergebnisse der 5, 7, 13 und 15ten Zeile ausgezeichnete Relative sind, deshalb auch ihrem Konversen gleich.
1; a; (b ɟ 0) = (0 ɟ 1; a · b̆); 1 = 1; (ă; 1 · b ɟ 0)
1; a ɟ b; 1 = 1; (a + b̆) ɟ 0 = 0 ɟ (ă + b); 1 (0 ɟ a); b; 1 = (0 ɟ a · 1; b̆); 1 = 1; (ă · b; 1 ɟ 0)
1; a ɟ b ɟ 0 = 1; (a + 0 ɟ b̆) ɟ 0 = 0 ɟ (ă + b ɟ 0); 1 (0 ɟ a); (b ɟ 0) = (0 ɟ ab̆); 1 = 1; (ăb ɟ 0)
0 ɟ a ɟ b; 1 = 1; (0 ɟ a + b̆) ɟ 0 = 0 ɟ (ă ɟ 0 + b); 1.
Wesentlich neu sind nur die diese betreffenden Angaben in unsrer Zusammenstellung — welche in allen andern Fällen lehrt, die relative Knüpfung auf eine identische zurückzuführen, in jenen 8 genannten aber solche Zurückführung doch wenigstens so weit als möglich treibt.
Mit Rücksicht auf den Abacus und 5) verstehen sich die 24 übrigen Formeln 23) schon aus 16), 17) und 18) von selbst.
Z. B. es ist 1; a ɟ 1; b = 1; a ɟ 0 ɟ 1; b nach 5), und dies, nach 16) rechts, = 1; a ɟ 0 + 0 ɟ 1; b = 1; a ɟ 0 + 1; b wiederum nach 5), q. e. d. Etc.
Die vorerwähnten achte lassen (links vom Mittelstriche) nach 5) sich leicht auf die erste von ihnen zurückführen — indem z. B. 1; a; (b ɟ 0) = 1; a; (b ɟ 0); 1 sein wird, etc.
Es bleibt also nur diese erstere, d. i. die der 5ten Zeile von 23) links — zu beweisen.
Dieses ist leicht unmittelbar durch die Koeffizientenevidenz zu leisten.
Nennt man L den ersten, R den zweiten der drei gleichgesetzten Ausdrücke, von welchem der dritte nur das Konverse ist, so hat man: Li j = Σh k l1i hah kbk l1l j = Σh k lah kbk l = ΣkΣh1i hah kΣl1i lb̆l k1k j = Ri j, q. e. d.
— Da wo rechterhand in 23) als Faktor oder Summand ein ausgezeichnetes Relativ erscheint — wie es bei der Hälfte der 24 Fälle zutrifft, in denen das Ergebniss nicht schon selbst ein solches war — vereinfacht sich natürlich das Endergebniss noch sehr, je nachdem jenes den Wert 0 oder 1 aufweist.
Die vorstehenden Formeln sind als Schemata für das Rechnen in unsrer relativen Algebra von ungemeiner Nützlichkeit.
Wir fahren mit der Sammlung fort: 25) [Formel] 26) [Formel] 27) 28)
Und so weiter für noch mehr Terme:
1; a; 1 = 1; ă; 1 0 ɟ a ɟ 0 = 0 ɟ ă ɟ 0
1; a; 1; b; 1 = 1; b; 1; a; 1 0 ɟ a ɟ 0 ɟ b ɟ 0 = 0 ɟ b ɟ 0 ɟ a ɟ 0.
Nicht nur ist die Reihenfolge von Relativen, welche einzeln zwischen lauter relative Faktoren 1 sich eingeschaltet finden, allemal gleichgültig; sondern es können auch irgend welche dieser Relative durch ihre Konverse ersetzt werden, desgleichen ist es erlaubt, ein jedes dieser Relative, wie a, zu ersetzen durch ein relatives Produkt von beliebig viel Faktoren, welche abwechselnd es selbst und sein Konverses sind, wie a; ă, ă; a, a; ă; a, ă; a; ă, a; ă; a; ă, etc., sowie umgekehrt jedes solche Produkt zwischen den relativen Faktoren 1 in das Relativ a selber zusammengezogen werden darf.
Ein dual entsprechender Satz gilt für Relative die sich zwischen lauter relative Summanden 0 eingestreut finden.
Aus S. 151 wiederholt, und schon aus 3) und 6) bis 9) des § 11 ersichtlich.
Beweis leicht aus den drei letzten Formelgespannen zu führen.
Die Formeln 25), 26), 27), 28) sind bezüglich als 20) des § 18, 22) § 18, 9) § 10 und (implicite) 3) des § 11 bereits vorgekommen und bedürfen darum keines Beweises mehr.
Ihnen reihen wir die Formeln 29), 30) an, die als 16), 17) des § 18 vorkamen: 29) [Formel] Insbesondre: 30) [Formel] desgleichen a und ā̆ vertauscht.
Korollar: 31) [Formel] Unter der nächsten Chiffre geben wir miscellenhaft einige Sätzchen, die als Übung zu beweisen: 32) etc. (d. h. die Gespanne sind noch konjugirt zu ergänzen). a; b · a; b̄ ⋹ a; 1, a; b · ā; b ⋹ 1; b (a; 1)b; c(1; d) = a; 1 · b; c · 1; d = a; 1; d · b; c 1; (ă; 1)b; 1 = 1; a(1; b̆); 1 = 1; a; b; 1 a ɟ 0 ɟ a ⋹ a ⋹ a; 1; a, (a; 1 ⋹ ā) = (a = 0)
0 ɟ a ɟ 0 ⋹ a ⋹ 1; a; 1, (ā; 1 ⋹ a) = (a = 1)
(a ɟ 0 + ā); 1 = 1 a; 1 · ā ɟ 0 = 0 (ā̆ + 0 ɟ a); 1 = 1 ā̆ · 1; a ɟ 0 = 0 {a + (ā ɟ 0)b}; 1 = (a + b); 1 a(ā; 1 + b) ɟ 0 = ab ɟ 0 {a + (0 ɟ ā)b}; 1 = a; 1 + b; (ā̆ ɟ 0) a(1; ā + b) ɟ 0 = (a ɟ 0)(b ɟ ā̆; 1)
(ā ɟ b ⋹ a; b) = (a; 1 = 1) (a ɟ b ⋹ ā; b) = (a ɟ 0 = 0) (a ɟ b̄ ⋹ a; b) = (1; b = 1) (a ɟ b ⋹ a; b̄) = (0 ɟ b = 0).
Von den Beweisen ist vielleicht der des Satzes in der zweiten Zeile von 32) am wenigsten leicht zu finden:
Man konvertire in ā̆; 1 + (0 ɟ a); 1 das zweite Glied, welches ja ein ausgezeichnetes Relativ ist, und kommt für b = ă ɟ 0 auf den Satz 2): b̄ + 1; b = 1.
Das letzte Quadrupel von Sätzen, die man als Aussagensubsumtionen vor- und rückwärts leicht beweisen wird, indem man die beiderseitigen Aussagen etwa rechts auf 0 bringt, bildet den Kern von Peirce’s Betrachtungen in 5 auf p. 54, der sie dort mittelst Argumentirens auf die Elementepaare oder deren Negate gewinnt.
Der Studirende oder Historiker, der sich einen Begriff zu bilden wünscht von den Schwierigkeiten, die ich behufs Berücksichtigung der Vorarbeiten zu überwinden hatte, wolle einmal versuchen, nach alledem und unter Benutzung des in § 29 von mir gegebnen „Schlüssels“ zu dieser Abhandlung von Peirce, die l. c. von diesem Autor gegebne Deduktion zu verstehen.
Einmal aufmerksam gemacht sei auch im Haupttext auf diese Gruppe von Formeln: 33) [Formel] 34) 35) 36) 37) [Formel] deren Beweis so leicht ist — und zwar mittelbar, ohne Zuhülfenahme der Koeffizientenevidenz, dass wir glauben, darüber keine Worte verlieren zu sollen.
a; b ⋹ a; 1; b a ɟ 0 ɟ b ⋹ a ɟ b
a; 1 + a; b = a; 1, a; b + 1; b = 1; b (a ɟ 0)(a ɟ b) = a ɟ 0, (a ɟ b)(0 ɟ b) = 0 ɟ b
a; 1 · a; b = a; b = a; b · 1; b a ɟ 0 + a ɟ b = a ɟ b = a ɟ b + 0 ɟ b
Wir fügen hinzu: 38) [Formel] wonach denn auch sein muss (Korollar):
a; b + a ɟ b̄ = a; b + 0 ɟ b̄ (a ɟ b) · a; b̄ = (a ɟ b) · 1; b̄ a; b + ā ɟ b = a; b + ā ɟ 0 (a ɟ b) · ā; b = (a ɟ b) · ā; 1.
Die erste der Formeln 38) ergibt sich durch Umstellen der Glieder aus 1; b ⋹ a; b + ā; b.
Soviel über primäre Formeln (im Boole’schen Sinne).
Was sekundäre betrifft, so ist zunächst in Erinnerung zu rufen der als 22) des § 9 sowie als 35) des § 15 bereits vorgekommne Satz: 39) und diesem schliesst sich als ein neuer Satz der folgende an: 40) [Formel] welcher für das Folgende fundamental ist und somit den Übergang von unsrer Formelsammlung zur Theorie der Systeme bildet.
(a; 1 = 0) = (a = 0) = (1; a = 0) (a ɟ 0 = 1) = (a = 1) = (0 ɟ a = 1),
Behufs Beweises brauchen wir nur die Äquivalenz der Subsumtionen (a; 1 ⋹ a) = (a ⋹ a ɟ 0) darzuthun, sintemal die rückwärtigen ohnehin gelten.
Sie besteht aufgrund des ersten Inversionstheorems.
Zudem ist in der That (a; 1 ⋹ a) = Πh k(Σlah l ⋹ ah k) = Πh(Σlah l ⋹ Πkah k), (a ⋹ a ɟ 0) = Πh k(ah k ⋹ Πlah l) = Πh(Σkah k ⋹ Πlah l), wobei offenbar die rechten Seiten nur in den Namen laufender Zeiger differiren, q. e. d.
Die übrigen Äquivalenzen unter 40) ergeben sich aus der hiemit bewiesenen durch Kontraposition und Konjugation.
Die einander äquivalenten Gleichungen der ersten Zeile von 40) sind nun die verschiednen Formen der Charakteristik des „Systems“.
Wir nennen jedes Relativ a ein System, wenn es die Forderung a; 1 ⋹ a oder also die a; 1 = a erfüllt. 1 und 0 sind Systeme.
Da i; 1 = i bekanntlich — vergl. 2) des § 25 — ist, so muss jedes Element ein System sein und kann (siehe nachher) in der That als ein „einelementiges System“ bezeichnet werden.
Die Gleichungen der zweiten Zeile von 40) charakterisiren ebenso ein Relativ als Systemkonvers.
Denn wenn ă für a darin gesagt wird, so folgen sie (durch beiderseitiges Konvertiren) aus denen der ersten Zeile, und umgekehrt.
Auch das Negat eines Systems ist ein System, das Negat eines Systemkonverses wiederum Systemkonvers — wie aus der Symmetrie der Formeln 40) hinsichtlich a und ā unmittelbar einleuchtet.
Ebenso muss Summe und Produkt zweier Systeme wieder ein System sein, d. h. wir haben den Satz: 41) (a; 1 = a)(c; 1 = c) ⋹ {(a + c); 1 = a + c}(ac; 1 = ac).
Behufs Beweises der ersten Behauptung braucht man nur die Prämissen mit Rücksicht auf 4) des § 6 überschiebend zu addiren; die zweite Behauptung ergibt sich mit ac; 1 ⋹ a; 1 · c; 1 = ac nach 5) des § 6 mit Rücksicht auf die Geltung der umgekehrten Subsumtion.
Die vorstehenden Sätze lassen sich zusammenfassend verallgemeinern zu dem Theorem:
Jede „Funktion im identischen Kalkul von lauter Systemen muss auch ein System sein.
Für die relativen Knüpfungen eines Systems (oder „absoluten Terms“, siehe weiter unten) a = a; 1 mit einem beliebigen Relativ b gelten nun die Formeln:
Sofern a; 1 = a: 42) [Formel] 43) [Formel] — desgleichen ā für a gesetzt.
Dieselben fliessen nach der Voraussetzung sofort aus 16) — oder 17), cf. 40) — und 21) — oder 22) — letztres indem (1; ă)b; 1 = b; a; 1 wegen 1; ă = ă, etc. die erste Formel 43) gibt.
Endlich für die relativen Knüpfungen von zwei Systemen (oder „Klassen“, siehe weiter unten) a = a; 1 und c = c; 1 haben wir die Sätze:
Sofern a; 1 = a, c; 1 = c: 44) [Formel] desgleichen ā für a oder c̄ für c, oder beides gesetzt. 45) 46) desgleichen a oder c, oder beide, mit Negationsstrich versehen.
a; c̆ = ac̆ a ɟ c̆ = a + c̆
ă; c = c̆; a = 1; ac = ăc̆; 1 ă ɟ c = c̆ ɟ a = 0 ɟ (a + c) = (ă + c̆) ɟ 0,
Diese Formeln fliessen leicht durch die Annahme b = c und eventuelle Vertauschung von a mit c aus denen 42) und 43).
Dass bei 46) 1; ac seinem Konversen gleich sein muss, geht daraus hervor, dass nach 41) 1; ac = 1; ac; 1 ein ausgezeichnetes Relativ sein muss.
Demnach gilt:
Ein Systemkonvers von einem Systeme ist entweder 1 oder 0, jenachdem beide Systeme etwas gemein haben oder nicht.
Ein System von einem Systemkonverse ist immer das (identische) Produkt beider (also ein Augen-Quaderrelativ).
Für ein System von einem Systeme gilt nach 44), weil auch 1; c = 1; c; 1 ein ausgezeichnetes Relativ ist: Korollar zu 44) [Formel] insbesondre muss also unbedingt sein: a; a = a = a ɟ a, d. h. bei Systemen (und Systemkonversen) gilt auch für die relativen Knüpfungen eine Art „Tautologiegesetz“.
Da i ≠ 0 ist, hat man jedenfalls auch a; i = a, d. h. Ein System von irgend einem Elemente ist jenes selber.
Ein Element von einem Systeme ist gedachtes Element selbst, sobald das System kein leeres (d. h. ≠ 0 ist).
Genauer:
Ein bestimmtes Element i von einem bestimmten Systeme a, das heisst i; a, ist = i · 1; a; 1, mithin i selbst, sobald a nicht 0 ist, andernfalls 0.
Wir fragen: Fällt dieser Begriff zusammen mit dem: das Element i des Systems a?
Die Antwort lautet: nein!
Letzteres (natürlich in der suppositio nominalis betrachtet) ist ein konnotativer Name, gleichbedeutend mit: das Element i, welches (nebenbei gesagt) dem System a angehört.
Der Relativsatz ist dabei ein prädikativer und nicht ein determinativer — vergl. Bd. 1, S. 221 sq.
Das bestimmte Element i ist als solches durch diesen seinen Namen schon hinreichend, nämlich vollständig, gekennzeichnet.
Entweder gehört dasselbe dem System a an oder nicht.
Im ersten Falle ist (i ⋹ a) = 1, im letztern (i ⋹ a) = 0.
Das Element i, welches dem a angehört, das ist „i(i ⋹ a)“ wird also = i · 1 = i sein, wird einfach i vorstellen im erstern Falle, dagegen = 0 sein, nichts vorstellen im letztern Falle; in diesem nenne ich den Namen für die Logik einen undeutigen oder sinnlosen, mögen Psychologen oder die es zu sein glauben auch noch so viel Empfindungsgehalt, Bedeutung und Sinn darin entdecken.
Diese Entscheidung fällt nun mit dem obigen Resultat nicht zusammen, wonach ja i; a = i zu gelten hat, sobald nur a ≠ 0 ist, unbekümmert darum, ob i ⋹ a ist oder nicht.
Hiedurch werden wir auf einen Doppelsinn in der Wortsprache aufmerksam:
es sind zwei ganz verschiedene Partikeln „of“ in „element of a system“ und in „lover of a benefactor“.
Jene ist nicht die Übersetzung des Zeichens (;) der relativen Multiplikation.
Die Präposition „von“, sofern sie einen genitivus partitivus oder possessivus vertritt, erfüllt eine andre Bestimmung, funktionirt logisch anders, als bei der Zusammensetzung von Relativen.
Fällt gar der Ausdruck: „ein System von Elementen“, so kann dieses von“ noch weniger für die Partikel der Komposition von Relativen ausgegeben werden, die wir in „Wohlthäter von einem Dienenden“ beispielsweise erblicken.
Dies nur ganz beiläufig.
Noch nimmt uns ja die Algebra der Relative zu sehr gefangen.
Ein Elementkonvers von einem Elementkonvers endlich ist immer das letztere Elementkonvers selbst, sofern das erstere nicht verschwindet; im andern Falle ist es = 0.
Die dualen Sätze für die relativen Summen auszusprechen sei dem Leser überlassen.
Den Sätzen über Systeme und deren Konverse sind von rechtswegen auch die Theoreme noch anzureihen, welche sich aufstellen lassen über die Einordnung zwischen solchen und Moduln, sowie zwischen jenen unter sich und — noch allgemeiner — über die Einordnung zwischen Quaderrelativen.
Denn die Quaderrelative beider Arten, d. i. sowol der Form a; 1; b als der a ɟ 0 ɟ b, begreifen ja, wie man für b oder a gleich 1 resp. 0 sofort erkennt, auch die Systeme und Systemkonverse als Partikularfälle unter sich.
Die Einordnung zwischen Quaderrelativen und Moduln wurde schon S. 291 sq. erledigt.
Man kann als Sonderfälle für Systeme — in Ergänzung von 39) — auch noch notiren: 47) [Formel] — Formeln, deren konjugirte hinzuschreiben wir dem Leser überlassen, und die auch äusserst leicht direkt zu beweisen sind.
Über Einordnung zwischen Relativen der vier Formen a; 1, 1; a, a ɟ 0, 0 ɟ a ergeben sich mir die Sätze: 49) [Formel] 50) [Formel] wo die mittlere Subsumtion der ersten oder letzten gleichgesetzt zu lesen.
Nicht auf einfachere Ausdrucksformen zurückführbar scheint das (zu sich selbst duale, also) konjugirte Zweigespann von Relationen zu sein:
[Formel] — es sei denn, dass man die erstre, z. B., in ab̄ ɟ 0 = 0 oder 1 = (ā + b); 1 umschreiben wollte.
Dagegen gilt das Viergespann, sowie die zugleich dualen und konjugirten Zweigespanne von Formeln: 51) [Formel] 52) [Formel]
Der Beweis der behaupteten Äquivalenzen als vor- und rückwärtige Aussagensubsumtionen ist durch beiderseitig relatives Multipliziren mit 1 etc. der Prämisse, ev. nach dem ersten Inversionstheoreme, und mit Rücksicht auf die Eigenschaften der ausgezeichneten Relative durchweg leicht zu führen.
Z. B. bei der letzten 53) schliesse man aus der linkseitigen Prämisse zunächst: 1; a; 1 ⋹ 0 ɟ b ɟ 0, wonach denn entweder 1; a; 1 = 0 oder 0 ɟ b ɟ 0 = 1 sein muss, etc.
Zu 52) schliesst man aus der ersten Subsumtion sowol 1; (a ɟ 0) ⋹ 1; b als a ɟ 0 ⋹ 1; b ɟ 0, woraus nach 6) S. 147 folgt 1; b = 1 sobald a ɟ 0 ≠ 0, und a ɟ 0 = 0 sobald 1; b ≠ 1. Etc.
Inbezug auf Einordnung zwischen Quaderrelativen von beiderlei Art sind vier Möglichkeiten in’s Auge zu fassen, die sich zu drei Gespannen vereinigen.
Fürs erste gilt als duales Zweigespann der Satz: 54) [Formel] , worin auch (a = 0) + (b = 0) durch (a ɟ 0 ɟ b = 0) und (c = 1) + (d = 1) durch (c ɟ 0 ɟ d = 1) ersetzbar wäre nach 26) S. 291.
Beweis.
Es zerfällt L = (a; 1 · 1; b ⋹ c; 1)(a; 1 · 1; b ⋹ 1; d).
Der erste Aussagenfaktor gibt a fortiori die Konklusion: (a; 1)(1; b); 1 ⋹ c; 1; 1 oder a; 1 · 1; b; 1 ⋹ c; 1.
Nun ist entweder b = 0 und alsdann diese Forderung erfüllt, oder b ≠ 0, 1; b; 1 = 1, wo sie auf a ⋹ c; 1 nach 49) hinausläuft — womit denn aus jenem: (a ⋹ c; 1) + (b = 0) gefolgert ist; der Rückschluss ist selbstverständlich, mithin unser erster Faktor äquivalent dieser Konklusion.
Man kann jedoch auch sofort nach bekannten Sätzen transformiren: a; 1 ⋹ c; 1 + 0 ɟ b̄, a ⋹ (c; 1 + 0 ɟ b̄) ɟ 0 = c; 1 + 0 ɟ b̄ ɟ 0, etc.
Analog ist der zweite Aussagenfaktor von L zu behandeln — womit die erste Zeile von 54) bewiesen ist.
Die zweite erhält man daraus durch Ausmultipliziren unter Weglassung eingehender Aussagenterme, q. e. d.
Sodann gilt der ein „Eingespann“ von Formeln bildende Satz: 55) [Formel]
Derselbe beweist sich, indem man zunächst die Prämisse L zerfällt in die vier Aussagen: L = (a ɟ 0 ⋹ c; 1)(a ɟ 0 ⋹ 1; d)(0 ɟ b ⋹ c; 1)(0 ɟ b ⋹ 1; d), sodann die beiden mittleren nach Schema 52) umschreibt in {(a ɟ 0 = 0) + (1; d = 1)}{(0 ɟ b = 0) + (c; 1 = 1)}, endlich alles ausmultiplizirt, mit Unterdrückung eingehender, d. h. durch die übrigen von selbst bedingter (oder erfüllter) Aussagenfaktoren — so z. B. wenn bereits c; 1 = 1 sein muss, so braucht a ɟ 0 ⋹ c; 1 als selbstverständlich nicht mehr notirt zu werden.
Nun fehlt nur mehr ein Satz über Subsumtionen der Form: a; 1; b ⋹ c ɟ 0 ɟ d — das wäre, rechts auf 0 gebracht, eine Relation a; 1; b · c̄; 1; d̄ = 0.
Eine solche ist nicht zerfällbar und scheint sich überhaupt nicht in Alternativen oder Systeme von einfachern Relationen auflösen zu lassen.
Dagegen lässt sie sich noch auf drei Arten in Relationen der nämlichen Form umschreiben.
Letzteres aufgrund des Satzes: 56) der nach 16) aufgrund des Kommutationsgesetzes leicht zu erweisen ist.
Darnach begreift sich sogleich, dass (a; 1; b ⋹ c ɟ 0 ɟ d) = (a; 1; d̄ ⋹ c ɟ 0 ɟ b̄) = (c̄; 1; b ⋹ ā ɟ 0 ɟ d) und auch = (c̄; 1; d̄ ⋹ ā ɟ 0 ɟ b̄), welch letzteres aber, als aus Kontraposition der Prämisse unmittelbar ersichtlich, nicht mit aufgeführt zu werden braucht. —
a; 1; b · c; 1; d = a; 1; d · c; 1; b a ɟ 0 ɟ b + c ɟ 0 ɟ d = a ɟ 0 ɟ d + c ɟ 0 ɟ b,
Damit schliessen wir unsre auf Gewinnung einer Formelsammlung gerichtete Aufstellung von Sätzen über Systeme vorläufig ab — obzwar dieselbe zweifellos noch mancher Ergänzung bedarf, die sich eben erst bei der Weiterentwicklung der Disziplin und bei ihren Anwendungen auf die vielseitigsten Gebiete erkennen lassen und als wünschenswert aufdrängen wird.
Jedoch nicht ohne noch einen Ausblick auf eine nächste Gruppe von Problemen zu eröffnen.
Die Quaderrelative bilden eine nächstübergeordnete Klasse von Relativen zu den Systemen und Systemkonversen.
Wie schon S. 291 statuirt wurde, führen auch die Spezies der Negation und Konversion nicht aus dem Kreis der Quaderrelative heraus, und ferner ist leicht zu sehen, dass identische Multiplikation von lauter Augenquaderrelativen immer wieder ein solches liefern, desgleichen die Summe von Lückenquaderrelativen ein ebensolches Relativ sein muss.
(Spezieller gilt:
System plus oder mal System gleich System.
Ebenso Systemkonvers plus oder mal Systemkonvers gleich Systemkonvers.
System mal Systemkonvers gleich Augenquaderrelativ.
System plus Systemkonvers gleich Lückenquaderrelativ.)
Es ist z. B. a; 1; b · c; 1; d = a; 1 · c; 1 · 1; b · 1; d = System mal Systemkonvers mithin Augenquaderrelativ, wie behauptet.
Aber schon die Summe zweier Augen-, das Produkt zweier Lückenquaderrelative, nicht minder wie Summe oder Produkt eines Augen- mit einem Lückenquaderrelativ braucht kein Quaderrelativ mehr zu sein, wie es leicht konstruirbare einfache Beispiele darthun.
Von den Quaderrelativen (oder Systemen und deren Konversen) aus wird man also schon durch die identischen Knüpfungen zu einer noch allgemeineren Klasse von Relativen geführt, und verdiente es untersucht zu werden, mit welchem Relativbegriffe, als dem allgemeinsten so erhältlichen, die „Gruppe“ derselben abschliesst.
Dies sei Forschern empfohlen.
Was das Rechnen mit Systemen (und deren Konversen) in unsrer Algebra betrifft, so ist dem Studirenden anzuraten, dass er sich von der Nötigung, Formeln nachzuschlagen, baldigst zu emanzipiren suche und darnach strebe, sich auf den Standpunkt des Bias, zu dem „Omnia mea mecum porto“, emporzuringen.
Es ist das nicht so schwer, als es bei der fast übergrossen Menge der Formeln anfänglich aussieht, und man wird bei einiger Praxis bald diejenigen unter denselben inne werden, welche gleichsam den Angelpunkt der ganzen Technik bilden.
Noch häufig detaillirt von uns durchgeführte Rechnungen werden die Aneignung dieser Kunst erleichtern.
Wichtig bleibt dabei, dass man jeden Ausdruck, der ein System vorstellen muss, auch rasch als ein solches erkenne.
Hierauf deutet in der Regel schon ein relativer Endfaktor „; 1“ oder Endsummand ɟ 0“ beim ersten Blick hin, und zwar nicht nur wenn er ein freier, sondern auch wenn er ein in freier relativer Knüpfung gebundener ist.
Nicht nur nämlich muss, wie selbstverständlich, jedes Relativ der Form (a ɟ b); 1, a; b ɟ 0 System sein, sondern auch ein jedes von der Form a ɟ b; 1 = a ɟ (b; 1), a; (b ɟ 0), wie sogleich zu sehen, indem man b; 1 durch b; 1 ɟ 0, b ɟ 0 durch (b ɟ 0); 1 ersetzt denkt.
Dagegen würden ungeachtet der terminalen 1 oder 0 natürlich a; b(c; 1), a ɟ (b + c; 1), a; b(c ɟ 0) etc. kein System im allgemeinen vorstellen.
Die Endung auf 1 oder 0 kann jedoch auch durch das Symbol i oder ī eines Elementes oder Elementnegates vertreten sein, ohne dass der Ausdruck darum aufhörte ein System vorzustellen (sintemal eben i = i; 1 = i ɟ 0 etc.).
Und inbezug auf Systemkonverse spielt ein Anfangsterm 1 oder 0 sowie ĭ und ī̆ die analoge Rolle.
Bildet man für ein System a = a; 1 den allgemeinen Relativkoeffizienten zum Suffix ij, so bemerkt man dass derselbe 57) ai j = (a; 1)i j = Σhai h unabhängig von j, d. h. unabhängig von seinem zweiten Index ist.
Es erscheint dadurch nahe gelegt, den letztern, der durch jeden beliebigen Elementbuchstaben vertreten werden kann, als belanglos zu unterdrücken, mithin festzusetzen, dass (58) ai j(= ai h = ai k = …) = ai — für a = a; 1 — gelten solle.
[Der Tautologiegesetze halber wird dann auch Σhai h = Πhai h gleich ai, wie überhaupt a; 1 = a ɟ 0 sein müssen.]
Diese Festsetzung schliesst sich den fundamentalen Konventionen des § 3 an.
Wird sie zugrunde gelegt, so gelten folgende Darstellungen: 59) [Formel] für jedes System a, d. h. für jedes Relativ a, das = a; 1 ist.
Zur Begründung und Erläuterung von diesen ist Mehreres zu sagen.
Wir beweisen zunächst die erste von den Formeln, indem wir für L = a und R = Σiaii die Übereinstimmung des allgemeinen Koeffizienten zum Suffix hk nachweisen.
Wir haben Lh k = ah k und wegen 57), (8) des § 3, 12) des § 8 und (58):
Rh k = Σiaiih k = ΣiΣlai l1'i h = ΣlΣiai l1'i h = Σlah l = ah, mithin nach (58) in der That Lh k = Rh k.
Dafür, dass hier sogleich (Σaii)h k = Σaiih k gesetzt worden, sind nur die Festsetzungen (15) und (10) des § 3 — mit Rücksicht etwa auf die Bemerkung am Schlusse des § 10 — anzuziehen gewesen.
Nach eben bewiesenem Schema der ersten Gleichung 59) muss nun, weil, wenn a System ist auch ā System sein wird, auch gelten: ā = Σiāii — wobei über die Bedeutung des Koeffizienten āi = (ā)i = Σhāi h kein Zweifel obwalten kann.
Nach der Bemerkung in [ ] unter 58) ist dies jedoch auch = Πhāi h = Σhai h͞ und damit als ein Satz bewiesen: 60) āi = (ai)͞.
Hiernach aber geht aus unsrer Darstellung von ā durch Kontraposition die zweite Darstellung, von a = Πi(ai + ī), im Gespanne 59) hervor, der eine ähnliche für ā entsprechen wird.
Aus den hiemit gerechtfertigten beiden Doppelgleichungen der ersten Zeile von 59) folgen sodann die der zweiten Zeile mittelst beiderseitigen Konvertirens.
Dabei wird nur zu beachten sein, dass, weil ai blos = 0 oder = 1 sein kann und diese in unsrer Theorie mit den Wahrheitswerten identifizirten Moduln durch Konvertiren nicht geändert werden, auch 61) (ai)͝ = ai bleibt — wovon aber ăi = (ă)i, wie nachher zu sehn, wohl unterschieden werden muss.
Mit dem ersten Satze des Gespannes 59) ist nun bewiesen:
Jedes System ist darstellbar als eine Summe von Elementen (welche natürlich derselben eingeordnet sein werden), es ist ein Inbegriff von in ihm enthaltnen Elementen, desgleichen ist es darstellbar als identisches Produkt („Gemeinheit“) von Elementnegaten, den Negaten solcher Elemente die nicht in ihm enthalten sind — und zwar, wie noch zu sehn, von allen diesen.
Die Darstellung ist nur auf eine Weise möglich.
Was nämlich die erstere betrifft, so gilt für a = a; 1 und b = b; 1 der Satz: 62) (a = b) = Πi(ai = bi), ebenso (a ⋹ b) = Πi(ai ⋹ bi).
Denn wegen ai j = ai, bi j = bi haben wir im Hinblick auf (14) des § 3 und Korollar, S. 33 (ai j = bi j) = (ai = bi) auch für jedes j, etc. q. e. d.
Wären nun zwei Darstellungen a = Σiaii und a = Σibii zulässig, so müsste, wegen a = a, für jedes i sein bi = ai, d. h. die beiden müssten ganz und gar zusammenfallen; sie wären nicht zweierlei, sondern eins.
Wenn damit die Eindeutigkeit der additiven Darstellung von a erwiesen ist, so folgt die der multiplikativen durch Kontraposition.
Denn hätten wir zwei verschiedene multiplikative Darstellungen für a, so würden sich durch beiderseitiges Negiren auch zwei verschiedene additive Darstellungen für ā ergeben, was bereits für ein „System“ ā, so gut wie für a, als unmöglich erwiesen ist, q. e. d.
Der allgemeine Systemkoeffizient ai hat die Bedeutung der Aussage: i ist ein Element von a, d. h. wir haben (Peirce8 p. 197, 6p. 2) 63) (ai = 1), = ai = (i ⋹ a) — als ein merkwürdiges Gegenstück zu 17) des § 25.
Um dies zu beweisen, braucht man sich blos die Bedeutung der Subsumtion (i ⋹ a), als Πh k(ih k ⋹ ah k) = ΠhΠk(1'i h ⋹ ah) = Πh(0'i h + ah = 1) = Πh(0'i h + ah) = ai nach 12) des § 8, zu vergegenwärtigen.
Wir können jetzt also sagen: das System ist die Summe, der Inbegriff seiner Elemente.
Wird der Wert aus 63) in die erste Gleichung 59) eingesetzt, so erhalten wir die Darstellung: a = Σi(i ⋹ a)i, welche wesentlich zusammenfällt mit derjenigen, die wir in Bd. 2 S. 345 ‥ 348 in eigenartiger Betrachtungsweise aufstellten.
Wäre ich damals schon weit genug in das Verständniss von Peirce’s Theorie der Relative eingedrungen gewesen, so würde ich nicht unterlassen haben, an dortiger Stelle zu bemerken, dass diese Darstellung bereits in letzterer von andern und bessern Gesichtspunkten aus gewonnen und zudem (bei ihrer geeignet modifizirten Übertragung auf die höheren Denkbereiche) noch weit überholt worden.
Insbesondre ist nun auch der zweite Denkbereich 12, das ist der absolute Modul 1, als binäres Relativ betrachtet, ein „System“, und zwar gilt: 64) 1 = Σii, 0 = Πiī. 1 ist also (auch im zweiten Denkbereiche) das umfassendste, das Universum, Totum aller Systeme, nämlich die Summe sämtlicher „Elemente des ersten Denkbereiches.
Jenes folgt schon aus 1; 1 = 1.
Um dieses, d. h. die erste Formel 64) zu beweisen, ist Lh k = Rh k, d. h. 1h k = 1 = Σiih k = Σi1'i h zu zeigen, welches zutrifft, weil die Summe bei h = i das Glied 1'i i, = 1, enthält. —
Ebenso ist wegen 0; 1 = 0 auch der Modul 0 „ein System“; er kann das Nullsystem oder leere System genannt werden.
Nach 58) sind wir damit nun auch berechtigt, in unsrer ganzen Theorie zu schreiben:
1i j = 1i, 0i j = 0i und müssen allgemein haben: 65) 1i = 1, 0i = 0.
Auch die in unserm Buche stillschweigend sich vollziehende Verdrängung der Benennung von 1 und 0 als „identische Moduln“ durch den Namen „absolute Moduln“ erscheint damit nachträglich gerechtfertigt.
Ist b = ă ein „Systemkonvers“, mithin b = 1; b, so kann man analog zu 47) bemerken, dass der allgemeine Koeffizient dieses Relativs: bi j = (1; b)i j = Σhbh j unabhängig von i ist.
Dadurch erschiene es von vornherein nahe gelegt, den ersten Index i als belanglos zu unterdrücken und unser bi j, = bh j = bk j = …, kürzer blos mit bj zu bezeichnen.
Nachdem aber die Festsetzung (58) bereits getroffen ist, nach welcher uns vielmehr bj = bj i = bj h = … mit der Unterstellung b = b; 1 wird zu bedeuten haben, erscheint solches nicht mehr angängig:
man kann ja dem einfachen Suffixe nicht ansehen, ob es den Überrest des ersten oder den des zweiten Index aus einem doppelten Suffixe als einzig verbleibenden Zeiger zu vertreten habe!
Überhaupt dürfen wir auch mit solchen „Unterstellungen“ nicht regellos wechseln, sondern müssen, um eine reine „Theorie der Systeme“ zu erhalten, die eine Unterstellung konsequent festhalten: dass uns die einfachen Buchstaben jeweils Systeme vorstellen, somit für ein a, b, x, u die Annahmen a = a; 1, b = b; 1, x = x; 1, u = u; 1 stillschweigend zugrunde gelegt werden.
Trifft dies für jene zu, so muss es auch für die mit Negationsstrich versehenen Buchstaben zutreffen, nach 40) auch ā = ā; 1, etc. sein.
Aber für die mit Konversionsringel versehenen Buchstaben wird es nicht zutreffen.
Eine inbezug auf Systeme allgemeine Formel wird daher niemals in dem Sinne allgemein sein, dass man — gleichwie in den schlechthin allgemeinen Formeln — die Buchstaben auch durch ihre Konverse ersetzen dürfte.
Mit der Unterstellung a = a; 1 oder der Annahme, dass a System sei, haben wir vielmehr im Einklang mit (58): ăi j = (1; ă)i j = Σhăh j = Σhaj h = aj i = aj, also ăi j = aj.
Und wird hierin ă = b genannt, so entsteht mit der Unterstellung b = 1; b, das ist, als für Systemkonverse b gültig: 66) bi j = bh j = bk j = … = b̆j.
Diese Abkürzung: in b̆j — im Gegensatz zu der wie gezeigt verwerflichen in bj — ist legitim, und sie erklärt den Sinn des Symbols oder Koeffizienten b̆j für die Fälle, wo ihm eine Erklärung bislang zuteil geworden, nämlich für die, wo b̆ ein System vorstellt.
Etabliren wir jetzt auch noch die Sätze: 67) 68) als geltend, sofern alle a und b Systeme vorstellen, immer a = a; 1, b = b; 1 ist — welche Sätze in der That mit Rücksicht auf (58) durch die Festsetzungen (10) und (15) des § 3 unmittelbar gewährleistet erscheinen — so haben wir schon alles wesentliche Material gewonnen, um eine sehr wichtige Bemerkung vorzubereiten.
(ab)i = aibi (a + b)i = ai + bi
(Πa)i = Σai (Σa)i = Σai
Dieser wollen wir jedoch noch eine weitere lehrreiche Betrachtung voraufgehn lassen.
Fundamental ist auch noch dieser Satz: 69) [Formel] . Derselbe ist vor- und rückwärts als eine Aussagensubsumtion zunächst zu beweisen.
Vorwärts.
Ist die linkseitige Aussage L erfüllt, so dürfen wir nach § 25 das dadurch als ein „Element“ charakterisirte Relativ x etwa i nennen.
Dann sind die Folgerungen i ≠ 0 und i; 1 = i bereits längst aus dieser Charakteristik gezogen und handelt es sich nur noch darum darzuthun, dass für jedes System u sein müsse: (i ⋹ u) + (i ⋹ ū) = 1.
Nach 63) läuft dies aber in der That hinaus auf die Selbstverständlichkeit ui + ūi = 1.
Rückwärts ist aus den Voraussetzungen R der rechten Seite von 69) die Behauptung linkerhand oder die nach 8) des § 25 mit ihr äquivalente Aussage: Σi(x = i) zu schliessen.
Nun können wir in R unter den Relativen u auch die Elemente i des ersten Denkbereiches hervorhebend verstehen, indem wir die auf andre Relative u bezüglichen Faktoraussagen von R unterdrücken oder ungenutzt lassen.
Darnach bleibt von R bestehen: R' = (x ≠ 0)(x; 1 = x)Πi{(x ⋹ i) + (x ⋹ ī)} und dies genügt bereits, um L zu folgern.
Von der Alternative hinter Π können nämlich (wie früher schon erwähnt) niemals (d. i. für kein i) beide Gliederaussagen zugleich zutreffen, weil sonst (x ⋹ i)(x ⋹ ī), = (x ⋹ iī = 0) im Widerspruch zu x ≠ 0 folgen würde.
Unfehlbar hat also jeweils das eine Glied der Alternative den Wahrheitswert 1, das andre dann den (Unwahrheitswert)
0. Es kann aber auch nicht durchweg das zweite Glied den Wahrheitswert 1 haben, weil man mit der Annahme Πi(x ⋹ ī), = (x ⋹ Πiī) = (x ⋹ 0) wegen 64) auf den nämlichen Widerspruch kommen würde.
Folglich gibt es mindestens ein Element i, für welches das erste Glied der Alternative erfüllt ist, somit gilt: (x ≠ 0)(x; 1 = x)(x ⋹ i), was = (x = i) nur mehr noch nachzuweisen bleibt.
Da ih k = 1'i h = 0 für h ≠ i und x ⋹ i ist, so muss auch jedes xh k = 0 für h ≠ i sein und können höchstens die xi k gleich 1 werden.
Wegen x; 1 = x sind aber nach k alle xi k einander gleich und = xi; letzteres kann nicht 0 sein, weil sonst x = 0 folgte; also muss xi, das ist nach k jedes xi k, gleich 1 = 1'i i = ii k sein; und da für h ≠ i auch schon xh k = 1'i h = ih k erwiesen war, so ist allgemein xh k = ih k und x = i dargethan, q. e. d.
— Weil alle Elemente unsres ersten Denkbereichs verschieden sind, so kann es natürlich nur eines dieser Elemente sein, welchem x eingeordnet folglich gleich ist, und dieses ist dann in Erfüllung des zweiten Glieds unsrer Alternative in dem Negate jedes andern Elementes enthalten. —
Denkt man sich die linkseitige Aussage im Satze 69) durch das Urteil ersetzt:
„x ist ein Element“, und macht man die Unterstellung, dass alle Buchstaben eo ipso Systeme vorstellen, d. h. beschränkt man sich mit den Betrachtungen ganz und gar auf den Denkbereich der Systeme, so werden in der rechten Seite von 69) die Aussagenfaktoren x; 1 = x, u; 1 = u als selbstverständlich erfüllte unterdrückbar und lehrt jener Satz:
[Formel] , oder, wenn wir durch Bezeichnung des x mit dem Buchstaben i die linke Seite zu einer selbstverständlichen machen, so resultirt die Behauptung, dass [Formel] den Wahrheitswert 1 habe, oder gelte.
Aus der Übereinstimmung dieser Resultate mit der Individuumsdefinition des Klassenkalkuls erhellt nun also, dass in dem, aus 11 schon ganz hervorgehenden, Denkbereich der Systeme das „Element“ die Rolle des „Individuums“ spielt.
Die nunmehr genügend vorbereitete Bemerkung, um die es uns zu thun war, zielt dahin ab, zu konstatiren: dass in der Algebra der binären Relative die Theorie der „Systeme“ dasjenige unter sich begreift, was man „die Theorie der uninären Relative zu nennen hätte, ja dass sie, bei geeigneter Beschränkung, mit dieser geradezu zusammenfällt.
Der Begriff der letztern ist dadurch zu gewinnen, dass man im ersten Denkbereiche so weit als thunlich analog vorgeht wie wir’s im zweiten, mit § 3 beginnend, thaten.
Aufgrund von analogen Festsetzungen muss die gedachte Disziplin auch analog und selbständig sich begründen und aufbauen lassen.
Nur die Festsetzungen:
(7) als die relativen Moduln, (9) als das individuelle binäre Relativ, und (12), (13) als die relativen Operationen betreffend, werden ohne Analoga bleiben — sofern man nicht sagen will, dass das Analogon von (8), welches das Element als uninäres Relativ zu definiren haben wird, ohnehin zugleich das Analogon von (9) vorstelle; sie werden jedenfalls beiseite zu lassen sein.
Bei solchem Verfahren nach der Analogie sind als die fundamentalen Festsetzungen der Algebra der uninären Relative folgende hinzustellen.
Es sind von den Festsetzungen des § 3 die Definition (1) der Gleichheit nebst dem Abacus (2) bis (4) beibehalten und wiederum vorangestellt zu denken.
Als Denkbereich gilt der 11, = 1, bestehend aus den „Elementen A, B, C, D, …, deren irgendwelche durch die Buchstaben i, j, h, … vorgestellt werden.
Analog zu (5) ist dann ein uninäres Relativ allgemein zu definiren durch die aus 59) zu entnehmende Festsetzung: a = Σiaii, worin die Koeffizienten ai auf den Wertbereich 0, 1 zu verweisen sind.
Jedes Relativ ist darnach von vornherein eine Summe von Elementen.
Zur völligen Bestimmung eines Relativs genügt die Angabe von seinen Koeffizienten oder von deren linearer Matrix (als einer Reihe von Augenpunkten und Leerstellen).
Analog zu (6) wird darnach die 1 und die 0 als uninäres Relativ definirt durch die Festsetzung aus 65) 1i = 1, 0i = 0.
Analog zu (8) und wenn man will auch (9) ist das Element i selbst sodann als uninäres Relativ zu definiren mittelst der Angabe seiner Koeffizienten: 70) ii = 1, ih = 0 für h ≠ i, die wir noch nicht chiffrirt hatten, die aber mit (58) in der Anwendung auf a = i als ih k = ih = 1'i h implicite schon gegeben war.
Analog zu (10) und (15) haben wir die Definitionen 67) und 68) von Produkt und Summe resp. Π, Σ.
Analog zu (11) die Definition 60) des Negates ā.
Endlich analog zu (14) nebst Korollar in 62) die Definition der Einordnung zwischen Relativen, etc.
Diese Grundlagen der Algebra der uninären Relative haben wir also von der Algebra der binären aus beim Studium der „Systeme als „Sätze“ gewonnen.
Würden sie von vornherein als Konventionen hingestellt, so liessen sich aus ihnen denknotwendig die Gesetze eines Kalkuls deduziren, welcher drei Spezies kennt: Multiplikation, Addition und Negation.
Die Konversion kann in diesem Kalkul keine Stätte finden, weil sie auf ein System oder uninäres Relativ angewendet zu einem Systemkonvers, d. h. aus dem Denkbereiche der uninären Relative heraus, führt.
Aber auch was die knüpfenden unter den drei relativen Operationen betrifft, so scheinen dieselben nach unserm Korollar zu 44) fast zur Bedeutungslosigkeit (insignificance) herabzusinken, insofern sie, als nunmehr blos zwischen Systemen anzuwendende, allemal nur das erste von diesen ungehindert reproduziren, sofern sie es nicht in 0 resp. 1 verwandeln.
Jedenfalls können sie ebenfalls beiseite gelassen werden und sollen sie hiernächst unberücksichtigt bleiben.
Vielleicht gibt einmal die Frage ihrer doch immerhin möglichen Zuziehung einem Forscher Anlass zu einer interessanten Studie.
Dieser Kalkul nun wird zweifellos kein andrer sein, als der „identische Kalkul“.
Mit ihm fällt die „Algebra der uninären Relative somit wesentlich zusammen.
Die Elemente des Systems sind, wie gezeigt — in ihr — die „Individuen“ desselben.
Letztre erscheinen zum „Systeme“ kollektiv zusammengefasst — wie die Teile zu einem Ganzen.
Wird, anstatt dessen, der Name des Systems als ein genereller gefasst, so dass er sich auf dessen Individuen distributiv verteilt, nämlich einem jeden derselben einzeln schon (aber ganz und ungeteilt) als ein Prädikat zugesprochen wird, so nennen wir das System eine „Klasse“.
Geschieht solches durchweg, bei allen in die Untersuchung als deren Substrat einbezogenen Systemen, so wird unser Kalkul zum „Klassenkalkul“.
Systeme von Elementen und Klassen von Individuen sind (in der gehörigen suppositio natürlich) „absolute Namen“ und können sonach auch als „absolute Terme“ (ich übersetze so in Ermangelung eines bessern Ausdrucks das englische „absolute terms“) hingestellt werden.
In 5 p. 48 gebraucht Peirce auch den Ausdruck: „terms of singular reference“, während er daselbst „Systeme“ als „complete as to their correlate“ umschreibt.
Bekannt ist nun aber, dass auch jeder relative Name als ein absoluter gebraucht werden kann.
Jeder relative Begriff gibt Veranlassung zur Bildung auch eines (zumeist beinah völlig gleichlautend benamten) absoluten Begriffes.
Von den Begriffen „Liebender von-“, Vater von-“, „Bild von-“ vermögen wir auch zu abstrahiren die Begriffe: „Liebender“, „Vater“, „Bild“ (überhaupt).
An diesen wichtigen Prozess oder Übergang knüpfen sich nun noch einige fundamentale Überlegungen, und wollen wir diesen zunächst analytisch beikommen, an sie von den Gesichtspunkten der Algebra aus herantreten.
Ist a kein System sondern ein beliebiges binäres Relativ, so wissen wir zwar was das Symbol ai j bedeutet, dagegen ist dem Symbole ai bis jetzt noch keine Erklärung zuteil geworden.
Wir können aber versuchen, den Begriff von ai von den Systemen auf beliebige Relative auszudehnen.
Dazu bieten sich zwei ursprünglich gleichberechtigte aber auf Verschiedenes hinauslaufende Wege dar.
Wäre a System, so hätten wir kraft 58) im Hinblick auf 40): (ai j =) (a; 1)i j = ai = (a ɟ 0)i j.
In jedem Falle ist sowol (a; 1)i j = Σhai h als auch (a ɟ 0)i j = Πhai h vom zweiten Index im Suffixe, nämlich von j, unabhängig; aber wenn a kein System ist, sind die beiden Ausdrücke von einander verschieden, und müssen wir uns für den einen von ihnen als den zur Definition von ai zu verwendenden entscheiden.
Wir thun dies für den ersten, sodass uns die Gleichung (71) ai = (a; 1)i j bedingungslos gelten wird.
Damit gewinnt aber ai die Bedeutung der Aussage:
„i ist ein a“, wo a den zum relativen Begriff „a von-“ gehörigen absoluten Begriff a“ vorstellt.
Wir wollen dies und noch einiges dazu Gehörige an dem Paradigma erläutern, wo a als binäres Relativ = amans, Liebender vonbedeutet.
Mit dem absoluten Namen „Liebender“ ist ein jeder zu bezeichnen, der überhaupt jemanden (irgendwen, oder irgendetwas) liebt (eventuell auch blos eine Sache; doch vereinfacht es unsre Erörterungen, wenn wir den Denkbereich 11 auf Personen beschränkt annehmen).
Gibt es nun eine Person h die von i geliebt wird, d. h. existirt ein Element h derart dass i ⋹ a; h oder ai h = 1 ist, so wird auch (a; 1)i j = Σhai h = 1 und damit ai = 1 sein; und andernfalles haben wir ai = 0.
Es ist also ai gleich 1 oder gleich 0, jenachdem i ein „Liebender (schlechtweg)“ ist oder nicht, q. e. d. Ebenso heisst „Vater“ einer, der überhaupt ein Kind gezeugt hat, und würde unser ai besagen: i ist Vater, sobald uns das binäre Relativ a den Begriff „Vater von-“ repräsentirte.
Etc.
Mit (71) wird auch die Abkürzung gegeben sein: 72) Σhah j = (1; a)i j = (ă; 1)j i = ăj.
Es gelten aber für den so erweiterten Begriff der Koeffizienten ai nicht mehr alle die Sätze die für den engern im Denkbereiche 11 der uninären Relative aufgestellt worden.
Namentlich werden die Gleichungen 60, 67, 68) teilweise zu modifiziren sein zu den Subsumtionen: 73) (ai)͞ ⋹ āi oder (ā)i, 74) 75) wie aus a; 1͞ ⋹ ā; 1, nämlich ā ɟ 0 ⋹ ā; 1, sowie links ab; 1 ⋹ a; 1 · b; 1, (Πa); 1 ⋹ Π(a; 1) sive Πa; 1 mit Rücksicht auf 71) analytisch sofort erhellt.
Die Formeln rechts in 74, 75) bleiben als Gleichungen in Kraft und entsprechen denen links nur mehr „pseudodual“; sie verstehen sich als gültige aus a; 1 + b; 1 = (a + b); 1 und Σ(a; 1) sive Σa; 1 = (Σa); 1. Dass sie in der That aus denen links nicht durch Kontraposition ableitbar sind, oder umgekehrt, geht eben daraus hervor, dass gemäss 73) auch (āi)͞ nicht = sondern blos ⋹ ai sein muss.
(ab)i ⋹ aibi ai + bi = (a + b)i
(Πa)i ⋹ Πai Σai = (Σa)i,
Bildet man Πhai h als das Negat von Σhāi h, etc. so ergeben sich nach (71) auch noch für diese Π die Abkürzungen: 76) Πhai h = (a ɟ 0)i j = (āi)͞, Πhah j = (0 ɟ a)i j = (ā̆j)͞ — welche etwas unbequemen Symbole jedoch nach dem Gesagten nicht weiter reduzirbar sind.
Die Formeln 59) gelten für die erweiterte, mit (71) zu einer allgemeingültigen erhobene Begriffserklärung der ai, welche somit von der Einschränkung, dass a von vornherein als ein System gedacht werden müsse, befreit ist, nicht.
Es muss im allgemeinen unmöglich bleiben, ein binäres Relativ a durch die Systeme a; 1, a ɟ 0, ā; 1 und ā ɟ 0 und deren Konverse auszudrücken, aus diesen allein schon es abzuleiten!
Der Umstand, dass mit dieser Festsetzung (71) wenn nicht Ausnahmen geschaffen, so doch eine Nötigung zur Beobachtung besondrer Vorsichten beim Rechnen eingeführt wird, würde es unter dem rechnerischen Gesichtspunkte fraglich erscheinen lassen, ob überhaupt es in der Algebra sich empfehle, besagte Festsetzung zu treffen.
Dem steht indess gegenüber, dass die im gewöhnlichen Denken so häufig vollzogene Umwandlung von relativen Begriffen in die absoluten uns belehrt, dass für die Zwecke der Interpretation, und Anwendung unsrer Algebra auf das verbale Denken, besagter Prozess doch nicht ohne Wichtigkeit sein kann:
Gemäss (71) — indem man von ai j blos ai beibehält — den zweiten Index jedes Relativkoeffizienten fallen zu lassen, somit bei a vom Korrelate zu abstrahiren, und das ist imgrunde: das binäre Relativ a in das System a; 1 verwandeln, heisst nichts andres als wie: den relativen Begriff „a von-“ in den absoluten „a“ umzudeuten, von jenem auf diesen schliessen — ein Prozess, den ich in der ersten Vorlesung als eine Zurückdeutung des Relativs a aus dem zweiten in den ersten Denkbereich bezeichnet habe.
Da durch ein gegebnes a; 1 noch keineswegs a bestimmt erscheint, so lässt sich beim Wiedervordeuten das ursprüngliche Relativ nicht mehr zurückgewinnen — wie man denn von jemand, von dem blos bekannt ist, dass er „Liebender“ ist, d. h. dass es Personen gibt, die er liebt, damit allein noch nicht wissen wird, welche Personen es sind, die er liebt.
Dazu, dass die linkseitige Formel 74) nicht als Gleichung gilt, haben wir implizite schon S. 81 ein Beispiel erörtert (wobei blos „jemand“ für den „Dienenden“ zu sagen).
Es sei zum Schlusse auch noch der Formel 73) eine exemplifizirende Betrachtung gewidmet.
Mit dem gleichen Rechte, wie bei der Exemplifikation unter (71) haben wir als „Nichtliebenden“ alles, einen jeden zu bezeichnen, der überhaupt irgendetwas, gewisse Personen nicht liebt.
Ebendieser kann sehr wohl (gewisse andre) Personen auch lieben; er kann zugleich auch „Liebender“ sein.
Die absoluten Begriffe Liebender und Nichtliebender schliessen sich also keineswegs aus, sind nicht disjunkt; sie stehen nicht einmal in konträrem Gegensatz zu einander, geschweige in kontradiktorischem.
Wenn i nicht ein Liebender ist, so — besagt 73) — ist i jedenfalls ein Nichtliebender, aber nicht umgekehrt!
Die Begriffe „Nichtliebender“ und „was (wer) nicht ein Liebender ist fallen nicht zusammen, sind vielmehr wohl zu unterscheiden!
Den Begriff „Nichtliebender“ werden wir dargestellt erhalten, indem wir das binäre Relativ ā = Nichtliebender von- in den Denkbereich 11 zurückdeuten, diesen relativen in den (zugehörigen) absoluten Begriff umwandeln — wodurch wir ā; 1 erhalten.
Der Begriff: „was nicht ein Liebender ist“ entsteht durch Negation aus dem absoluten Begriffe „Liebender“
= a; 1 und hat also ā ɟ 0 zum Ausdrucke.
Wenn für jenen bei der Zurückdeutung der Name ā beibehalten wird in 11, so wäre für diesen der Name a1 (mit dem in Bd. 1 und 2 verwendeten vertikalen Negationsstrich) am Platze.
Es ist also sub 11: ā = ā; 1 von a1 = ā ɟ 0 verschieden.
Oder: die Reihenfolge der beiden Prozesse:
Negation und Zurückdeutung (oder Umdeutung des relativen in den absoluten Begriff) ist — ebenso wie bei der Zurückdeutung und der identischen Multiplikation — keineswegs belanglos.
Negirt man zuerst und deutet dann zurück, so bekommt man aus a = amans den Begriff Nichtliebender (schlechtweg, d. i. von gewissen Personen oder Dingen).
Deutet man erst zurück und negirt hernach, so gelangt man zu dem Begriffe Nichtliebender von allen (ausser keinen, d. i. von allen ohne Ausnahme).
Darnach würde (ai)͞ sich auch als (a1)i schreiben lassen.
Elfte Vorlesung.
Studien über Elimination, Produktir- und Summirungsaufgaben.
§ 28. Eine Studie gemäss Peirce über Elimination.
Solange wir — wie noch S. 177 betont — nicht verfügen über eine allgemeine Methode um die Elimination eines Relativs x aus einem irgendwie gegebnen Propositionensystem oder dessen vereinigter Gleichung zu vollziehen, d. h. um deren volle Resultante nach x zu gewinnen, so ist einstweilen jeder Gedanke von Wert, aufgrund dessen sich überhaupt aus „x-führenden“ Prämissen von bestimmten Formen solche Konklusionen ziehen lassen, in denen der Eliminand x nicht vorkommt; jede Quelle ist schätzbar, aus der Resultanten fliessen, seien diese auch nicht immer die vollen.
Handelt es sich ja doch in der Logik darum, die Kunst des Schliessens zu fördern!
Dies bleibt in Kraft, obschon es uns (zu Ende des Paragraphen) gelingen wird doch das allgemeine Eliminationsverfahren zu finden.
Denn die technischen oder rechnerischen Schwierigkeiten, welche dessen Anwendung und Durchführung entgegenstehn, pflegen ohne Vergleich erheblicher zu sein als diejenigen, die verknüpft sind mit der Verwertung solcher Gedanken oder glücklichen Appercus wie die sind, um die es sich hier handelt.
Unter diesem Gesichtspunkt nehmen wir nun hier in vereinfachter Gestalt eine auf Bewerkstelligung von Eliminationen hinauslaufende Arbeit von Peirce aus 9cp. 195 ‥ 198 auf.
Die Veranlassung für Herrn Peirce zu gedachter Untersuchung ist eine logisch zu interessante, als dass wir es unterlassen dürften, späterhin auf dieselbe zurückzukommen; ihr Vorwurf ist nichts Geringeres als eine eigentümliche Syllogistik, die eine verbindende Stellung zwischen Umfangs- und Inhaltslogik einnimmt und weder der einen noch der andern von diesen beiden ausschliesslich anzugehören scheint!
Vorderhand jedoch wollen wir uns begnügen, die Arbeit — was sie sehr nötig hat — blos in rein rechnerischer Hinsicht zu revidiren.
Der Grundgedanke sei im voraus gekennzeichnet.
In § 8, S. 126 wurde schon ausgeführt, dass und wie jede Subsumtion sich auch auf das Subjekt 1' (gleichwie, wenn man will, auf das Prädikat 0') bringen lässt.
Unbeschadet der Allgemeinheit können wir also jede etwa als eine Prämisse gegebene Subsumtion von vornherein als eine solche, deren Subjekt 1' ist, annehmen.
Wir wollen nun aus zwei Prämissensubsumtionen (derart), deren jede das „Mittelglied“, den terminus medius x nur einmal enthält, dieses eliminiren lernen.
Das gelingt, sobald in der einen Prämisse das Mittelglied unnegirt, als x selbst, in der andern aber negirt, als x̄ vorkommt und ausserdem diese Terme x und x̄ beide als letzte Operanden in den Prädikaten gedachter Prämissensubsumtionen erscheinen (desgleichen also auch, falls x sowol wie x̄ als erste Terme in diesen Prädikaten figuriren sollten) — und zwar einerlei ob sie „freie“ Operationsglieder sind, oder aber als mit noch andern, und zwar gegebnen Relativen a, b, ‥ als sogenannten Parametern, verknüpfte von Klammern umschlossen sind — die Knüpfungen jedoch durchgängig als relative vorausgesetzt.
Und zwar gelingt es durch geschickte Verwertung der beiden Sätze 3) des § 8: 1' ⋹ x ɟ x̄̆, x; x̄̆ ⋹ 0' in Verbindung mit den Assoziations- 6) und den Grundgesetzen 7) des § 6, welche lauteten: a; (b ɟ c) ⋹ a; b ɟ c, (a ɟ b); c ⋹ a ɟ b; c.
Der von Erfolg gekrönte Witz sei zunächst für den Fall freier Operanden x und x̄ dargelegt.
Haben nämlich unsre Prämissen die Form: 1' ⋹ a ∘ x, 1' ⋹ b ☉ x̄, wo für den Augenblick das Knüpfungszeichen ∘ uns nach Belieben entweder den Strichpunkt (;) oder das Piuzeichen ɟ vertreten soll — und ebenso, jedoch ganz unabhängig davon, auch das Zeichen ☉ — so kann man, die zweite Prämisse konvertirend, dieselbe schreiben:
1' ⋹ x̄̆ ☉ b̆ und jetzt sie mit der ersten durch relatives Übermultipliziren verknüpfen zu der Folgerung:
1' ⋹ (a ∘ x); (x̄̆ ☉ b̆).
Sind nun die Knüpfungen ∘ und ☉ von gleicher Art — beide relative Multiplikationen, oder beide relative Additionen — so kann man aufgrund des Assoziationsgesetzes der relativen Knüpfungen diese Folgerung äquivalent umschreiben in: 1' ⋹ a ∘ (x; x̄̆) ☉ b̆, sind jene aber von ungleicher Art, so kann man doch aufgrund der angeführten Theoreme 7) des § 6 ebendiese Konklusion aus unsrer letzten Folgerung ziehen.
Da nun aber x; x̄̆ ⋹ 0', so ergibt sich a fortiori weiterhin der Schluss:
1' ⋹ a ∘ 0' ☉ b̆ und dieser ist „eine“ und zwar die von Peirce abgeleitete Resultante.
War x oder auch x̄ nicht freies, sondern von einer Klammer innerhalb des Prädikates umschlossenes (oder umschlossen zu denkendes) Operationsglied, so gelingt es dennoch mittelst vorgängiger Anwendung der erwähnten Sätze 7) des § 6, die Terme x und x̄̆ in der ersten und der konvertirten zweiten Prämisse erst einmal frei zu bekommen, darnach wie oben dieselben sozusagen zusammen zu bringen, und so einen von x unabhängigen Schluss auf vorstehende Weise zu gewinnen — wie dies nachher die Ausführung im Detail erkennen lassen wird.
Für die eine, die „erste“ Prämisse komme (wie sich noch genauer motiviren liesse) nur eine von den vier Formen in Betracht: 1)
1' ⋹ a ɟ x, 1' ⋹ a; x, 1' ⋹ a ɟ b; x, 1' ⋹ a; (b ɟ x), für die andre oder „zweite“ Prämisse ebenso, nur x̄ statt x gesagt, und die Parameter a, b durch eventuell andere b, c oder c, d ersetzt.
Da eine etwaige Vertauschung von x mit x̄ oder auch der ersten Prämisse mit der zweiten den Charakter des Problems nicht ändert, m. a. W. keine neue Art von Aufgaben liefert, so haben wir im ganzen zu lösen die [Formel] = 4 + 3 + 2 + 1 = 10 Aufgaben: x zu eliminiren aus 2)
[Formel]
Anstatt unsrer vier Formen 2) stellt Peirce l. c. deren sechs auf, die aber doch — indem man etwa für ein blos aus Parametern zusammengesetztes b ɟ c oder für ein b; c kürzer a sagt — nur auf jene vier hinauskommen.
Infolgedessen sind von den 21 Untersuchungen dieses Autors („the various kinds of syllogism“) elfe blosse Wiederholung (in andern Buchstaben) von bereits vertretenen.
Nämlich unsrer Chiffre entspricht Peirce’s 1, 2, 3, 4, 5, 6, 7, 8, 9, 100) Nr. 1, 4, 11, 2, 6, 13, 5, 15, 12, 3, 7, 9, 14, 8, 18, 20, 17, 10, 16, 21, 19.
Sodann nimmt Peirce — obzwar unbeschadet der Richtigkeit und Tragweite seiner Resultate — keine Notiz davon, dass von seinen Prämissen einzelne schon für sich allein eine Resultante nach sich ziehen, und endlich kümmert er sich nicht um die Frage der Vollständigkeit seiner Resultanten.
All diese Umstände lassen eine Revision der Arbeit, wie gesagt, angezeigt erscheinen.
Zuvörderst ist zu beachten, dass von unsern vier Aussagen 2) die drei letzten schon je einzeln eine Resultante bedingen.
Diese, und zwar die vollständigen Resultanten, gibt das Tableau: 3)
[Formel] wo eben die Konklusion 0 = 0 wie üblich auf keine Resultante, das Fehlen einer solchen hinweist.
Wegen x ⋹ 1, b; x ⋹ b; 1, b ɟ x ⋹ b ɟ 1 = 1 verstehen diese Resultanten sich als Konklusionen von selbst.
Dass sie aber die vollen Resultanten sind, muss zunächst bewiesen werden; auch wird unsern Resultanten noch eine bessere Form zu geben sein.
Dass die Proposition 1' ⋹ a ɟ x keine Resultante liefern kann, geht daraus hervor, dass bei irgendwie gegebnem a der Wert x = 1 ihr immer schon (als eine „Wurzel“) genügt.
Ebenso ist bei der zweiten, dritten und vierten Proposition ersichtlich, dass die von uns angegebne Resultante die volle sein muss, weil jener, sobald diese erfüllt ist, eben die Wurzel x = 1 genügt.
Nun haben wir den Satz — vergl. 48) S. 453: 4)
[Formel] dem wir nebenbei auch diesen sogleich zugesellen wollen: 5)
[Formel]
Beweis zu 4).
Denn aus 1' ⋹ a; 1 folgt auch 1'; 1 ⋹ a; 1; 1 oder 1 ⋹ a; 1, also a; 1 = 1, und umgekehrt, falls letzteres gilt, so ist auch 1' ⋹ a; 1 — als äquivalent mit 1' ⋹ 1 — erfüllt.
Beweis zu 5) aus den Koeffizienten zu führen.
Die Subsumtion 1'i j ⋹ Σhai h0'h j ist bei j ≠ i nichtssagend, bei j = i dagegen äquivalent mit 1 ⋹ Σhai h0'h i = Σh(0'a)i h = (0'a; 1)i j = 1i j, q. e. d.
Die zweite und vierte unsrer Resultanten 3) statuirt also — cf. 4) — einfach, dass das Relativ a keine Leerzeilen haben dürfe, mithin von der Form a = ᾱ ɟ 0 + α sei — cf. 14) des § 16.
Ebenso ist bezüglich der dritten Resultante 3) leicht zu rechtfertigen, dass sein muss: 6)
[Formel] , wo die dritte Transformation sich aus dem ersten Inversionstheoreme rechtfertigt, sonst aber nur Schemata des identischen Kalkuls anzuwenden waren.
Darnach kann b beliebig angenommen werden, muss aber a die Leerzeilen von b, in Vollkolonnen verkehrt, enthalten.
Ziehen wir nun unbekümmert um diese Einzelresultanten zunächst in Peirce’scher Manier die von x freien Konklusionen, so haben wir — immer unter Anwendung der oben citirten Sätze — folgende 10 Rechnungen.
Es ist die Prämisse von
10) = (1' ⋹ a ɟ x)(1' ⋹ x̄̆ ɟ b̆) ⋹ {1' ⋹ (a ɟ x); (x̄̆ ɟ b̆) ⋹ (a ɟ x); x̄̆ ɟ b̆ ⋹ ⋹ (a ɟ x; x̄̆) ɟ b̆ ⋹ (a ɟ 0') ɟ b̆ = a ɟ b̆} also ⋹ (1' ⋹ a ɟ b̆).
20) = (1' ⋹ a ɟ x)(1' ⋹ x̄̆; b̆) ⋹ {1' ⋹ (a ɟ x); x̄̆; b̆ ⋹ (a ɟ x; x̄̆); b̆ ⋹ ⋹ (a ɟ 0'); b̆ = a; b̆} also ⋹ (1' ⋹ a; b̆).
Wir hätten hier auch schliessen können: 1' ⋹ a ɟ x; x̄̆; b̆ ⋹ a ɟ 0'; b̆, also 1' ⋹ a ɟ 0'; b̆.
Aber diese Resultante ist eine unmittelbare Folgerung aus der vorigen, weil a; b̆ = (a ɟ 0'); b̆ ⋹ a ɟ 0'; b̆.
Dieselbe ist mithin minder umfassend oder wertvoll — und ähnlich verfällt man auch bei den folgenden Rechnungen leicht in die Gefahr, weniger zu schliessen als sich schliessen lässt.
30) = (1' ⋹ a ɟ x)(1' ⋹ x̄̆; c̆ ɟ b̆) ⋹ [1' ⋹ (a ɟ x); (x̄̆; c̆ ɟ b̆) ⋹ (a ɟ x); x̄̆; c̆ ɟ b̆ ⋹ ⋹ (a ɟ x; x̄̆); c̆ ɟ b̆ ⋹ (a ɟ 0'); c̆ ɟ b̆] also ⋹ (1' ⋹ a; c̆ ɟ b̆).
Wir hätten hier auch schliessen können: 1' ⋹ a ɟ x; x̄̆; c̆ ɟ b̆ ⋹ a ɟ 0'; c̆ ɟ b̆, allein diese Resultante ist eine unmittelbare Folgerung aus der vorigen, weil: a; c̆ ɟ b̆ = a; 1'; c̆ ɟ b̆ = a; (1' ɟ 0'); c̆ ɟ b̆ ⋹ a; 1' ɟ 0'; c̆ ɟ b̆ = a ɟ 0'; c̆ ɟ b̆ und hätte mithin geringere Tragweite.
40) = (1' ⋹ a ɟ x){1' ⋹ (x̄̆ ɟ c̆); b̆} ⋹ {1' ⋹ (a ɟ x); (x̄̆ ɟ c̆); b̆ ⋹ ⋹ (a ɟ x; x̄̆ ɟ c̆); b̆ ⋹ (a ɟ 0' ɟ c̆); b̆} also ⋹ {1' ⋹ (a ɟ c̆); b̆}.
50) ebenso ⋹ (1' ⋹ a; x; x̄̆; b̆) also ⋹ (1' ⋹ a; 0'; b̆).
60) ⋹ [1' ⋹ a; x; (x̄̆; c̆ ɟ b̆) ⋹ a; (x; x̄̆; c̆ ɟ b̆)] also ⋹ {1' ⋹ a; (0'; c̆ ɟ b̆)}.
70) ⋹ {1' ⋹ a; x; (x̄̆ ɟ c̆); b̆ ⋹ a; (x; x̄̆ ɟ c̆); b̆ ⋹ a; (0' ɟ c̆); b̆} also ⋹ (1' ⋹ a; c̆; b̆).
80) ⋹ {1' ⋹ (a ɟ b; x); (x̄̆; d̆ ɟ c̆) ⋹ (a ɟ b; x; x̄̆); d̆ ɟ c̆ oder anders ⋹a ɟ b; (x; x̄̆; d̆ ɟ c̆)} also ergibt sich sowol 1' ⋹ (a ɟ b; 0'); d̆ ɟ c̆ als auch 1' ⋹ a ɟ b; (0'; d̆ ɟ c̆) und beide Resultanten sind ⋹ (1' ⋹ a ɟ b; 0'; d̆ ɟ c̆).
90) ⋹ [1 ⋹ (a ɟ b; x); (x̄̆ ɟ d̆); c̆ ⋹ {a ɟ b; x; (x̄̆ ɟ d̆)}; c̆ ⋹ ⋹ {a ɟ b; (x; x̄̆ ɟ d̆)}; c̆ ⋹ {a ɟ b; (0' ɟ d̆)}; c̆] also ⋹ {1' ⋹ (a ɟ b; d̆); c̆}.
100) ⋹ {1' ⋹ a; (b ɟ x); (x̄̆ ɟ d̆); c̆ ⋹ a; (b ɟ x; x̄̆ ɟ d̆); c̆ ⋹ a; (b ɟ 0' ɟ d̆); c̆} also ⋹ {1' ⋹ a; (b ɟ d̆); c̆}.
Es verlohnt wol, unsre Ergebnisse mit den Data zu eignen (Eliminations-) Theoremen zusammenzustellen: 7)
[Formel] , wobei die zweite Form der Resultante mittelst einer Konversion aus der ersten oben gefundnen hervorgeht.
Aus dem Anblick der zweiten und von 50) an beider Formen der Resultante erhellt sogleich, dass diese Peirce’schen Resultanten durchweg auch diejenigen in sich schliessen, welche gemäss 3) aus den getrennten Prämissen schon einzeln folgten.
Es ist also bei Peirce straflos geblieben, sachlich gerechtfertigt, von den letzteren keine Notiz zu nehmen.
Muss z. B. 1' ⋹ b; ă sein, so folgt ja a fortiori auch 1' ⋹ b; 1; und hatten wir 1' ⋹ b ɟ c; ă, so involvirt dies bereits 1' ⋹ b ɟ c; 1, etc.
Sodann ist zu bemerken, dass bei den vier ersten Theoremen 7) die Peirce’sche Resultante sogleich auch als die vollständige nachweisbar ist.
Sobald nämlich bei 10) bis 40) die angegebne Resultante erfüllt ist, existirt auch sicher eine Wurzel der Aufgabe, und zwar in Gestalt von x = ā̆, welches die eine Prämisse kraft der Formel 1' ⋹ a ɟ ā̆, die andre eben kraft der Resultante erfüllt.
Von den übrigen Resultanten 50) ‥ 100) bleibt es vorerst fraglich, ob sie die vollen sind, und glaube ich, dass die Entscheidung zum Teil verneinend ausfallen wird. Dieselben würden so nur den Wert von Schlüssen haben, deren Validität ausser Zweifel steht, die aber nicht alles erschöpfen, was ohne Rücksicht auf x aus den Prämissen folgt.
Vermag man nun nicht Alles zu gewinnen, so muss man eben mit Einigem sich schon begnügen.
Zu den oben verwerteten Sätzen 3) des § 8 über relative Knüpfungen gelten analog für identische Knüpfungen eine Stufe tiefer die Sätze 2) des § 8: 1' ⋹ a + ā̆, aā̆ ⋹ 0'.
Der Versuch, letztere ebenso zu verwerten, scheitert an dem Umstande, dass man, nachdem die erste mit der konvertirten zweiten Prämisse durch identische Multiplikation überschiebend verknüpft ist, nicht mehr über solche Sätze verfügt, die eine Klammerverschiebung gestatten und es so ermöglichen würden, das x mit dem x̄̆ „zusammenzubringen“.
Desgleichen lässt uns die Methode im stich bei den entsprechenden Aufgaben, wo nur der Negationsstrich über dem x (in der zweiten Prämisse) entfällt — vergleiche S. 489 oben.
Abgesehen von der vorstehend dargelegten genialen Ausnutzung derselben halte ich überhaupt die Idee, die Subsumtionen auf das Subjekt 1' oder das Prädikat 0' (statt 1, 0) zu bringen, für nicht besonders förderlich.
Vielmehr scheint mir zunächst vor dieser eine andre Schreibweise den Vorzug wegen ihrer grössern Durchsichtigkeit zu verdienen.
Wie man nämlich für 1' ⋹ a ɟ b besser a + b̆ = 1 gemäss 22) des § 8 schreiben wird, so wird man auch bei 1' ⋹ a; b gut thun einen Satz zu berücksichtigen, der lautet wie folgt: 8)
(1' ⋹ a; b) = (ab̆; 1 = 1) = (1; ăb = 1) | (a ɟ b ⋹ 0') = {(a + b̆) ɟ 0 = 0} = {0 ɟ (ă + b) = 0} und lehrt, dass 1' ⋹ a; b lediglich besagt, dass das Relativ ab̆ keine Leerzeilen habe — gemäss welchem also wegen 4) auch noch nebenher gelten muss: 9)
(1' ⋹ a; b) = (1' ⋹ ab̆; 1) = (1' ⋹ 1; ăb) | (a ɟ b ⋹ 0') = {a + b̆) ɟ 0 ⋹ 0'} = {0 ɟ (ă + b) ⋹ 0'}.
Beweis von 8).
Es ist: 1'i j = Σhai hbh j für j ≠ i als nichtssagend erfüllt, für j = i dagegen äquivalent mit: 1'i i = 1 = 1i j = Σhai hbh i = Σh(ab̆)i h = (ab̆; 1)i j, q. e. d.
Nach den genannten Schemata wollen wir nun die Formeln 7) sowol hinsichtlich der Prämissen als auch der Resultanten noch übersichtlicher darstellen.
Bei jenen zunächst getrennt zu nehmenden wird somit das Vorbild zu beachten sein: (1' ⋹ a ɟ x) = (a + x̆ = 1), (1' ⋹ a; x) = (ax̆; 1 = 1), (1' ⋹ a ɟ b; x) = (a + x̆; b̆ = 1), {1' ⋹ a; (b ɟ x)} = {a(x̆ ɟ b̆); 1 = 1}, nach dessen Anwendung sie wieder vereinigt werden können.
Sowol x als x̄ wird dann nur noch mit dem Konversionsringel behaftet vorkommen, und wird man zur Vereinfachung der Schreibung x für x̆ sagen.
Ersetzt man ebenso diejenigen von den Parametern, welche darnach in den Prämissen noch geringelt auftreten, durch ihre Konverse, so stellen die Sätze 7) sich nunmehr wie folgt dar: 10) [Formel] , wo die Vollständigkeit, wie gesagt, nur bei den vier ersten Resultanten garantirt werden kann.
Diese fliessen aus einem gemeinsamen Schema: 11) {(a + x)f(x̄) = 1} ⋹ {f(a) = 1} welches gilt und die volle Resultante der Elimination von x aus der Proposition linkerhand liefert, sobald in f(x̄) — populär zu reden — wirklich „blos x̄ (ohne x selber) vorkommt“.
Stellt nämlich — genauer gesagt — f(x̄) das Ergebniss vor von irgendwelchen Knüpfungen (vermittelst der vier knüpfenden von den 6 Spezies) der beiden Relative x̄ und x̄̆ mit irgendwelchen von x unabhängigen Relativen, m. a. W. ist nur beim Aufbau der Funktion f ausgeschlossen, dass an deren Argumente oder an den daraus abgeleiteten Ausdruckteilen (den dasselbe wesentlich führenden, den davon abhängigen Termen) die Operation einer Negation sich vorgeschrieben finde, so kann man wie folgt schliessen.
Nämlich c bei 30), 40), 60), 70), b und d bei 80), 90), 100).
Die Prämisse zerfällt in: 1 ⋹ a + x, was mit x̄ ⋹ a äquivalent ist, und in 1 ⋹ f(x̄).
Durch kombinirte Anwendung der Sätze 1) und 13)
[Konversion betreffend] des § 6 folgt aber aus x̄ ⋹ a — unter den für f stipulirten Voraussetzungen — auch f(x̄) ⋹ f(a) und somit erhalten wir a fortiori: 1 ⋹ f(a).
Dies aber muss die volle Resultante sein, weil, sobald sie erfüllt, in Gestalt von x = ā ein Relativ x als existent nachweisbar ist, welches den Forderungen der Prämisse genügt.
Der Schluss würde unzulässig sein, wenn in f(x̄) auch x selber wesentlich vorkäme, weil wir dann nicht x ⋹ ā sondern ā ⋹ x durch Kontraposition hätten, sonach inbezug auf die das f(x̄) zusammensetzenden „Unterfunktionen“ oder Ausdruckteile wir nur über Subsumtionen verfügen würden, welche x bald im Subjekte, bald auch im Prädikate aufweisen müssten, sodass durch deren überschiebende Knüpfung kein Schluss der Einordnung inbezug auf f(x̄) und f(a) — oder f(x̄, x) und f(a, ā) — erhältlich wäre.
Um auch für die übrigen Resultanten Peirce’s — ja blos für deren erste 50) — die Frage ihrer Vollständigkeit zur Entscheidung zu bringen, müssen wol einige Vor-Aufgaben gelöst werden, die zu den Auflösungsproblemen mit mehrern Unbekannten gehören und auch an sich nicht unwichtig sein dürften — weshalb wir gerne weiter (als nötig) ausholen.
Aufgabe 110).
Nach x und y symmetrisch allgemein die Subsumtion aufzulösen: 12) x; y ⋹ a.
Die Lösung, wie sie sich schon auf den ersten Anlauf ergibt, ist: 13) x = u(a ɟ v̄̆), y = (ū̆ ɟ a)v.
Und es stimmen damit beide Proben, die zweite wegen x ⋹ a ɟ ȳ̆, x = x(a ɟ ȳ̆), y ⋹ x̄̆ ɟ a, y = (x̄̆ ɟ a)y für x = u, y = v augenscheinlich, die erste wegen x; y ⋹ u; (ū̆ ɟ a) ⋹ u; ū̆ ɟ a ⋹ 0' ɟ a = a, desgleichen wegen x; y ⋹ (a ɟ v̄̆); v ⋹ a.
Man könnte vorstehend gelöstes das „erste Inversionsproblem mit zwei Unbekannten“ nennen.
Auf das Gespann desselben sind auch die beiden Probleme: x; a ⋹ y resp. a; y ⋹ x mittelst Umformung in resp.: x; ȳ̆ ⋹ ā̆, x̄; y̆ ⋹ ā auf das Leichteste zurückführbar.
Aufgabe 120).
Nach x und y die Subsumtion aufzulösen: 14) a⋹x; y, d. i. das „zweite Inversionsproblem mit zwei Unbekannten“.
Eine befriedigende „symmetrisch allgemeine“ Lösung fand ich gegeben durch: 15) [Formel] .
Da unsre Proposition mit a(x̄ ɟ ȳ) = 0 zusammenfällt, so ist in der That auf den ersten Blick ersichtlich, dass die Probe 2 stimmt, nämlich für ein jedes Wurzelpaar x, y die beiden Gleichungen rechts für u = x, v = y erfüllt sein werden.
Dass auch die Probe 1 stimmt, ist so zu sehen.
Wenn zur Abkürzung u; v = c, also ū ɟ v̄ = c̄ genannt wird, so haben wir: x; y = c + u; 1; ac̄ + ac̄; 1; v + ac̄; 1; ac̄, und der Nachweis, dass bei beliebigem u, v stets a ⋹ x; y sein müsse, läuft darauf hinaus zu zeigen, dass ac̄ ⋹ der Summe der drei letzten Glieder in x; y sei.
Wird ac̄ = b genannt, so ist aber b in der That schon ⋹ dem letzten dieser Glieder, indem b ⋹ b; 1; b aus b ⋹ b; 1 und b ⋹ 1; b wegen b; 1 · 1; b = b; 1; b folgt, q. e. d.
Das hiermit gelöste Problem wird uns vorwiegend für den Fall a = 1' von Interesse werden.
Welche von den drei Buchstabenrelativen a, x, y aber auch gegeben sein mögen, so können wir jetzt immer die allgemeine Lösung vollständig angeben.
Sind x und y (ad libitum) gegeben, so wird blos a = α · x; y zu nehmen sein, wo α beliebig. a und x, sowie a und y können nicht beliebig angenommen werden, sondern müssen der Resultante a ⋹ x; 1 resp. a ⋹ 1; y genügen, was bei gegebnem x resp. y durch a = x; 1 · α resp. a = α · 1; y geschieht, bei gegebnem a aber durch: x = u + a(ū ɟ 0), y = v + a(0 ɟ v̄) nach 25) des § 18. Hernach wird nach 10) des § 18 sein: y = v + x̆; (x̄ ɟ v̄)a, resp. x = u + a(ū ɟ ȳ); y̆, und nach einigen Umformungen lassen sich diese beiden Werte auch leidlich einfach durch u und v ausdrücken wie folgt: y = v + ŭ; a(ū ɟ v̄) + ă; a(ū ɟ 0)(ā ɟ v̄), x = u + a(ū ɟ v̄); v̆ + a(0 ɟ v̄)(ū ɟ ā); ă.
Die Umformungen wollen wir für den letzteren in extenso darlegen.
Man hat: y̆ = v̆ + ă(v̄̆ ɟ 0), ȳ = v̄(ā + 1; v), also nach 8) des § 27:
ū ɟ ȳ = (ū ɟ v̄){ū ɟ (ā + 1; v)} = (ū ɟ v̄)(ū ɟ ā + 1; v).
Dies in x eingesetzt gibt: x = u + a(ū ɟ v̄)(ū ɟ ā + 1; v); v̆ + a(ū ɟ v̄)(ū ɟ ā + 1; v); ă(v̄̆ ɟ 0) = = u + a(ū ɟ v̄ā); v̆ + a(ū ɟ v̄); v̆(v̆; 1) + a(0 ɟ v̄)(ū ɟ v̄)(ū ɟ ā + 1; v); ă nach 9) und 10) des § 27. Hierin ist nun zu unterdrücken: im dritten Gliede der Faktor v̆; 1 als v̆ in sich schliessend — darnach aber das ganze zweite Glied, als wegen ū ɟ āv̄ ⋹ ū ɟ v̄ vom so vereinfachten dritten absorbirt — im vierten Gliede der Term 1; v weil in seine Negation multiplizirt, desgleichen der Faktor ū ɟ v̄ als den 0 ɟ v̄ enthaltend, und somit bleibt für x das obige Ergebniss.
Aufgabe 130):
Die Gleichung x; y = a nach x und y symmetrisch allgemein zu lösen — wäre als das „dritte Inversionsproblem mit zwei Unbekannten“ zu bezeichnen.
Ihre Lösung steht jedoch noch aus.
Aufgabe 140).
Nach x, y, z die Proposition 16) (a ⋹ y; x)(b ⋹ z; x̄) symmetrisch allgemein aufzulösen.
Auflösung.
Nach dem Schema 15) müssen wir für gewisse u, v, w die untereinanderstehenden Gleichungen haben: 17) y = a(v̄ ɟ ū); 1 + v, z = b(w̄ ɟ u); 1 + w, x = u + 1; a(v̄ ɟ ū), x̄ = ū + 1; b(w̄ ɟ u).
Zugleich aber muss die Negation des letzten Ausdrucks mit dem links vorhergehenden übereinstimmen: u + 1; a(v̄ ɟ ū) = u{0 ɟ (b̄ + w; ū)} sein.
Diese Gleichung rechts auf 0 gebracht gibt: u · 1; b(w̄ ɟ u) + ū · 1; a(v̄ ɟ ū) + 1; a(v̄ ɟ ū) · 1; b(w̄ ɟ u) = 0.
Aber aus uβ + ūα = 0 folgt ohnehin αβ = 0.
Mithin ist der letzte Term linkerhand unterdrückbar, und das Verschwinden der beiden ersten Terme fordert: 1; a(v̄ ɟ ū) ⋹ u, 1; b(w̄ ɟ u) ⋹ ū oder v̄ ɟ ū ⋹ ā + 0 ɟ u, w̄ ɟ u ⋹ b̄ + 0 ɟ ū.
Dies involvirt durch Elimination von v, w die Resultanten für u: 0 ɟ ū ⋹ ā + 0 ɟ u, 0 ɟ u ⋹ b̄ + 0 ɟ ū, und sobald diese durch u erfüllt sind, werden sich v̄ und w̄, somit auch v und w aus den beiden vorhergehenden Subsumtionen nach dem zweiten Inversionstheoreme ermitteln lassen.
Wegen 0 ɟ u ⋹ 1; u reduziren sich unsre Resultanten zu a⋹ 1; u, (0 ɟ u ⋹ b̄ oder) b ⋹ 1; ū, und bildet die Auflösung dieses Subsumtionenpaares nach der Unbekannten u eine Hülfsaufgabe der obigen.
Dass dasselbe keine Bedingung für a und b (als Resultante der Elimination von u aus beiden Subsumtionen) in sich schliessen kann, geht daraus hervor, dass (ihnen) u ⋹ 1' oder 0' unbedingt genügt.
Sind sie erfüllt, so wird 18) x = u selbst sein müssen, sintemal oben die Nullgleichung für u die Einordnung des zweiten Terms von x unter den ersten garantirt.
Man kann daher durchweg x für u schreiben und wird sich ferner nach 11) des § 18 ergeben: v̄ = v̄{(ā + 0 ɟ x + v; x) ɟ x̄̆}, w̄ = w̄{(b̄ + 0 ɟ x̄ + w; x̄) ɟ x̆}, v = v + a(1; x̄)(v̄ ɟ x̄); x̆, w = w + b(1; x)(w̄ ɟ x); x̄̆, was nach 9) des § 27 auch umschreibbar in: 19) w = v + a(v̄ ɟ x̄); (x̄̆; 1)x̆, w = w + b(w̄ ɟ x); (x̆; 1)x̄̆.
Sonach erübrigt blos noch die Lösung der Hülfsaufgabe:
Aufgabe 150) (a ⋹ 1; x)(b ⋹ 1; x̄), = (1; a ⋹ 1; x)(1; b ⋹ 1; x̄).
Von x ist damit einfach gefordert, dass es die besetzten Kolonnen von a besetzt habe, während sein Negat auch die besetzten Kolonnen von b besetzt haben soll.
Dann müssen also die besetzten Kolonnen von b auch Lückkolonnen von x sein.
Wir teilen demnach alle vorhandenen Kolonnen in vier Kategorieen: 1 = (0 ɟ ā)(0 ɟ b̄) + (0 ɟ ā) · 1; b + 1; a · (0 ɟ b̄) + 1; a · 1; b, deren erste die bei a und b unbesetzten Kolonnen zu Vollkolonnen zusammenfasst, die zweite ebenso die bei a unbesetzten aber bei b besetzten, die dritte die bei a besetzten und bei b unbesetzten, die vierte die bei a und b zugleich besetzten.
Dann wird: x = (0 ɟ ā)(0 ɟ b̄)u + (0 ɟ ā) · 1; b · u2 + 1; a · (0 ɟ b̄)u3 + 1; a · 1; b · u4 sein müssen, wo u willkürlich ist, u2, 3, 4 aber das allgemeinste Relativ vorstellt, welches lauter Lückkolonnen resp. lauter besetzte Kolonnen resp. lauter besetze Lückkolonnen hat.
Diese Relative sind aber in § 16 ermittelt, und zwar (ibidem Aufg. 17, 9, 25) ist: u2 = u · 1; ū, u3 = u + 0 ɟ ū, u4 = u · 1; ū + (0 ɟ u)0' + (0 ɟ ū)1'.
Durch Einsetzung dieser Werte in x und Ausmultipliziren der identischen Summen ergibt sich x als eine Summe von sieben Gliedern.
Von diesen liefert aber das erste und dritte Glied zusammen: (0 ɟ b̄)u, sowie das zweite und fünfte Glied zusammen: 1; b · u · 1; ū, und schlägt man hiezu aus dem vorigen Ergebnisse noch (0 ɟ b̄)u · 1; ū, so entsteht der Term u · 1; ū selbst.
Ebenfalls aus jenem 1; a · (0 ɟ b̄)(0 ɟ u)0' zum sechsten Gliede 1; a · 1; b · (0 ɟ u)0' schlagend zieht man dieses leicht zusammen zu 1; a · (0 ɟ u)0'.
Endlich aus dem vierten Gliede 1; a · (0 ɟ b̄)(0 ɟ ū) diesen mit 1' multiplizirten Teil zum siebenten Gliede 1; a · 1; b · (0 ɟ ū)1' schlagend vereinfacht man letztres zu 1; a · (0 ɟ ū)1'.
Damit ist die Lösung gewonnen: 20) [Formel] {x = u · 1; ū + (0 ɟ b̄)u + 1; a · (0 ɟ b̄)(0 ɟ ū) + 1; a · (0 ɟ ū)1' + 1; a · (0 ɟ u)0'}
{x̄ = ū · 1; u + (0 ɟ ā)ū + 1; b · (0 ɟ ā)(0 ɟ u) + 1; b · (0 ɟ u)1' + 1; b · (0 ɟ ū)0'}.
Unter diese haben wir auch sogleich den Wert von x̄ gesetzt, welcher mit dem von x verglichen erkennen lässt, dass unsre Lösung die in der Aufgabe liegenden Anforderungen der Symmetrie erfüllt, welche dahin zu statuiren sind, dass die Lösung ungeändert bleiben muss, wenn man a, x, u mit b, x̄, ū vertauscht.
Dieser Wert ergibt sich durch regelrechtes Negiren desjenigen von x, wenn man das entstehende Produkt von Summen, unter jeweiliger Bedachtnahme auf thunlichste Vereinfachung nach bekannten Sätzen, ausmultiplizirt.
Man erhält so jedoch den Wert von x̄ nicht sofort völlig in der angegebnen Form, sondern statt des letzten Glieds unsres x̄ wird 1; b · ū0' auftreten.
Wegen ū = ū · 1; u + 0 ɟ ū — vergl. 4) des § 27 — kommt dies aber auf das Angegebene hinaus, indem der vom ersten Glied des ū herrührende Term im ersten Glied des x̄ eingeht.
Analog konnte man bemerken, dass das letzte Glied unsres x in 13) auch zu 1; a · u0' sich vereinfachen liesse, indem man zu demselben aus dem ersten Gliede desselben auch 1; a · u · 1; ū · 0' hinzuschlagen kann.
Die Vereinfachungen wären aber nur solche des Namens und keineswegs solche für die Ausrechnung des x oder x̄, nach der Vorschrift dieses Namens, aus gegebnem u, weshalb wir sie in der Formel unberücksichtigt liessen.
Wir machen nun mit dieser Lösung unsrer Hülfsaufgabe die beiden Proben.
Probe 1. Man findet nach bekannten Sätzen 12, 13) des § 27:
1; x = 1; u · 1; ū + (0 ɟ b̄){1; u + 1; a · (0 ɟ ū)} + 1; a · (0 ɟ ū + 0 ɟ u), weil 1; 1' = 1; 0' = 1 ist.
Hierin kommt 1; a multiplizirt vor in 1; u · 1; ū + 0 ɟ ū + 0 ɟ u = 1, und stimmt somit: 1; a ⋹ 1; x. Symmetriehalber ist auch die Probe für 1; b ⋹ 1; x̄ bereits geleistet.
Vereinfacht stellt sich dar: 1; x = 1; a + 1; u · (1; ū + 0 ɟ b̄), 1; x̄ = 1; b + 1; ū · (1; u + 0 ɟ ā).
Probe 2. Trifft die Assumtion links in 13) zu, so muss auch die rechte Seite für u = x erfüllt sein.
In der That ist dann 1; a · (0 ɟ x̄) = 0 und bleibt uns zu bewahrheiten, dass x = x · 1; x̄ + (0 ɟ b̄)x + 1; a · (0 ɟ x)0' = x{1; x̄ + 0 ɟ b̄ + 1; a · 0'} sei.
Wegen 1; b ⋹ 1; x̄, 0 ɟ x ⋹ 0 ɟ b̄ kann man aber hierin 0 ɟ x + 0 ɟ b̄ für 0 ɟ b̄ einsetzen und erweist rechts sich x in 1; x̄ + 0 ɟ x + etc.
= 1 multiplizirt, q. e. d.
Möglichst einfach geschrieben ist: 21) [Formel]
Hiermit ist nun auch unser voriges Problem prinzipiell gelöst:
es wären nur mehr die Werte 20) oder 21) von x in die letzten Ausdrücke 19) für v, w, diese aber samt u = x in die Ausdrücke 17) von y und z einzutragen.
Wegen u · 1; u = u erkennt man leicht dass: x · 1; x̄ = u · 1; ū + 1; a · 1; b · {(0 ɟ ū)1' + (0 ɟ u)0'}, x̄ · 1; x = ū · 1; u + 1; a · 1; b · {(0 ɟ u)1' + (0 ɟ ū)0'}, wird, wonach auch das Konverse hievon, das in v, w vorkommt, leicht hinzuschreiben.
Obwohl sich noch manche fernere Vereinfachung allgemein erzielen lässt, wollen wir die Eintragung nicht ausführen, sintemal uns nur ein Partikularfall des Problemes für unsre Studie interessiren wird, nämlich der Fall: a = b = 1'.
Hier wird 1; a = 1, 0 ɟ ā = 0, desgleichen in b, sodann stellt sich heraus: 22) x = u · 1; ū + (0 ɟ ū)1' + (0 ɟ u)0', x̄ = ū · 1; u + (0 ɟ u)1' + (0 ɟ ū)0', worin die letzten Glieder auch durch u0' resp. ū0' ersetzbar, und x · 1; x̄ = x, x̄ · 1; x = x̄, nach welchen konvertirten Gleichungen (x̄̆; 1)x̆ = x̆, etc. sich vereinfacht: v = v + 1'(v̄ ɟ x̄); x̆, w = w + 1'(w̄ ɟ x); x̄̆.
Ersetzen wir noch die Buchstaben y, v, z, w durch a, α, b, β, so ist gefunden: 23) [Formel] · [a = 1'(ᾱ ɟ x̄){(0' + α; x) ɟ x̄̆ ɟ x̄}; 1 + 1'(ᾱ ɟ x̄); x̆ + α] · [b = 1'(β̄ ɟ x){(0' + β; x̄) ɟ x̆ ɟ x}; 1 + 1'(β̄ ɟ x); x̄̆ + β] worin α, β, u die den a, b, x zugeordneten unbestimmten Parameter vorstellen.
Diese Angabe enthält alle möglichen Lösungen a, b, x des Problemes 50) unter 7) und nur solche, mithin gibt sie auch ausschliesslich alle Wertepaare a, b, welche der (unbekannten) vollen Resultante der Elimination des x genügen.
Im Hinblick auf 28) S. 231 sagt unser Ergebniss 22) aus, dass x lauter besetzte Lückkolonnen haben muss, der Leer- und Vollkolonnen entratend.
Aufgabe 160).
Die Peirce’sche Resultante zum Probleme 50) sub 7): 24) (1' ⋹ a; 0'; b̆), = (1' ⋹ b; 0'; ă) = {(a; 0')b; 1 = 1} = {(b; 0')a; 1 = 1} nach den Unbekannten a, b symmetrisch allgemein zu lösen.
Die Lösung nebst Verifikation folgt unter 27).
Der Methodik zuliebe lege ich auch die Herleitung dar.
Auflösung.
Um der Forderung 1 ⋹z; 1 zu genügen, hat man bekanntlich z = w + w̄ ɟ 0.
Soll aber z = a; 0' · b gedacht werden, so muss der Adventivforderung zuliebe auch w = α; 0' · β genommen werden; somit entsteht: a; 0' · b = α; 0' · β + (ᾱ ɟ 1' + β̄) ɟ 0 was = c genannt werde.
Nach Bd. 2, § 51, Aufg. 15 ist aber x = c + uv̄, y = c + ūv die allgemeine Lösung der Forderung xy = c.
Soll dies auf x = a; 0', y = b angewendet werden, so muss der Adventivforderung halber u durch α; 0', v durch β ersetzt werden, also kommt: a; 0' = α; 0' + (ᾱ ɟ 1' + β̄) ɟ 0 = {α + (ᾱ ɟ 1' + β̄) ɟ 0}; 0', b = β + (ᾱ ɟ 1' + β̄) ɟ 0, sintemal e ɟ 0 = (e ɟ 0); 0' gilt — 17) § 15. Nunmehr braucht nur noch der Forderung a; 0' = d; 0' allgemein genügt zu werden, wo d = α + (ᾱ ɟ 1' + β̄) ɟ 0 bedeutet.
Dies geschieht nach 26) des § 19 durch: a = (d ɟ 1')d̄ + (d; 0' ɟ 0){(ᾱ ɟ 1'); 1 + α}, wobei wir haben: d̄ = ᾱ · (α; 0')β; 1, und da nach 17) des § 15 e; 1 ɟ 1' = e; 1 gilt: d̄ ɟ 1' = (α ɟ 1') · (α; 0')β; 1, (d̄ ɟ 1')d = (ᾱ ɟ 1')α · (α; 0')β; 1, sintemal e; 1 · (ē ɟ 0) = 0 auf e = (α; 0')β anwendbar; weiter: d; 0' = α; 0' + (ᾱ ɟ 1' + β̄) ɟ 0, d; 0' ɟ 0 = α; 0' ɟ 0 + (ᾱ ɟ 1' + β̄) ɟ 0, somit endlich: a = (ᾱ ɟ 1')α · (α; 0')β; 1 + (α; 0' ɟ 0)α + {(ᾱ ɟ 1' + β̄) ɟ 0}{(ᾱ ɟ 1'); 1 + α}.
Werden die Glieder, die α zum Faktor haben, gesammelt, so kommt: a = α{ᾱ ɟ 1' + α; 0' ɟ 0 + (ᾱ ɟ 1' + β̄) ɟ 0} + {(ᾱ ɟ 1' + β̄) ɟ 0} · (ᾱ ɟ 1'); 1, indem das Negat eines Gliedes als Faktor eines andern unterdrückbar.
Fügt man ferner dem dritten Gliede in der ersten geschweiften Klammer das Negat des vorhergehenden Gliedes als Faktor zu, so geht der davon herrührende Term im letzten Gliede von a ein, und bleibt: a = (α; 0' ɟ 0 + ᾱ ɟ 1')α + {(ᾱ ɟ 1' + β̄) ɟ 0} · (ᾱ ɟ 1'); 1.
Zeilenschematisch rechnend findet man aber leicht, dass allgemein ist (α; 0' ɟ 0 + ᾱ ɟ 1')α = α, und darnach haben wir als die allgemeine Lösung unsres Problems: 25) [Formel] womit in der That die beiden Proben stimmen — bei Rücksicht darauf dass allgemein α; 1 + ᾱ ɟ 1' = 1, und a fortiori α; 1 + (ᾱ ɟ 1'); 1 = 1 wie auch zeilenrechnerisch leicht zu zeigen.
Das Ergebniss lässt jedoch noch an Symmetrie zu wünschen.
Wegen 0'̆ = 0' gilt aber nach 11) des § 27 der Satz: 26) und konjugirt dazu.
Darnach lässt sich auch schreiben: a = α + {(β̄ ɟ 1' + ᾱ) ɟ 0} · (ᾱ ɟ 1'); 1 und würde die Symmetrie unsrer Lösung eine vollkommne sein, falls der Faktor (ᾱ ɟ 1'); 1 wegfiele.
Dies legt die Vermutung nahe, dass schon folgendes die Lösung darstelle: 27) a = α + (β̄ ɟ 1' + ᾱ) ɟ 0, b = β + (ᾱ ɟ 1' + β̄) ɟ 0 — worin die zweiten Glieder denselben Wert repräsentiren und blos in ihrer Ausdrucksform differiren.
(a; 0')b; 1 = (b; 0')a; 1 (a ɟ 1' + b) ɟ 0 = (b ɟ 1' + a) ɟ 0
Und dies bestätigen die beiden Proben.
Nennt man zur Abkürzung 28) (α; 0')β; 1 = γ = (β; 0')α; 1, so ist a = α + γ̄, b = β + γ̄ unsre Lösung.
Denn für γ = 1 wird a = α, b = β und stimmt somit die Probe 2.
Weil ferner γ sowie γ̄ „System ist, haben wir γ̄; 0' = γ̄; 1; 0' = γ̄; 1 = γ̄ a; 0' = α; 0' + γ̄, a; 0' · b = α; 0' · β + γ̄, (a; 0')b; 1 = (α; 0')β; 1 + γ̄ = γ + γ̄ = 1, und stimmt also auch die Probe 1 für beliebige α, β, q. e. d.
Die beiden Lösungsformen für a sind gleichwohl wesentlich verschieden, sintemal zu ihrer Übereinstimmung erforderlich (und hinreichend) wäre, dass allgemein (ᾱ ɟ 1' + β̄) ɟ 0 ⋹ α + (ᾱ ɟ 1'); 1 gälte, was schon bei β̄ = 1 nicht zutrifft.
Wir hatten nun durch x der Forderung 50) sub 10) Genüge zu leisten, welche bedingt: 1 ⋹ ax; 1 ⋹ x; 1, 1 ⋹ bx̄; 1 ⋹ x̄; 1, d. h. a fortiori muss x; 1 = 1 und x̄; 1 = 1 sein, oder unser x — nach S. 475 das konverse desjenigen in 22) — kann weder Leerzeilen noch Vollzeilen haben.
Weil γ̄ = etc. ɟ 0 System ist, so muss also sein γ̄x; 1 = γ̄ · x; 1 = γ̄, ebenso γ̄x̄; 1 = γ̄, und wenn wir die Abkürzung 28) beibehalten, so dreht sich die Frage darum, ob es möglich ist mit den Werten 27) von a, b unsrer Forderung 50) bei ganz beliebigen Werten von α, β allemal durch ein x zu genügen.
Diese Forderung hat aber nach dem Gesagten die Gestalt: 29) (αx; 1 + γ̄ = 1)(βx̄; 1 + γ̄ = 1).
In Worten: jede Zeile der beiden linkseitigen Membra muss zur Vollzeile gemacht werden können.
Aufgrund des Wertes: 30) γ̄ = (β̄ ɟ 1' + ᾱ) ɟ 0 = (ᾱ ɟ 1' + β̄) ɟ 0 lässt sich auch ohne Kenntnis der allgemeinen Lösung zu 29) zeigen, dass dies in der That möglich ist.
Im allgemeinen wird γ̄ selbst schon gewisse Vollzeilen haben, und für diese bleibt dann ihre Besetzung bei x resp. x̄ mit Augen und Leerstellen in’s Belieben gestellt.
Zu jenen gehören wegen ᾱ ɟ 0 ⋹ γ̄ und β̄ ɟ 0 ⋹ γ̄ zunächst die Leerzeilen von sei es α sei es β.
Sodann aber auch diejenigen Zeilen, wo ein Zeilenreiter von α zusammenfällt mit einem Zeilenreiter von β, d. h. wo α und β eine einbesetzte Zeile gemein haben.
Denn da β̄ ɟ 1' nächst den Vollzeilen von β̄ nur aus den einbesetzten Zeilen von β besteht, werden letztere (und nur sie) mit den in ᾱ in ihr einlückiges Negat verkehrten kongruent einbesetzten Zeilen von α sich noch zu Vollzeilen ergänzen.
Nun hebt das Relativ (ᾱ ɟ 1')α aus α dessen einbesetzte Zeilen hervor und ebenso das (β̄ ɟ 1')β die einbesetzten Zeilen aus β.
Das Produkt der beiden: (ᾱβ̄ ɟ 1')αβ gibt die dem α und β gemeinsamen einbesetzten Zeilen, und ebendies, mit 1 relativ nachmultiplizirt, liefert die Vollzeilen, welche demnach den Überschuss von γ̄ über die Summe aus ᾱ ɟ 0 und β̄ ɟ 0 allein noch ausmachen können und um welche γ̄ diese Summe wirklich übertrifft, weil solche Zeilen weder zu den Leerzeilen von α noch zu denen von β gehören können.
Wesentlich aus der geometrischen Evidenz ist hiermit ein Satz entdeckt, der, wenn man noch a, b für ᾱ, β̄ sagt und sein konjugirtes Gegenstück voranstellt, lautet: 31) [Formel] etc., und aus welchem rechts die Symmetrie der linken Seiten bezüglich a und b erhellt.
Zur Stelle wollen wir diesen Satz auch aus den Koeffizienten beweisen.
Der links vom Mittelstriche läuft auf zwei Subsumtionen hinaus, die bei Umstellung gewisser Terme sich darstellen als: 32) (a; 0')b; 1 · (āb̄ ɟ 1')ab; 1 ⋹ 0, 33) a; 1 · b; 1 ⋹͇ (a; 0')b; 1 + (āb̄ ɟ 1')ab; 1 = {a; 0' + a(b̄ ɟ 1')}b; 1.
Zum Beweis der erstern ist zu zeigen, dass Σh k lai h0'h kbi kai lbi lΠm(āi mb̄i m + 1'm l) = 0 sein müsse, was in der That daraus einleuchtet, dass bei h ≠ k und m ≠ l doch sicher entweder āi hb̄i h oder āi kb̄i k als effektiver Faktor des Πm auftritt und am vorhergehenden Negate des einen von den beiden Termen, nämlich an dem ai h oder an dem bi k, zerschellt.
Die letztre Subsumtion erheischt den Nachweis dass: Σh kai hbi k⋹Σh k {ai h0'h k + ai kΠm(b̄i m + 1'm k)}bi k. Ersetzt man im letzten Teile den laufenden Zeiger k durch h, so lässt sich die rechte Seite auch schreiben: Σhai h{Σkbi k0'k h + Πm(b̄i m + 1'm h)bi h}, worin der Faktor Πm (‥) als Negat des vorhergehenden Gliedes unterdrückbar.
Ersetzt man alsdann das verbleibende letzte Glied bi h durch das ihm gleiche Σkbi k1'h k, so zieht sich wegen 0'h k + 1'h k = 1 die rechte Seite zusammen zu Σhai hΣkbi k, das ist zur linken selber, woraus erhellt, dass die zweite Subsumtion sogar als Gleichung gilt.
Man kann jedoch hier auch ohne die Koeffizientenbetrachtung zum Ziele kommen, indem man ihre rechte Seite selbst kraft 26) umschreibt in: a{b; 0' + (b̄ ɟ 1')b}; 1 = a(b; 1); 1 = a; 1 · b; 1, sintemal zunächst der Faktor b̄ ɟ 1' wegfällt, dann b; 0' + b = b; 1 in Betracht kommt. —
Man könnte jedoch die rechte Seite von 33) auch umformen in: (a; 0' + a)(a; 0' + b̄ ɟ 1')b; 1 = a; 1 · (a; 0' + b̄ ɟ 1')b; 1 = a; 1 · {b; 0' · a + (b̄ ɟ 1')b}; 1, wo nun die geschweifte Klammer zerlegbar in (b; 0' + b){a + (b̄ ɟ 1')b}, darnach das Ganze wird = a; 1 · b; 1 · {a + (b̄ ɟ 1')b}; 1 und endlich der dritte Faktor im ersten eingeht.
Die übrigen, weder zu ᾱ ɟ 0 noch zu β̄ ɟ 0 als Vollzeilen gehörigen Zeilen müssen nun bei α sowol als bei β besetzte Zeilen sein.
Sooft in einer solchen Zeile α ein Auge trägt, welches nicht mit einem Auge von β zusammenfällt, genügt es aber, jenes zu x und irgend ein in derselben Zeile stehendes Auge von β zu x̄ zu schlagen, d. h. bei x leer zu lassen, um ebendiese Zeile sowol bei αx; 1 als bei βx̄; 1 zur Vollzeile zu machen.
Ebenso, wenn α und β in einer Zeile mindestens zwei Augen gemein haben, kann man das eine zu x das andre zu x̄ schlagen und wird dieselbe Wirkung erzielen.
Nur wenn α und β das Auge einer einbesetzten Zeile gemein haben, würde solches unmöglich bleiben.
Hier aber werden wir durch den Umstand, dass alsdann, wie gezeigt, die Zeile in γ̄ als Vollzeile figurirt, der Auflage oder Nötigung dazu überhoben.
Wir sind damit zu dem Ergebnisse gelangt, dass bei unabhängigen Parametern α, β das Problem 29) stets nach x auflösbar ist.
Oder: auch zu dem Probleme 50) sub 10) ist Peirce’s Resultante noch die volle.
Sie ist es also bei den fünf ersten der zehn sub 10) gelösten Probleme.
Ähnlich eine Entscheidung auch für die übrigen fünf Probleme herbeizuführen dürfte seine Schwierigkeiten haben, und sei Forschern zur Bethätigung empfohlen.
Peirce’s Grundgedanke, die Prämissen als Subsumtionen mit dem Subjekte 1' angesetzt zu nehmen, erscheint mir — abgesehen von der von ihm beabsichtigten Anwendung (deren Berechtigung wir noch zu prüfen haben werden) auf eine verbal-logische Syllogistik — kein besonders glücklicher.
Derselbe ist für sein Eliminationsverfahren keineswegs wesentlich und bewirkt nur, dass erstlich die Prämissen eine speziellere (engere) Form erhalten als nötig, und zweitens, dass man — ungeachtet meiner Reduktion von 22 auf 10 — doch immer noch mehr Fälle zu unterscheiden bekommt als bei allgemeinrer Fassung des einschlägigen Eliminationsproblemes.
Unter dem rechnerischen Gesichtspunkte empfiehlt es sich daher, sich von jener Stipulation zu emanzipiren und statt des Subjektes 1' sogleich beliebige Parameter a, b, c, … als Subjekte zuzulassen.
Alsdann kommen in der That nur Prämissen von dreierlei (statt viererlei) Formen in Betracht, nämlich für die erste Prämisse: 34) a⋹x, a⋹b; x, a ⋹ b; (c ɟ x) — desgleichen für die zweite Prämisse, wo nur x̄ statt x zu sagen und statt der Parameter a, b, c neue Parameterwerte (eventuell b, c …)
d, e, f zu nehmen sind.
Eine Form a ⋹ b ɟ x, welche äquivalent b̄̆; a ⋹ x, käme in der That auf a ⋹ x für ein durch b̄̆; a vertretnes Subjekt a hinaus, und kann daher als aparte Prämissenform nicht in Betracht kommen.
Ebensowenig wäre a ⋹ b ɟ c; x, als äquivalent b̄̆; a ⋹ c; x, von unsrer zweiten Prämissenform wesentlich verschieden.
Wir erhalten so nur 6 Probleme (von allgemeinerem Charakter) statt der 10 früheren (die von speziellrer Natur gewesen).
Die nach Peirce’s Methode durch Konversion der einen Prämisse und überschiebendes relatives Multipliziren dieser konvertirten mit der andern in solcher Folge, dass x und x̄̆ (oder x̄ und x̆) zusammenkommen (= meet), zu gewinnenden Resultanten sind die nachfolgend angegebenen: 35) [Formel] . Rechts neben sie haben wir diejenigen Teilresultanten gestellt, welche aus einer Prämisse schon einzeln folgen — die „Einzelresultanten“.
Als Herleitung hat man z. B. bei der vorletzten Aufgabe: c; ă ⋹ d; (e ɟ x̄); x̆; b̆ ⋹ d; (e ɟ x̄; x̆); b̆ ⋹ d; (e ɟ 0'); b̆ = d; e; b̆, und bei der letzten: a; d̆ ⋹ b; (c ɟ x); (x̄̆ ɟ f̆); ĕ ⋹ b; {(c ɟ x); x̄̆ ɟ f̆}; ĕ ⋹ b; {(c ɟ x; x̄̆) ɟ f̆}; ĕ ⋹ ⋹ b; {(c ɟ 0') ɟ f̆}; ĕ = b; (c ɟ f̆); ĕ, doch kann man hier noch auf zwei andre Arten weiterschliessen und findet dasselbe Ergebniss, z. B. sogleich mit ⋹ b; (c ɟ x; x̄̆ ɟ f̆); ĕ ⋹ b; (c ɟ 0' ɟ f̆); ĕ = etc.
Dagegen würden a; d̆ ⋹ (b; c ɟ f̆); ĕ oder ⋹ b; (c ɟ f̆; ĕ) oder gar ⋹ b; c ɟ f̆; ĕ entschieden weniger sagende Teilresultanten der vorigen sein.
Das erste von den sechs Problemen fällt in den Umkreis, Rayon des identischen Kalkuls.
Um die verschiednen Formen seiner Resultante direkt aufeinander zurückzuführen, schliesse man nach dem ersten Inversionstheoreme: (a; b̆ ⋹ 0') = (a ⋹ 0' ɟ b̄ = b̄ = b̄ ɟ 0') = (b̆; a ⋹ 0').
Etc. cf. 22) des § 8 S. 127.
Während die Resultante beim ersten Problem (sonach) die volle ist, begreifen die übrigen fünf nach Peirce’s Methode gewonnenen Resultanten nicht einmal die „Einzelresultanten“ der Prämissen unter sich und sind zweifellos nicht die vollen.
Diese können wir leicht auch beim zweiten und dritten Probleme angeben, wo sie vielmehr lauten: 36) [Formel] und sich nach Kontraposition der ersten Prämisse in x̄ ⋹ ā a fortiori ergeben.
Der Beweis ihrer Vollständigkeit liegt darin, dass, sobald sie erfüllt, sich x = a als eine Lösung erweist.
Dass in der That die Peirce’sche Resultante aus unsrer vollen mit folgt, ist beim dritten Probleme aus c; (d ɟ ā) ⋹ c; d ɟ ā nach 7) des § 6 unmittelbar ersichtlich, indem eben jene nach dem ersten Inversionstheorem in b ⋹ c; d ɟ ā umgeschrieben werden kann.
Der gleiche Nachweis führt beim zweiten Probleme zur Konstatirung eines interessanten Satzes: 37) [Formel] in welchem man natürlich auch die untereinanderstehenden Subsumtionen in eine einzige zusammenziehen könnte.
Beweis mittelbar aus a; b; b̄̆ ⋹ a; 0' durch Hinüberwerfen des b̄̆, oder auch mittelst des Schlusses: a; b = a; (0' ɟ b) ⋹ a; 0' ɟ b.
Auch mittelst rhetorischer Evidenz:
Ein Liebender (amans) von Wohlthätern (benefactors) ist nicht nur (äquivalent) Liebender von »andern als: allen ausser Wohlthätern«, sondern auch (subsumtion weise) „Liebender von Andern“ inbezug auf alle ausser Wohlthätern; und letztres lässt sich offenbar nicht umkehren:
Wer inbezug auf alle ausser Wohlthätern, inbezug auf alle Nicht-Wohlthäter ein Liebender ist von Andern, braucht darum noch nicht ein Liebender zu sein von Wohlthätern.
Beim Beweise durch die Koeffizientenevidenz kommt man, rechts auf 0 bringend, nach Weglassung der vorangeschriebnen Σh und Σl auf die Gleichung: ai hbh jb̄l jΠk(āi k + 1'k l) = 0, worin im Produkte Π der Faktor mit k = l unwirksam.
Nun ist für h = l das Verschwinden der linken Seite ersichtlich; für h ≠ l aber wird k = h einen wirksamen Faktor āi h abgeben, der mit dem ersten zusammentreffend 0 liefert, q. e. d.
Bei n = 3, also im Denkbereiche 1 ⅓, hat man, wenn bei a das konstante erste Suffix i, bei b das letzte j unterdrückt wird, z. B. die Einordnung: a1b1 + a2b2 + a3b3 ⋹ (a2 + a3 + b1)(a1 + a3 + b2)(a1 + a2 + b3).
Bei dem vierten Probleme 35) haben wir für die Prämissen nach unserm Theorem 18) des § 18 und durch Kontraposition die Äquivalenzen: (a ⋹ b; x) = {b̆; a(b̄ ɟ x̄) ⋹ x} = {x̄ ⋹ b̄̆ ɟ (ā + b; x)}, (c ⋹ d; x̄) = {d̆; c(d̄ ɟ x) ⋹ x̄} = {x ⋹ d̄̆ ɟ (c̄ + d; x̄)}.
Setzt man in der letzten Form der einen für x resp. x̄ ohne Ende fort das Prädikat aus der letzten Form der andern (sowie umgekehrt) ein, so erhält man a fortiori die Konklusionen: 38) [Formel] und diese vereinigt dürften wol(?) die vollständige Resultante vorstellen, welche hienach zu komplizirt ist, um in geschlossner Form gegeben werden zu können.
Wol in ähnlicher Weise müssten auch bei den folgenden Eliminations-Problemen 35) die Peirce’schen Resultanten noch zur vollen Resultante Ergänzung finden.
Immerhin besitzt Peirce’s Eliminationsverfahren das Verdienst, in geschlossener Form Schlüsse zu liefern, welche, ohne eine Technik wie diejenige unsrer Disziplin, mit dem gemeinen Verstande nicht leicht jemand zu ziehen vermöchte!
Ich habe hiermit die Studie so weit geführt, als mir bei der Überlast der sonstigen Themata unsrer Disziplin vergönnt gewesen.
Ersetzte man in der zweiten Prämisse der sechs Probleme 35) — die erste ungeändert beibehaltend — das x̄ ebenfalls durch x, so würde schon das System der „Einzelresultanten“ jeweils das volle Eliminationsergebniss darstellen, indem hernach x = 1 eine Wurzel sein müsste.
Die Probleme verlören damit als Eliminationsprobleme ihr hauptsächlichstes Interesse.
Ich mache übrigens zuguterletzt (und im Laufe der Drucklegung) die Entdeckung: dass in unsrer Algebra der Relative das Eliminationsproblem sich ganz allgemein lösen lässt.
Und zwar ist zu irgend einer Gleichung F(x) = 0 die volle Resultante der Elimination des x angebbar in Gestalt der (augenscheinlich von x freien) Relation: 39) — ein Sachverhalt, der sich erschöpfend ausdrücken lassen wird in Form der Aussagenäquivalenz: 40) [Formel] .
Diese kann als solche schon aus dem Schema 8) des § 11, S. 152 gerechtfertigt werden, wie sogleich erhellen wird.
Jedoch lässt sich alles auch ganz leicht unmittelbar einsehen wie folgt.
Gibt es ein x, für welches die Gleichung F(x) = 0 besteht, so verschwindet in unserm [Formel] bei 39) mindestens der (dem u = diesem x entsprechende) Faktor 1; F(x); 1 und ist darum die Gleichung 39) als „eine Resultante“ notwendig erfüllt.
Aber auch umgekehrt: falls 39) gilt, so muss, da jeder Faktor des [Formel] als ein ausgezeichnetes Relativ blos der beiden Werte 0 und 1 fähig ist, mindestens ein Faktor dieses Π gleich 0 sein, und, wenn x der Wert eines solchen u genannt wird, wofür dies zutrifft, so ist nach 5) des § 10, S. 147 dieses x auch eine Wurzel der Gleichung F(x) = 0, die Gleichung mithin auflösbar.
Das heisst: die Resultante 39) muss die volle sein.
In diesem Falle läuft die Äquivalenz 40) auf 1 = 1 hinaus.
Gibt es kein x, welches die Gleichung F(x) = 0 erfüllt, so ist jedes F(u) ≠ 0, sonach jeder Faktor des [Formel] gleich 1 und also auch dieses selber = 1. Alsdann tritt als Resultante 39) die absurde Gleichung 1 = 0 zutage, comme de juste.
Und umgekehrt, wenn als Resultante 1 = 0 aus F(x) = 0 folgt, so kann diese Gleichung unmöglich eine Wurzel haben.
In diesem Falle bewahrheitet sich die Äquivalenz 40) ebenfalls, und zwar als 0 = 0, q. e. d.
Die andre oben angedeutete Begründungsweise unsrer Äquivalenz 40) beruht ersichtlich auf dem 43) der folgenden Schemata, zu denen sich mit Rücksicht auf 3), 4) des § 11 die dortigen Sätze 6) bis 9) auch noch zusammenziehn lassen: 41) 42) 43) 44) — worin a als ein variables Relativ zu denken ist, und die Π, Σ irgendwelche, aber beiderseits die nämliche Erstreckung haben mögen.
Π(a = 0) = {1; (Σa); 1 = 0} Π(1 = a) = (1 = 0 ɟ Πa ɟ 0)
Σ(a ≠ 0) = {1 = 1; (Σa); 1} Σ(1 ≠ a) = (0 ɟ Πa ɟ 0 = 0)
Σ(a = 0) = (1; Πa; 1 = 0) Σ(1 = a) = {1 = Σ(0 ɟ a ɟ 0)}
Π(a ≠ 0) = (1 = 1; Πa; 1) Π(1 ≠ a) = {Σ(0 ɟ a ɟ 0) = 0}
„Eine“ richtige Resultante der Elimination des x aus F(x) = 0 ist allemal auch schon die Gleichung: 45) [Formel] .
Diese aber wird im allgemeinen keineswegs die volle sein.
Denn da uns F(u) nur irgend ein Relativ vorstellt, welches (auch) andre Werte als 0 und 1 anzunehmen fähig ist, so kann das ΠF(u) sehr wohl verschwinden ohne dass überhaupt jemals ein Faktor desselben 0 würde.
Mit 40) oder 39) erscheint die vollständige Lösung des allgemeinen Eliminationsproblems zurückgeführt auf die Auswertung einer Summe Σ, resp. eines Produktes Π.
Wie jene im Gegensatz zur Addition eine Summation, Summiren genannt wird, so gestatte ich mir, diese im Gegensatz zur Multiplikation als eine Produktation, ein Produktiren zu bezeichnen; denn ein unterscheidender und kurzer Name dafür stellt sich als unentbehrlich dar.
Beide Aufgaben und Operationen sind demnach von fundamentaler Bedeutung.
Ein einfaches Beispiel zu dem mit Schema 39) gegebnen Eliminirverfahren dürfte wol willkommen sein.
Sei x zu eliminiren aus a ⋹ x; b, so muss die volle Resultante lauten:
[Formel] . Das Π zur Linken muss aber den Wert haben:
1; a(0 ɟ b̄); 1, denn dieser dem Werte ū = 0 entsprechende Faktor ist in allen andern enthalten und kommt bei u = 1 wirklich vor; er ist der minimale unter allen Faktoren.
Die gesuchte Resultante fordert also das Verschwinden besagten Faktors und Produktwertes, was auf a(0 ɟ b̄) = 0 selbst hinausläuft und womit in Übereinstimmung mit § 18 nunmehr „systematisch“ a ⋹ 1; b als die Resultante gefunden ist.
Die Erstreckung der Σ, Π war vorstehend „die absolute“, nämlich über alle Relative u des Denkbereiches 12 — ein Fall jedoch, auf welchen auch der einer beschränkten, irgendwie bedingten Erstreckung jeweils leicht zurückzuführen sein wird — vergl. 35) des § 29.
Der allgemeine Term der Π, Σ, in 39) von der (spezielleren) Form eines ausgezeichneten Relativs, kann jedoch allgemeiner — und wie z. B. in 45) — als eine beliebig gegebene Relativfunktion angesetzt werden.
[Von dem S. 35 erläuterten Begriffe einer solchen Relativfunktion f(u) ist der Begriff eines Relativs, welches „Funktion“ ist, wohl zu unterscheiden.]
Fundamental ist also namentlich die Ermittelung des Schnittes, der Gemeinheit Π von all den Relativwerten, die ein Ausdruck f(u) anzunehmen vermag.
Durch diese Erwägungen erscheint es gerechtfertigt, wenn wir nun im nächsten Paragraphen den Sätzen über die Π und Σ von Relativen, sowie den Methoden zu ihrer Evaluation unsre Aufmerksamkeit zuwenden — Methoden, auf deren weitrer Ausgestaltung und Vervollkommnung schliesslich die Zukunft unsrer Disziplin zu einem Hauptteile beruhen wird.
§ 29.
Über von Peirce so genannte „Entwickelungsformeln“: Summationen und Produktevaluationen.
Zum Inversionsproblem.
In 9c p. 190 (desgl. 5 p. 55) bemerkt Peirce, es gebe in der relativen Algebra eine Anzahl von „curious development formulae“, wie: 1) wo die Π und Σ als identische Produkte resp. Summen zu erstrecken sind über alle Relative des Denkbereiches 12.
Es fehlt jegliche Andeutung über Entdeckungsweise, Beweis und etwaige Verwendungsweise dieser ganz eigenartigen Formeln, derengleichen — mit sehr entfernter Ähnlichkeit — uns bis jetzt nur in § 23 und 24 vorgekommen.
Die Schemata werden sich als zur Auswertung von Summen Σ und Produkten Π sehr nützliche erweisen.
Wir wollen uns zunächst mit dem Beweis der Formeln 1) beschäftigen, der nur für die erste derselben geleistet zu werden braucht.
Dabei wird von selbst ein Weg sich offenbaren, auf welchem die Formeln auch entdeckt werden konnten.
Durch naheliegende Umformungen ergibt sich:
[Formel] und daraus, indem man beiderseits das Π nach u nimmt: 2)
[Formel] .
Und nebenbei mag man, d für u sagend, die Sätze notiren: 3)
[Formel] welche sich denen 14) und 15) des § 6 anreihen, übrigens (in u statt d) auch schon aus 1) abgelesen werden können, indem das Produkt eingeordnet seinem Faktor, etc.
Durch 2) ist nun die erste Gleichung 1) bereits als vorwärtige Subsumtion [Formel] etc. erwiesen.
Um nun auch die umgekehrte Subsumtion zu beweisen, könnte man folgenden Weg einschlagen, welcher wenigstens zu einem bedingten Beweise der Formel 1) führt, daneben uns mit einem nicht uninteressanten Auflösungsprobleme bekannt macht.
Da das Produkt [Formel] in 1) einem jeden Faktor seinerselbst eingeordnet ist, so wird die Einordnung desselben unter ab; c, und damit unser Satz sicher dann erwiesen sein, wenn es uns gelingt zu zeigen, dass es unter den Faktoren des [Formel] — sagen wir bei u = x — einen gibt, welcher selbst ⋹ ab; c ist.
Diesen entdecken wir durch Auflösung der Subsumtion: a; xc + b; x̄c ⋹ ab; c, welche auch als Gleichung ansetzbar, da die rückwärtige nach 3) ohnehin gilt.
Die Subsumtion aber zerfällt in: (a; xc ⋹ ab; c)(b; x̄c ⋹ ab; c), was = (xc ⋹ ā̆ ɟ ab; c)(x̄c ⋹ b̄̆ ɟ ab; c) nach dem ersten Inversionstheorem ist.
Sonach finden wir leicht als Resultante und Lösung: c · b̆; {(ā + b̄) ɟ c̄} ⋹ x ⋹ c̄ + ā̆ ɟ ab; c oder — getrennt — als Resultante: c⋹ā̆ ɟ ab; c + b̄̆ ɟ ab; c und als Lösung (für ein arbiträres v): x = (c̄ + ā̆ ɟ ab; c)
v + c · b̆; {(ā + b̄) ɟ c̄} · v̄.
Die eben erwähnte Gleichung gehörte also zu den komplizirteren, die wir doch in geschlossener Form zu lösen vermögen.
Nebenbei lässt die gleiche Überlegung sich auch an die Gleichung 2) anknüpfen, indem man ganz analog x aus der Forderung ab̄; xc + āb; x̄c ⋹ ab; c bestimmt.
Man findet nur die Resultante und Lösung in etwas komplizirteren Formen, und müssen die Ergebnisse wesentlich mit den vorigen übereinstimmen, die Grenzen namentlich, zwischen denen x einzuschliessen ist, dieselben wie vorhin sein — wohlgemerkt aber nur sofern die Resultante erfüllt ist, wogegen sie im Allgemeinen, bei beliebigen a, b, c, von den vorigen differiren.
Hierin sind wieder manche Sätze verborgen. —
Dass nun unsre Resultante nicht identisch erfüllt ist, zeigt sich, abgesehen von der Vergeblichkeit jedes Versuchs, sie aus den Koeffizienten zu beweisen, am besten exemplificando.
Für b = ā, c = 0' z. B. müsste sich erweisen:
0' ⋹ ā̆ ɟ 0 + ă ɟ 0, wo für ă = 1αβγ0 das Prädikat 10001 mit beliebigen Leerzeilen ausgestattet ist und folglich das Subjekt 0' nicht unter sich enthalten kann.
Unser Satz 1) ist hienach bis jetzt blos für den Fall, wo die Resultante erfüllt ist, erwiesen.
Man könnte nun, weil es einen Wert x von u der gesuchten Art nicht unbedingt gibt, versuchen ob sich nicht vielleicht zwei Werte x und y von u finden lassen, so, dass bedingungslos: (a; xc + b; x̄c)(a; yc + b; ȳc) ⋹ ab; c wird, und falls auch hiefür wieder eine Bedingung resultiren sollte, nach drei Werten x, y, z von u fahnden, für welche das Produkt der einschlägigen Faktoren ⋹ ab; c wäre, und so fort.
Doch dürfte ein weiteres Vordringen auf diesem Wege immer schwieriger werden; auch erscheint es fraglich, ob solchem Verfahren ein endlicher Erfolg zufallen würde — der: den Satz 1) als bedingungslos gültigen bewiesen zu haben.
Bevor wir die Digression dieses Kontextes verlassen, sei noch darauf aufmerksam gemacht, dass der Satz 3) für c = 1 — wenn zuletzt für d dann c gesagt wird — in Gestalt von ab; 1 ⋹ a; c + b; c̄ eine Verstärkung, Steigerung unsres Satzes 14) des § 6 vorstellt: nicht blos ab, sondern, was noch mehr besagt, sogar ab; 1 ist der rechten Seite eingeordnet.
Ebenso ist der Spezialfall für c = 1 resp. 0 des Satzes 1): 4) besonders bemerkenswert.
Endlich sei als schätzenswerte Übung dem Anfänger empfohlen, auch die Gleichung a; x + b; x̄ = ab, welche mit ihrer vorwärtigen Untersubsumtion äquivalent ist, in analoger Weise aufzulösen.
Man findet b̆; (ā + b̄) ⋹ x ⋹ ā̆ ɟ ab, und lässt die Resultante 1 = ā̆ ɟ ab + b̄̆ ɟ ab sich in vielen merkwürdigen Formen schreiben, z. B. (scheinbar unsymmetrisch) als 1' ⋹ ā̆ ɟ ab ɟ ăb̆ ɟ b̄, sowie als a; b̆ + b; ă ⋹ ab ɟ ăb̆, wo von den zwei Gliedern links auch eines unterdrückbar.
Man zeige, dass dann auch ab = ab ɟ 0 = ab; 1, mithin ab „System“ sein muss.
Mit einem Schlage beweist sich unser Satz 1) aus 2) durch den Nachweis, dass hier rechterhand das letzte Glied verschwindet.
Wir haben in der That die Sätze: 1a) deren ersten blos noch zu beweisen erübrigt.
Hiezu genügt der Nachweis, dass es unbedingt möglich ist, u so anzugeben, dass eine irgendwie gewählte Matrix-Stelle des Relativs R = ab̄; uc + āb; ūc zur Leerstelle wird.
Gibt es für jede Stelle in R ein solches Relativ u, für welches gerade diese als Leerstelle sich erweist, so werden in dem [Formel] auf alle Stellen in gewissen der Faktoren Leerstellen kommen und das Produkt wird 0 sein.
Nun ist für ein irgendwie angenommenes aber dann bestimmt festgehaltenes Suffix ij:
[Formel] .
Nimmt man das u so an (genauer gesagt: fasst man von allen erdenklichen u, über welche das Π sich erstreckt, das durch die nachfolgende Beschreibung charakterisirte in’s Auge), dass für alle h bei gedachtem bestimmten ij uh j = (āb)i h = āi hbi h also ūh j = (a + b̄)i h = ai h + b̄i h ist — beispielsweise [man könnte auch die Summe links, das Produkt rechts ansetzen] — so wird nun in der That, wie gewünscht, das betreffende Ri j = 0 sein.
Und um diesen Effekt hervorzubringen war blos erforderlich, die jte Kolonne von u so wie eben angegeben besetzt, die übrigen Stellen von u irgendwie ausgefüllt (oder auch leer gelassen) zu denken.
Allgemein, nämlich für alle ij zugleich, lässt sich diese Wirkung durch ein und dasselbe u nicht erzielen, weil ja die Besetzung seiner Kolonnen, als eine von dem Zeilenindex i der a und b abhängige, gleichzeitig verschiedenen und im Allgemeinen nicht miteinander vereinbaren Bestimmungen unterliegen würde.
In dem Produkte [Formel] ist demnach mindestens einer der Faktoren Ri j gleich 0 — bei einem andern ij der einem andern u entsprechende — und folglich verschwindet dasselbe für jedes ij, wie behauptet.
Die Schlussweise sei noch durch ein Korollar bekräftigt und illustrirt.
Für b = ā erhalten wir insbesondre:
[Formel] , was etwa für c = 1, a = 1' gibt:
[Formel] .
Obwol nun z. B. für die Modulwerte von u der allgemeine Faktor dieses Π nichts weniger als verschwindet, vielmehr in drei Fällen = 1, im vierten noch = 0' wird, muss doch das Produkt verschwinden.
Kolonnenschematisch haben wir nämlich für u = 1αβγ0 hier u + 0'; ū = 1α111.
Der allgemeine Faktor unsres Π besteht also stets und ganz aus Vollkolonnen und einlückigen Kolonnen.
Werden letztre auf jede erdenkliche Weise angesetzt, so fällt auf jede Matrixstelle in mindestens einem Faktor eine Lücke einer einlückigen Kolonnen und das Produkt verschwindet.
In der Reihe seiner Abhandlungen über die Algebra der Relative, die sich immerhin über anderthalb Jahrzehnte erstrecken, hat Herr Peirce 2, 5, 6, 9c, 8 sein Bezeichnungssystem mehrmals mehr oder minder gründlich gewechselt.
Dies lag in der Natur der Sache.
Kam es doch darauf an, von den noch so unvollkommnen Anfängen De Morgan’s sich erst emporzuringen zu einer den Bedürfnissen des logischen Denkens vollkommen adäquaten „Begriffsschrift“, die auch das weite Feld der relativen Begriffe beherrsche — was nach und nach vollbracht zu haben ein unsterbliches, kaum hoch genug zu preisendes Verdienst Peirce’s bleibt!
Was jedoch das Studium seiner Abhandlungen nicht unerheblich erschwert ist der Umstand, dass der Autor, bei solchem durch sein eignes Fortschreiten bedingten Wechsel des Bezeichnungssystems jeweils das bisherige ältere nicht gebührend verabschiedet, dass er den Wechsel so gut wie unvermittelt vollzieht — sodass es dem Leser, der das eine, etwa das vollkommnere Bezeichnungssystem sich angeeignet, überlassen bleibt, sich den „Schlüssel“ zum Verständnis des andern, aller vorhergehenden, selbst zu suchen, was die Zumutung birgt, sozusagen in eine von ihrem Autor (und ihm allein!) vor Jahren einmal gebrauchte, und zugunsten einer bessern für immer aufgegebene, fremdsprachige Hieroglyphenschrift sich von vorne einarbeiten zu müssen.
Um für den Leser meines Buchs die Abhandlung 5 von Peirce, soweit sie unsre Relative betrifft, verständlich zu machen und ihm Vergleichungen zu erleichtern, wenn nicht zu ermöglichen, will ich solchen Schlüssel hier beibringen — wie ihn die Rückübersetzung (in unsre Zeichensprache) der verbalen (auch nicht immer zweifellos univoken) Auslegung von Peirce’s ältern dortigen Symbolen liefert (vergleiche spätere Studien über Interpretation, nebst Einkleidungsübungen).
Statt zweier werden l. c. noch vier relativ knüpfende Spezies unterschieden, ihre Erzeugnisse, wie in Klammer folgt, bezeichnet und sie zu benennen vorgeschlagen: 5)
[Formel] .
Von diesen vier Operationen — bemerkt Peirce l. c. — habe De Morgan die drei ersten „studirt“, der vierten, und damit der völligen Symmetrie seiner Aufstellungen, entratend.
Zugunsten unsrer beiden a; b und a ɟ b erzeugenden Spezies sind diese Bezeichnungsarten samt den zugehörigen Benennungen mit Recht in 9c fallen gelassen.
In ihnen jedoch finden sich die Formeln 1) erstmals auf 5 p. 55 mitgeteilt, wobei begreiflich viele Wiederholungen unterlaufen, nämlich, was für ein a, b, ‥ schon allgemein gesagt worden, für ein ā, ‥ nochmals statuirt wird — Wiederholungen, die blos in der älteren Bezeichnung nicht als solche zutage treten.
Ähnliches gilt inbezug auf die 5 p. 56 unter den Überschriften „Class 1 bis „Class 4“ von Peirce gegebnen Formelkomplexe, auf die wir vielleicht noch zurückkommen.
Übrigens lassen Peirce’s Sätze 1) sich sogleich verallgemeinern zu den folgenden: 6)
[Formel] .
Beweis ähnlich wie oben.
Es ist: au; b + cū; d = (ac + ac̄)u; (bd + bd̄) + (ac + āc)ū; (bd + b̄d) = = ac; bd + R, wo R = acu; bd̄ + ac̄u; bd + ac̄u; bd̄ + + acū; b̄d + ācū; bd + ācū; b̄d bedeutet, und — unter x das erste Π in 5) verstanden — [Formel] sein muss.
Es bleibt also nur ΠR = 0 zu beweisen.
Nun ist:
[Formel] .
Hält man aber multiplikativ zusammen ein jedes der drei Produkte acbd̄, ac̄bd, ac̄bd̄ mit jedem der dreie acb̄d, ācbd, ācb̄d, so bemerkt man, dass allemal mindestens zwei Faktoren zusammentreffen, die Negate von einander sind, und das verhält sich nicht anders, wenn die beiden ersten Faktoren in jedem dieser sechs Produkte mit dem Suffix ih, die beiden letzten mit dem hj behaftet sind.
Es ist sonach für jedes h: αhβh = 0.
Diese Gleichung ist aber die notwendige und hinreichende Bedingung dafür, dass ui h sich der Forderung αhui h + βhūi h = 0 gemäss bestimmen lasse.
Für ein bestimmtes ij kann also der Forderung Ri j = 0 dadurch genügt werden, dass nach h jedes ui h als Wurzel letztrer Gleichung angenommen wird, und damit wird auch [Formel] gleich 0 werden.
Im [Formel] fällt mithin auf jede Stelle mindestens eine Niete und muss deshalb ΠR = 0 sein, q. e. d.
Eine noch weiter gehende Ausdehnung des Satzes werden wir am Schluss des Paragraphen anführen.
Die Peirce’schen Sätze 1) und unsre Erweiterung derselben bilden den ersten Grundstock eines Kapitals von Sätzen und Methoden, welche uns in den Stand setzen: in unsrer Disziplin Summationen Σ auszuführen, sowie Produkte Π auszuwerten.
Bei vielen Untersuchungen ist es von Wert, das identische Produkt (die Gemeinheit) angeben zu können aller der Relative x, welche eine bestimmte Bedingung erfüllen, z. B. Wurzeln einer gegebnen Gleichung sind — wie solches schon in der neunten Vorlesung zutage trat; desgleichen kann die Frage nach der identischen Summe von all den Wurzeln belangreich sein.
Darum schon verdient die — nicht ganz leichte — Kunst des Summirens und der Produktermittelung gepflegt und systematisch ausgebildet zu werden.
Vollends trat dieselbe am Schluss des § 28 als eine für die Probleme des Eliminirens, und Schliessens überhaupt, ganz fundamentale zutage.
Als der Sache nach hierher gehörig, wenn auch nicht mehr unter Peirce’s Publikationen fallend, will ich demgemäss nun eine Reihe von (eignen) Untersuchungen vortragen, welche auf die Vermehrung jenes Kapitals abzielen.
Es handelt sich jeweils um Summen Σ und Produkte Π, welche die „absolute“ Erstreckung: über den ganzen Denkbereich, haben.
Je nachdem aber der laufende Zeiger ein Elementsymbol i oder j, etc. und dessen Erstreckung der erste Denkbereich 11 ist, oder aber als Summations- resp. Produktationsvariable ein binäres Relativ u von beliebiger Art auftritt mit dem zweiten Denkbereiche 12 als Erstreckung — je nachdem können wir Summations- und Produktermittelungs-Aufgaben von zweierlei Stufe unterscheiden.
Während Peirce’s Sätze 1) schon der zweiten Stufe angehören, wollen wir damit beginnen, den Aufgaben erster Stufe auch unsre Aufmerksamkeit zuzuwenden.
Zur Einleitung wird der Leser sich leichtlich diese Gruppe von Sätzchen aus der Koeffizientenevidenz beweisen: 7) 8)
9) worin als laufender Zeiger immer i zu denken ist.
Σi = Σī = Σĭ = Σī̆ = 1 Πi = Πī = Πĭ = Πī̆ = 0
Σiĭ = 1' = Π(i + ī̆) = Π(ī + ĭ) Σiī̆ = Σīĭ = 0' = Π(ī + ī̆)
* Σīī̆ = 1 Π(i + ĭ) = 0,
Behufs des Beweises braucht man sich nur für die Σ resp. das Π den allgemeinen Koeffizienten zum Suffix hk anzusetzen und denselben zu diskutiren.
Z. B. bei 9) links wird solcher: (Σiīī̆)h k = Σiīh kīk h = Σi0'i h0'i k. Enthält nun der Denkbereich 11 mehr als zwei Elemente, so gibt es immer, auch bei h ≠ k, ein i für welches, weil es von beiden Elementen h und k verschieden ist, 0'i h0'i k = 1 ist, und wird die letzte Σi gleich 1, q. e. d.
Für den Denkbereich 1 ½ aus nur zwei Elementen würden die rechten Seiten in den Gleichungen 9) durch 1' resp. 0' zu ersetzen sein.
Wird für den Augenblick J unterschiedslos zum Repräsentanten eines der vier Elementverwandten i, ī, ĭ, ī̆ genommen, so kann man sich die Formeln 7) abkürzen in:
Weil dann Πφ(i)J ⋹ ΠJ, etc., so ist klar, dass auch allgemeiner wird sein müssen:
ΣJ = 1 ΠJ = 0.
Σ{φ(i) + J} = 1 Πφ(i)J = 0.
Von vornherein sind wir dadurch dessen überhoben, etwa Produktformeln für Ausdrücke wie Πia; i · i, Πiĭ · i; b, und dergleichen aufzustellen oder zu buchen, weil solche auf den ersten Blick — als gleich 0 — zu erkennen sind.
Etc.
Sätze, wie die sich auf Doppel- oder mehrfache Summen oder Produkte beziehen, wollen wir vorerst als solche noch ausser Betracht lassen.
Σi jij̆ = 1 Πi j(ī + j̄̆) = 0,
Mit Rücksicht auf 7) folgt nun aus 29) des § 25 der Satz: 10) [Formel] .
Doch ist es natürlich auch leicht, z. B. mit {Πi(a; i + ī̆)}h k = Πi{(a; i)h k + īk h} = Πi(ah i + 0'i k) = ah k die Koeffizientenevidenz für irgend eine der Formeln herbeizuführen.
Endlich werden dieselben — z. B. in Gestalt von Σia; i · ĭ; 1' = a; 1' — aus einem nachher zu gebenden allgemeineren Satze 14) ableitbar sein.
Weiter vermögen wir die Σi und die Πi zu evaluiren für die 16 Knüpfungen zwischen einem allgemeinen Relativ a und einem Verwandten des i, welche in den Formeln 21) bis 23) des § 25 abgehandelt wurden.
Fragliche Ergebnisse bringen 32 Formeln zum Ausdruck, die nebenher auch bemerkenswerte Darstellungen für Modulknüpfungen des a liefern.
Wenn hinsichtlich des laufenden Zeigers, als welcher i zu denken, a als konstant vorausgesetzt wird, so gilt: 11) [Formel] 12) [Formel] , 13)
[Formel]
Behufs Beweises von 11) beachte man — z. B. rechts vom Mittelstriche — dass i; a = i · 1; a nach 21) des § 25 ist, somit Πi; a = 1; a · Πi, was nach 7) verschwindet.
Etc.
Bei 12) braucht auch nur 7), wonach Σa; i = a; Σi = a; 1, Π(a ɟ i) = a ɟ Πi = a ɟ 0 ist, und schliesslich a; i = a ɟ ī aus 22) des § 25, berücksichtigt zu werden.
Einen Teil dieser Formeln wird man jedoch auch so, wie (wegen ĭ; 1 = 1): Σia; i = Σia; i · ĭ; 1 = a; 1, Πia; i = Πi(a; i + ĭ; 0) = a ɟ 0, aus einem folgenden allgemeinern Satze 14) ableiten können.
Demnach bedürfen von diesen Formeln nur die letzten 13) noch einer Rechtfertigung, welche für die erste rechts durch den Hinweis erbracht wird, dass Lh k = Πi(a; ī)h k sich von Rh k — im Hinblick auf den zu 28) des § 25 gegebenen Beweis — nur durch die Bezeichnung des laufenden Produktzeigers (mit i statt m) unterscheidet.
Hervorragend einfach und wichtig ist, wie mir scheint, das folgende Gespann von Sätzen: 14) von welchen man gut thut den ersten links und rechts zu memoriren. Dieselben lehren: ein relatives Produkt in eine identische Summe, eine relative Summe in ein identisches Produkt aufzubrechen.
a; b = Σia; i · ĭ; b = Σi(a ɟ ī)(ī̆ ɟ b) = a ɟ b = Πi(a; i + ĭ; b) = Πi(a ɟ ī + ī̆ ɟ b) = = Σiĭa; 1; bi = Σi{(ī̆ + a) ɟ 0}{0 ɟ (b + ī)} = Πi{(ī̆ + a) ɟ 0 ɟ (b + ī)} = Πi(ĭa; 1 + 1; bi),
Der Beweis folgt am schnellsten kraft 32) des § 25, wonach wir haben: Σia; i · ĭ; b = Σia; ib = a; bΣi = a; b1 = a; b wegen 7).
Etc.
Die übrigen Formen des Satzes sind Umformungen des hiermit bewiesenen gemäss 22) des § 25 — und würden solcher sich offenbar noch mehrere angeben lassen.
Als Gegenstück zu 14) haben wir auch noch: 15) kraft 12), indem auch linkerhand Πia; i · ĭ; b = Πia; i · Πiĭ; b sein muss, etc.
Πia; i · ĭ; b = (a ɟ 0)(0 ɟ b) Σi(a; i + ĭ; b) = a; 1 + 1; b
Während wir nun also hiernach auch das 15a) — vergl. 32) des § 25 — leicht zu evaluiren vermögen, ist solches schon mit Πia; īb, etc. keineswegs der Fall und wird man überhaupt der grossen Mehrzahl der Summen- und Produktausdrücke noch ziemlich ratlos gegenüberstehn.
Πiaĭ; b = Πia; ib = (a ɟ 0)(0 ɟ b) Σi{(a + ĭ) ɟ b} = Σi{a ɟ (i + b)} = a; 1 + 1; b
Darum erscheint es wünschenswert: erstlich einen möglichst vollständigen Grundstock von einfachsten Summen- und Produktformeln zur Verfügung zu haben, und zweitens Methoden kennen zu lernen, um eine gegebene Summirungs- etc. Aufgabe thunlichst auf die in jenem Grundstock gelösten einfachsten Aufgaben zurückzuführen.
In erstrer Hinsicht glauben wir mindestens noch folgende Gespanne von Sätzen anführen, besprechen und begründen zu sollen.
Und zwar zunächst als Gegenstücke und Ergänzungen zu 10): 16) [Formel] 17) [Formel] 18) [Formel] 19)* [Formel] wo ohne Stern für a; 1 zu lesen wäre a; 0'; 0'. Etc., 20) [Formel]
In den 32 Formeln 10) und 16) bis 20) wird man die Σ und Π vertreten finden von allen (binären identischen) Produkten und Summen, die aus a; i oder a; ī, sowie aus a ɟ ī oder a ɟ i, und ĭ oder ī̆ selbst, gebildet werden können, etc. — soferne wenigstens solche Π, Σ, welche auf den ersten Blick sich auf 0 oder 1 reduziren, nicht mit berücksichtigt werden.
Formeln solcher Art aber, in deren allgemeinem Terme statt a; i oder a; ī etwa a; ĭ oder a; ī̆ aufträte, etc., würden, weil letztres ja in a; 1 · ĭ resp. a; 1 · ī̆ zerfällt, ohnehin leicht auf schon Bekanntes zurückzuführen sein; sie stünden nicht auf gleicher Rangstufe mit den bisherigen und verdienten nicht, gleich ihnen registrirt zu werden.
Von den angeführten Formeln erscheinen die 18) besonders merkwürdig deshalb, weil sie gewisse relative Produkte wie a; 0' als identische Produkte darzustellen lehren, während sonst das nur in Form einer identischen Summe gelingt.
Behufs Begründung der Sätze ist bei 16) auf 30) des § 25 und auf 7) zu verweisen.
Die 17) gehn als Partikularfälle aus unserm Th. 14) hervor, indem z. B. rechts Πi(a; i + ĭ) = Πi(a; i + ĭ; 1') = a ɟ 1' sein muss.
Bei 18) transformire man identisch rechnend: a; ī + ī̆ = a; ī · ĭ + ī̆ = = a; 0' · ĭ + ī̆ = a; 0' + ī̆ gemäss 30) des § 25, wo dann Πi(a; 0' + ī̆) = = a; 0' + Πiī̆ = a; 0' + 0 nach 7) sein muss.
Bei 19) und 20) rekurrire man auf die Koeffizientenevidenz, wonach links resp. ist:
Lh k = Σi(a; ī)h kī̆h k = ΣiΣlah līl kīk h = Σlah lΣi0'l i0'i k = (a; 0'; 0')h k, Lh k = ΣiΠl(ah l + il k)īk h = ΣiΠl(ah l + 1'l i)0'i k = Rh, q. e. d.
Als Gegenstücke und Ergänzungen zu den Formeln 14), 15) sind ebenso anzuführen die Sätze, welche auch als Verallgemeinerungen der obigen 16) bis 20) angesehen werden können: 21) 22) 23) 24)*
Σi(a ɟ i)(ĭ ɟ b) = (a ɟ 1'); (1' ɟ b) Πi(a; ī + ī̆; b) = a; 0' ɟ 0'; b,
Σi(a ɟ i)(ī̆ ɟ b) = Σi(a ɟ i) · ĭ; b = (a ɟ 1'); b Πi(a; ī + ĭ; b) = Πi(a; ī + ī̆ ɟ b) = a; 0' ɟ b Σi(a ɟ ī)(ĭ ɟ b) = Σia; i · (ĭ ɟ b) = a; (1' ɟ b) Πi(a; i + ī̆; b) = Πi(a ɟ ī + ī̆; b) = a ɟ 0'; b,
Σia; ī · ī̆; b = a; 1; b Πi(a ɟ i + ĭ ɟ b) = a ɟ 0 ɟ b.
Die Πi der allgemeinen Terme links und die Σi derer rechts wären, weil zerfallend, schon nach 11) bis 13) leicht anzugeben.
Beweise.
Nach 3) und 4) des § 25 kann i = 1' ɟ ī, ĭ = ī̆ ɟ 1', ī = 0'; i, ī̆ = ĭ; 0' gesetzt werden, wonach denn auch sich umschreiben lässt: 25) [Formel] (sowie ohnehin a ɟ ī = a; i, ī̆ ɟ b = ĭ; b) in Ergänzung zu 23) des § 25 S. 418.
Daraufhin fallen alle Formeln 21) bis 24) unter das Schema (der ersten Gleichung links und rechts) in unserm Theorem 14).
Man ersieht aus 25) in Verbindung mit 21) und 22) des § 25, dass bei Knüpfungen von Relativen mit Elementverwandten (selbst) die relative Addition immer entbehrlich gemacht, nämlich auf eine relative Multiplikation (auch ohne Kontraposition) hinausgespielt werden kann, wo sie nicht ohnehin auf identische Addition hinauskommt.
Wesentlich braucht man blos mit Ausdrücken der beiden Formen a; i und ĭ; b ordentlich rechnen zu lernen.
Sehr häufig treten — bei Untersuchungen — auch Summationen und Produkte (nach i) auf von Termen, die aus Relativen der Sorte a; i, a; ī, a ɟ i, etc. und dazu i oder ī (statt ĭ, ī̆) mittelst identischer Knüpfung zusammengesetzt sind.
Die Werte solcher geben vollständig die Formelgespanne an: 26) [Formel] 27) [Formel] 28) [Formel] 29)
[Formel]
Begründung.
In 26) ist blos Σa; i · i = Σa; i · 1'; i = Σa1'; i = = 1'a; Σi = 1'a; 1 zu bedenken.
Dagegen fasst 27) wesentlich dreierlei Gespanne zusammen, deren erstes sich links, die beiden andern rechts von dem die Seitenmitte einnehmenden Ausdruck finden.
Jenes beweist sich mit Σa; i · ī = Σ0'a; i = 0'a; Σi = 0'a; 1 aus 31) des § 25.
Von diesen findet sich: Σa; i · i = Σa; 0'; i · i = 1'(a; 0'); 1, Σ(a ɟ i)i = Σ(a ɟ 1'); i · i = 1'(a ɟ 1'); 1 nach 25) und 26) zunächst auf die rechts angegebnen Werte zurückgeführt.
Diese aber kommen sodann auf diejenigen in 27) zurück aufgrund des Satzes: 30) [Formel] — woraus wegen 1'b = 1'b̆ sogleich mit folgt: 1'(0'; a); 1 = 0'ă; 1, etc. — und dessen Beweis aus der Koeffizientenevidenz sehr leicht zu liefern ist.
Nach 25) kommt jetzt auch zu 29) die Ermittelung von Σ(a ɟ i)ī = = Σ(a ɟ 1'); i · ī auf den ersten Satz von 27) zurück.
Zur Rechtfertigung von 28) aber haben wir ähnlich: Σa; ī · ī = = Σa; 0'; i · ī = 0'(a; 0'); 1, was sich aber noch vereinfacht aufgrund des Satzes: 31) [Formel] zu dessen Beweis die Koeffizientenevidenz anzurufen ist mit: Li j = Σh k0'i hai k0'k h = Σkai kΣh0'i h0'h k = Ri j.
Anstatt noch mehr der Formeln aufzustellen, wollen wir jetzt an einer Reihe von kleinen Aufgaben zu zeigen suchen, auf welche Weise mittelst der bisherigen Sätze schon zahlreiche und in mannigfacher Art gegebene Produkte oder Summen ermittelt werden können.
Wir halten uns dabei vorwiegend an Produkte und verzichten auf die Vollständigkeit der Gespanne.
Aus unsrer Behandlung der Beispiele schon hier — und noch mehr im nächstfolgenden Abschnitte — wird der Leser wenigstens ein Stück Methode zu abstrahiren imstande sein.
Aufgabe 1. Gesucht sei x = Πi(a; ĭ + ī̆; b).
Wir haben: x = Πi(a; 1 · ĭ + ī̆; b) = Πi(a; 1 + ī̆; b)(ĭ + ī̆; b) = = (a; 1 + Πiī̆; b)Πi(ĭ + ĭ; 0'; b) = (a; 1 + 0 ɟ 0'; b)Πiĭ; (1' + 0'; b) nach 13), mithin endlich: x = (a; 1 + 0 ɟ 0'; b){0 ɟ (1' + 0'; b)}.
Aufgabe 2. Gesucht x = Πi(a; ĭ + ī; b).
Lösung. x = Πi(a; 1 · ĭ + ī · 1; b) = (a; 1 + 1; b)(a; 1 + Πiī)(Πiĭ + 1; b)Πi(ĭ + ī) = = a; 1 · 1; b · Πi(0'; i + ĭ; 1') = a; 1; b · (0' ɟ 1'), also x = 1' · a; 1; b.
Aufgabe 3. x = Πi(a; i + i; b) = Πi(a ɟ ī + i; b). x = Πi(a; i + i · 1; b) = (Πia; i + 1; b)Πi(a; i + i) = (a ɟ 0 + 1; b)Πi(a + 1'); i = = (a ɟ 0 + 1; b){(a + 1') ɟ 0} = a(a + 1') ɟ 0 + {(a + 1') ɟ 0} · 1; b, also x = a ɟ 0 + {(a + 1') ɟ 0}; b.
Insbesondre wenn a = 0' genommen, darnach a für b gesagt wird, ergibt sich die zweite Formel links des folgenden Gespannes: 32) [Formel] welches ein interessantes Gegenstück zu 18) insofern bildet, als es zeigt, wie auch das relative Produkt a; 1, etc. als ein Πi (statt wie sonst Σi) dargestellt werden kann.
Die Formeln sind übrigens leicht auch direkt einzusehn.
Aufgabe 4. Gesucht x = Πi(a ɟ i + i; b).
Mit Rücksicht auf 25) fällt dies als x = Πi{(a ɟ 1'); i + i; b} unter die vorhin gelöste Aufgabe, und muss demnach sein: x = a ɟ 0 + {(a ɟ 1' + 1') ɟ 0} · 1; b.
Man kann jedoch auch mittelst Durchganges durch ein Doppelprodukt wie folgt x ermitteln.
Kraft 14) ist x = Πi{Πj(a; j + j̆; i) + i; b} = Πi j(a; j + j̆; i + i; b) = Πj{a; j + Πi(j̆; i + i; b)}.
Nun ist nach dem Schema der vorigen Aufgabe: Πi(j̆; i + i; b) = j̆ ɟ 0 + {(j̆ + 1') ɟ 0} · 1; b = 0 + (1' ɟ j) · 1; b = 0* nach 3) des § 25, und folglich *x = Πja; j = a ɟ 0.
Dies stimmt mit dem vorhin gefundnen Resultat erst überein bei Berücksichtigung des Satzes aus 31):
*(a ɟ 1' + 1') ɟ 0 = a ɟ 0, welcher auch geometrisch daraus erhellt, dass bei a = z1αβγ0 das a ɟ 1' = 1ᾱ000 nur aus den Vollzeilen von a und einbesetzten Zeilen besteht, deren Auge einer Lücke der Einlückzeilen von a entspricht.
Durch Hinzutritt je eines weitern Auges auf der Hauptdiagonale (aus + 1') können letztere Zeilen doch niemals zu Vollzeilen werden, sobald der Denkbereich 11 mehr als zwei Elemente umfasst.
Dann also fallen die Vollzeilen des Relativs a ɟ 1' + 1' durchaus mit den Vollzeilen von a zusammen.
Analytisch ist ja der Satz dual wie der erste 31) zu beweisen und implicite bereits bewiesen.
Aufgabe 5. Gesucht x = Πi(a ɟ ī + ī; b) = Πi(a; i + ī; b). x = Πi(a; i + i · 1; b) = (Πia; i + 1; b)Πi(a; i + ī) = (a ɟ 0 + 1; b)Πi(a + 0'); i, also: x = (a ɟ 0 + 1; b){(a + 0') ɟ 0} = a ɟ 0 + 1'a; 1 · 1; b = a ɟ 0 + 1'a; 1; b.
Aufgabe 6. Gesucht x = Πi(a ɟ i + ī; b) = Πi{(a ɟ 1'); i + ī; b}.
Hier ist nach dem Schema der vorigen Aufgabe sogleich angebbar: x = a ɟ 0 + 1'(a ɟ 1'); 1; b.
Man kann aber auch durch das Doppelprodukt hindurchgehn: x = ΠiΠj(a; j + j̆; i + ī; a) = Πj(a; j + j̆ ɟ 0 + 1'j̆; 1; b) = = Πj(a; j + 1'; j; b) = Πj(a; j + j; b) = a ɟ 0 + {(a + 1') ɟ 0}; b nach Aufg. 5 und 3.
Die Übereinstimmung beider Ergebnisse besteht aufgrund des zweiten Satzes 30.
Die Π in Aufg. 6 und 3 sind gleich!
Aufgabe 7. Gesucht x = Πi(i; a + ī; b). x = Πi(i; a + ī · 1; b) = (Πii; a + 1; b)Πi(i; a + ī) = (0 + 1; b)Πi(0'; i + i; a), also nach Aufg. 3: x = 1; a · 1; b.
Etc.
So zahlreich die Aufgaben sind, die sich in solcher Weise lösen lassen, so können wir doch beispielsweise schon das Πia; īb mit den bisherigen Mitteln noch nicht entdecken. —
Wenden wir jetzt unsre Aufmerksamkeit auch den Summirungs- resp. Produktirungsaufgaben der zweiten Stufe zu.
Ein wichtiges Problem von allgemeinem Charakter ist: die „Gemeinheit“ Π sowie den (gemeinschaftlichen oder gesamten) „Bereich Σ aller der binären Relative x zu ermitteln, welche eine gegebne Bedingung — etwa Gleichung F(x) = 0 — als deren „Wurzeln“ erfüllen.
Es scheint nahe gelegt, diese beiden Unbekannten (als Produkt und Summe) mit P und S zu bezeichnen.
Doch ist das Produkt gerade Subjekt, die Summe Prädikat zu einer jeden von den Wurzeln, sodass diese Bezeichnung irre führen könnte.
Ich will deshalb P und Q sagen.
Indem er die Erstreckungsbedingung unterhalb des Π, Σ-zeichens anmerkte, würde der Mathematiker zu schreiben geneigt sein:
[Formel] , [Formel] {F(x) = 0}
{F(x) = 0}.
Unsre Disziplin aber geniesst den Vorzug, dass in ihr die Erstreckungsbedingung dem Π, Σ-Ausdruck selbst einverleibt werden kann.
Auf welche Weise, das soll sogleich für eine naheliegende Erweiterung des Problemes gesagt werden.
Die Aufgabe lässt sich noch wesentlich verallgemeinern dadurch, dass anstatt der Wurzeln x selber eine irgendwie gegebne Funktion Φ(x) derselben zu produktiren resp. zu summiren verlangt wird.
Gesucht also möge nun sein:
[Formel] , [Formel] {F(x) = 0}
{F(x) = 0}.
Wir geben den Π, Σ die absolute Erstreckung — über alle erdenklichen Relative x des zweiten Denkbereiches.
Alsdann kommt es blos darauf an, den allgemeinen Term allemal dann zu einem ineffektiven zu machen, wenn x die Erstreckungsbedingung F(x) = 0 nicht erfüllt, d. h. es ist dafür Sorge zu tragen, dass in jedem solchen Falle der allgemeine Term des Π, Σ belanglos, nämlich sofern er Produktfaktor ist, gleich 1, sofern er Summand ist, gleich 0 werde.
Wogegen für jedes x, welches die Erstreckungsbedingung erfüllt, als Term wirklich Φ(x) in Ansatz, Erscheinung oder Wirkung zu treten hat.
Dies wird erreicht, indem man schreibt: 33) [Formel] .
Je nachdem x Wurzel ist oder nicht, wird in der That in Q die Faktoraussage F(x) = 0 den Wahrheitswert 1 oder 0 haben, umgekehrt aber die als Summand in P auftretende Negation derselben gleich 0 oder 1 sein, etc.
Sofern nun das Polynom F(x) unsrer Bedingungsgleichung von vornherein als ein Aussagensymbol, etwa eine Koeffizientenfunktion oder auch als ein „ausgezeichnetes“ Relativ lediglich der Werte 0 und 1 fähig sein sollte, könnten wir Obiges vereinfachen zu [Formel] . In diesem Falle hätten wir nämlich (F ≠ 0) = (F = 1) = F und (F = 0) = = (F̄ = 1) = F̄.
In jedem andern Falle dagegen wäre dergleichen ein gröblicher Fehler.
Allgemein kann nun, in 33), der Aussagenterm nach den Schemata des § 11 durch ein binäres und zwar ein ausgezeichnetes Relativ ersetzt werden, welches mit ihm zugleich den Wert 0 oder 1 annimmt, und zwar ist:
F(x) = 0͞ = {F(x) ≠ 0} = 1; F(x); 1, {F(x) = 0} = 0 ɟ F̄(x) ɟ 0, wonach denn 34) [Formel] sich ergibt.
Hierin könnte denn auch u für x geschrieben werden.
In dem Unterfalle des Problems, welcher zuerst unser Interesse auf sich zog, haben wir insbesondre: 35) [Formel] .
Vermöchten wir nun für eine irgendwie gegebene Funktion von u das nach u mit der absoluten Erstreckung (über alle binären Relative) genommene Π resp. Σ zu evaluiren, so wären wir nach diesen Schemata 34), 35) in der Lage, das fragliche P und Q zu ermitteln — sogar ohne die Wurzeln x [der Bedingungsgleichung F(x) = 0] selbst zu kennen oder eruirt zu haben!
Kennt man aber in Gestalt von x = f(u) bereits die allgemeine Wurzel oder Lösung jener Bedingungsgleichung, so befindet man sich der Lösung unsres Problems gegenüber in einer noch günstigern Lage und hat sofort und einfacher: 36) [Formel] sowie im Unterfalle 35) unsres Problemes: 37) [Formel] .
Nach dem Begriffe der allgemeinen Lösung gilt ja dann in der That für jedes u:
F{f(u)} = 0, F̄{f(u)} = 1.
Mögen wir indess den einen oder den andern Weg einschlagen, so ist die Kunst erforderlich und hinreichend: von einer irgendwie gegebnen Relativfunktion Ψ(u) das nach u mit der absoluten Erstreckung genommene Π und Σ eruiren zu können.
Eine Methode, dieses wichtige Problem in seiner vollen und unbegrenzten Allgemeinheit zu lösen, ist nicht bekannt.
Vielmehr ist die Entdeckung solcher Methode ein Ideal der Theorie, dessen völlige Verwirklichung derselben vielleicht niemals erreichbar ist und dem es uns wol nur vergönnt sein wird in stufenweisem unbegrenztem Fortschreiten uns mehr und mehr zu nähern.
Vergleiche übrigens den Schluss dieses Paragraphen.
Fürs erste können wir uns demnach hier nur ein bestimmtes Ziel setzen und behufs dessen Erreichung ein Stück Methode auszubilden suchen.
Ein praktisches Ziel derart — und in der That vom systematischen Gesichtspunkt das nächstliegende — bildet die Ermittelung des Π und der Σ von allen Wurzeln eines unsrer drei elementaren Inversionsprobleme.
Von diesen scheidet jedoch — als sofort zu erledigen — das erste Inversionsproblem aus.
Weil nämlich x = u(a ɟ b̄̆) die allgemeine Wurzel der Subsumtion x; b ⋹ a ist, und selbstverständlich [Formel] sein muss, sintemal u = 0 und u = 1 selbst unter den Werten, über die u sich erstreckt, figurirt, so muss auch [Formel] sein, und müssen wir haben:
[Formel] quod erat inveniendum.
Sooft überhaupt zu den Wurzeln x der gegebenen Bedingung die 0 gehört, wird das Πx gleich 0, und sobald zu ihnen die 1 gehört, wird die Σx gleich 1 sein und weiter kein Interesse hier beanspruchen.
Beispielsweise versteht sich so auch [Formel] auf den ersten Blick von selbst.
Es bleibt demnach unsre Aufgabe nur mehr für das (erweiterte) zweite und für das dritte Inversionsproblem zu lösen, und hier wird es — wenn wir uns bei jedem Gespanne immer nur an einen Repräsentanten desselben halten — wesentlich darauf ankommen, dass wir ein Produkt von der Form: 38) [Formel] auszuwerten lernen.
Dieses nur allmälig zu realisirende Ziel vor Augen nehmen wir eine Reihe von Vor-aufgaben in Angriff.
Aufgabe 8. Gesucht [Formel] .
Nach Peirce’s Satze 1) oder 4) ist hier sogleich angebbar:
[Formel] sich schreiben lässt.
Wegen 1; i 1' = ĭ; 1' = ĭ wird insbesondre:
[Formel] .
Als Korollar zu der Aufgabe ist nun auch gefunden:
[Formel] , indem der allgemeine Faktor zerlegbar ist in (u + a)(u + ū; b), somit auch das Π sich spaltet in dasjenige des ersten Faktors: Π(u + a) = a + Πu = a + 0 = a und das Π des zweiten, welches unter das obige Schema fällt.
Aufgabe 9. Gesucht [Formel] .
Nach 14) lässt sich ū ɟ b als ein Produkt (nach i) darstellen, womit wir sozusagen gewonnenes Spiel haben.
Man kann nämlich darnach schliessen:
[Formel] nach 4), und weiter: x = Πi(ĭ; a + ĭ; b) = Πiĭ; (a + b).
Nach der letzten Formel 12) ist damit gefunden: x = 0 ɟ (a + b) — was merkwürdigerweise symmetrisch ist inbezug auf a und b.
Nimmt man a = 1' an und sagt dann a für b, so ist insbesondre gefunden:
[Formel] . [Nähme man dagegen, u und ū vertauschend, b = 0' an, so würde man das Resultat der Aufgabe 8 in etwas andrer Gestalt, als 0 ɟ (a + 0') wieder erhalten.]
Als Korollar zum vorstehenden Ergebnisse kennen wir nun auch:
[Formel] , was ähnlich wie oben daraus abzuleiten.
Ganz nach derselben Methode lässt sich auch lösen die, eine Erweiterung der vorigen vorstellende
Aufgabe 10. Gesucht [Formel] . [Formel] = Πi(b; i + ĭ; c + 1; ai) = Πi{b; i + ĭ; (c + a)} = b ɟ (a + c) nach 14), 4) und 14).
Insbesondre ist damit gefunden:
[Formel] . Wie in 1) durch eine Σ nach u, so können wir also jetzt a ɟ (b + c) — der Form nach allerdings unsymmetrisch — auch durch ein Π nach u darstellen.
Aufgabe 11. Gesucht [Formel] .
Dies Problem nach Art der beiden vorigen zur Lösung zu bringen, gelingt nicht, da wir das relative Produkt im zweiten Glied des allgemeinen Faktors nicht als ein Πi, sondern nur als eine Σi gemäss 14) darzustellen vermögen, ein Σ aber von hinter einem Π nicht vor dasselbe darf geschoben werden.
Im Falle b = 0' jedoch könnte man sich auf 18) berufen.
Darnach muss in der That — um nur den einfachsten Fall zu erledigen — sein: [Formel] gemäss 7) und Aufg. 8 — was wir übrigens auch schon S. 494 aus Peirce’s Formel 1) eingesehen haben.
Nun ist aū; b0' ⋹ ū; 0', mithin auch [Formel] . Zerlegt man jetzt (bei x) b = 0'b + 1'b und berücksichtigt dass nach 24) des § 22 ist aū; b1' = aū · 1; b1', so zerfällt u + aū; b = u + aū; b0' + a · 1; b1', indem der Faktor ū beim letzten Gliede gegen das erste unterdrückt werden durfte.
Wir erhalten folglich: x = a; 1'b, indem das noch rechterhand hinzutretende [Formel] nach dem vorhergehenden Ergebnisse verschwindet.
Insbesondre ist:
[Formel] . — Beachtung verdient, dass ungeachtet der durch die Klammerstellung bedingten Verschiedenheit der vorliegenden Aufgabe mit dem Korollar zu Aufg. 8 das Endergebniss bei beiden das nämliche ist.
Man kann auch den gefundenen Wert sogleich als eine untere Grenze für x erkennen, indem [Formel] nach Peirce’s Th. 1), wegen au ⋹ u aber y ⋹ x sein muss.
Dieselbe untere Grenze kann man auch mittelst:
[Formel] daraus gewinnen, dass nach dem Aussagenschema o) S. 41 sein muss:
[Formel] . Da nun Πuh k = 0 und, wie wir unter der nächsten Aufgabe zeigen, Π(uh k + ūh l) = 1'k l ist, so folgt: Σlah lbl k1'l k = (a; 1'b)h k ⋹ xh k. [Der untern liesse auch eine obere Grenze für x sich zugesellen aus der Überlegung, dass aū; b ⋹ a; b · ū; b, wonach sich ergibt: x ⋹ a; b · 1; b1' = = a; b; 1'b, und nebenbei der Satz gelten muss: a; 1'b ⋹ a; b; 1'b, der unschwer auch direkt erweislich.
Indessen haben wir ja bereits die untere Grenze als den exakten Wert erkannt.]
Aufgabe 12. Gesucht [Formel] .
Diese ist von schwierigerer Art.
Ohne weitres gelingt ihre Lösung nur für gewisse partikulare Fälle, wie [Formel] deren Ergebniss man nach dem Bisherigen leicht daraus gewinnt: weil das zweite Glied des allgemeinen Faktors hier zerfällt — in (ū ɟ 0) · 1; b resp. (ū ɟ a) · 1; b1' — wonach denn auch der allgemeine Faktor selbst, und dessen Π zerfällbar.
Das letzte Ergebniss entsteht durch multiplikative Vereinigung von 0 ɟ (a + 1') mit 1; b1', welches = 0 ɟ (b + 0').
Ein wichtiger Partikularfall ferner, wo die Lösung noch leicht gelingt, ist der Fall b = i.
Nennen wir nämlich:
[Formel] , und behandeln zunächst diese Unteraufgabe, so werden wir haben:
[Formel] . Dass in der That:
[Formel] ist, erhellt daraus, dass für l = k dies Π gleich 1, für l ≠ k aber gleich 0 sein muss, letzteres, weil dann unter den (d. h. unter allen erdenklichen) u sich auch solche finden, für welche uh k = 0 und zugleich uh l = 1 also auch ūh l = 0 ist, mithin ein Faktor des Π verschwindet.
Mit Obigem also ist gefunden: y = ĭ; (ă ɟ 1').
Im allgemeinen Falle lassen sich (wieder) zwei Grenzen finden, zwischen welchen das unbekannte (jedoch völlig bestimmte) Relativ x jedenfalls liegt.
Diese Grenzen vorweg zu ermitteln, ist aus zwei Gründen verlohnend.
Einmal liefern sie uns — gleichwie die vorausgeschickten Partikularfälle — eine schätzbare Kontrole für den nachher mittelst ganz neuer Methode zu gewinnenden exakten Wert des x. Sodann auch werden wir hierbei durch einen Zufall geführt zur Entdeckung merkwürdiger Sätze.
Nach 14) haben wir:
[Formel] und da, nach dem Aussagenschema ο) S. 41, ΣΠ ⋹ ΠΣ ist, so muss sein:
[Formel] — vergleiche 26) des § 25, also nach 12): 1; (ă ɟ 1')b ⋹ x, was die fragliche untere Grenze kund gibt.
Um eine obere Grenze zu finden, schreiben wir ebenfalls nach 14):
[Formel] . Hierin ist es nun nicht gestattet, die geschweifte Klammer zu ignoriren.
Ihre Unterdrückung läuft vielmehr auf eine Verschiebung derselben hinaus und muss Übergeordnetes liefern nach dem Schema {Πa}; b ⋹ Πa; b, welches = Π{a; b} bedeutet.
Folglich ist:
[Formel] — cf. Aufg. 8.
Aber wegen i; b = i · 1; b und 1; i1' = ĭ; 1' = ĭ lässt sich das erste Glied umwandeln in ĭ · 1; b und entsteht: x⋹Πiĭ; (1' + a; b) · (1; b + Πiĭ; a; b) = {0 ɟ (1' + a; b)}(1; b + 0 ɟ a; b) = = 0 ɟ a; b + {0 ɟ (a; b + 1')} · 1; b. Hierin ist jedoch das erste Glied, als im zweiten enthalten, auch unterdrückbar; denn wir haben sowol 0 ɟ a; b ⋹ 0 ɟ (a; b + 1'), als auch 0 ɟ a; b ⋹ ⋹ a; b ⋹ 1; b.
Es bleibt mithin das zweite Glied als die gesuchte obere Grenze und ist im Ganzen sichergestellt, dass sein muss: 1; (ă ɟ 1')b ⋹ x ⋹ {0 ɟ (a; b + 1')} · 1; b = 0 ɟ (a; b + 1; b · 1').
Versuche, den exakten Wert unsres x zu ermitteln, müssen daran scheitern, dass man beim letzten Ausdruck des x das Πi auf keine Weise aus der geschweiften Klammer in äquivalenter Transformation herauszubringen vermag, und ebensowenig imstande ist, beim erstern Ausdrucke für x, wie er oben behufs Ermittelung der unteren Grenze aufgestellt worden, das Σi vor das [Formel] zu schieben.
Etwas derartiges gelingt nur durch ein Verfahren, das eine gewisse Kühnheit besitzt:
Die Methode besteht darin: auch mit unendlich (oder unbegrenzt) vielfachen Produkten Π zu operiren, ja sogar mit einem solchen, dessen Π-zeichen eventuell ein Kontinuum bilden würden (sofern man es ausführlich hinschreiben wollte), indem etwa jedem Punkte der Geraden ein Π nach einer eigens benannten Produktationsvariabeln zu entsprechen hat!
Auch auf derartige Produkte und Summen dürfen wir unbedenklich die Schlussweisen übertragen und anwenden, die unsre auf dem dictum de omni beruhenden Aussagenschemata gewährleisten.
Solches geschieht an dieser Stelle in der gesamten Mathematik wol erstmals.
Ich will deshalb den Studirenden heuristisch den Gang führen, auf welchem sich die Methode mir aufdrängte.
Ich versuchte zunächst den Partikularfall y unsres Problems, wo die Lösung gelang, dahin zu erweitern, dass ich — als nächste Unteraufgabe — zu ermitteln suchte:
[Formel] . Wir haben:
[Formel] . Nun ist aber:
[Formel] , nämlich gleich 0 für (m ≠ k)(n ≠ k), weil dann unter andern ein Faktor mit uh k = 0, uh m = 1, uh n = 1 vorkommen wird, und gleich 1 für (m = k) + (n = k).
Folglich: zh k = ΠmΠn(1'k m + am i + 1'k n + an j) = Πm(1'k m + am i) + Πn(1'k n + an j) = = (1' ɟ a)k i + (1' ɟ a)k j = {(1' ɟ a); i + (1' ɟ a); j}k h, womit gefunden ist: z = (ĭ + j̆); (ă ɟ 1').
Wenn nun die Lösung unsrer Aufgabe 12 unschwer gelang für den Fall, wo b = i ein Element ist, sowol als auch für den, wo b = i + j ein System von zwei Elementen vorstellt, so ist nicht abzusehen, warum sie nicht auch für den Fall gelingen sollte, wo b = b; 1 System überhaupt, mithin eine Summe von irgendvielen Elementen ist, die eventuell als Punkte auch kontinuirlich eine Strecke ausfüllen.
Man bemerkt sogleich, dass die Untersuchung lediglich quantitativ sich muss verallgemeinern lassen, und in der That werden wir finden:
[Formel] .
Zurückblickend auf zh k nimmt man wahr, dass unsre Schlüsse nicht durchführbar gewesen wären, wenn wir — was a priori angängig gewesen — für den laufenden Zeiger n des letzten Π den nämlichen Buchstaben m verwendet hätten, wie für den des vorhergehenden Π.
Wenn dagegen in einer aktuellen Summe alle Glieder Produkte Π sind mit von einander unabhängigen eigens benamten Zeigern, so ist es ohne weiteres gestattet, diese sämtlichen je mit ihrem Zeiger als Suffix behafteten Π nach links voranzuschieben, und diese Wahrnehmung wird sich auch für eine symbolisch mittelst Σ dargestellte Summe verwerten lassen müssen.
Wir wollen nunmehr die vorstehende Formel links S. 512 unten (von der die rechts nur ein Spezialfall ist) wirklich ableiten — indem wir das gesuchte Π nach u etwa s nennen — weil uns dies Veranlassung geben wird, unser Verfahren zu schematisiren.
Dabei ist es bequem, für das System b; 1 = b die im § 27 gewonnene Darstellung als b = Σi bii oder kürzer [Formel] zu benützen, wobei man sich nur gegenwärtig zu halten hat, dass die Summe nach i, bei deren Σ der Zeiger nicht als Suffix angehängt ist, sondern wo er (ad hoc) darunter geschrieben erscheint, nicht die volle, sondern eine irgendwie gegebene (begrenzte oder unbegrenzte) Erstreckung aus dem Denkbereich 11 der Elemente haben soll.
Für [Formel] .
Hiermit ist ohne einen neuen Gedanken nichts anzufangen, weil man auf keine Weise das Πm vor die [Formel] und damit vor das [Formel] zu bringen vermag.
Der den Erfolg herbeiführende (bereits angedeutete) Gedanke aber ist der, den wir nun im Haupttext allgemein formuliren und mit seinem dualen Gegenstück konfrontiren wollen — ohne übrigens mit Worten zumeist das letztere mit zu berücksichtigen.
Hat man eine Σi von einem Πm eines allgemeinen Terms f(i, m) und man wünscht aus irgend einem Grunde in äquivalenter Umformung das Σ hinter das Π zu schieben, so ist dies ohne weitres nicht angängig.
Wegen ΣΠ ⋹ ΠΣ ginge solches vielmehr ja nur in dem Verfahren des Ziehens von abgeschwächten Schlüssen an — sofern man eben mit solchen sich begnügen mag.
Andernfalles jedoch hindert nichts: in jedem andern Gliede der Σi den laufenden Zeiger des Πm anders zu bezeichnen, das ist: alle diese Zeiger als mι (m mit dem Suffixe Iota) „zu differenziiren“ — wobei nur zu unterstellen ist, dass ι parallel“ mit i sich ändert.
Es erscheint nahegelegt, für ι den Buchstaben i selbst zum Suffixe für m zu nehmen.
Abgesehen davon, dass mi bereits eine schon anderweitig feststehende Bedeutung als Relativkoeffizient des Elementes m in § 27 gewonnen hat, wäre aber solches doch nicht angängig.
Wie bald zu sehen, darf — wofern die Operationen Erfolg haben sollen — für ι überhaupt nicht ein den Namen i enthaltendes Symbol — wie φ(i) — gewählt werden!
Dies wird den Vorteil bringen, dass wir alsdann jedes einzelne nach einem bestimmten mι zu nehmende Π voranschieben dürfen vor unser Σ.
Es wird sich das wichtige Schema rechtfertigen lassen: 39) [Formel] , durch welches der Erfolg erzielt ist, alle Π vor das Σ gebracht zu haben.
Der Bequemlichkeit des Druckes zuliebe haben wir hier die Zeiger i und m so angesetzt, als ob sie als Elemente die volle Erstreckung über 11 hätten.
Dies ist ja gewiss zulässig.
Indessen ist es für die Geltung unsres Schemas keineswegs erforderlich.
Vielmehr dürften i und m auch irgendwie gegebene Erstreckungen im Denkbereiche 11 haben — die Erstreckung von m natürlich von vornherein als unabhängig von i, für jedes i die gleiche, vorausgesetzt, und auch auf jedes mι übertragen, d. h. einem jeden von diesen wiederum zugeschrieben (eine Beschränkung, von welcher sogar der letzte Teil eines jeden der beiden Doppelschemata unabhängig ist). M. a. W. wir dürften auch [Formel] für Σi oder [Formel] für Πm etc. schreiben.
Ja unser Schema bliebe auch in Kraft, wenn die beiden Zeiger, oder einer von ihnen, gar keine Elementbuchstaben wären, sondern als ein u oder v ihre Erstreckung im Denkbereiche 12 hätten.
Doch wollen wir auf letztre Möglichkeiten an dieser Stelle nicht näher eingehn.
Der letzte Teil unsrer Schemata bedarf noch der Erläuterung, muss vor seiner Begründung erst verstehen gelernt werden.
Wenn ι (parallel mit i) etwa eine Wertenreihe 1, 2, 3, … zu durchlaufen hätte, so würde sich die Bedeutung des rätselhaften Operators vor dem letzten Σi in 39) dadurch erklären lassen, dass man diesen in der gewöhnlichen Schreibung ausführlich, explizirt hinsetzte — unter Nichterwähnung des allgemeinen Terms oder Faktors nämlich, in Gestalt von:
[Formel] ihn als das Produktationssymbol für ein (eventuell unbegrenzt) „vielfaches Produkt“ definirte.
Und ebenso wäre [Formel] weiter nichts als wie das Summationssymbol zur Andeutung einer „mehrfachen Summe“.
Da letztere unzweifelhaft dem mehrfachen Produkte dual entspricht, so sieht man zunächst, dass in der neuen Symbolik (die zur Abkürzung schon hier fast unentbehrlich sich zeigt) das Πι ausnahmsweise nicht in Σι dual darf umgeschrieben werden, sondern als Πι verharrend auch in das duale Gegenstück des Schemas eingehen muss.
Ob die Theorie jemals auch von Symbolen, wie [Formel] , [Formel] wird Gebrauch zu machen haben, durch welche von den Π resp. Σ nach mι nur gewisse, irgendwelche, aber mindestens eines, gesetzt würden, muss ich dahingestellt sein lassen.
Von den gegebnen Darstellungen oder Ausdrucksweisen sind die letzten rechts minder gut, vielleicht irreführend, aus dem Grunde, weil ja das zusammengesetzte Suffix m1m2m3 … eines Π oder Σ nicht ein wirkliches Produkt sein soll (weder ein identisches noch ein relatives), sondern konventionell steht für die „Reihe“ m1, m2, m3 … (cf. S. 24).
Freilich weist auch unser Πι ebensowenig auf ein wirkliches Produkt hin, sondern nur auf eine Succession von Zeichen (der dahinter in Klammer gesetzten Art), die eventuell auch ein Kontinuum werden mag.
Wenn (nämlich, resp.) nun aber das ι parallel mit i ein Kontinuum von Werten zu durchlaufen hat, wie etwa die sämtlichen Punkte einer Strecke, so kann man die Bedeutung des [Formel] nicht mehr explizirt hinschreiben.
Die Arithmetik gewährt freilich das Mittel, indem sie jene Punkte den reellen Zahlen eines Intervalles zuordnet, sie allesamt und unterscheidend, zu benennen!
Seien etwa mι die jenen Punkten ι entsprechenden Zahlen.
Alsdann kann man aber zur Erklärung unsres Symboles doch nur sagen: dasselbe schreibe vor, dass für jeden Punkt ι der Strecke ein [Formel] gesetzt gedacht werden solle.
Die Reihenfolge in der solche Π nach verschiednen Zeigern genommen werden (wenn man überhaupt, was oft gar nicht nötig, dieselben in eine bestimmte Folge gebracht denken will), ist bekanntlich ohnehin belanglos.
Denn — nach dem hinreichend weit gefassten dictum de omni: was bei jedem m für jedes n gilt, muss denknotwendig auch bei jedem n für jedes m gelten, etc.
Zur Begründung unsres Schemas 39) linkerhand wollen wir uns aus didaktischen Gründen zuerst wieder an den Fall einer diskreten Wertenreihe der i und ι halten, indem wir zu den Werten A, B, C, … oder auch i1, i2, i3, … von i bezüglich den Namen m1, m2, m3, … für den laufenden Zeiger m des Πm wählen.
Alsdann ist die linke Seite unsres Schemas linkerhand:
[Formel] .
Zur Rechtfertigung ist blos zu bemerken, dass die Gesamtheit der Glieder von L, welche dem Π nach einem bestimmten mλ vorangehen oder folgen, diesen Zeiger mλ gar nicht enthält und als Konstante hinsichtlich desselben mit a oder b ad hoc bezeichnet werden kann.
Alsdann ist zur Transformation von L in R blos erforderlich, für jedes einzelne der differenziirten (d. i. verschieden benannten) m das Schema anzuwenden: a + Πmf(m) + b = Πm{a + f(m) + b}, wonach das Πm auch über den vorangehenden oder nachfolgenden konstanten Addenden miterstreckt werden darf.
Ebendieses Schema — vergl. 26) S. 100 — war aber aus dem Aussagenschema λ) S. 40 leicht zu rechtfertigen.
Ähnlich hätte man für das Schema 39) rechterhand:
[Formel] . —
Das hier Gesagte soll nun aber nicht blos — etwa durch Schluss der vollständigen Induktion — für eine beliebige diskrete Wertenreihe der i und ι gerechtfertigt und statuirt sein (für die wir es vorstehend sozusagen nur illustrirt haben), sondern es soll nach dem dictum de omni für alle i, ι schlechthin in Anspruch genommen werden.
Wenn nunmehr die i, ι auch ein Kontinuum von Werten etwa sollten zu durchlaufen haben, so wird man sich doch für einen jeden iλ, λ ihrer Werte darauf berufen dürfen, wie aus β) S. 37 beweisbar gewesen, dass nach 18) S. 98 jeder Term einer „Σ“ auch darstellbar ist als wirkliches Glied einer (binären) „Summe“ (im engsten Sinne), deren andres Glied alsdann, als unabhängig von dem in jenem Term auftretenden m mit a bezeichnet, dem Schema Πmf(m) + a = Πm{f(m) + a} unterworfen sein muss.
Etc. q. e. d.
Schliesslich sieht man, dass unser Schema falsch und illusorisch würde, wollte man den Zeigernamen mι durch mi, oder überhaupt ein φ(i), ersetzen.
Denn in seinem letzten Teile würde alsdann Σif(i, mi) als allgemeiner Faktor der Π auftreten, und dieses müsste einen von i gänzlich unabhängigen Wert aufweisen, sintemal der Buchstabe i darin blos als Stellvertreter funktionirt für die ihm aus dem Erstreckungsbereich des i beizulegenden Werte.
Es könnte darnach auch mi als solches in seinem ausgewerteten Ausdrucke nicht mehr vorkommen.
(Analog wie ein bestimmtes Integral unabhängig ist von seiner Integrationsvariablen!) Darnach käme der dem Term vorangehende Operator [Formel] ganz in Wegfall, gemäss dem Tautologiegesetze Πa = a, und unser Schema müsste sich noch ausserordentlich vereinfachen!
Dass solche Vereinfachung im Allgemeinen nicht zulässig, würde sich exemplificando darthun lassen.
In Nutzanwendung unsres Schemas auf unsre Unteraufgabe erhalten wir nun:
[Formel] . Wieder ist jedoch leicht unmittelbar zu sehen, dass 40) [Formel] sein muss, was für den Fall, dass auch nur eines der mι gleich k ist, in Gestalt der Gleichung 1 = 1 ohne weitres einleuchtet, für den Fall dagegen, dass sämtliche mι der Summe nach i ungleich k sind, in Gestalt der Gleichung 0 = 0 daraus zu erkennen ist, dass alsdann unter den zulässigen Werten des u auch ein solcher sein wird, für welchen sowol uh k = 0 als auch nach i (und dem parallel damit sich ändernden ι) jedes [Formel] , d. h. jedes [Formel] zugleich ist, mithin ein Faktor des [Formel] verschwindet.
Darnach entsteht:
[Formel] , indem wir unser Schema 39) auch wieder rückwärts anwenden durften. D. h. [Formel] — womit in Übereinstimmung mit der obigen Angabe s = 1; b̆; (ă ɟ 1') gefunden ist.
Nachdem jetzt die Methode zur Lösung kund geworden, wollen wir anstatt der speziellen Aufgabe 12 lieber sogleich die allgemeinere Aufgabe in Angriff nehmen und lösen, welche wir über Aufg. 8 charakterisirt haben.
Vorausbemerkt sei jedoch zur Stelle, dass durch Spezialisiren des Ergebnisses dieser allgemeineren Untersuchung sich die Lösung unsrer Aufg.
12 unschwer ergeben wird als: x = 1 : (ă ɟ 1')b. D. h. die S. 511 für x ermittelte untere Grenze stellt im vorliegenden Falle den exakten Wert dieser Unbekannten vor.
Damit stimmt denn begreiflicherweise die durch die Vorausbestimmung jener Grenzen gegebne Kontrole für unser Ergebniss.
Ebendieses gibt auch für die schon zum voraus erledigten partikularen Fälle des Problemes deren Resultate richtig wieder.
So ohne weiteres für a = 0. Steht dagegen b1' für b, so muss eingesehen werden, dass: 1; (ă ɟ 1')b1' = 0 ɟ (a0' + b1') ist.
Zu dem Ende kann man nach einem (ich greife ein wenig vor) demnächst statuirten Satze 47), 46) die linke Seite zerlegen in 1; (ă ɟ 1')1' = = 1; (1' ɟ a)1' = 0 ɟ (a + 1') und 1; b1' = 0 ɟ (b + 0'), so wird sich das Produkt dieser beiden Ausdrücke 0 ɟ (a + 1')(b + 0') als die rechte Seite darstellen, q. e. d.
Wenn endlich b; 1 für b steht, so hat man sofort: 1; (ă ɟ 1')(b; 1) = = 1; b̆; (ă ɟ 1), q. e. d. —
Zuweilen gelangt man auch, indem man einen Fehler macht, zu interessanten Sätzen!
Ich hatte bei der weiter unten gegebnen Ableitung des x durch ungenaue Reminiszenz der Sätze 27) des § 26 mich verleiten lassen (ĭ ɟ a); b fälschlich umzuwandeln in ĭ ɟ a; b und war dadurch zu dem Werte 0 ɟ (a; b + 1') für x gelangt, mit welchem von den vier vorstehenden Kontrolen, mit Ausnahme der letzten, alle stimmten.
Merkwürdigerweise namentlich liegt dieses fehlerhafte Resultat ebenfalls richtig zwischen den vorermittelten beiden Grenzen, und indem man dieses kontrolirt, gewinnt man sehr bemerkenswerte Sätze.
Wir müssen in der That haben:
1; (ă ɟ 1')b ⋹ 0 ɟ (a; b + 1') ⋹ 0 ɟ (a; b + 1' · 1; b).
Da der Major bereits in {0 ɟ (a; b + 1')}{0 ɟ (a; b + 1; b)} = x · (0 ɟ 1; b) = = x · 1; b zerlegt worden, so ist aus x ⋹ x · 1; b nur noch x ⋹ 1; b darzuthun, was mit: 0 ɟ (a; b + 1') ⋹ 0 ɟ (1; b + 1') = 0 ɟ 1' + 1; b = 1; b folgt.
Wertvoller ist, was der Minor, die erste Teilsubsumtion unsrer Doppelsubsumtion lehrt.
Diese kann nach dem ersten Inversionstheoreme äquivalent umgeschrieben werden in 1; 1; (ă ɟ 1')b ⋹ a; b + 1', oder also in den ersten Satz des folgenden Gespannes: 41) [Formel] dessen konjugirte Sätze, mit einander und schon anderweitig Bekanntem vereinigt, uns gestatten, das relative Produkt und die relative Summe zwischen folgende Grenzen einzuschliessen: 42) [Formel]
Behufs Beweises aus der Koeffizientenevidenz des ersten Satzes 41) haben wir, die rechte Seite auf 0 bringend, zu zeigen dass: 0' · 1; (ă ɟ 1')b · (ā ɟ b̄) = 0, also 0'i jΣhΠk(ak h + 1'k j)bh jΠl(āi l + b̄l j) = 0 ist, oder also ΣhΠk l0'i j(ak h + 1'k j)(āi l + b̄l j)bh j = 0.
Da j ≠ i, k ≠ j in den effektiven Gliedern und Faktoren sein muss, so ist jedenfalls der Wert k = i vertreten und wird für jedes h ein Faktor des Πk l bei k = i, l = h als 0'i j(ai h + 1'i j)(āi h + b̄h j)bh j gleich 0, mithin verschwindet jedes Glied der Σh, q. e. d.
A fortiori ist natürlich auch: 0'{a(1' ɟ b̆) + (ă ɟ 1')b} ⋹ a; b, also z. B. 0'(ă ɟ 1')b(ā ɟ b̄) = 0
womit gewisse identische Produkte nachgewiesen sind als solche, die allermindestens enthalten sein müssen im relativen Produkte.
Etc.
Aufgabe 13. Gesucht [Formel] , wie in 38) S. 508.
Sie begreift die vorhergehenden Aufgaben 8 bis 12 als Sonderfälle unter sich — die 9 und 10 allerdings nicht voll, sondern nur mit deren hervorgehobnem Unterfalle.
Wir haben — demnächst kraft 39):
[Formel] und frägt sich zunächst, welchen Wert dieses letzte [Formel] besitzt.
Hierbei ist zu beachten, dass die mι nicht konstant bezüglich i sind, sondern in der Σi parallel mit i von Glied zu Glied wechseln.
Sofern nach ι alle mι ungleich k sind, wird uh k = 0 neben nach ι allen [Formel] vorkommen und unser [Formel] verschwinden.
Sind jedoch nach ι einige mι gleich k, so wird in den zugehörigen Gliedern der letzten Σi der Faktor [Formel] gegen den Summanden uh k fortfallen und [Formel] als unveräusserlicher Bestandteil des allgemeinen Faktors in unserm [Formel] auftreten, auf diesen aber auch das ganze [Formel] sich reduziren, weil neben uh k = 0 auch die übrigen [Formel] (in denen mι von k verschieden) = 0 vorkommen werden — sintemal ja für u alle erdenklichen Werte aus 12 gesetzt werden sollen.
Also muss sein: 43) [Formel] , was auch für den vorhergehenden Fall den richtigen Wert 0 wiedergibt.
Die Summe rechterhand dürfte selbstverständlich nicht nach dem Schema 12) der S. 121 zu einem einzigen Gliede reduzirt werden, weil in ihr mι nicht bezüglich i konstant ist, sondern seine Bedeutung parallel mit i wechselt; diese Summe kann vielmehr der effektiven Glieder beliebig viele haben.
Damit wird:
[Formel] , wenn wir unser (oben vorwärts angewendetes) Schema 39) nun wieder rückwärts anwenden.
Nun kann man cm i = c̆i m = (i; c̆)h m = (c; i)m k nach Belieben schreiben, den Term auch tautologisch verdoppelt ansetzen und für den einen die vorletzte, für den andern die letzte Form wählen.
Je nachdem ergibt sich: Πm(bh m + cm i + 1'm k) = {(b + ĭ; c̆) ɟ 1'}h k = {b ɟ (c; i + 1')}h k = {(b + ĭ; c̆) ɟ (c; i + 1')}h k, und da auch noch ah i = (a; i)h k, di k = (ĭ; d)h k, so wird: xh k = Σi[a; i · {(b + ĭ; c̆) ɟ (c; i + 1')} · ĭ; d]h k oder also: x = Σia; i · {(b + ĭ; c̆) ɟ (c; i + 1')} · ĭ; d, wo von den beiden Termen ĭ; c̆ und c; i auch nach Belieben der eine oder der andre (aber nicht beide) unterdrückbar.
Man mag etwa als das Einfachere für unser Ergebniss schreiben: 44) x = Σia; i · {b ɟ (c; i + 1')} · ĭ; d.
Damit ist x zwar noch nicht völlig in geschlossener Form dargestellt, aber doch das Π nach u von der zweiten auf eine Σ nach i der ersten Stufe oder Ordnung reduzirt.
Dieser letzteren jedoch lässt sich sogleich auch die noch einfachere Form geben: 45) x = Σii · a{b ɟ (c + i)}; d — worin wiederum der Summand i auch von c abgetrennt und als Summand ĭ zu b geschlagen werden dürfte.
Dies lässt sich einerseits leicht verifiziren, indem man auch für letztres x den allgemeinen Koeffizienten xh k aufstellt; als solcher stellt sich in der That — nur l für i gesagt — sogleich der vorletzte Ausdruck von xh k heraus.
Andrerseits kann man auch den letzten Ausdruck 45) des x aus dem vorhergehenden 44) systematisch ableiten — mittelst Durchgangs durch eine Doppelsumme.
Zu dem Ende schreiben wir in 44) den mittleren Faktor als (b + ĭ; c̆) ɟ 1' in der Form e ɟ 1' an und wählen von den vier Darstellungen über die wir nach 14) oder 17), 16) oder 22), und 18) für e ɟ 1' verfügen: e ɟ 1' = Πj(e; j + j̆) = Πj(e ɟ j̄ + j̆) = Πj(e ɟ j + j̄̆) = Σj(e ɟ j)j̆ die letzte, weil alsdann die beiden Summationszeichen unmittelbar vertauscht werden dürfen.
Dann wird aber: (b + ĭ; c̆) ɟ j = b ɟ (c; i + j) = b ɟ (c + j); i = {b ɟ (c + j)}; i wegen j = j; i, etc. sein, und wir erhalten: x = Σjj̆ · Σia; i · {b ɟ (c + j)}; i · ĭ; d = = Σjj̆ · Σia{b ɟ (c + j)}; i · ĭ; d = Σjj̆ · a{b ɟ (c + j)}; d, was abgesehen von der Bezeichnung der Summationsvariabeln die Darstellung 45) von x ist.
[Zu berücksichtigen waren vorstehend die Sätze (wegen i = i; 1) 10) des § 27, 10), sodann 27) und 26) des § 25, zuletzt 14).]
Der Kontrolen für unser Ergebniss sind nun viele.
Vor allem wollen wir die schon kontrolirte Lösung der Aufgabe 12 aus ihm ableiten.
Zu dem Ende ist in 45) a = 1, b = 0 zu nehmen, hernach a und b für c und d zu schreiben.
So entsteht zunächst: x = Σiĭ · {0 ɟ (a + i)}; b = Σiĭ · (ĭ ɟ a); b = Σiĭ · ĭ; (1' ɟ a); b, vergleiche 32) des § 25, nebst 25).
Also nach 26): x = 1; {(1' ɟ a); b}1' = 1; 1'{b̆; (ă ɟ 1')}, weil 1'c = 1'c̆.
Nun gilt der bemerkenswerte Satz: 46) [Formel] dessen (hier benötigte) zweite Formel links sich aus der Koeffizientenevidenz beweist mittelst:
Li j = Σl1i lΣhal hbh j1'l j = Σhaj hbh j = Σh1ih(ăb)h = Ri j.
Dieser Satz gehört einer Gruppe von Sätzen an, die sich auf Relative der Form 1'a; 1, etc. beziehen und von denen wir einige bereits unter 24), 25) des § 22 kennen gelernt haben (S. 335), einen Sonderfall in Gestalt von 30).
Dazu gehört auch noch — als aus ai ibi i = (ab)i i einleuchtend: 47) [Formel] was auch sofort auf mehr als zwei Terme ausdehnbar.
Nach 46) ist denn nun als Lösung der Aufg. 12: x = 1; (ă ɟ 1')b, wie oben S. 517 angegeben, gefunden.
Und damit hätten wir denn schon einige Kontrolen des in der Gleichsetzung der Werte von x aus 38), 44) und 45) bestehenden Hauptresultates [Formel] unsrer Untersuchung: 48) [Formel] .
Als fernere Kontrolen seien dem Studirenden überwiesen: die Herleitung der übrigen Produktwerte, welche in Aufg. 8 bis 11 unter das Schema unsrer Aufg.
13 fallen, aus diesem die letztre lösenden Ergebnisse.
Für d = 1' gelangt man dabei zu einem Satze: 49) Σi{b ɟ (c; i + 1')}ĭ = b ɟ (c + 1'), der aus der Koeffizientenevidenz erweislich.
Weiter, nachdem ein Resultat der Form Πv = Σw gefunden ist, so muss wegen w ⋹ Σw ⋹ Πv ⋹ v sich w ⋹ v bewahrheiten.
In unserm Falle lassen in der That die beiden Subsumtionen: 49a) a; i · {b ɟ (c; i + 1')} · ĭ; d sowie ĭ · a{b ɟ (c + i)}; d ⋹ u + a{(ū + b) ɟ c}; d als für jedes Element i und jedes binäre Relativ u bei irgendwelchen a, b, c, d gültige sich aus der Koeffizientenevidenz rechtfertigen.
Dazu empfiehlt es sich, das Glied u als Faktor ū nach links zu werfen und e für ū zu schreiben.
Dass alsdann (vergl. xh k S. 519): ah iΠm(bh m + cm i + 1'm k)di keh k ⋹ Σlah lΠm(eh m + bh m + cm l)dl k ist, sieht man so.
Rechts kommt bei l = i das Glied vor: ah iΠm(eh m + bh m + cm i)
di k, welchem bereits die linke Seite als eingeordnet nachweisbar, indem für alle m ≠ k schon jeder Faktor des Πm links ⋹ dem entsprechenden in diesem Gliede rechts: bh m + cm i ⋹ eh m + bh m + cm i, für m = k aber wenigstens 1 · eh k ⋹ eh k + bh k + ck i ist, q. e. d.
Endlich würden sich auch für unser x in 38) auf verschiedne Weise wieder Grenzen ermitteln und mit diesen der gefundne exakte Wert des x sich kontroliren lassen.
Dass alle Kontrolen stimmen, wird das Zutrauen in unser Schema 39) festigen.
Der Sonderfall b = 0 wird für die von uns beabsichtigten Anwendungen der Formel 48) besonders wichtig und zeichnet sich dadurch aus, dass in ihm die Summationen nach i sich (in geschlossner Form) „ausführen“ lassen.
Zunächst entsteht bei Vornahme noch eines kleinen Buchstabenwechsels:
[Formel] , welcher gesuchte Wert y heisse.
Nun wird: 0 ɟ (b; i + 1') = ĭ; b̆ ɟ 1' = ĭ; (b̆ ɟ 1'), 0 ɟ (b + i) = ĭ ɟ b = ĭ; (1' ɟ b) — vergl. 27) des § 25, und 25).
Darnach kommt resp. y = Σia; i · ĭ; (b̆ ɟ 1')c = Σiĭ · a{ĭ; (1' ɟ b)}; c = Σia; {(b̆ ɟ 1'); i}c · ĭ — erstres wegen 26) des § 25.
Der Wert der ersten Summe lässt sich sogleich nach meinem Satze 14) ausgerechnet hinschreiben als a; (b̆ ɟ 1')c.
Und für den (zweiten oder) dritten Summenausdruck das Summationsproblem sogleich verallgemeinernd haben wir überdies den Satz: 49b) Σia; (b; i)c · ĭ = a; bc, der mit Lh k = Σi l mah lbl mim kcl kik h = Σi l mah lbl m1'i mcl k1'i k = Σlah lbl kcl k = Rh k sich auch unmittelbar beweist.
Nach seinem Schema ergibt sich der gleiche Ausdruck für y wie vorhin, sodass doppelt gefunden ist: 50) [Formel]
Wir schreiten nunmehr zur Nutzanwendung auf unsre Inversionsprobleme; sie wird uns beim zweiten ein sehr wichtiges Ergebniss liefern.
Aufgabe 14. Gesucht sei 51) [Formel] . Daraus geht dann, indem man nur ac; b für a setzt, mit Leichtigkeit auch der Wert des Produktes [Formel] hervor, indem in der That dadurch a · c; b in ac; b · c; b = ac; b verwandelt wird — wogegen y aus dem letzten Produkte abzuleiten nur bedingungsweise möglich sein würde.
Wir nehmen daher die Aufgabe besser in ihrer obigen Form in Angriff.
Auflösung.
Als allgemeine Lösung der Subsumtion a · c; b ⋹ xc; b haben wir nach 11) des § 19: x = u + a(c; b){(ū + c̄) ɟ b̄}; b̆, worin das b̆ auch durch 1 ersetzbar.
Hiervon das Π nach u genommen gibt — mit Rücksicht auf die letzte Bemerkung — nach den Schemata 48): 51a) [Formel] sintemal ĭ; 1 = 1 ist.
Hervorragendes Interesse bietet uns der Fall c = 1, wo wir für die allgemeine Wurzel x der Subsumtion des zweiten Inversionsproblems a · 1; b ⋹ x; b nach den Ergebnissen des § 18 [unter Meidung der dem Fehlerverzeichniss verfallenen Formel 26)] die Ausdrucksformen haben: 52) [Formel] deren drei erste nach Schema 27) des § 25 auf je eine der zwei letzten (und somit zum Teil auch aufeinander) zurückführbar sind.
Demgemäss ergeben sich nun auch für die Gemeinheit y jener Wurzeln nach 5) die Ausdrücke: 53) [Formel] bezüglich deren Ähnliches zu bemerken wäre.
Die Gleichheit der beiden letzten von diesen beruht auf dem Satze 15) S. 210, wonach wir, b̆ mit b vertauschend, haben: a; (b̄ ɟ 1')(b; 1) = a; (b̄ ɟ 1')b, weil eben (b̄ ɟ 1') · b; 1 = = (b̄ ɟ 1')b.
Für Letztres, was zeilenrechnerisch leicht zu erweisen, kann man auch den Beweis per Koeffizientenevidenz geben mit:
Li j = Πk(b̄i k + 1'k j)Σlbi l, Ri j = Πk(b̄i k + 1'k j)bi j.
Da im Πk nun k ≠ j sein muss, so gibt bei l ≠ j uns k = l einen effektiven Faktor, wobei in Li j sich b̄i l mit bi l vernichtet, und bleibt sonach von der Σl in jenem nur das Glied mit l = j stehen, worauf Li j mit Ri j übereinstimmt, q. e. d.
Unser Ergebniss ist also, dass: 54) [Formel] .
Da dieses Πx jedem der x eingeordnet sein muss, so wird sich nun auch der Satz zu bewahrheiten haben: 55) [Formel]
Beweis.
Aus der Prämisse links folgt: a(1; b); (b̄̆ ɟ 1') ⋹ x; b; (b̄̆ ɟ 1'), aber x; b; (b̄̆ ɟ 1') ⋹ x, sintemal letzteres nach dem ersten Inversionstheoreme hinauskommt auf: x; b ⋹ x ɟ b; 0', worin ein Zwillingssatz unsres Theorems 37) in § 28 zu erblicken ist.
Damit wird denn gemäss 51) die Behauptung a fortiori erwiesen sein.
Jener lautet: 56) [Formel] und wird in der Fassung a; b; (b̄̆ ɟ 1') ⋹ a mit 58) weiter unten bewiesen sein.
Man kann ihn, mit dem vorigen zusammengefasst, sich etwa einprägen in der Gestalt: wobei von den Zeichen 0' resp. 1' irgendwelche bis auf eines, was übrig bleiben muss, unterdrückbar bleiben. —
a; b ⋹ 0'; a; 0' ɟ 0'; b; 0' (1' ɟ a ɟ 1'); (1' ɟ b ɟ 1') ⋹ a ɟ b,
Da weiter 52) die allgemeine Wurzel unsrer Subsumtion a · 1; b ⋹ x; b gewesen, so wird auch dieser das Π derselben, y = Πx, eingeordnet sich zeigen müssen.
Dies gibt, wenn man das Glied u von rechts als Faktor ū nach links wirft und dann c für ū sagt, den Satz: 57) — womit die linke Seite dann auch a fortiori ⋹ a(c ɟ b̄); 1 sein wird.
Wir beweisen diesen, rechts auf 0 bringend, auch aus der Koeffizientenevidenz, als: a; (b̄̆ ɟ 1')b̆ · c{(ā + c̄; b) ɟ b̄̆} = 0.
Zu zeigen ist also, dass: Σhai hΠk(b̄k h + 1'k j)bj hci jΠl(āi l + Σmc̄i mbm l + b̄j l) = 0 sein müsse, d. h. dass das allgemeine Glied dieser Σh verschwindet.
Dieses hat in der That einen verschwindenden Faktor, als welcher bei l = h hervortritt:
[Formel] .
Denn es kommen zunächst die unterwellten Terme in Wegfall.
Von der Σm sodann wird das Glied, in welchem m = j ist, durch den Faktor ci j zerstört.
Die Glieder aber, wo m ≠ j ist, finden in dem nachfolgenden Π, worie k ≠ j postulirt ist, mit k = m einen effektiven Faktor b̄m h vor, an dem sie zerschellen, q. e. d.
a; (b̄̆ ɟ 1')b̆ · c ⋹ a(c ɟ b̄); b̆ etc.
Hienach werden denn alle Kontrolen unsres Ergebnisses 57) gestimmt haben.
Sagt man jetzt a; b für a, so wird sich zu den zwei für y in geschlossener Form gefundenen Ausdrücken noch ein dritter angeben lassen — der als ein identisches Produkt jenen für gewöhnlich vorzuziehen ist — und zwar aufgrund des Satzes: 58) [Formel] .
Beweis.
Schreibt man die erste Zeile als L = M = R, so ist L = M bereits mit der letzten Gleichung 53) gegeben; denn indem man dort a; b für a schreibt, wird sich der Faktor b̆; 1 des nunmehr dritten relativen Faktors konvertirt als 1; b zum zweiten b schlagen lassen und in diesem eingehen.
Bleibt also noch M = R zu beweisen, wo Mi j = Σh kai hbh kΠl(b̄l k + 1'l j), Ri j = ai jΣkΠl(b̄l k + 1'l j)bj k.
In Mi j verschwindet aber in der That jedes Glied der Σh worin h ≠ j ist, weil dann in ihm bh k mit einem effektiven Faktor b̄h k des Πl zusammentrifft, q. e. d.
Sonach erhalten wir an Stelle von 54) und 55): 59) [Formel] , 60) [Formel]
Seiner Wichtigkeit halber wollen wir auch diesen letztern Satz nochmals — selbständig — beweisen.
Aus der Prämisse folgt: a⋹x; b ɟ b̄̆, also a · 1; (b̄̆ ɟ 1')b̆ ⋹ (x; b ɟ b̄̆) · 1; (b̄̆ ɟ 1')b̆ und wird die Behauptung a fortiori erwiesen sein, sofern sich zeigen lässt, dass dieses Prädikat selber ⋹ x sein muss.
Nach 58), ferner 3) des § 19, und wieder 58) haben wir in der That: x̄ · (x; b ɟ b̄̆) · 1; (b̄̆ ɟ 1')b̆ = x̄ · (x; b ɟ b̄̆); b; (b̄̆ ɟ 1') = x̄ · x; b; (b̄̆ ɟ 1') = = x̄ · x · 1; (b̄̆ ɟ 1')b̆ ⋹ x̄x = 0.
Sehr wichtig ist nun aber die Bemerkung, dass der durch 60) [oder 55)] verbürgte Schluss von der Voraussetzung oder linken Seite der Aussagensubsumtionen auf die Behauptung oder rechte Seite derselben, nicht umkehrbar ist. M. a. W.
Die Gemeinheit Π aller Wurzeln x der Subsumtion a; b ⋹ x; b ist selbst im Allgemeinen keine Wurzel derselben!
Die Aussagensubsumtionen 55), 60) haben also nicht die Kraft von Gleichungen, oder:
Durch äquivalente Transformation kann ein relativer Faktor des Prädikats einer Subsumtion nicht isolirt werden (sei es als Subjekt sei es) als Prädikat, sondern solches ist nur mittelst Schlusses a fortiori (d. i. im abgeschwächten, besser: in abschwächendem Schliessen) möglich — im Gegensatz zum Falle des relativen Faktors im Subjekte, wofür wir die so einfachen ersten Inversionstheoreme hatten.
Die — im Vergleich damit fühlt man sich versucht zu sagen: „vertrakte“ — Gestalt, in der sich uns die zweiten Inversionstheoreme boten, und aus der im Anwendungsfalle so viele Schwierigkeiten bei den Untersuchungen erwachsen, ist hienach wol eine unumstössliche, mit der man endgültig zu rechnen haben wird; sie erscheint im Allgemeinen nicht durch eine einfachere oder handlichere Form ersetzbar.
Am schnellsten leuchtet das vorstehend Gesagte bei der Exemplifikation auf b = 1 ein, wo sich andernfalles die Relation a; 1 ⋹ x; 1 als mit der gar nichts sagenden Subsumtion 0 ⋹ x äquivalent erweisen müsste.
Soll — allgemein in a, b, x — der erste unsrer Schlüsse umkehrbar sein, soll also (wie im Falle b = i) ein einfaches zweites Inversionstheorem existiren, so ist die hinreichende (und notwendige) Bedingung dafür diese, dass von a und b die Relation erfüllt sei (welche leicht als solche nachzuweisen): 61)
[Formel] Trifft diese zu, so werden die genannten Formeln 55), 60) als Gleichungen, Aussagenäquivalenzen gelten — und umgekehrt (weil man dann für x selbst auch dessen Subjekt nehmen kann).
Aber auch die letzte Subsumtion 61) wird die Kraft einer Gleichung besitzen, indem die Geltung der umgekehrten Subsumtion: 62) a; b; (b̄̆ ɟ 1'); b ⋹ a; b oder a ⋹ a; b ɟ b̄̆ ɟ b; 0' ɟ b̄̆ als einer Formel wie folgt erweislich.
Wegen a; b ⋹ a; b ist bekanntlich a ⋹ a; b ɟ b̄̆, aber a; b = (a; b ɟ b̄̆); b ⋹ ⋹ (a; b ɟ b̄̆) ɟ b; 0' nach 56), woraus durch beiderseitig relatives Nachaddiren von b̄̆ nach Vorbemerktem a fortiori die Behauptung folgt.
Die erste Subsumtion 61) freilich gilt rückwärts nicht, wie schon die Annahme b = 1 zeigt.
Vergleicht man die letzte Subsumtion in 61) mit der darüberstehenden, welche sich auch in die Form a; b ⋹ a; {b (1' ɟ b̄); 1}b setzten lässt, während beide die Kraft von Gleichungen haben, so drängt sich die Bestätigung findende Vermutung auf, dass — a für b gesagt — der Satz gelten möchte: 63) [Formel]
Beweis.
Li j = Σh lΠkai h(āk h + 1'k l)ai j, Ri j = ΣhΠkai h(1' i k + āk h) ai j · Multiplizirt man in Li j das allgemeine Glied der Σh l mit (1'i l + 0'i l) das = 1 ist — was auf die Unterscheidung der Fälle l = i und l ≠ i bei deren Gliedern hinauskommt, so ergibt sich:
Li j = Ri j + Σh lΠk0'lai h(āk h + 1'l)al j. Wegen l ≠ i und k ≠ l gibt aber k = i einen effektiven Faktor des Πh, als welcher āi h mit dem vorhandenen ai h zusammentrifft.
Es verschwinden also für jedes h alle Glieder der Σl bei denen l ≠ i ist, und damit die letzte Doppelsumme, d. h. es ist L = R, q. e. d.
Es kann an dieser Stelle nicht unsre Aufgabe sein zu untersuchen, wie der Forderung 61) durch a und b auf die allgemeinste Weise zu genügen sei.
Aufgabe 15. Gesucht das Π und die Σ von allen Wurzeln x der Gleichung x; b = a; b des dritten Inversionsproblemes.
Nach 19) des § 19 war dessen allgemeine Wurzel gegeben durch 64) [Formel] bedeutete, und sonach c; b = a; b sein musste.
Da [Formel] , so hat man sofort: 65) [Formel] .
Und da der Ausdruck 64) von x unter das Schema 38) fällt, so werden wir, indem wir das Πx = y nennen, nach 44) und 45) auch sogleich haben: 66) [Formel] , welche Summationen vorerst im Allgemeinen nicht weiter ausführbar erscheinen. —
Indem wir von diesen schwierigern Problemen wieder eine Stufe herabsteigen, so sei auch noch als
Aufgabe 16. Gesucht Π und Σ nach u der allgemeinsten Funktion identischen Kalkuls von u und ŭ, das ist also des allgemeinsten Ausdruckes, welcher sich durch die vier von unsern 6 Spezies, als da sind: die drei identischen Spezies und die Konversion, aus u ableiten lässt.
Dieser Ausdruck x kann bekanntlich in den beiden Formen angesetzt werden: 67) x = auŭ + buū̆ + cuŭ + dūū̆ = (a + ū + ū̆)(b + ū + ŭ)(c + u + ū̆)(d + u + ŭ), deren zweite sich aus der ersten durch doppeltes Negiren ergibt.
Die erstre ist zur Ermittlung der Σ, die letztre zu der des Π geeignet.
Nun gilt der Satz: 68)
Die Formeln der ersten Zeile leuchten daraus ein, dass u = 1 und u = 0 selbst als Werte von u im Erstreckungsbereiche vorkommen.
Die der zweiten Zeile leuchten zunächst nur als die Subsumtionen Σ ⋹ 0', 1' ⋹ Π aus 2) des § 8 ein.
Dass aber bei der Σuū̆ auch jede Augen- Stelle von 0' ein Auge trägt, erhellt im Hinblick auf S. 139 daraus, dass unter den Werten von u auch solche figuriren, welche die gedachte Stelle unparig besetzt zeigen, wo sie dann auch in uū̆ ein Auge haben wird.
Etc. q. e. d.
Hienach ist denn sogleich: 69) [Formel] .
Untersuchung 17.
Als in methodologischer Hinsicht von Interesse mag eine Nutzanwendung der Sätze 14) hier noch vorgetragen werden, die ich von denselben behufs Lösung des dritten Inversionsproblemes zu machen suchte zu einer Zeit, als mir dessen in § 19 gegebne definitive Lösung noch verschlossen war.
Obwol diese Anwendung nicht den beabsichtigten Erfolg herbeiführte, erschloss sie doch den Einblick in eine merkwürdige Umformung der Problemstellung und ist vielleicht auch, nachdem das Problem schon anderweitig gelöst worden, selbst in objektiver Hinsicht nicht ohne Wert.
Das allgemeine dritte Inversionsproblem des § 19, nämlich die Auflösung der Gleichung x; b = a; b, lässt sich nach 14) nun auch in der Form in Angriff nehmen: 70) Σix; i · ĭ; b = Σia; i · ĭ; b, und liegt es nahe, diese Gleichung zunächst nach den x; i als Unbekannten aufzulösen.
Diese Aufgabe fällt unter das Schema der in Bd. 2, § 51 unter Aufg.
20 symmetrisch allgemein gelösten.
Nach diesem Schema ergibt sich unschwer: 71) [Formel] — worin der Faktor ĭ; b̄ zunächst als ī̆ ɟ b̄ auftrat.
Mit diesem Resultat stimmt bei beliebigem u auch die Probe 1 — wobei nur zu berücksichtigen, dass Σiĭ; b = 1; b und a; b · 1; b = a; b, sowie dass nach 26) des § 25: ĭ; b · ĭ; b̄ = ĭ; bb̄ = ĭ; 0 = 0 ist, wonach sich denn die linke Seite von 70) gleich a; b · (ū ɟ b̄ + u; b) = a; b · 1 herausstellt, q. e. d.
Nennen wir nun die rechte Seite in 71) kurz c, so bleibt nach x nur mehr die Gleichung aufzulösen: 72) x; i = c.
Diese zerfällt in x; i ⋹ c und c ⋹ x; i = x ɟ ī mit Rücksicht auf 22) des § 25, und es lassen sich beide Teilsubsumtionen nach dem ersten Inversionstheorem äquivalent transformiren wie folgt: (c ⋹ x ɟ ī) = (c; ĭ ⋹ x), (x; i ⋹ c) = (x ⋹ c ɟ ī̆), wonach denn die Doppelsubsumtion 73)
c; ĭ ⋹ x ⋹ c ɟ ī̆ die gesuchte Auflösung darstellen wird, mithin der Gleichung 72) äquivalent sein muss.
Diese Äquivalenz mittelst vorgesetzten Πi für alle i in Anspruch genommen gibt: 74) Πi(x; i = c) = {Σic; ĭ ⋹ x ⋹ Πi(c ɟ ī̆)} = (Lu ⋹ x ⋹ Ru).
Wäre c konstant inbezug auf i, so würde Lu = Σic; ĭ sich gleich c; 1, und Ru = Πi(c ɟ ī̆) sich gleich c ɟ 0 ergeben.
Obgleich nun aber c als Funktion von i gegeben ist und als solche ausdrucksvoller mit ci hätte bezeichnet werden sollen, so lassen sich Lu und Ru, nämlich Subjekt und Prädikat von x, doch in konziser Form evaluiren, indem man für Lu die erste, für Ru die zweite Form von c aus 71) bequemer benutzt.
Man findet unter Anwendung bekannter Sätze: 75) [Formel] . Mit diesen Werten muss also sein: 76) [Formel] , und gelingt es, hiermit die beiden Proben zu leisten.
Probe 1 fordert zu zeigen, dass, sobald es ein u gibt, derart, dass die Doppelsubsumtion rechts in 76) besteht, dann x; b = a; b ist.
Aus der Annahme folgt aber Lu; b ⋹ x; b ⋹ Ru; b und wird der Nachweis geliefert sein, sobald es gelungen ist zu zeigen, dass a; b ⋹ Lu; b, Ru; b ⋹ a; b für jedes u ist, indem alsdann a fortiori a; b ⋹ x; b ⋹ a; b, d. h. x; b = a; b geschlossen werden kann.
Hiezu nun sind, obzwar es einige Rechnung erfordert, die schon bekannten Sätze ausreichend und stellt sich dabei, sowie auch nachher bei der andern Probe, heraus, dass in Lu der unterwellte Term 1; b̄̆ auch unterdrückbar ist unbeschadet der Allgemeingültigkeit und des erschöpfenden Charakters der Lösung.
Probe 2 verlangt, als vorwärtige Subsumtion die Äquivalenz zu beweisen: (x; b = a; b) = {(x̄ ɟ b̄)(a; b); 1 + x(a; b; 1 + 1; b̄̆) ⋹ x ⋹ (x̄ ɟ b̄)(a; b) ɟ 0 + x(a; b ɟ b̄̆)}, welche als rückwärtige soeben durch die Probe 1 implicite erwiesen worden.
Aus der Hypothesis folgt aber in der That: (x̄ ɟ b̄)(a; b) = 0, und somit reduzirt sich die Behauptung zu der Doppelsubsumtion:
[Formel] , deren erster Teil (auch ohne das unterwellte Glied) selbstverständlich ist, während der zweite auf x ⋹ a; b ɟ b̄̆, das ist x; b ⋹ a; b hinausläuft, q. e. d.
Trotz alledem wäre es voreilig, unser Inversionsproblem mit 75, 76) gelöst zu wähnen.
Die damit gewonnene Lösungsform lässt nämlich das u nicht unbestimmt oder willkürlich, sondern involvirt für dasselbe in Gestalt der Resultante: 77) Lu⋹Ru eine Relation, Bedingung oder Bestimmung.
Alle Versuche, dieser Forderung, oder auch successive den Teilforderungen in welche sie leicht zerfällt, vermittelst allgemeinster Bestimmung von u zu genügen, führen in fatale Zirkel, und in ähnliche Schwierigkeiten wird man auch verwickelt, wenn man etwa sucht, die Resultante c = c ɟ 0 = c; 1 = c; i der Elimination von x aus 72) zu erfüllen, welche u so zu bestimmen fordert, dass die rechte Seite c in 71) „System“ sei.
Die Betrachtungen haben uns also der — glücklicherweise in § 19 ja schon anderweitig ermittelten — Lösung unsres Problemes nicht näher gebracht. Dieselben wenigstens in ihren Hauptzügen dargelegt zu haben, schien mir gleichwohl aus schon angeführten Gründen nicht überflüssig.
Zudem schöpfen wir aus dem Exkurse Veranlassung, nochmals auf jenes dritte Inversionsproblem x; b = a zurückzukommen, inbezug auf welches ja, wie wir bereits in § 19 angedeutet, noch Manches zu erledigen bleibt.
Aufgabe 18. Zunächst sollte auf gewisse Partikularfälle des Problems (nicht zu verwechseln mit Partikularlösungen desselben) noch näher eingegangen werden.
Dergleichen Partikularfälle, die besonderes Interesse beanspruchen, sind ausser den 4 bereits erledigten, wo b gleich einem der Moduln, die 8, wo b Elementepaar, Element, System oder ein Verwandtes von einem dieser ist, d. h. wo bezüglich b = i : j, i : j͞, i, ī, ĭ, ī̆, b; 1, 1; b. [Diesen werden sich späterhin mindestens noch die 6 Annahmen, wo b Funktion, Argument, oder Substitution, resp. deren Negat ist, zugesellen.]
In diesen Fällen ist schon, wenn das Problem als ein nur bedingungsweise lösbares in der Form x; b = a angesetzt wird, die Diskussion der Resultante zuweilen lehrreich, und möge solches gelegentlich mit einem Seitenblick gestreift werden.
Setzen wir dagegen unser Problem als ein unbedingt lösbares in der Gestalt x; b = a; b an, so war die Lösung gegeben durch 64), und wird es nicht immer ganz leicht sein, die Vereinfachungen wahrzunehmen, die sich in den Partikularfällen ergeben.
Zudem bietet lehrreiche Momente die Vergleichung des Ergebnisses mit solchen Lösungen, die sich selbständig für ebendiese Partikularfälle finden liessen und nicht immer mit den durch die Partikularisirung gewonnenen wesentlich übereinstimmen.
Erstens.
Sei b System, oder besser gesagt: es stehe b; 1 (bei wiederum beliebig anzunehmendem b) an Stelle von b, mithin b̄ ɟ 0 für b̄, 1; b̆ für b̆, 0 ɟ b̄̆ für b̄̆.
So wird: c = a; b; 1 ɟ 0 ɟ b̄̆ = a; b; 1 + 0 ɟ b̄̆, c̄ = (ā ɟ b̄ ɟ 0) · 1; b̆, ū + c̄ = (ū + ā ɟ b̄ ɟ 0)(ū + 1; b̆), woran nun mit ɟ b̄ ɟ 0 zu operiren ist.
Der zweite Faktor wird alsdann (ū + 1; b̆) ɟ b̄ ɟ 0 = ū ɟ (b̄ ɟ 0 + b; 1) = ū ɟ 1 = 1, cf. 10) des § 27, das Ganze mithin gleich dem ersten Faktor, d. h. das (ū + c̄) ɟ b̄ des Schema’s 64) wird = ū ɟ b̄ ɟ 0 + ā ɟ b̄ ɟ 0, und (a; b){(ū + c̄) ɟ b̄} wird a; b; 1 · (ū ɟ b̄ ɟ 0).
Dies ist mit dem frühern b̆, also 1; b̆, wonicht mit 1, relativ nachzumultipliziren, wodurch entsteht: (ū ɟ b̄ ɟ 0) · a; b; 1; b̆, worin jedoch der Faktor 1; b̆ auch durch 1; 1, = 1, ersetzbar, mithin unterdrückbar.
Darnach ergibt sich leicht: 78) [Formel] als die allgemeine Wurzel der Gleichung x; b; 1 = a; b; 1.
Bei Unterdrückung des als unterdrückbar erwiesenen unterwellten Faktors stimmt dies Ergebniss völlig überein mit dem, welches ich lange vor 22) selbständig gefunden hatte, indem ich die Koeffizientenforderung: Πi {Σhxi h(b; 1)h = Σhai h(b; 1)h} nach dem Schema von Bd. 2, § 51, Aufg.
21 systematisch auflöste.
Für das etwa durch die Fortlassung des unterwellten Terms vereinfachte Ergebniss gelingt es unschwer auch die beiden Proben zu leisten, wobei zu Probe 1 nur zu beachten ist, dass a; b; 1 · 1; b; 1 = a; b; 1, sowie nach 10) des § 27: u(0 ɟ b̄̆); b; 1 = u; (b̄ ɟ 0)(b; 1) = u; 0 = 0 ist, und sich dann x; b; 1 gleich a; b; 1 mal ū ɟ b̄ ɟ 0 + u; b; 1, welches = 1 ist, ergibt.
Probe 2 betreffend ist zu zeigen, dass, sooft x; b; 1 = a; b; 1 ist, die Gleichung 78) für u = x zutrifft.
Darin verschwindet aber rechts das erste Glied wegen a; b; 1 ⋹ ⋹ x; b; 1, und bleibt blos x ⋹ a; b; 1 + 0 ɟ b̄̆ zu zeigen, was aus x; b; 1 ⋹ a; b; 1 zunächst in der Gestalt x ⋹ a; b; 1 ɟ 0 ɟ b̄̆ nach dem ersten Inversionstheoreme durch Hinüberwerfen des relativen Faktors b; 1 in der That folgt, q. e. d.
Speziell b durch i ersetzend erhalten wir nun auch die Lösung: x = (ū ɟ ī) · a; i + a; i · u + u(0 ɟ ī̆) und haben noch etwas vereinfachend im Hinblick auf 29) S. 420 etc. den Satz: 79) [Formel] und ähnlich auch: 80) [Formel] .
Zweitens.
Sei b Systemkonvers, oder stehe 1; b für b, 0 ɟ b̄ für b̄, b̆; 1 für b̆, b̄̆ ɟ 0 für b̄̆.
So wird c = a; 1; b ɟ b̄̆ ɟ 0 = (a; 1 ɟ b̄̆)(1; b ɟ b̄̆) ɟ 0 = (a; 1 + 0 ɟ b̄̆) ɟ 0 = = a; 1 + 0 ɟ b̄̆ ɟ 0 = a; 1 + 0 ɟ b̄ ɟ 0, c̄ = (ā ɟ 0) · 1; b; 1, jenes in Anbetracht, dass 1; b ɟ b̄̆ = 1 ist.
(ū + c̄) ɟ b̄ wird = ū ɟ 0 + (ā ɟ 0) · 1; b; 1 + 0 ɟ b̄, und dies, mit a; b, das heisst a; 1 · 1; b multiplizirt, gibt a; 1; b · (ū ɟ 0).
Und dies von(;) b̆, also b̆; 1, genommen gibt (ebenso, wie von 1 genommen): (ū ɟ 0) · a; 1 · 1; b; 1. Darnach erhalten wir: 81) x = (a; 1 + 0 ɟ b̄ ɟ 0)u + a; 1; b; 1 · (ū ɟ 0) als die allgemeine Wurzel der Gleichung x; 1; b = a; 1; b.
Auch mit ihr stimmen leicht die beiden Proben.
Jenachdem b verschwindet oder nicht, vereinfacht sich deren Ausdruck jedoch ungemein, und zwar zu: 82) [Formel] .
Das Ergebniss stimmt nicht überein mit einem schon früher als Lösung zu x; 1 · 1; b = a; 1 · 1; b von mir selbständig gefundenen: 83) x = (0 ɟ b̄ ɟ 0) u + u · a; 1 + a; 1 · 1; b · (ū ɟ 0) = (a; 1 + 0 ɟ b̄ ɟ 0)u + a; 1; b · (ū ɟ 0), welches sich vielmehr vereinfacht zu: 84) [Formel] , und ist die Vergleichung beider Lösungsformen sehr lehrreich.
Für den Fall b ≠ 0 erscheint in 82) die allgemeine Wurzel x als unabhängig von b, und zwar ist sie in der That keine andre als die aus 24) des § 19 uns schon bekannte Lösung der Gleichung x; 1 = a; 1, welche demnach (für b ≠ 0) mit der Gleichung x; 1; b = a; 1; b äquivalent sein muss.
Wie diese in der That stets aus jener folgt, so ist der umgekehrte Schluss — nur für b ≠ 0 — wie folgt zu ziehen.
Aus x; 1; b = a; 1; b folgt x; 1; b; 1 = a; 1; b; 1 oder x; 1 · 1; b; 1 = a; 1 · 1; b; 1, was für b ≠ 0 mithin 1; b; 1 = 1 auf x; 1 = a; 1 hinauskommt, q. e. d.
Trotz ihres in 84) minder einfachen Ausdrucks erscheint die selbständig gefundene Lösung als die bessere gegenüber 82) unter dem Gesichtspunkt, dass weniger Augen (und keine Vollzeilen) zu dem willkürlich angenommenen u bei der Ausrechnung des x hinzugefügt werden müssen, mithin die sozusagen an dem u, um es in eine Wurzel zu verwandeln, anzubringende „Korrektur geringfügiger ist.
Zudem lernen wir aber, dass auch umgekehrt für die allgemeine Wurzel der Gleichung x; 1 = a; 1 der zweite Ausdruck 84) angesetzt werden konnte.
In ihm wird dann b die Rolle eines unwesentlichen Parameters spielen, welcher nur insofern nicht willkürlich ist, als sein Verschwinden ausgeschlossen sein muss.
Ersetzt man aber b durch die allgemeinste Wurzel v + 0 ɟ v̄ ɟ 0 der Gleichung b ≠ 0, so wird 1; b = 1; v + 0 ɟ v̄ ɟ 0 und entsteht als eine zulässige Lösungsform der Gleichung x; 1 = a; 1 auch diese: 85) [Formel] , worin v als „unwesentlicher Parameter“ schlechthin beliebig bleibt.
In die zweite 82) geht diese Formel nur bei der Annahme v = 0 über, und andernfalls deckt sie sich mit der zweiten 84) — wobei nur v für b steht.
Solche Lösungsform kann in gewissem Sinne „vollkommner“ als die 24) des § 19 genannt werden, indem sie nur den Leerzeilen von u, welche bei a besetzt sind, anstatt sie sofort in Vollzeilen zu verwandeln, irgend welche Augen (in jedem Falle mindestens ein Auge) zuteilt, was ja genügt, um sie auch bei x in besetzte Zeilen zu verwandeln.
Man kann z. B. auch v durch irgend ein ĭ ersetzen, womit dann in jeder unter a; 1 fallenden Leerzeile des u gerade nur ein Auge angebracht wird, alle so zugefügten Augen aber in einer Vertikalflucht liegen werden.
Die betrachteten Lösungsformen 81) bis 85) stellen uns hienach zugleich auch schon die allgemeine Wurzel der Gleichungen x; ĭ = a; ĭ sowie x; ī̆ = a; ī̆ dar; doch kann man solche nach dem zuletzt Gesagten auch spezifizirter schreiben als: 86) [Formel] 87) [Formel] oder auch rechterhand ĭ und ī̆ vertauscht.
Die Betrachtung eröffnete uns also den Ausblick in mögliche Vervollkommnungen unsrer Lösungsformen der Aufgaben — sozusagen innerlichen Charakters, indem sie freilich äusserlich sich nicht als solche darstellen, nämlich nur auf Kosten der Einfachheit des Ausdrucks der Wurzeln zu erzielen sein werden.
Drittens.
Sei b = i : j = ij̆ = i; j̆ Elementepaar, Einauge, also b̄ = ī + j̄̆ = ī ɟ j̄̆, b̆ = jĭ = j; ĭ, b̄̆ = j̄ + ī̆ = j̄ ɟ ī̆.
So wird: a; b = a; i · j̆ und c = (a; i ɟ j̄ ɟ ī̆)(j̆ ɟ j̄ ɟ ī̆).
Wegen j̄; 1 ⋹ j̄ ist aber 1 ⋹ j̆ ɟ j̄, mithin der zweite Faktor von c gleich 1 ɟ ī̆ = 1. Bleibt: c = a; i ɟ 0 ɟ j ɟ 0 ɟ ī̆ = a; i + ī̆, c̄ = ā; i · ĭ — cf. 2) des § 25, da 0 ɟ j = 0.
Nach 29) des § 25 aber diehn sich diese Ergebnisse noch zusammen in: c = a + ī̆, c̄ = āĭ.
Damit wird: (ū + c̄) ɟ b̄ = (ū + ā)(ū + ĭ) ɟ ī ɟ 0 ɟ j̄̆ = {(ū + ā) ɟ ī} {(ū + ĭ) ɟ ī} + j̄̆ = (ū + ā); i + j̄̆, sintemal (ū + ĭ) ɟ ī = ū ɟ (i + ī) = ū ɟ 1 = 1 nach 32) des § 25 ist.
Wir erhalten also: (d = )(a; b){(ū + c̄) ɟ b̄} = a; i · (ū + ā); i · j̆ = a; i · ū; i · j̆ = aū; i · j̆, sintemal nach 26) des § 25: a; i · ā; i = aā; i = 0; i = 0.
Das Ergebniss d = aū; i · j̆ ist nun mit b̆ (oder auch mit 1) relativ nachzumultipliziren.
Es wird: d; b̆ = aū; i · j̆; j; ĭ = aū; i · ĭ = aūĭ, da j̆; j = 1; jj = 1; j = 1 ist (dagegen d; 1 = aū; i selbst, weil j̆; 1 = 1).
Jenes führt zu der Lösung: x = (a + ī̆)[u + aūĭ] = (a + ī̆)(aĭ + u) = ĭa + au + uī̆ = aĭ + uī̆, womit der Satz gefunden ist: 88) [Formel] . (Dieses, d. h. Benutzung des d; 1, würde zu einer minder einfachen und von der vorstehenden wesentlich verschiedenen Lösungsform führen, bei welcher rechts in x noch das Glied aū; i · ī̆ hinzuträte.)
Weit bequemer, als wie soeben durch Partikularisiren aus der Lösung des allgemeinen Inversionsproblemes, lässt sich das so einfache Ergebniss 88) gewinnen, indem man die Gleichung x; i · j̆ = a; i · j̆ selbständig auflöst — und zwar wie folgt:
Die beiden in der Gleichung enthaltnen Subsumtionen geben äquivalent die Doppelsubsumtion: a; i · j̆ ⋹ x; i ⋹ a; i + j̄̆, aus deren zweiter Teilsubsumtion sofort x als Subjekt, aus deren erster aber nach Ersetzung des x; i durch x ɟ ī auch x als Prädikat isolirt werden kann — beides nach dem ersten Inversionstheoreme.
So entsteht: (a; i) j̆; ĭ ⋹ x ⋹ (a; i + j̄̆) ɟ ī̆, wo das Subjekt sich vereinfacht zu a; i · ĭ · j̆; 1 = aĭ, das Prädikat zu a; i + j̄̆ ɟ 0 ɟ ī̆ = a; i + ī̆ = a + ī̆ und x = aĭ + u(a + ī̆) gefunden ist im Einklang mit 88).
Es stimmt hiemit die Probe 1, indem: x; i = aĭ; i + uī̆; i = a; ii + u; īi = a; i wird, und dass auch die Probe 2 stimme, ist mit der eben gegebenen selbständigen Herleitung implicite gezeigt.
In der Gestalt x; (i : j) = a angesetzt, bedingt unser Problem eine Resultante, die einiger Beachtung wert ist.
Systematisch, nach dem Schema 2) des § 19 gebildet lautet sie: a ⋹ (a ɟ j : i͞); (i : j) = (a ɟ j̄ ɟ ī̆); i; j̆ = (a; j ɟ 0 ɟ ī̆); i; 1; j̆ = = (a; j + ī̆); i · j̆ = (a; j; 1; i + 1; īi)j̆ = a; j · j̆, also a = a; (j : j), oder nach 29) des § 25: a = aj̆, a ⋹ j̆.
Als eine Konklusion kann man diese einfache Resultante freilich auch sofort aus der Schreibung x; i · j̆ = a des Problems gewinnen.
Viertens.
Sei b = i : j͞ = ī + j̄̆ = ī ɟ j̄̆ Negat eines Elementepaares, Einaugennegat oder „Einlücker“, mithin b̄ = ij̆ = ij̆, b̆ = j̄ + ī̆ = j̄ ɟ ī̆, b̄̆ = jĭ = j; ĭ.
So wird: a; b = a; ī + a; 1 · j̄̆ = a; 1 · (a; ī + j̄̆), c = (a; 1 ɟ j)(a; 1 ɟ ĭ){(a; ī + j̄̆) ɟ jĭ} = (a; 1 + 0 ɟ j)(a; 1 + ĭ)(a; ī + j̄̆ ɟ jĭ) = = a; 1 · (a; ī + ĭ) = a; ī + a; 1 · ĭ = a; (ī + ĭ), da j̄̆ ɟ j = 0 ɟ (j + j̄) = 1, j̄̆ ɟ ĭ = = j̄̆ ɟ 0 ɟ ĭ = 0 ɟ ĭ = ĭ, also: c̄ = ā ɟ iī̆, ū + c̄ = (ū + ā ɟ i)(ū + ā ɟ ī̆), (ū + c̄) ɟ b̄ = {(ū + ā ɟ i) ɟ i}{(ū + ā ɟ i) ɟ j̆}{(ū + ā ɟ ī̆) ɟ i}{(ū + ā ɟ ī̆) ɟ j̆} = = (ā ɟ i + ū ɟ i)(ā ɟ i + ū ɟ 0 + j̆){(ū + ā ɟ 0 + ī̆) ɟ i}{(ū + ā ɟ 0 + ī̆) ɟ 0 + j̆} = = {ā ɟ i + (ū ɟ i)(ū ɟ 0 + j̆)}{ā ɟ 0 + (ū + ī̆) ɟ i}{ā ɟ 0 + (ū + ī̆) ɟ 0 + j̆}, wobei der mittlere Faktor wegen des Gliedes ū ɟ (ī + i) = ū ɟ 1 = 1 wegfällt.
Also wird: (ū + c̄) ɟ b̄ = {ā ɟ i + ū ɟ 0 + (ū ɟ i)j̆}(ā ɟ 0 + ū ɟ ī + j̆) = = ā ɟ 0 + (ā ɟ i)(ū; i + j̆) + ū ɟ 0 + (ū ɟ i)j̆, d = (a; b){(ū + c̄) ɟ b̄} = a; ī · {ū ɟ 0 + (ū ɟ i)j̆} + a; 1 · {(ā ɟ i) · ū; i + ū ɟ 0}j̄̆, wovon der erste Term a; ī · (ū ɟ 0), mit j̆ + j̄̆ multiplizirt, zum einen Teile im nächsten, zum andern im letzten Terme eingeht, mithin bleibt: d = a; ī · (ū ɟ i)j̆ + a; 1 · (ā ɟ i + ū ɟ 0) · ū; i · j̄̆, indem das ū; i = ū ɟ ī dem ihm eingeordneten ū ɟ 0 als Faktor zugesetzt werden darf.
Nunmehr ist — wollen wir alle uns zugänglichen Lösungsformen finden — sowol d; b̆ als d; 1 zu bilden.
Letzteres gestaltet sich einfacher: d; 1 = a; ī · (ū ɟ i) + a; 1 · (ā ɟ i + ū ɟ 0) · ū; i, sintemal diese Faktoren — als durchweg „Systeme“ — vortreten, hernach j̆; 1 sowie j̄̆; 1 = 1 ist.
Bei ersterem erhalten wir: d; b̆ = d; j̄ + d; ī̆ = α · j̆; j̄ + β · j̄̆; j̄ + d; 1 · ī̆, wenn α das erste, β das zweite der beiden Glieder des d; 1 für den Augenblick genannt wird.
Nun ist aber j̆; j̄ = 1; jj̄ = 0 und j̄̆; j̄ = 1; j̄j̄ = 1, sonach entsteht: d; b̆ = β + (α + β)ī̆ = αī̆ + β = a; ī · (ū ɟ i)ī̆ + a; 1 · (ā ɟ i + ū ɟ 0) · ū; i.
Da nunmehr [Formel] zu setzen ist, so erhalten wir als erste Lösungsform: x = (a; ī + a; 1 · ĭ){u + a; ī · (ū ɟ i)ī̆ + a; 1 · (ā ɟ i + ū ɟ 0) · ū; i}, woraus die zweite durch Unterdrückung des Faktors ī̆ hervorgeht.
Man kann hier sogleich den Faktor a; 1 ganz und gar vorziehen (der ja auch bei a; ī anbringbar ist).
Multiplizirt man im übrigen mit a; ī + ĭ oder besser a; ī + (ā ɟ i)ĭ in die folgende Klammer, des Inhaltes: u + a; ī · (ū ɟ i)ī̆ + (ā ɟ i) · ū; i + a; ī · (ū ɟ 0), hinein, und berücksichtigt, dass nach 29) des § 25: ū; i · ĭ = ūĭ ist, so erhält man nach einer Zusammenziehung von u + ū, und Wiederausmultipliziren mit a; 1: 89) x = a; 1 · (ā ɟ i)ĭ + a; ī · {u + ū ɟ 0 + (ū ɟ i)ī̆} als erste Lösungsform, welche sich in der zweiten Form noch vereinfacht zu der in dem Satze dargestellten: 90) [Formel] .
Mit letztrer 35) stimmt ganz glatt die Probe 1, gelingt nämlich der Nachweis, dass 91)
x; ī + x; 1 · j̄̆ = a; ī + a; 1 · j̄̆ bei beliebigem u sein wird.
Man braucht nämlich nur immer die Faktoren, welche „Systeme“ sind, wie a; 1, a; ī, ā ɟ i, ū ɟ i, voranzustellen, dann (hinter einem Punkt) zu berücksichtigen, dass ĭ; ī = 0, 1; ī = 1, ĭ; 1 = 1, so wird die linke Seite:
= a; ī · (ū ɟ i + u; ī) + a; 1 · {ā ɟ i + a; ī · (ū ɟ i + u; 1)}j̄̆, und dass nun ū ɟ i + u; 1 = 1 sein müsse, geht daraus hervor, das u; 1 auch u; ī als Glied (neben u; i) umfasst, etc.
Ähnlich stimmt Probe 1 mit der Lösungsform 89).
Beide Lösungsformen sind indessen als wesentlich verschiedene leicht nachzuweisen.
Weniger mühevoll, als durch das Partikularisiren aus dem allgemeinen Schema 64) der Lösung des dritten Inversionsproblems, ist die Lösung unsrer Aufgabe wiederum selbständig zu gewinnen.
Wir geben hiernächst auch eine selbständige Auflösung schon darum, weil aus ihr die Relationen zu lernen sein werden, aufgrund von welchen für unsre Ergebnisse 89), 90) die Probe 2 zu leisten sein wird.
Die aufzulösende Gleichung 91) zerfällt äquivalent in die vier Subsumtionen α), die sich bezüglich zu den danebengesetzten β) vereinfachen: α1) α3)
Aus α1 folgt nämlich pariter nach dem ersten Inversionstheoreme: x⋹ (a; ī + a; 1 · j̄̆) ɟ ĭ = a; ī + a; 1 · (j̄̆ ɟ 0) + 0 ɟ ĭ = a; ī + ĭ und aus α2) zunächst mit identischem Rechnen: x; 1 ⋹ a; ī + a; 1 · j̄̆ + j̆ = a; ī + a; 1 + j̆ = a; 1 + j̆, hernach ebenso: x ⋹ (a; 1 + j̆) ɟ 0 = a; 1 + j̆ ɟ 0 = a; 1 — während in der zweiten Zeile nur a und x die Rollen tauschen.
x; ī ⋹ a; ī + a; 1 · j̄̆, α2)x; 1 · j̄̆ ⋹ a; ī + a; 1 · j̄̆ β1)x⋹a; ī + ĭ, β2)x ⋹ a; 1
a; ī ⋹ x; ī + x; 1 · j̄̆, α4)a; 1 · j̄̆ ⋹ x; ī + x; 1 · j̄̆ β3) a⋹x; ī + ĭ, β4) a ⋹ x; 1.
Die Gleichung 91) ist daher äquivalent dem Produkt der vier Subsumtionen β).
Von diesen ziehn β2) und β4) sich in die Gleichung x; 1 = a; 1 zusammen, und kann denselben auf die allgemeinste Weise genügt werden durch den Ansatz: γ) x = a; 1 · {v + (v̄ ɟ 0)ĭ}.
Die Beifügung des Faktors ĭ ist ein durch die Betrachtungen unter „Zweitens“ als zulässig gerechtfertigter Kunstgriff, durch den sich das weitre sehr vereinfacht.
Soll nämlich dieses x nun auch die Fordrung β1) erfüllen, so braucht nur mehr a; 1 · v ⋹ a; ī + ĭ gemacht zu werden, indem sich das andre Glied in γ) als ohnehin in ĭ enthalten erweist.
Jenes aber leistet der Ansatz: v = w(a; ī + ĭ + ā ɟ 0), womit v̄ = w̄ + (ā ɟ i)ī̆ · a; 1, v̄ ɟ 0 = {w̄ + a; 1 · (ā ɟ i)}(w̄ + ī̆) ɟ 0 = {a; 1 · (ā ɟ i) + w̄ ɟ 0}(w̄ ɟ ī) = = a; 1 · (ā ɟ i) · w̄; i + w̄ ɟ 0 und x = a; 1 · {(a; ī + ĭ)w + (ā ɟ i)w̄ĭ + (w̄ ɟ 0)ĭ} = = a; 1 · (ā ɟ i)ĭ + a; 1 · (w̄ ɟ 0)ĭ + a; ī · w, d. h. weil a; 1 in a; 1 · (ā ɟ i) + a; ī zerlegbar: δ) x = a; 1 · (ā ɟ i)ĭ + a; ī · {w + (w ɟ 0)ĭ}.
Da hiemit x; ī = a; ī · w; ī wird und nur mehr noch die Fordrung β3) aī̆ ⋹ x; ī zu erfüllen bleibt, so ist nun aus aī̆ ⋹ w; ī noch das w zu bestimmen, wozu das zweite Inversionstheorem verhilft.
[Dass die andre Teilforderung von β3), nämlich aī̆ ⋹ a; ī oder a ⋹ a; ī + ĭ identisch erfüllt sein, als Formel gelten muss, wurde bereits S. 421 über 32) des § 25 gebucht.]
Nach 10) des § 18 oder auch 8) des § 18 muss man haben:
[Formel] und damit ergibt sich aus δ) im „unteren“ Falle (wo ī̆ durch 1 ersetzt ist) nach geringer Reduktion die Lösung 90), im oberen Falle jedoch eine neue Lösungsform, die sich von 89) durch den Wegfall des Gliedes ū ɟ 0 unterscheidet: 92) x = a; 1 · (ā ɟ i)ĭ + a; ī · {u + (ū ɟ i)ī̆}.
Behufs Probe 2 für alle drei Lösungsformen 89, 90, 92) ist nun zu zeigen, dass unter der Voraussetzung 91) sein muss: 93) [Formel] , wobei jeder unterwellte Term auch wegfallen dürfe.
Dabei dürfen wir jedoch die unter β) bereits aus 91) gezognen Konklusionen: ε) a; 1 = x; 1 und a(x̄ ɟ i)ī̆ + x(ā ɟ i)ī̆ = 0 benutzen.
Nach erstrer ist zunächst a; ī · (x̄ ɟ 0) ⋹ a; 1 · (x̄ ɟ 0) = 0 und fällt das letzte unterwellte Glied heraus.
Ersetzt man ferner in 93) das a; 1 durch x; 1 = x + x; 1 und fügt zu dem aus x entspringenden Gliede den letzten Summanden sub ε) hinzu, so entsteht (ā ɟ i)x, welches sich mit dem folgenden Terme a; ī · x von 93) zu x selbst zusammenzieht, sodass nur noch zu zeigen bleibt, dass [Formel] sei, was das Verschwinden der beiden letzten Glieder bedingt.
Nun folgt aus β1) a fortiori: x; ī ⋹ a; ī; ī + ĭ; ī = a; ī und ebenso aus β3): a; ī ⋹ x; ī, d. h 91) bedingt auch dass ζ)
x; ī = a; ī, x̄ ɟ i = ā ɟ i sei — eine Bemerkung aufgrund von welcher die selbständige Herleitung unsrer Lösung auch hätte unter Benutzung von 80) variirt und vielleicht noch vereinfacht werden können (was wir zugunsten des systematischern Vorgehens unterliessen).
Darnach ist das Verschwinden des letzten Gliedes von x mit und ohne den unterwellten Faktor ersichtlich.
Das vorletzte Glied kann man schreiben: x̄(x; ī + x; i)(ā ɟ i)ĭ = x̄(a; ī + x; i)(ā ɟ i)ĭ = x̄ · x; i · ĭ(ā ɟ i) = x̄xĭ(ā ɟ i), woraus auch dessen Verschwinden ersichtlich, q. e. d.
Aufgabe 19.
Es möge jetzt auch noch die S. 268 aufgetauchte Frage zur Entscheidung gebracht werden, ob die ebenda unter 22) gegebene allgemeine Lösung der Gleichung x; 0' = a; 0' mit derjenigen in der ersten Zeile von 26) auf S. 269 wesentlich zusammenfällt?
Die Frage ist zu bejahen.
Dabei wird man auf Sätze geführt, die von einigem Interesse sind.
Zuvörderst bemerke man, dass sich mittelst Einsetzung von a ɟ 0 = (a ɟ 1')a schon die Lösung 25) S. 269 zu x; 0' = a noch vereinfachen lässt zu: 94) x = (a ɟ 1'){ā + u + (ū ɟ 1'); 1}, wonach sie sich nur mehr aus 7 statt 9 Termen aufbaut und an Durchsichtigkeit wol nichts mehr zu wünschen lässt.
Statt des (letzten) relativen Faktors 1 könnte auch 0' geschrieben werden — vergl. 15) S. 229.
Ebenso kann man den Ausdruck von x in 26) S. 269 dem genannten in 22) l. c. zunächst näher bringen, indem man einsetzt: a; 0' ɟ 0 = (a; 0' ɟ 1') · a; 0', (ā ɟ 1')a = (a; 0' ɟ 1')(ā ɟ 1').
Darnach lässt sich auch in 26) l. c. der Faktor a; 0' ɟ 1' vorziehn, und entsteht: 95) x = (a; 0' ɟ 1'){ā ɟ 1' + u + (ū ɟ 1'); 0'} als ein vereinfachter Ausdruck für die allgemeine Wurzel der Gleichung x; 0' = a; 0', der sich nur mehr aus 9 statt 10 Termen aufbaut.
Zudem ist der Vorteil erreicht, dass nun in den beiden als zusammenfallende nachzuweisenden Ausdrücken von x das a blos noch in der Verbindung a; 0' = c, ā ɟ 1' = c̄ vorkommt.
Sagt man wiederum a für dieses c und b für u, so wird sich in der That schon als eine allgemeingültige Formel beweisen lassen, dass unbedingt: 96) (a ɟ 1')[b + ā{(b̄ + ā; 0') ɟ 1'}; 0'] = (a ɟ 1'){ā + b + (b̄ ɟ 1'); 0'}.
Beweis.
Die beiden Teilsubsumtionen dieser Gleichung L = R zerfallen selbst wieder, weil ihr Prädikat ein Produkt ist, und sind hievon die Teilforderungen L ⋹ a ɟ 1' und R ⋹ a ɟ 1' schon augenscheinlich erfüllt.
Bleibt also nur noch zu zeigen, dass: R⋹b + a{(b̄ + ā; 0') ɟ 1'}; 0' und L ⋹ ā + b + (b̄ ɟ 1'); 0', d. h. b̄R und ab̄L bezüglich ⋹ dem letzten Gliede rechts.
Das letztre rechts vollends auf 0 gebracht läuft auf ab̄(b; 0' ɟ 1')(a ɟ 1') · a{(b̄ + ā; 0') ɟ 1'}; 0' = 0 hinaus, wobei noch der Faktor b̄ sich als irrelevant erweist.
Ersetzt man (a ɟ 1')a durch a ɟ 0, so kann man zunächst den aufgrund von 24) S. 255 und (a ɟ 0)a = a ɟ 0 leicht erweislichen Satz anwenden: 97) (a ɟ 0) · ab; c = (a ɟ 0) · b; c. Darnach bleibt noch zu zeigen, dass (a ɟ 0)(b; 0' ɟ 1') · {(ā; 0' + b̄) ɟ 1'}; 0' = 0.
Auch ohne genannten Satz würde aus letzterem die Behauptung schon a fortiori folgen.
Hierin lässt sich nun ferner der Term ā; 0' unterdrücken, wonach der letzte Faktor als das Negat des vorletzten erscheint und die Behauptung einleuchtet.
Jenes folgt daraus, dass überhaupt sein muss: 98) (a ɟ 0) · {(ā; b + c) ɟ d}; e = (a ɟ 0) · (c ɟ d); e.
Denn multiplizirt man mit (a ɟ 0)i j nämlich Πhai h in die ΣkΠl(Σmāi mbm l + ci l + dl k)ek j hinein, so wird wegen Zusammentreffens jedes āi m mit einem Faktor ai m des Πh die ganze Σm getilgt.
Die Subsumtion für ab̄L ist hienach erfüllt, und bleibt noch die für b̄R nachzuweisen: b̄R = (a ɟ 1')āb̄ + (a ɟ 1')b̄ · (b̄ ɟ 1'); 0' ⋹ a{(b̄ + ā; 0') ɟ 1'}; 0', welche wegen des additiv zusammengesetzten Subjektes in zwei Teile zerfällt.
Der letzte leuchtet auch ohne den Faktor b̄ nach Umstellung der zwei letzten Terme und Ausmultipliziren des a ɟ 1' mit dem Negat der rechten Seite als a · b(a ɟ 1'); 0' ɟ 1' ⋹ b; 0' ɟ 1' daraus ein, dass der relative Vorsummand links bereits ⋹ dem b; 0' rechts erscheint.
Denn unterdrückt man identische Faktoren, so muss man allemal Übergeordnetes erhalten.
Der andre Teil, rechts auf 0 gebracht, fordert ähnlich: āb̄{a · b(a ɟ 1'); 0' ɟ 1'} = 0, worin der Faktor a wie sich zeigt auch weggelassen werden kann, und dies führt b, a für ā, b̄ gesagt zu einem tiefer liegenden Satze: 99) etc., zu dessen Beweis die Koeffizientenevidenz angerufen werden muss, sintemal weder a ⋹ (a ɟ 1'); 0' noch b ⋹ (b; 0' ɟ 1'); 0' = b; 0' für sich gilt.
Sagen wir für die erste Subsumtion S ⋹ P, so ist Si j = ai jbi j ⋹ Pi j zu zeigen, wo Pi j = Σh0'h jΠk(ai k + Σlbi l0'l k + 1'k h).
ab⋹ {(a + b; 0') ɟ 1'}; 0' a(b ɟ 1'); 0' ɟ 1' ⋹ a + b
Um es ganz analytisch zu machen, fügen wir zum allgemeinen Faktor des Πk den Term 0'k j1'k j hinzu, welcher ja = 0 ist, und zerlegen gemäss dem Schema a + bc = (a + b)(a + c), das Πk des ersten Faktors sogleich gemäss 12+) S. 121 evaluirend: so kommt: Pi j = Σh0'h j(ai j + Σlbi l0'l j)Πk(ai k + Σlbi l0'l k + 1'k h + 1'k j).
Multipliziren wir ferner das allgemeine Glied der letzten Σl mit 1'l j + 0'l j, welches ja = 1 ist, und evaluiren die vom ersten Terme herrührende Σl gemäss 12×) S. 121, so tritt der Summand bi j · 0'j k auf, der sich wegen des folgenden 1'k j zu bi j vereinfacht, und lässt sich dieses Glied als ein von k unabhängiges vor das Πk schieben.
Es entsteht: Pi j = Σh0'h j(ai j + Σlbi l0'l j){bi j + Πk(ai k + Σlbi l0'l k0'l j + 1'k h + 1'k j)}.
Durch Ausmultipliziren lassen sich hieraus leicht die Glieder herausheben: ai jbi jΣh0'h j = (ab)i j · 1 = Si j, womit die Einordnung und damit alles Bisherige bewiesen ist.
In 99) dürfte links zum Subjekte natürlich auch noch b; 0' als Glied hinzugefügt werden. —
Noch besser als die — auf S. 272 unten — angegebene Formel für x würde diese: x = (a; b ɟ b̄̆)[(ā ɟ b̄); b̆; b + u + (ū ɟ b̄); b̆] empirisch die Resultate zusammenfassen, welche sich für b = einem der vier Modulwerte auf S. 268 sq. für die allgemeine Wurzel von x; b = a; b ergeben haben.
Bei beliebigem b gelingt es mir jedoch nicht, die Lösungen S. 266 des dritten Inversionsproblems noch ähnlich zu vereinfachen.
Studie 20.
Auch inbezug auf Partikularlösungen des allgemeinen (dritten) Inversionsproblems kann ich zu dem in § 19 erreichten Standpunkt noch Einiges hinzufügen.
Um nachzuweisen, dass die Einsetzung von u = a · a; b; b̆ in die allgemeine Lösung 64) unsres Problems auch x = u liefern muss, mithin dieses u eine partikulare Lösung, Wurzel vorstellt, war die folgende fast monströs erscheinende Gleichung als eine allgemein gültige Formel zu beweisen:
[Formel] . In dieser kommt zunächst nach einer S. 267 erwähnten aus a; b ⋹ a; b dort gefolgerten Formel ā + (ā ɟ b̄); b̆ = ā das unterwellte Glied in Wegfall.
Weil sodann nach 9) des § 19 a(a; b; b̆); b = a; b ist, so haben wir (ā + ā ɟ b̄ ɟ b̄̆) ɟ b̄ = ā ɟ b̄, und damit wird das zweite Glied in der eckigen Klammer gleich (a; b)(ā ɟ b̄); b̆ = 0; b̆ = 0, bleibt also nur zu zeigen, dass (a; b ɟ b̄̆)a · a; b; b̆ = a · a; b; b̆ oder a · a; b; b̆ ⋹ a; b ɟ b̄̆ sei.
Dies aber folgt mit a(a; b; b̆); b ⋹ a; b aus 5) des § 6, q. e. d.
Freilich zeigt sich hier der sonderbare und in unsrer Disziplin erschwerend wirkende Umstand, dass das als Partikularfall des allgemeinen dritten Inversionstheorems auf diesem Wege zu entdecken gewesene Theorem 9) des § 19 dabei unterwegs schon benutzt werden musste, sodass wir seiner selbständigen Entdeckung und Rechtfertigung (wie sie früher gegeben ist) wol nicht entraten könnten!
Im Anschluss hieran sei noch darauf aufmerksam gemacht, dass auch x = a · a; b; 1 eine partikulare Lösung vorstellt, sodass wir als Gegenstück zu dem citirten auch noch dieses Formelgespann haben: 100) [Formel] Man hat nämlich sogleich: a(a; b; 1); b = a; b; 1 · a; b = a; b, q. e. d.
Beide Formelgespanne kann man in den allgemeineren Satz zusammenfassen, dass auch x = a · a; b; (b̆ + w) eine Klasse von Partikularlösungen des Problems x; b = a; b bei beliebigem w vorstellt, etc., eine Klasse von schon ziemlicher Allgemeinheit und doch einfachem Ausdruck der Wurzeln.
Aufgabe 21.
Was endlich die „Determination“ unsres allgemeinen Problems 64) betrifft, so sei auch zu dieser ein Beitrag geleistet:
Die vornehmsten Fragen sind: Wann (d. h. unter welchen Bedingungen für a und b) bleibt das durch die Fordrung x; b = a; b bestimmte x vollkommen beliebig?
Und wann ist x durch diese Fordrung vollkommen bestimmt?
Die erste Frage ist leicht dahin zu beantworten: dass b gleich 0 sein muss, wenn x = u ganz unbestimmt sein soll.
Denn wenn für jedes u sein soll u; b = a; b, so muss — wie die Annahme u = 0 zeigt — a; b = 0 sein, dann also u; b = 0 für jedes u, mithin auch 1; b = 0 oder b = 0, q. e. d.
Für die Bejahung der zweiten Frage erkannten wir zwar b = 1', wo x = a sein muss, als eine hinreichende Bedingung, doch ist dieselbe keineswegs notwendig.
Um die notwendige und hinreichende Bedingung dafür zu finden, dass es nur eine Wurzel der Gleichung x; b = a; b gebe, oder: dass die Lösung 64) inbezug auf u konstant sei, müssen wir etwas weiter ausholen.
Die ausreichende sive zulängliche und notwendige sive unerlässliche Bedingung dafür, dass eine Funktion f(u) eines (beschränkt oder unbeschränkt) variabeln Relativs u inbezug auf dasselbe konstant sei, ist: 101) [Formel] (wobei im erstern in der Klammer erwähnten Falle die Σ und Π nur über den Variabilitätsbereich von u zu erstrecken sind, im zweiten — hiernächst vorliegenden — Falle aber die absolute Erstreckung haben).
Denn ist f(u) = e für alle u von gleichem Werte, so gilt wegen [Formel] und [Formel] gewiss die obige Gleichung.
Umgekehrt, wenn diese gilt, so kann man den übereinstimmenden Wert ihrer beiderseitigen Ausdrücke e nennen (und wird solcher, da u in jenen nur als laufender Zeiger auftritt, unabhängig von u sein).
Wegen f(u) ⋹ Σf(u) und Πf(u) ⋹ f(u) hat man sodann für jedes u auch f(u) ⋹ e und e ⋹ f(u), mithin f(u) = e, wie zu zeigen war. —
Unter Anwendung dieses Schema’s 101) findet man nun durch Vergleichung von 65) mit 66): c = cΣi ‥, oder c ⋹ Σi ‥, d. h. 102)
c⋹Σiĭ · (c; b){c̄ ɟ (b̄ + i)}; 1 als die gesuchte notwendige und hinreichende Bedingung dafür, dass die Wurzel x der Gleichung x; b = a; b durch ebendiese vollkommen bestimmt (= a) sei.
Kraft dieser Forderung wird sogar das als a; b ɟ b̄̆ definirte c gleich a selbst sein müssen, wie — wol ungleich leichter als aus ihr selbst — aus der Bemerkung hervorgeht, dass, weil c und a stets Wurzeln sind, auch diese zusammenfallen müssen.
Es müssen überhaupt die allgemein bekannten Partikularlösungen der Gleichung zusammenfallen, was uns — cf. S. 260 — c = a = a · a; b; b̆ = = c · a; b; b̆ liefert und auf die Doppelsubsumtion hinausläuft: 103) a; b ɟ b̄̆ ⋹ a ⋹ a; b; b̆, deren erster Teil die Kraft einer Gleichung hat.
Beim Überspringen (Ignoriren) des mittleren Terms folgt (a; b ɟ b̄̆)(ā ɟ b̄ ɟ b̄̆) = (a; b)(ā ɟ b̄) ɟ b̄̆ = 0 ɟ b̄̆ ⋹ 0, was konvertirt b̄ ɟ 0 = 0, somit als eine Resultante für b liefert: 104) b; 1 = 1 und lehrt, dass b keine Leerzeilen haben darf.
Auch dieses Ergebniss durch Elimination von a aus 102) direkt zu gewinnen, dürfte seine Schwierigkeiten haben.
In 102) darf nach alledem auch a für c geschrieben werden . Thut man dies, nachdem man sämtliche vier Schreibweisen aus 66) berücksichtigt, und bringt rechts auf 0, so entsteht ebenfalls in vier Formen: 105) [Formel] — worin nämlich der unterwellte Term auch unterdrückbar — als Ausdruck der gesuchten Bedingung.
Dieser kann aber jetzt nicht mehr für sich, sondern erst in Verbindung mit der ersten Subsumtion 103), welche uns c = a verbürgte, „hinreichend“ genannt werden.
Die hinreichende oder volle Bedingung drückte 105) allein noch aus, falls man c für a restituirte und dann für c seinen Wert a; b ɟ b̄̆ einsetzte.
In den Koeffizienten stellt sich die letzte Forderung 105) einfachst dar als: 1050) ah kΠm{(ā ɟ b̄)h m + Σlah l0'k lbl m} = 0.
Aus 105) können manche Folgerungen gezogen werden.
Die Forderung muss nämlich a fortiori bestehen, wenn man hinter dem Πi irgendwelche Glieder unterdrückt, ev. auch Faktoren zufügt.
So muss z. B. gelten: aΠi{(ā ɟ b̄); i + ĭ; b̄̆} = 0, d. h. nach 14) a(ā ɟ b̄ ɟ b̄̆) = 0 oder a ⋹ a; b; b̆ in Bestätigung der zweiten Subsumtion 103).
Ebenso folgt dies aus der letzten Form von 105) sofort, imgleichen wie: a(ā ɟ b̄ ɟ 0) = 0 oder a ⋹ a; b; 1, was sich durch 104) bestätigt.
Etc.
Ferner muss sein aΠi(ī̆ + a; īb ɟ 0) = 0.
Nach 7) des § 6 ist aber a; (īb ɟ 0) ⋹ ⋹ a; īb ɟ 0 und hier das Subjekt gleich a; (ī ɟ 0)(b ɟ 0) = a; ī(b ɟ 0) = a(0 ɟ b̆); ī, folglich a fortiori aΠi{a(0 ɟ b̆); ī + ī̆} = 0, was nach 18) gibt: a · a(0 ɟ b̆); 0' oder 106) a · a; 0'(b ɟ 0) = 0 als eine fernere notwendige Bedingung.
Nun kann man zwar der ersten Subsumtion 103) für sich auf die allgemeinste Weise genügen durch den Ansatz: a = α; b ɟ b̄̆, wie schon in 40) des § 19) gezeigt; der zweiten für sich durch den Ansatz a = α · α; b; b̆.
Beiden Forderungen 103) zugleich, die auch 104) involvirten, lässt sich, wie ich durch eine mühsamere Untersuchung fand, auf allgemeinste Weise in unabhängigen Parametern α, β genügen durch die unschwer zu verifizirenden Ansätze: 107) a = α; (β̄ ɟ 0) + α; β ɟ 0 + (α; β ɟ β̄̆) · 1; β̆, b = β̄ ɟ 0 + β, und so könnte man vielleicht noch fortfahren, durch weitre Bestimmung der Parameter auch fernern Teilforderungen oder Unter-Bedingungen des Problemes — wie 106) — nach und nach Genüge zu leisten.
Allein solange man nicht die Produkte Πi in 105) in geschlossener Form auszuwerten vermag, indem man dieselben äquivalent in Funktionen von a und b transformirt, die sich lediglich vermittelst der 6 Spezies aus diesen Argumenten und vielleicht den Moduln aufbauen, ist wenig Aussicht vorhanden, dass man auf diesem Wege zur völligen Lösung dieser unsrer schwierigen „Determinationsaufgabe“ (zum dritten Inversionsprobleme) gelangen wird.
Es muss deshalb das Problem hier stehn gelassen werden.
Versuchte Auswertung jener Πi ferner dürfte kaum Erfolg versprechen, solange sie nicht bei soviel einfacheren Produkten wie: 108) x = Πia; īb = Πiaī̆; b gelungen ist.
Über dies letztre Problem erster Stufe, mit dem wir wieder zu dem Hauptthema unsres Paragraphen zurückkehren, und das — schon für b = 0' — noch nicht gelöst werden konnte, liesse zwar sich bereits viel Interessantes sagen; doch müssen wir uns bescheiden, und sei dasselbe als nächsteinfaches unter den bislang ungelösten Problemen zu weitern Forschungen empfohlen.
Bei der Wichtigkeit, ja der für den Vollzug von Eliminationen, für das Schliessen überhaupt, ganz fundamentalen Bedeutung, welche indess das Summirungs- resp. Produktirproblem zweiter Stufe am Ende des § 28 gewann, seien zum Schlusse nunmehr diesem noch einige Betrachtungen gewidmet.
Es wird sich in (praktisch unerheblicher) Modifikation des S. 468 Gesagten zeigen, dass unsre Algebra allerdings auch über Methoden zur Lösung dieses Problemes verfügt, welche theoretisch von allgemeiner Anwendbarkeit sind, deren versuchte Anwendung jedoch praktisch zumeist in anscheinend unüberwindliche technische Schwierigkeiten oder rechnerische Komplikationen verwickelt.
Wenn die Erstreckung der Π, Σ die absolute (über den ganzen Denkbereich 12) ist, so kann als selbstverständlich gelten, dass 109) [Formel] und ähnlich für Σ — wonach denn auch die Produktationsvariable durch jedes ihrer verwandten Relative ersetzbar wäre.
Denn nimmt u jeden Wert an, so auch ū, ŭ etc.
Wenn ferner im Ausdrucke von f(u) nach gehöriger Reduktion desselben als namentlich Ausführung aller Negationen an zusammengesetzten Ausdruckteilen (neben irgendwelchen Parameterrelativen sive Konstanten hinsichtlich u) blos u und ŭ vorkommt, nicht aber ū und ū̆ (oder umgekehrt), so ist von vornherein [Formel] bekannt, was auch einfacher schon darstellbar ist durch 110) [Formel] .
Dann haben wir nämlich f(0) als minimalen und in allen übrigen enthaltenen Faktor in unserm Π, wofür der Nachweis durch kombinirte Anwendung von den Sätzen u0 ⋹ uv, u + 0 ⋹ u + v, u; 0 ⋹ u; v, u ɟ 0 ⋹ u ɟ v und von deren konjugirten, mithin wesentlich des Theorems 1) des § 6 mit Rücksicht auf 0 ⋹ v, auch detaillirter noch geliefert werden könnte.
So hat man beispielsweise sogleich [Formel] .
Das dual Entsprechende für die Σ zu statuiren überlassen wir zumeist dem Leser.
Als Problem kann daher nur die Ermittelung solcher Π, Σ ein Interesse bieten, bei denen im allgemeinen Term f(u) neben u oder ŭ auch ū oder ū̆ wesentlich vorkommt.
Aufgaben dieser Art haben wir in 1) und 6) gelöst. Dieselben lassen sich durch nachher zur Kenntniss zu nehmende Methoden nochmals verallgemeinern zu dem Satze 111) [Formel] , worin die Summen nach ϰ und λ sich über irgendwelche Reihen oder Gebiete von Suffixwerten, wie 1, 2, 3, … erstrecken.
Allgemeinern Erörterungen über die Methode wollen wir noch ein paar konkrete Beispiele vorausschicken, die nach Herleitung und Resultat von Interesse.
Aufgabe 22. Beim Anblick von 5) drängt sich als Gegenstück die Frage auf nach dem Werte der nächstfolgenden Produkte Π, hinter die wir aber sogleich die sie beantwortende Wertangabe setzen: 112) [Formel] — wobei das zweite Ergebniss sich auch durch Buchstabenvertauschung mit Rücksicht auf 109) aus dem ersten ableiten lässt.
Behufs Herleitung und Beweises nennen wir x das gesuchte erste Π, und U dessen allgemeinen Faktor, so ist:
[Formel] Ui j = Σhai hbh jui h + Σkci kdk jūk j.
Diesen Ausdruck „entwickeln“ wir nun nach ui j, indem wir letztres (und sein Negat) sozusagen „prominent machen“ oder „in Evidenz bringen“.
Zu dem Ende ist nämlich erforderlich und ausreichend, dass man die Glieder oder Terme, in welchen u oder ū mit diesem bestimmten Suffixe ij behaftet ist, überall wo sie sich finden können, hervor- oder heraustreten lasse.
Dies kann rein rechnerisch gemacht werden, in unserm Falle: indem man das allgemeine Glied der Σh mit (1 =)(1'h j + 0'h j), das der Σk mit (1 =)(1'k i + 0'k i) multiplizirt, dann zerlegt, und auf die ersten Teile das Schema 12×) von S. 121 anwendet.
So kommt in der That: Ui j = ai jbj jui j + ci idi jūi j + Σh0'h jai hbh jui h + Σk0'i kci kdk jūk j, wo nun also in den beiden letzten Summen nur von einander und von ui j verschieden bezeigerte u-Koeffizienten vorkommen.
Diese werden im [Formel] jedenfalls auch mit 0-Werten ui h = 0 (bei h ≠ j), ūk j = 0 (bei k ≠ i) versehen vorkommen, sodass nur die beiden ersten Glieder zum Wert von x etwas beizusteuern vermögen.
Der wirklich vorkommende minimale Wert, der in allen Werten enthalten ist, von einer homogen linearen Funktion: αu + βū, = αβ + αβ̄u + ᾱβū muss aber das Produkt von deren Koeffizienten, also αβ sein, sintemal bei der Annahme u = ᾱβ die beiden letzten Glieder in der That verschwinden.
Demnach enthält das für alle erdenklichen u gebildete Ui j allemal zum mindesten das Glied ai jbj jci idi j und wird auch für gewisse Werte von u nicht mehr als diesen Term umspannen, sodass [Formel] gefunden ist.
Damit haben wir xi j = (ad)i j(1'c; 1)i j(1; b1')i j und x = ad · 1'c; 1; b1', q. e. d.
Die Überlegung ist gewiss unanfechtbar; aber so günstig, dass sie sich dermassen glatt und einfach abwickelt, liegen die Verhältnisse nur selten.
Einen tiefern Einblick in die allgemein Erfolg verheissende Produktirmethode werden wir schon durch die heuristische Herleitung (des ersten) der folgenden Resultate gewinnen.
Aufgabe 23.
Zu entdecken, dass: 113) [Formel] — wonach also, bei Vertauschung von d mit d̆ im einen Ausdrucke, die untereinander stehenden gleich ausfallen würden.
Herleitung.
Indem wir wieder die erste Aufgabe als x = ΠU formuliren, werden wir haben:
[Formel] und Ui j = Σlai lbl jui l + Σkci kek jΠl(ūi l + dl k).
Die Sache liegt hier wiederum einfach insofern, als die u durchweg nur mit dem ersten Index i behaftet vorkommen.
Wir machen nun für irgend ein bestimmtes h hierin ui h prominent.
Wie zu dem Ende die Σl zu behandeln ist, haben wir im vorigen Kontext geschildert (man multiplizire das allgemeine Glied mit 1'l h + 0'l h).
Dual entsprechend wird zum allgemeinen Faktor des Πl blos (0 =)0'l h1'l h zu addiren, derselbe sodann nach dem dualen Gegenstück des Distributionsgesetzes in (ūi l + dl k + 0'l h)(ūi l + dl k + 1'l h) zu zerfällen und von jedem dieser beiden Faktoren das Πl einzeln zu nehmen sein, wo beim ersten das Schema 12+) von S. 121 anwendbar wird.
So kommt: Ui j = ai hbh jui h + Σl0'l hai lbl jui l + Σkci kek j(ūi h + dh k)Πl(1'l h + ūi l + dl k).
Dies hat bereits die entwickelte (lineare) Form: Ui j = αui h + βūi h + γ, die man besser im nicht homogenen Zustande belässt.
Bevor wir die Werte von α, β, γ, die hieraus ersichtlich, ausdrücklich hinschreiben, wollen wir aber eine etwas bequemere Symbolik einführen, die sich für alle derartigen Aufgaben zu empfehlen scheint.
Eine Summe der Form Σl0'l hφ(l) stellt nichts andres vor als wie die Summe aller φ(l) ohne φ(h), und kann dies auch durch die Schreibung [Formel] vollständig ausgedrückt werden.
Analog wird [Formel] die Summe nach l aller φ(l) ohne φ(h) und φ(k) ausdrücken, und so weiter.
Dual entsprechend kann auch [Formel] u. s. w. geschrieben werden, indem die linkseitigen Ausdrücke nichts andres vorstellen als das Produkt aller φ(l) ohne φ(h), resp. ohne φ(h) und φ(k), etc.
Durch diese kleine Modifikation der in unsrer Disziplin legitimen Symbolik wird der Vorteil erzielt, dass, wenn fortgesetzt immer mehr Glieder aus der Summe, Faktoren aus dem Π weggelassen werden sollen, der allgemeine Term der Σ und des Π stetsfort den nämlichen (einen immer gleich einfachen) Ausdruck behält (während in der legitimen Darstellung dieser immerfort an Schwülstigkeit zunehmen müsste); mithin kann auch dieser allgemeine Term, als selbstverständlich der alte bleibend, unerwähnt gelassen, er braucht nicht wiederholt zu werden.
Wenn schliesslich von der Σl alle ihre Glieder, von dem Πl alle seine Faktoren derart ausgeschlossen sive in Wegfall gekommen sind, so wird jene gleich 0 und dieses gleich 1 geworden sein.
Benutzen wir dies, so werden wir haben:
[Formel] wo als allgemeiner Term der Σl nun ai lbl jui l, des Πl aber ūi l + dl k geradeso wie im ersten Ausdrucke unsres Ui j zu denken ist. —
Wie immer nun auch die übrigen ui l (ohne ui h) gegeben sein mögen, so lässt sich ui h so bestimmen, wählen, dass die obige lineare Funktion desselben, Ui j, ihren Minimalwert annimmt.
Dieser muss sein: (α + γ)(β + γ), = γ + αβ und wird hier nach geringfügiger Zusammenziehung:
[Formel] .
Nunmehr machen wir in diesem γ + αβ ein weitres ui h' prominent, wo h' ≠ h gedacht werden muss, weil h darin gar nicht mehr vorkommt.
Es wird:
[Formel] , und wieder ist der Minimalwert dieses Ausdrucks hinsichtlich der Variabeln (sive als Funktion von) ui h':
[Formel] .
Dies konnte auch ohne die Zwischenrechnung augenblicklich hingeschrieben werden aufgrund der Wahrnehmung, dass γ + αβ bezüglich der ui l wieder dieselbe Form zeigt wie Ui j — bis auf das Fehlen eines Terms (also bis auf die Erstreckung) in den Σ und Π nach l, und bis auf den Umstand, dass der dem Πl als Faktor vorangehende Parameter — oder Konstantenausdruck —
ci kek j in Ui j — in γ + αβ ein komplizirterer geworden (so wie er dort zu erblicken ist).
Dieselbe Wahrnehmung trifft nun auch bei γ' + α'β' zu, wobei das Bildungsgesetz bereits einleuchtet.
Denken wir uns diese Schlüsse unbegrenzt fortgesetzt bis alle Glieder der Σl fortgefallen, zugleich damit alle Faktoren des Πl unwirksam, = 1, geworden sind, so wird als xi j der letzte Ausdruck des Minimalwerts, γ(∞) + α(∞)β(∞), gefunden sein: xi j = Σkci kek jΠh(ai hbh j + dh k), = = Σkci kΠh(ai h + dh k)Πh(d̆k h + bh j)ek j = {(a ɟ d)c; (d̆ ɟ b)e}i j, somit x = (a ɟ d)c; (d̆ ɟ b)e, q. e. d.
Wie man sieht läuft das Verfahren auf eine „Grenzwertbestimmung hinaus, charakterisirt sich als eine Art von „Exhaustionsverfahren“: es wurden die Σ und Π nach l sozusagen nach und nach „ausgeschöpft — imgrunde wie wenn beim zugehörigen Problem der Elimination von x die unbegrenzte, eventuell ein Kontinuum bildende Doppelserie von dessen Koeffizienten xh k mittelst fortschreitender Ausmerzung von einem dieser nach dem andern eliminirt würde.
Genau so haben wir in der That vorstehend eines der ui h nach dem andern ausser Betrachtung gesetzt, oder „abgethan“, indem wir immer blos zurückbehielten, was dasselbe nicht umhin kann von Ui j zu dem [Formel] beizusteuern. M. a. W.: wir suchten den Minimalwert vom Minimalwerte des Minimalwertes etc. von Ui j in Hinsicht eines der Argumente ui h (dieser Aussagenfunktion) nach dem andern — unter, kurz gesagt, „Minimalwert“ einer Funktion φ „in Hinsicht eines Argumentes u“ einen solchen Wert verstanden, der für ein gewisses u wirklich von ihr angenommen wird, zugleich aber in allen Werten, deren diese Funktion für irgendwelche u nur fähig ist, enthalten bleibt — und zwar dies fortgesetzt bis einschliesslich zum letzten Argumente ui h sofern es ein „letztes“ gibt, allgemeiner gesprochen also: bis solches in Hinsicht jedes Argumentes ui h geschehen war.
Alsdann war der resultirende Minimalwertausdruck von Ui j von sämtlichen Argumenten ui h, kürzer gesagt: von u, unabhängig geworden und durfte das Zeichen [Formel] vor dieser Konstanten nach dem Tautologiegesetz unterdrückt werden.
Nebenbei gesagt geht für a = 1, b = 1' nach einer kleinen Buchstabenvertauschung unser erstes Resultat 113) auch über in: 50) — jene Formel, die wir vordem auf kunstvollerem verschlungenen Wege, durch Vermittelung unendlich vielfacher Π, nur zu finden vermocht hatten.
Ebenso begreift unser Resultat für d = 0' auch unser Theorem 6) unter sich und erscheint als eines der allgemeinsten von den Π, die sich in geschlossener Form bisher angeben liessen.
„Theoretisch“ ist nun das bei den letzten Aufgaben Erkannte leicht zu verallgemeinern.
Soll mit der „absoluten Erstreckung“ ein [Formel] ermittelt werden, wo U = f(u) eine gegebne Relativfunktion ist, so suche man den allgemeinen Koeffizienten [Formel] .
Man wird zunächst keine Schwierigkeit finden, gemäss den Festsetzungen (10) bis (13) des § 3 den allgemeinen Faktor Uh k des letztern Π explizite als eine „Aussagenfunktion“ darzustellen, welche sich vermittelst der drei Spezies des Aussagenkalkuls nebst eventuell Σ und Πzeichen in bestimmter Weise aufbaut aus den Koeffizienten des Arguments u (und seines Negats ū) sowol als sämtlicher etwaigen Parameter a, b, c, … des f(u).
Diese Aussagenfunktion kann in der Gestalt Uh k = αui j + βūi j + γ „entwickelt“ werden nach dem u-Koeffizienten mit irgend einem bestimmten Suffixe ij.
Und zwar ist diese Entwickelung linear und wenn man will auch homogen; doch ist der homogenen Form (α + γ)ui j + (β + γ)ūi j die noch nicht homogen gemachte aus bald ersichtlichem Grunde vorzuziehn.
Die Polynomkoeffizienten α, β, γ sind zwar nicht unabhängig von u (sie führen nämlich ev. die übrigen u-Koeffizienten), aber doch sind sie unabhängig von ui j.
Um solchermasseen ui j „prominent zu machen“, es „in Evidenz zu bringen“ — wobei vielleicht die Fälle i = oder ≠ j sowie i, j = oder ≠ h, k getrennt zu behandeln sind — braucht man blos zu beachten: sooft ein erster Index l des u oder ū von einem Σl beherrscht ist, so kann man den allgemeinen Term dieser Σ mit 1'i l + 0'i l (= 1) multipliziren — bei einem zweiten Index dagegen thue man es mit 1'l j + 0'l j.
Sind sie dagegen von einem Πl beherrscht, so kann man 0'i l1'i l(= 0), resp. 0'l j1'l j zum allgemeinen Term addiren — beidemal gemäss dem Distributionsgesetze a(b + c) = ab + ac, beziehungsweise a + bc = (a + b)(a + c) zerlegend.
So zerfällt die Σ, das Π in eine Summe, ein Produkt von zwei solchen, und werden auf den einen Teil die Schemata 12) von S. 121 anwendbar, wodurch man zuletzt ui j oder ūi j als expliziten Faktor, Summanden bekommt.
Im andern Teile erscheint durch den Faktor 0'i l resp. 0'l j, bezüglich durch den Addenden 1'i l resp. 1'l j aus der verbleibenden Σl, bezüglich dem Πl, ein zuvor darin effektiv vorhanden gewesner Term fortan unwirksam gemacht, ausgemerzt, herausgeschöpft oder exkludirt.
Nun tritt für ui j = ᾱβ der „Minimalwert“ unsres Uh k wirklich ein, der in nach u allen Werten desselben enthalten sein muss, und zwar ist derselbe [Formel] , worin das Suffix ij, wenigstens, an u und ū nicht mehr auftreten wird.
Ist dann mn irgend ein neues Suffix, so kann man ebenso Vh k = α'um n + β'ūm n + γ' entwickeln, wovon als Faktor von xh k blos auftreten kann der in nach u allen Vh k enthaltene und für ein gewisses um n wirklich vorkommende Minimalwert [Formel] , worin nun weder ij noch mn als Index von u oder ū mehr vorkommen kann und in gewissen Σ, Π sogar zwei Terme exkludirt, ausgeschöpft erscheinen werden.
Und so weiter.
Es kommt nun blos darauf an, das Bildungsgesetz der Minimalwerte fort und fort zu übersehen — so lange fort, bis aus den überhaupt auf Indizes von u oder ū bezüglichen Σ und Π alle Terme exkludirt, ausgeschöpft sein werden.
Dies ist ja theoretisch möglich — praktisch können die Komplikationen rasch unabsehbar werden.
Die völlig ausgeschöpften Σ verschwinden, werden = 0, die Π gleich 1 zu setzen sein.
Das Verfahren lässt analytischem Geschick noch weiten Spielraum:
man kann die u-Koeffizienten z. B. reihenweise (zeilen- oder kolonnenweise) auszumerzen suchen, oder auch vorweg die ui i längs der Hauptdiagonale, oder auch die zu einander konversen paarweise, etc.
Gelingt das, so ist xh k als eine „Aussagenfunktion“ ermittelt, in der kein u-Koeffizient mehr vorkommt, vor der also das [Formel] unterdrückbar ist und die sich lediglich aus Koeffizienten der Parameter a, b, c, … des f(u) aufbaut.
Alsdann verbleibt nur noch die Aufgabe, diese Aussagenfunktion — ich möchte sagen: zu „verdichten“, zu „condensiren“, d. h. sie darzustellen als den Koeffizienten zum Suffix hk eines von h und k unabhängigen, aus a, b, c, … durch die 6 Spezies incl. Σ, Π aufgebauten Relatives, einer „Relativfunktion“ X, und wird damit x = X gefunden sein.
Letzteres gelingt auch praktisch immer, zum wenigsten unter Beihülfe von Summen und Produktformen erster Stufe, die sich blos über den Denkbereich 11 der Elemente erstrecken — wie wir nachher bei einer letzten Aufgabe noch zu zeigen gedenken.
Zumeist jedoch scheitert der Versuch praktisch an der vorhergehenden Auflage — und bleibt darum die Methode gewisslich noch weitrer Ausgestaltung bedürftig.
Aufgabe 25. Gesucht sei 114) [Formel] wobei h nicht als Elementbuchstabe gelten soll — sodass unser Π acht beliebige Relative als Parameter aufweist.
Man findet unschwer durch das Exhaustionsverfahren: 115) xi j = Σkei khk jΠl(bi lΣmai mcl mdm j + fi l + gl k) und kommt es jetzt noch darauf an, den Ausdruck zu „verdichten“, d. h. aufgrund dieser Koeffizientenbeziehung das Relativ x selbst durch die acht Parameter auszudrücken.
Dies gelingt, wenn wir schliesslich die laufenden Zeiger k, l durch j, i ersetzen, in der Gestalt: 116) x = Σje{(b + f) ɟ g}; j · j̆; h · Πi{a; (c̆; i)d + f; i + ĭ; g; j} — ein Resultat, aus welchem sich die meisten unsrer frühern Ergebnisse, z. B. für a = 1, d = 1' unter Buchstabenvertauschung das 113), als Sonderfälle in schätzbarer Kontrole richtig ableiten lassen.
Behufs Herleitung von 116) — woraus ein Stück Methode zu abstrahiren — formen wir um: cl m = c̆m l = (c̆; l)m j — vergl. S. 423 — worauf sich die Σm in {a; (c̆; l)d}i j verwandelt.
Wir zerlegen ferner das Πl in einesteils Πl(bi l + fi l + gl k) = {(b + f) ɟ g}i k was sich noch mit dem Faktor ei k zu [e{(b + f) ɟ g}]i k zusammenziehen wird — was kürzehalber ri k für den Augenblick heissen möge, und andernteils: Πl{a; (c̆; l)d + f; l + l̆; g; k}i j.
Wird nun noch ri khk j äquivalent in (r; k · k̆; h)i j umgeschrieben, so kann man rechts in 115) das Suffix ij gänzlich heraussetzen, und es hernach in Gemässheit der Festsetzung (14) Korollar, S. 33, sintemal die Gleichung 115) unter der Herrschaft des Zeichens Πi j zu denken war, beiderseits weglassen.
So wird aus 115) das Resultat 116) gewonnen sein.
Durch geeignete Benutzung der Formeln 34) bis 36) des § 25 wird sich solche „Verdichtung“, Zusammenziehung, jederzeit verwirklichen lassen.
Es ist also nur das Ausmerzungs-, oder Exhaustionsverfahren, worin noch unbewältigte Schwierigkeiten zutage treten können.
Solche wird der Forscher alsbald gewahren, wenn er z. B. das [Formel] zu ermitteln versucht. —
Wir lassen das Problem hier stehen, und bemerken nur noch, dass dasselbe eine gewisse Analogie mit dem mathematischen Probleme des „Rationalisirens“ einer algebraischen Gleichung, dem Beseitigen sämtlicher in ihr vorkommenden Wurzeln, zeigt.
Lässt sich auch jede einzelne von diesen Wurzeln dadurch beseitigen, dass man sie auf einer Seite der Gleichung isolirt und dann die Gleichung beiderseits mit ihrem Wurzelexponenten potenzirt, so gelingt auf diesem Wege doch nicht die Beseitigung sämtlicher Wurzeln, und sind dazu vielmehr noch feinere Methoden nötig.
Begreiflich ist dies bekanntlich daraus: weil beim Beseitigen (auf genanntem Wege) von einer bestimmten Wurzel die Zahl der übrigen zu beseitigen bleibenden Wurzeln sich mehrt.
Solches ist nun zwar hinsichtlich der Relativkoeffizienten beim Ausschöpfen, Eliminiren eines bestimmten von ihnen nicht der Fall, allein es pflegt sich hier doch wenigstens die Komplikation in der die übrigen Koeffizienten auftreten, jeweils zu erhöhen.
Zwölfte Vorlesung.
Theorie der Abbildung.
Ihre 15 Arten.
Eindeutigkeit bei Zuordnungen und Gleichmächtigkeit von Systemen.
§ 30. Direkt sowie umgekehrt nie undeutige und nie mehrdeutige Zuordnung.
Funktion, Argument und Substitution (Permutation) als Relative.
Im weitesten Sinne des Worts „Abbildung“ kann jedes binäre Relativ a als eine Abbildung hingestellt werden, nämlich als eine eventuell bald „undeutige“, bald „eindeutige“, bald auch „mehrdeutige Zuordnung (— Begriffe, die wir demnächst erst näher zu erläutern haben).
Wenn wir aber das Wort im engeren Sinne gebrauchen wollen, so wird von einem Relativ a, damit es als eine „Abbildung bezeichnet werden dürfe, hinfort zu verlangen sein, dass sei es a selber, sei es auch seine Umkehrung ă, mindestens eine der beiden Anforderungen erfülle: niemals undeutig, und niemals mehrdeutig zu sein.
Zur Motivirung der fraglichen Unterscheidungen bringe man sich folgendes zum Bewusstsein.
Jedes Relativ a genommen von einem Systeme b(= b; 1) liefert wieder ein System, sintemal dann a; b = a; (b; 1) = (a; b); 1 ersichtlich System sein muss.
Auch im weitesten Sinne des Worts „Bild“ gilt sonach:
Das a-Bild eines Systems ist stets ein System.
Da ein Element i = i; 1 ebenfalls System ist, so muss also ebenso auch gelten:
Das a-Bild eines Elementes muss allemal ein System sein: a; i = (a; i); 1.
Es kann sich nur fragen, ob dieses System ein leeres ist, „verschwindet“, oder ob es blos aus einem oder gar aus mehrern Elementen besteht.
Im ersten der drei Fälle „versagt“ die Abbildung a für unser Element i, ist a; i(= 0) nichtsbedeutend, sinnlos und u überhaupt als Abbildung „eventuell undeutig“ zu nennen; im zweiten ist sie „eventuell eindeutig“, nämlich zum mindesten so bei Anwendung auf unser i; im dritten ist sie „eventuell mehrdeutig“:
es kann dann a; i als Name einer Gattung gebraucht werden, der sich jedes Element dieses Systems a; i einordnet — sodass letztres System als „das a-Bild von i“ gegenübersteht (und wohl zu unterscheiden sein wird von) seinen Elementen, deren jedes auch — mit dem unbestimmten Artikel — „ein a-Bild von i“ genannt werden darf.
Bedingung des Verschwindens für das a-Bild eines Elementes i ist: α) (a; i = 0), = (a ⋹ ī̆), denn wir haben (a; i ⋹ 0) = (a ⋹ 0 ɟ ī̆ = ī̆).
Dafür also ist notwendig und hinreichend, dass das Abbildungsprinzip a (als binäres Relativ) die Kolonne ĭ zur Leerkolonne habe.
Damit a; i nicht 0 sei, muss a in dieser Kolonne ĭ mindestens ein Auge haben.
Zerlegt man a = uĭ + vī̆, so kommt: a; i = uĭ; i + vī̆; i = u; ii + v; īi = u; i + v; 0 = u; i d. h. der in den Raum ī̆ hineinfallende Teil (der Matrix) von a ist ohne Einfluss auf den Wert des a; i.
Es gilt m. a. W. (etwa u = v = a genommen) der Satz: β) a; i = aĭ; i.
Jedem Auge hi des Relativs aĭ (das mithin a innerhalb der Kolonne ĭ aufweisen mag) entspricht als zu a; i gehörig, d. i. als Bestandteil dieses Systems, ein apartes Element h, indem: hĭ; i = h; i = h; 1; i = h; 1 · 1; i = h · 1 = h. D. h. es gilt der Satz: γ) h; i = hĭ; i = h.
Also, populär gesprochen: soviel Augen das Relativ aĭ besitzt, soviel Elemente (oder „a-Bilder von i“) wird „das a-Bild von i“, a; i, unter sich begreifen.
In der Folge werden wir ausserordentlich viel zu thun haben mit Subsumtionen von einer der beiden Formen: i⋹a; j und a; j ⋹ i. Darum sei auch folgendes noch aus § 25 in Erinnerung gebracht, resp. neu konstatirt oder besonders hervorgehoben — und zwar weniger zugunsten des gegenwärtigen als vielmehr des nächsten Paragraphen.
Bis auf eine Bemerkung unter v) wird der Studirende von den ferneren Betrachtungen dieses Kontextes erst bei den Verweisungen im § 31 Kenntniss zu nehmen haben und kann sie vorläufig überschlagen.
Die (für die Subsumtionen unsrer ersten Form) fundamentale Äquivalenz: δ) (i ⋹ a; j) = (j ⋹ ă; i) liess sich aufgrund der Sätze 22) S. 418: a ɟ ī = a; i, (ī̆ ɟ a = ĭ; a), die als Gleichungen Geltung haben — durch deren Anwendung abwechselnd mit dem ersten Inversionstheorem und dem Kontrapositionsverfahren — ja auch leicht beweisen mittelst der äquivalenten Umformungen: (i ⋹ a; j) = (i ⋹ a ɟ j̄) = (ā̆; i ⋹ j̄) = (j ⋹ ă ɟ ī) = (j = ă; i).
Für die umgekehrte Subsumtion, die unsrer zweiten Form, erhält man zwar auch die Reihe von Äquivalenzen: (a; j ⋹ i) = (a ɟ j̄ ⋹ i) = (ī ⋹ ā; j) = (ī ⋹ ā ɟ j̄) = (ă; ī ⋹ j̄) = (j ⋹ ā̆ ɟ i) wo die vierte und die letzte Aussage auch unmittelbar gewinnbar aus der ersten.
Allein da gemäss 25) S. 419: a ɟ i ⋹ a; ī, (ĭ ɟ a ⋹ ī̆; a) blos als Subsumtion gilt, so lässt sich dies bei der vorletzten Aussage nicht zu äquivalenter Transformation benutzen, gibt vielmehr nur a fortiori die Konklusion: ă ɟ i ⋹ j̄ oder j ⋹ ā̆; ī was sich eben wegen ā̆ ɟ i ⋹ ā̆; i aus der letzten Aussage ohnehin mitversteht.
Ein Gegenstück zu δ) gilt daher für die umgekehrten Subsumtionen, die unsrer zweiten Form, nicht.
Vielmehr sieht man leicht, dass die Subsumtionen: ε) (a; j ⋹ i) = (aj̆; 1 ⋹ i) = (aj̆ ⋹ i ɟ 0) = (aj̆ ⋹ i) und (ă; i ⋹ j) = (aĭ ⋹ j) differiren müssen, wie denn die Polynome aīj̆ und aĭj̄ der rechts auf 0 gebrachten sich unterscheiden.
Allerdings ist für sie mit dem unterwegs gefundnen Satze: ζ) (a; j ⋹ i) = (ă; ī ⋹ j̄), woneben (a; j̄ ⋹ i) = (ă; ī ⋹ j) noch gestellt werden könnte, eine Möglichkeit der Umstellung oder Isolirung von Termen gewährleistet.
Allein es führt solche Umformung aus dem Kreise der uns vorzugsweise interessirenden obigen Subsumtionsformen heraus.
Zudem ist dieser Satz ζ) nur ein Sonderfall des für Systeme b = b; 1, c = c; 1 bei beliebigem a geltenden Satzes: η) (a; b ⋹ c) = (ă; c̄ ⋹ b̄) oder (a; b̄ ⋹ c) = (ă; c̄ ⋹ b), der sich als eine bemerkenswerte Anwendung des ersten Inversionstheorems erweist, insofern — vergl. S. 451 — (a; b̄ ⋹ c) = (a ⋹ c ɟ b̆ = c ɟ 0 ɟ b̆ = c ɟ 0 + 0 ɟ b̆ = c + b̆) = = (ă ⋹ c̆ + b = b ɟ c̆) = (ă; c̄ ⋹ b).
Innerhalb des Kreises der uns interessirenden Subsumtionsformen ist dagegen für die Subsumtionen der zweiten Form noch folgender Satz von Wichtigkeit: θ) (a; j ⋹ i) = (a; j = 0) + (a; j = i), wonach die Subsumtion die Kraft einer Gleichung haben muss, sobald ihr Subjekt nicht verschwindet, sobald es also ein a-Bild von j gibt.
Dieser Satz ist augenscheinlich nur ein Sonderfall des allgemeineren: ι) (c; 1 ⋹ i) = (c; 1 = 0) + (c; 1 = i), wonach für jedes System c; 1 = c gelten muss: κ) (c ⋹ i) = (c = 0) + (c = i).
Um diese Aussagenäquivalenz, die sich als Subsumtion rückwärtig von selbst versteht, als eine solche auch vorwärtig zu beweisen, erinnern wir daran, dass nach S. 461 für jedes System c gelten muss λ) (i ⋹ c) + (i ⋹ c̄), wo von den beiden Fällen der Alternative wegen i ≠ 0 der eine den andern ausschliesst.
Ist nun, während gemäss κ) c ⋹ i ist, c ≠ 0, so würde die Annahme i ⋹ c̄ mittelst c ⋹ i ⋹ c̄ zu der Konklusion c ⋹ c̄ oder c = 0 führen im Widerspruche mit c ≠ 0, und folglich ist von λ) die zweite Alternative zu verwerfen; es muss die erste gelten, zugleich mit c ⋹ i auch i ⋹ c d. h. c = i sein, q. e. d. —
Wenn wir nun eine Subsumtion der ersten Art, δ), nach 17) und 36) des § 25 sofort zusammenziehen konnten in einen Relativkoeffizienten sowol, als auf Wunsch auch sie verwandeln konnten in ein ausgezeichnetes Relativ, indem wir hatten: μ) (i ⋹ a; j) = ai j = ĭ; a; j, so frägt sich noch: welches ausgezeichnete Relativ und welcher Koeffizient denn mit der umgekehrten Subsumtion äquivalent sein wird?
Die Beantwortung aller derartigen Fragen kann auf die — wesentlich in 5) S. 147 schon vorgekommnen — Schemata gegründet werden: ν)
[Formel] nach denen die ausgezeichneten Relative geradezu die Rolle von Aussagen übernehmen und auf sie ebenfalls das „spezifische Prinzip des Aussagenkalkuls“ (1 ⋹ α) = α ausgedehnt und anwendbar wird:
Man hat sich, um irgend ein ausgezeichnetes Relativ korrekt als eine Aussage zu deuten (d. i. um es in dieser seiner Eigenschaft richtig zu verstehen), dasselbe jeweils als Prädikat hinter das Subjekt 1 gesetzt zu denken — wenn man will auch: es gleich 1 zu setzen.
Dieses „1 ⋹“, welches jede Behauptung (Proposition) beginnt, resp. das „= 1“ welches sie abschliesst, ist es im Allgemeinen ganz unnötig, hinzuschreiben (Peirce 9c p. 199), und wie bei den Aussagen, so auch bei den ja auf denselben Wertbereich 0, 1 angewiesnen ausgezeichneten Relativen mag der Zusatz gespart, unterdrückt werden.
Ein für sich stehendes, ein nur eben einfach hingesetztes „ausgezeichnetes Relativ“ kann jederzeit als eine Aussage angesehen werden, die wahr oder erfüllt sein wird, sofern das Relativ den Wert 1 annimmt, nicht erfüllt ist, sobald dasselbe verschwindet, während es bekanntlich ein tertium non datur.
Die Vorteile solchen Verfahrens, das wir aus dem Theoretischen mehr und mehr in’s Praktische zu übersetzen streben, werden bei der Einkleidung von Bedingungen bald zutage treten. —
Nunmehr haben wir: (a; j ⋹ i) = (a ⋹ i ɟ j̄̆ = i + j̄̆) = (1 ⋹ ā + i + j̄̆) und deshalb gibt: 0 ɟ (ā + i + j̄̆) ɟ 0 = 0 ɟ (ā + i) ɟ j̄ = ĭ ɟ ā ɟ j̄ = ĭ ɟ ā; j die Antwort auf die oben gestellte Frage, die auch aus 1 ⋹ ā ɟ j̄ + i = = ā; j + i mit 0 ɟ (ā; j + i) ɟ 0 = 0 ɟ (ā; j + i), sintemal der Klammerausdruck System ist, noch rascher ableitbar.
Sodass gefunden ist: ξ) (a; j ⋹ i) = ĭ ɟ ā; j = (ĭ ɟ ā); j — letzteres mit Rücksicht auf 27) S. 419.
Als einen Relativkoeffizienten zum Suffix ij der Form bi j mit von i und j unabhängigem b unser Ergebniss, d. i. die linkseitige Subsumtion darzustellen, ist überdies möglich, und zwar in der Gestalt: ο) (a; j ⋹ i) = (1' ɟ ā)i j = ĭ; (1' ɟ ā); j.
Dies ergibt sich zunächst kunstlos so: (a; j ⋹ i) = Πh k(Σlah ljl k ⋹ ih k) = Πh(Σlah l1'j l ⋹ 1'i h) = = Πh(ah j ⋹ 1'i h) = Πh(1'i h + āh j) = (1' ɟ ā)i j.
Man kann es aber auch durch äquivalente Transformation aus ξ) ableiten (sowie umgekehrt), indem: ĭ ɟ ā; j = ĭ; 1' ɟ ā; j = ĭ; (1' ɟ ā); j kraft 27) des § 25.
Wir verfügen darnach über zwei Formen der linkseitigen Aussage ξ), ο), welche uns gestatten, viele Forderungen auch in zweierlei Formen zu statuiren, deren Äquivalenz miteinander zwar auch direkt nachweisbar doch sonst wol nicht leicht zu entdecken wäre.
Dasselbe gilt von der Gleichung: π)
[Formel]
Formuliren wir ferner als einen Relativkoeffizienten, oder auch in Form eines ausgezeichneten Relativs die Aussage: dass das a-Bild eines Elementes j verschwinde.
Hier gilt als ein Zusatz zu α):
ρ)
(a; j = 0) = (ā̆ ɟ 0)j = (0 ɟ ā); j = j̆; (ā̆ ɟ 0),
(a; j ≠ 0) = (ă; 1)j = 1; a; j = j̆; ă; 1.
Denn wie einerseits kunstlos: (a; j = 0) = Πh k(Σlah ljl k = Σlah l1'j l = 0) = Πh(ah j = 0) = = (Σhah j = 0) = {(1; a)i j = 0} = {(ă; 1)j = 0} = (ā̆ ɟ 0)j, so ist andrerseits auch: (a; j ⋹ 0) = (a ⋹ 0 ɟ j̄̆ = j̄̆) = (1 ⋹ ā + j̄̆) = 0 ɟ (ā + j̄̆) ɟ 0 = 0 ɟ ā ɟ j̄ = = 0 ɟ ā; j = (0 ɟ ā); j, desgleichen noch einfacher: (a; j ⋹ 0) = (1 ⋹ ā ɟ j̄ = ā; j) = 0 ɟ ā; j ɟ 0 = 0 ɟ ā; j = (0 ɟ ā); j.
Mit Rücksicht auf ξ) oder ο) und π), ρ) kann jetzt auch der Satz θ) direkt an den ausgezeichneten Relativen verifizirt werden — am besten in der Gestalt:
ĭ; (1' ɟ ā); j = ĭ; (0 ɟ ā); j + ĭ; a(1' ɟ ā); j, sintemal 0 ɟ ā + a(1' ɟ ā) = 1' ɟ ā kolonnenrechnerisch (und anders) leicht erweislich. —
Ist a ein beliebiges Relativ, so sind beachtenswert die folgenden Formen für die Forderung, dass ein Element i in a enthalten sei: σ) (i ⋹ a) = (i ⋹ a ɟ 0) = (a ɟ 0)i = ĭ; (a ɟ 0) = (0 ɟ ă); i = ĭ; a ɟ 0 = 0 ɟ ă; i.
Zum Beweis der ersten Äquivalenz ist blos zu bemerken, dass wie sie rückwärts als Subsumtion aus a ɟ 0 ⋹ a a fortiori folgt, sie auch vorwärts als i = i ɟ 0 ⋹ a ɟ 0 sich ergibt.
Das Übrige versteht sich nach dem Bisherigen von selbst.
Sollte es demnach einmal wünschenswert erscheinen, die im § 31 über Abbildung eines Systems a in ein System b aufgestellten Sätze auf beliebige Relative a, b auszudehnen (was ich übrigens bezweifle), so brauchten blos nachträglich a, b durch a ɟ 0, b ɟ 0 durchweg ersetzt zu werden (nicht aber durch a; 1, b; 1) — siehe dortselbst.
Ist aber a = a ɟ 0 = a; 1 von vornherein System, so erhalten wir für σ einfacher: τ) (i ⋹ a) = ai = ĭ; a = ă; i, wo die rechte Seite schon ein ausgezeichnetes Relativ 1; ĭ; a; 1 sein wird. —
Drücken wir uns ferner aus: dass das a-Bild eines Elementes j in einem gegebnen Systeme b(= b; 1) enthalten sein solle.
Das Ergebniss ist: υ) (a; j ⋹ b) = (ā̆ ɟ b)j = (b̆ ɟ ā); j = j̆; (ā̆ ɟ b).
Beweis. L = Πh k(Σlah ljl h = Σlah l1'j l ⋹ bh k) = Πh(ah j ⋹ bh) = = Πh(āh j + bh j) = {0 ɟ (ā + b)}i j = (b̆ ɟ ā)i j = (ā̆ ɟ b)j i = (ā̆ ɟ b)j, sintemal ā̆ ɟ b System, q. e. d.
Schliesslich verdiente wol auf jede Weise zum Ausdruck gebracht zu werden, dass von den 7 Aussagen: φ1)
[Formel] irgend eine aus der andern folge (sofern sich solches nicht schon von selbst versteht), desgleichen, dass irgend zweie, oder mehr, äquivalent sind.
Wie viele und welche Bedingungen derart können überhaupt aufgestellt werden?
Zur Beantwortung dieser Fragen wollen wir hier wenigstens das wesentliche Material zusammentragen.
Wir haben nach μ, ξ, ο): φ2)
[Formel] .
Diese drei ersten von unsern 7 Forderungen sind die elementaren, aus denen sich die andern durch Multiplikation zusammensetzen.
Nach dem Aussagenschema (α ⋹ β) = ᾱ + β liefert zunächst die Einordnung zwischen je zweien dieser 3 elementaren Forderungen folgende Ausbeute:
[Formel] wobei 1; a aus a + 0'; a entstanden, etc.
Aus diesen 6 Bedingungen muss sich durch multiplikative Kombination schon ein Hauptteil von allen erdenklichen Bedingungen fraglicher Kategorie ergeben.
Da die Kombinationen zahlreich sind, zudem oft in mehrern Formen auftreten, so wollen wir der Druckersparniss zuliebe die Suffixe ij weglassen und ebenso das Ringelchen 0 an den Zahlen, das sie als blosse Chiffren kennzeichnen sollte.
Wir haben dann folgende fünfzehn Kombinationen zu zweien unsrer 6 Elementarbedingungen φ): φ3)
[Formel] . Unterweges kam auch einmal das Schema (1̄ + 2)(2̄ + 3) = 2̄1̄ + 1̄3 + 32 = = 1̄2̄ + 23 zur Anwendung.
Obige 15 Bedingungen wären nun mit den sechsen φ), desgleichen, weil φ4)
[Formel] mit diesen dreien: φ5)
[Formel] sowie letztre unter sich noch weiter zu kombiniren.
Die weitestgehende, alle andern mit umfassende Bedingung wird:
[Formel]
Da hienach schon gewisse drei von den sechs Bedingungen φ), vor- oder rückwärts angesetzt, alle übrigen nach sich ziehen, so wird die Zahl ihrer Kombinationen zu mehrern gar nicht mehr so erheblich werden.
Die sechs letzten Kombinationen φ3) zu zweien sind als eine dritte Bedingung involvirend zugleich auch Kombinationen derselben zu dreien, z. B. (1 ⋹ 2 ⋹ 3) = (1 ⋹ 2)(1 ⋹ 3)(2 ⋹ 3) = (1 + 2 ⋹ 3)(1 ⋹ 2) = (1 ⋹ 2 · 3)(2 ⋹ 3).
Und unschwer überzeugt man sich, dass zu den bisherigen 6 + 15 + 1 Kombinationen φ), φ3), φ6) als neue nur noch die 6 hinzutreten: φ7) [Formel] bei deren Ausrechnung blos in Betracht kam, dass (ā ɟ 1') · a; 1 = (ā ɟ 1')a, etc. — vergl. 15), S. 210.
Die Gesamtzahl dieser Kombinationen (ungerechnet die eine zur nullten Klasse) beträgt hienach 28.
Diese nunmehr noch mit den dreien φ5) und letztre unter sich zu kombiniren überlassen wir dem Leser. —
Formuliren wir auch: dass das a-Bild von i enthalten sei im a-Bild von j, so werden wir bekommen: χ) (a; i ⋹ a; j) = 0 ɟ (ā; i + a; j) = (ā̆ ɟ a)i j = ĭ; (ā̆ ɟ a); j.
Denn L = Πh k(Σlah lil k ⋹ Σlah ljl k) = Πh(Σlah l1'i l ⋹ Σlah l1'j l) = = Πh(ah i ⋹ ah j) = Πh(āh i + ah j) = (ā̆ ɟ a)i j.
Man kann aber auch überlegen: L = (1 ⋹ ā ɟ ī + a; j = ā; i + a; j) = 0 ɟ (ā; i + a; j) nach υ) in Anbetracht dass die Summe in der letzten Klammer System ist und deshalb das ɟ 0 hinter ihr unterdrückt werden konnte.
Auch dies gibt nun in der That nach 10) S. 414: L = ĭ; ā̆ ɟ a; j, was = ĭ; (ā̆ ɟ a); j nach 27) S. 419 ist, q. e. d.
Demnach ist nun auch der Ausdruck für die Gleichheit der a-Bilder von zwei Elementen dieser: ψ) (a; i = a; j) = 0 ɟ (a; i · a; j + ā; i · ā; j) = {(ā̆ ɟ a)(ă ɟ ā)}i j = ĭ; (ā̆ ɟ a)(ă ɟ ā); j, wobei zu beachten war, dass nach 26) S. 419: a; i · ā; i = aā; i = 0 ist, und dass nach dem gleichen Satze das Relativ j̆; (ā̆ ɟ a); i, zu ĭ; (ă ɟ ā); j konvertirt, mit dem obigen χ) vereinigt werden kann zu dem letzten ψ).
Nunmehr muss auch die Bedingung für die Verschiedenheit der a-Bilder zweier Elemente sein: ω) (a; i ≠ a; j) = 1; (a; i · ā; j + ā; i · a; j) = ĭ; (ā̆; a + ă; ā); j — eine Forderung, die jedoch auch schon erfüllt ist, wenn eines derselben ohne das andre verschwindet, d. h. wenn jenes gemeinhin zu reden gar kein a-Bild hat. —
Hiermit haben wir uns auch für die schwierigeren Untersuchungen des nächsten Paragraphen schon eine leidliche Vorbereitung gesichert. —
Nach dem eingangs Gesagten sollen für ein als eine „Abbildung zu qualifizirendes Relativ a vier Anforderungen in Betracht kommen, nämlich einzeln oder in Verbindungen für den ganzen Denkbereich maassgebend sein, die wir als Aussagen kurz wie folgt bezeichnen wollen:
0)
A1 = (Die Abbildung a ist nie undeutig)
A2 = („ „ a „ nie mehrdeutig)
A3 = („ „ ă „ nie undeutig)
A4 = („ „ ă „ nie mehrdeutig).
Mit diesen Redensarten verknüpfen wir folgenden Sinn.
A1 soll besagen:
Der Ausdruck „a-Bild von k“ sei niemals sinnlos, d. h. was für ein Element des Denkbereiches k auch immer vorstellen möge, so soll es stets (mindestens) ein Element h geben, welches davon ein a-Bild ist.
In Zeichen: 1) A1 = ΠkΣh(h ⋹ a; k).
A2 soll besagen, dass der Ausdruck „a-Bild von k“ „niemals mehrdeutig“ sei, d. h. dass, wenn ihm überhaupt ein Element h als Bedeutung zukommt, dies nicht mit noch andern Elementen ebenfalls der Fall sei, dass er also niemals mehrere „Bedeutungen“ im Denkbereiche habe.
So wenigstens populär zu reden.
In Anbetracht freilich, dass der Zahlbegriff — sei es auch nur der der Mehrzahl — hier nicht wesentlich soll vorausgesetzt werden, weil ja dieser Theorie die Mission zufällt, denselben erst wissenschaftlich strenge zu begründen, müssen wir der Forderung A2 eine formell etwas andre Fassung geben, nämlich: Verschiedne Elemente dürfen nicht ein- und demselben Elemente als dessen a-Bilder entsprechen, oder — um auch aus dem Wortlaute jegliche Pluralform zu bannen:
Sooft h ein a-Bild von k und l ungleich h ist, darf l nicht (auch) ein a-Bild von k sein.
In Zeichen: 2) A2 = Πh k l{(h ⋹ a; k)(l ≠ h) ⋹ (l ⋹ a; k)}.
Hienach wären, indem man nur ă für a setzt, auch A3 und A4 nun leicht zu formuliren.
Übrigens lassen sich diese Forderungen A3 und A4 auch analog wie A1, A2 in 1) und 2) charakterisiren und zwar ohne dass man den Begriff des konversen Relativs zuhülfe zu nehmen bräuchte.
A3 nämlich fordert, dass es zu jedem Elemente h des Denkbereiches mindestens ein Element k gebe, von welchem h ein a-Bild ist: 3) A3 = ΠhΣk(h ⋹ a; k).
A4 fordert:
Verschiednen Elementen darf nicht einunddasselbe Element als deren a-Bild (genauer: als ein a-Bild derselben) entsprechen.
Es darf zu jedem Elemente k nie mehr als ein Element h geben, welches von ihm ein a-Bild ist, oder: Sooft h ein a-Bild von k und l ungleich k ist, darf h nicht auch ein a-Bild von l sein: 4) A4 = Πh k l{(h ⋹ a; k)(l ≠ k) ⋹ (h ⋹ a; l)}.
Sintemal nach δ) (h ⋹ a; k) = (k ⋹ ă; h), gleichwie durch Kontraposition: (h ⋹ a; l) = (l ⋹ ă; h) sein muss, so sieht man leicht, dass in der That durch Vertauschung von a mit ă — unter Auswechslung der Zeigernamen h und k — A3 aus A1 und A4 aus A2 hervorgeht, sowie umgekehrt auch dieses in jenes ebendadurch übergeht.
Vor allem müssen nun unsre vier Forderungen 1) bis 4) auf handlichere Formen gebracht werden. Dieselben lassen sich auf sehr verschiedne Weise ansetzen in Gestalt einer einfachen Subsumtion oder Gleichung, sowie auch sich darstellen je als ein ausgezeichnetes Relativ.
Und in der Äquivalenz der verschiednen Formen einer jeden von diesen vier elementaren Abbildungscharakteristiken werden höchst bemerkenswerte Sätze sich ausprägen.
Wir geben zunächst den Überblick ihrer wichtigsten Ausdrucksformen: 5)
[Formel] 7)
[Formel] 6)
[Formel] 8)
[Formel] — wobei natürlich die Subsumtionen mit dem Subjekte 1 oder Prädikate 0 auch als Gleichungen lesbar.
Die den hier angeführten Äquivalenzen dual entsprechenden Sätze finden sich in der vorstehenden Tafel nicht angegeben, und empfehlen wir dem Studirenden, sich dieselben selbst zu Papier zu bringen.
Zunächst mögen diese verschiednen Ausdrucksformen, soweit sie nicht durch Kontraposition oder Konversion auf den ersten Blick schon aus einander hervorgehn, auf einander zurückgeführt werden.
Dies braucht blos bei A1 und A2 zu geschehen.
Hernach wird dann blos erforderlich sein, je eine von diesen Formen 5) aus 1), und 6) aus 2) abzuleiten.
Die Formen 5) von A1 sind nun einander äquivalent aufgrund der folgenden Überlegungen, bei denen man zur Koeffizientenevidenz keine Zuflucht zu nehmen braucht.
Weil 1; a ɟ 0 als ausgezeichnetes Relativ blos der Werte 1 und 0 fähig und (1 ⋹ 1) = 1, (1 ⋹ 0) = 0 ist, so muss sein: 1; a ɟ 0 = (1 ⋹ 1; a ɟ 0).
Letztre Subsumtion kommt aber nach dem ersten Inversionstheoreme auf 1; 1 oder 1 ⋹ 1; a äquivalent hinaus, und da 1; a = (1' + 0'); a = 1'; a + 0'; a = a + 0'; a ist, so lässt sich wiederum diese Subsumtion 1 ⋹ a + 0'; a nach bekanntestem Aussagenschema (α ⋹ β) = (1 ⋹ ᾱ + β) sofort umschreiben in ā ⋹ 0'; a, was kontraponirt auch 1' ɟ ā ⋹ a gibt.
Darnach sind alle Formen 5) aufeinander zurückgeführt bis auf die erste.
Um diese aus 1 ⋹ 1; a zu gewinnen, schreibe man letzteres als: 1 ⋹ (ă + ā̆); a = ă; a + ā̆; a ⋹ ă; a + 0' wegen 3) des § 8 und kann nun 1 ⋹ 0' + ă; a unmittelbar in 1' ⋹ ă; a wie vorhin umsetzen, sodass (1 ⋹ 1; a) ⋹ (1' ⋹ ă; a) erwiesen ist.
Um auch die umgekehrte Aussagensubsumtion zu beweisen, braucht man blos zu schliessen: (1' ⋹ ă; a) ⋹ (1; 1' ⋹ 1; ă; a) = (1 ⋹ 1; a) mit Rücksicht auf 26) des § 27, q. e. d.
Von den Formen 6) für A2 sind die beiden ersten einander schon aufgrund des ersten Inversionstheorems äquivalent; aus der zweiten Form folgt durch Kontraposition die dritte und aus beiden die vierte und fünfte, indem man die linke Seite auf 1 oder die rechte auf 0 bringt — womit denn die Formen der ersten Zeile von 6) aufeinander zurückgeführt erscheinen.
Was die Formen der zweiten Zeile betrifft, so ist wieder das ausgezeichnete Relativ 1; (1' ɟ ā) ɟ 0 = {1 ⋹ 1; (1' ɟ ā) ɟ 0} und dies = {1 ⋹ 1; (1' ɟ ā)} nach dem ersten Inversionstheorem, was kontraponirt nun auch 0 ɟ 0'; a ⋹ 0 gibt — und womit die Formen der zweiten Zeile aufeinander zurückgeführt erscheinen.
Nun ist kolonnenrechnerisch bekannt, vergl. 30) S. 216, dass 0 ɟ 0'; a = = 1; a(0'; a).
Mit 0 ɟ 0'; a ⋹ 0 ist also auch 1; a(0'; a) ⋹ 0 gegeben, was auf a · 0'; a ⋹ (0 ɟ 0 = ) 0 nach dem ersten Inversionstheorem hinausläuft.
Und aus letztrer Subsumtion hinwiederum folgt mit 1; a(0'; a) ⋹ 1; 0 = 0 auch ihrerseits die vorige.
Mit der hiermit dargethanen Aussagenäquivalenz aber: (a · 0'; a = 0) = (0 ɟ 0'; a = 0) ist nun auch von einer Form der ersten und einer Form der zweiten Zeile von 6) gezeigt, dass sie aufeinander zurückkommen, q. e. d.
Anstatt sich zu Anfang auf das erste Inversionstheorem zu berufen, konnte man indess auch besondre Kunstgriffe anwenden, z. B. schliessen:
Aus a; ă ⋹ 1' auf a; ă ɟ ā ⋹ 1' ɟ ā, und da nach 7) des § 6: a; (ă ɟ ā) ⋹ ⋹ a; ă ɟ ā ist, auf a; (ă ɟ ā) ⋹ 1' ɟ ā, sodann, da nach 3) des § 8: 1' ⋹ ă ɟ ā, auf a; 1' ⋹ 1' ɟ ā, womit die Konklusion a ⋹ 1' ɟ ā gewonnen ist.
Umgekehrt folgt aus dieser auch wieder: a; ă ⋹ (1' ɟ ā); ă ⋹ 1' ɟ ā; ă ⋹ 1' ɟ 0' = 1' also a; ă ⋹ 1'.
Nach μ) vereinfacht sich 1) nun unmittelbar zu A1 = ΠkΣhah k = Πk(Σh1i hah k + 0k j) = (1; a ɟ 0)i j = 1; a ɟ 0, sintemal ein ausgezeichnetes Relativ seinem allgemeinen Koeffizienten gleich ist.
Damit erscheinen die Theoreme 5) und 7) nun vollständig bewiesen.
Ebenso erhalten wir nach 2): A2 = Πh k l(ah k0'l h ⋹ āl k) = Πk l(Σh0'l hah k ⋹ āl k) = (0'; a ⋹ ā), womit die dritte Ausdrucksform der ersten Zeile von 6) gewonnen ist und nun auch die Theoreme 6) und 8) vollständig bewiesen erscheinen.
Natürlich konnte man jedoch auch auf irgend eine andre von jenen Ausdrucksformen von den Koeffizienten aus hinsteuern, z. B. vom ersten der vorstehenden Ausdrücke des A2 aus weiter schliessen: A2 = Πh k l(āh k + 1'l h + āl k) = Πh k{āh k + Πl(1'h l + āl k)} = Πh k(ā + 1' ɟ ā)h k = = 0 ɟ (ā + 1' ɟ ā) ɟ 0, was sich aufgrund des kolonnenschematisch bekannten Satzes 30) S. 216:
0 ɟ (ā + 1' ɟ ā) = 1; (1' ɟ ā) vereinfacht zu dem in 6) angegebnen ausgezeichneten Relative 1; (1' ɟ ā) ɟ 0.
Überblicken wir nun die hiemit gerechtfertigten Ergebnisse 5) bis 8), so drängt sich die Wahrnehmung auf, dass die dem Relativ a auferlegte Bedingung bei A1 und A2 wesentlich eine Kolonnenanforderung, bei A3 und A4 aber eine Zeilenanforderung im Sinne unsrer sechsten Vorlesung ist.
Wird, sei es kolonnen- sei es zeilenschematisch, a durch 1αβγ0 dargestellt, so zeigt sich, dass unsre vier Bedingungen folgendes stipuliren:
9)
A1 = (a = k1αβγ-) = (a hat keine Leerkolonne)
A2 = (a = k---γ0) = (a hat keine mehrbesetzte Kolonne)
A3 = (a = z1αβγ-) = (a hat keine Leerzeile)
A4 = (a = z---γ0) = (a hat keine mehrbesetzte Zeile).
Soll in der That (kolonnenschematisch) für a = 1αβγ0 bei A1 sein 1 ⋹ 1; a, so bedingt die Forderung 11111 ⋹ 11110 augenscheinlich, dass die durch die Ziffer 0 markirte Kategorie der Leerkolonnen in a fehle, mithin a von der Form sei: a = 1αβγ-.
Ganz dasselbe bedingt aber auch die Fordrung 1' ɟ ā ⋹ a in der Gestalt: 000γ1 ⋹ 1αβγ0.
Und umgekehrt wird jedes solche a = 1αβγ- den beiden Fordrungen gleichzeitig genügen, weshalb dieselben — nebenbei — auch äquivalent sein mussten.
Ein Relativ a von der Eigenschaft A1 (dass also 1; a = 1) nennt Peirce5 p. 49 — wie mir scheint ziemlich unglücklich — „unlimited as to its correlate“, ein solches von der Eigenschaft A3 (dass a; 1 = 1) aber unlimited as to its relate“, während er ibid. p. 48 unser „System“ (wo a; 1 = a) als „complete as to its correlate“, das Systemkonvers (wo 1; a = a) als „complete as to its relate“ bezeichnet. —
Soll ebenso bei A2 sein: a = 1αβγ0 ⋹ 000γ1 = 1' ɟ ā, so müssen offenbar die Kolonnenkategorieen, welche die Ziffern 1, α und β repräsentiren, in a fehlen, d. h. muss a von der Form sein: a = ---γ0.
Und umgekehrt wird auch jedes solche a die Forderung A2 erfüllen. A2 verlangt mithin dass a nur aus einbesetzten und Leerkolonnen bestehe, m. a. W. dass sämtliche Augen seiner Matrix „Kolonnenreiter“ seien.
Etc. q. e. d.
Doch muss auf einen Gegensatz noch aufmerksam gemacht werden, der zwischen A1, A3 einerseits, und A2, A4 andrerseits, besteht hinsichtlich der Anzahl der Arten, auf welche die Bedingung auf das Subjekt 1 (oder auf das Prädikat 0) gebracht zu werden vermag.
Ich will diesen Gegensatz bei A1 und A2 beleuchten.
Er beruht darauf, dass dort, bei A1, einer, hier, bei A2, aber drei Horizontalstriche in der schematischen Darstellung des a auftreten, und zwar bei A1 auch nur an der Stelle einer Randziffer die ohnehin blos mit 1 oder 0 besetzt sein kann.
Soll eine Subsumtion 11111 ⋹ xyzuv den Ausfall der drei ersten Ziffern xyz, und nur dieser, bei dem aus a = 1αβγ0 irgendwie abgeleiteten Kolonnenrelative rechterhand bedingen, so müssen u und v gleich 1 sein und kann ferner x als Randziffer nur den Wert 0 vorstellen, dagegen könnte in 11111 ⋹ 0yz11 unbeschadet der beabsichtigten Wirkung die zweite und dritte Ziffernstelle noch in folgender Weise wesentlich verschieden besetzt sein: yz = 00, 0β, 0β̄, α0, αβ, αβ̄, ᾱ0, ᾱβ, ᾱβ̄, und immer wird der Effekt derselbe sein: dass in a, damit die Subsumtion bestehen könne, die drei ersten Ziffernkategorien fehlen müssen.
Die neun durch Einsetzung dieser yz in das rechtseitige Schema zu gewinnenden Relative können leicht nach den Methoden des § 16 durch a ausgedrückt werden, und liefern, als Prädikat zu 1 gesetzt, ebensoviele „wesentlich verschiedene“ Ausdrucksformen von A2.
Für das erste Relativ haben wir 00011 = 1; (1' ɟ ā) und erhalten damit erneut den Beweis einer Formel von 6).
Eine andre würde aus dem letzten der neun Relative mit 0ᾱβ̄11 = ā + 1' ɟ ā sich unmittelbar ergeben.
Etc.
Die übrigen Formen haben wir in 6) nicht mit aufgenommen.
Also: abgesehn von dem als Prädikat zum Subjekte 1 verwendbaren ausgezeichneten Relative (welches ja nicht rein blos durch Parallelreihenoperationen aus a hervorgeht), lässt sich A1 nur auf eine, A2 dagegen auf neun Arten in die Form einer Subsumtion mit dem Subjekte 1 setzen.
Freilich könnte man auch noch schreiben: A1 = (1 ⋹ a + 0'; a) = {ā(1' ɟ ā) ⋹ 0}, welche Ausdrucksformen unter die 5) nicht mit aufgenommen (er)scheinen.
Da jedoch identisch a + 0'; a = 1; a, etc. ist, so sind diese Formen von den aufgeführten 1 ⋹ 1; a, etc. durchaus nicht wesentlich verschieden, fallen vielmehr mit ihnen eigentlich zusammen. —
Durch das Erfülltsein unsrer vier Bedingungen — einzeln oder in irgendwelchen Verbindungen — charakterisirt sich jede Art von „Abbildung“ — im engeren Sinne.
Nun lassen als syntaktische (sive kombinatorische) „Elemente“ die vier Bedingungen sich auf 1 + 4 + 6 + 4 + 1 = 16 Arten zur 0ten, 1ten, 2ten, 3ten, 4ten Klasse ohne Wiederholungen kombiniren.
Dieses, weil Wiederholungen belanglos sein müssten.
Die Kombination zur nullten Klasse, also die Abwesenheit jeglicher Bedingung lässt das Relativ u vollkommen unbestimmt, wonach wir keinen Grund hätten, es als eine „Abbildung“ zu bezeichnen — es sei denn, vielleicht: um das relative Produkt a; b, d. i.
„a von b“, etwas anschaulicher als „das a-Bild von b“ zu lesen.
Es kann daher nur 15 Arten von Abbildung (im engeren Sinne) geben.
Diese 15 Typen teils zu zweien einander, teils nur sich selber konjugirt, gruppiren sich zu 9 Haupttypen wie folgt: 10) [Formel] .
Will man (ebensoviele) einander gegenseitig ausschliessende Kategorien erhalten, so muss man bei jeder Kombination das Nichterfülltsein der nicht in sie eingehenden Bedingungen ausdrücklich verlangen, die Negationen letztrer also noch als Faktoren zufügen.
Andernfalles wird jeder Typus denjenigen ihm vorhergehenden Typen eingeordnet sein, desseen (sämtliche) Indizes in ihm vertreten erscheinen, der letzte Typus also allen ohne Ausnahme.
Die Wirklichkeit von Abbildungen aller fünfzehn disjunkten Kategorieen ist leicht durch Beispiele zu erweisen — allerdings nur bei voraussetzungslosem resp. unbegrenztem Denkbereiche.
Hier können wir nämlich — auf karrirtem Papiere — mit der Besetzung der Zeilen (durch Augen) derjenigen der Kolonnen (eventuell solche auch überspringend) beliebig vorauseilen, oder umgekehrt — wogegen bei endlichem Denkbereiche zu berücksichtigen bleibt, dass die Anzahl der Zeilen die gleiche sein muss, wie die Anzahl der Kolonnen.
Es sei vorgreifend bemerkt, dass bei begrenztem Denkbereiche infolge Zusammenfallens der Haupttypen 50, 70 und 80 mit 90 unsre fünfzehn Typen sich auf neune reduziren, die sich in die sechs Haupttypen 10, 20, 30, 40, 60 und 90 ordnen.
Nun gilt für alle 15 Typen der höchst bemerkenswerte
Satz.
Abbildungen vom selben Typus setzen sich stets wieder zu einer Abbildung von ebendiesem Typus zusammen.
Beweis.
Ist nur für zwei Relative a und b gezeigt, dass, sooft sie zum nämlichen Typus gehören, dies auch bei ihrem relativen Produkte a; b der Fall sein muss, so wird von da der Satz leicht auf beliebig viele Komponenten auszudehnen sein.
Jenes ist nun aber zunächst leicht beweisbar für die beiden ersten Typen.
Für A1 müssen wir haben: 11) (1' ⋹ ă; a)(1' ⋹ b̆; b) ⋹ (1' ⋹ a; b͝; a; b) = (1' ⋹ b̆; ă; a; b).
Denn mit Rücksicht auf die zweite und darnach auf die erste Prämisse ist in der That: 1' ⋹ b̆; 1'; b ⋹ b̆; (ă; a); b = b̆; ă; a; b, q. e. d.
Für A2 ist: 12) (a; ă ⋹ 1')(b; b̆ ⋹ 1') ⋹ (a; b; a; b͝ ⋹ 1') = (a; b; b̆; ă ⋹ 1').
Denn wir haben: a; (b; b̆); ă ⋹ a; 1'; ă = a; ă ⋹ 1', q. e. d.
Es ist eine lehrreiche Übung für Anfänger, auch mit irgend einer andern von den Formen 5), 6) für A1 oder A2 die vorstehenden Beweise zu führen.
Nach dem Konjugationsprinzip ist der Satz nun auch für die Typen A3 und A4 als erwiesen zu erachten; er gilt also für die vier ersten Typen — zunächst einzeln genommen — und mögen wir dies Resultat etwa so darstellen: 13) [Formel] indem wir die für ein Relativ a statuirte Bedingung 5) ausdrucksvoller mit A1a symbolisch bezeichnen, etc.
Nunmehr ist aber auch klar, dass, wenn irgend eine Kombination der vier Bedingungen A von a sowol als von b erfüllt ist, ebendiese auch durch a; b erfüllt sein muss.
Denn mit der Kombination sind natürlich auch deren Komponenten oder syntaktischen Elemente einzeln genommen gleichzeitig durch a und durch b erfüllt, woraus ebenderen Erfülltsein einzeln auch für a; b folgt.
Da dies aber für alle syntaktischen Elemente der Kombination nun gleichzeitig zutrifft, so ist auch diese Kombination von Bedingungen durch a; b erfüllt, q. e. d. Z. B. es muss sein: A1aA2a · A1bA2b ⋹ A1a; bA2a; b, sintemal wir die Faktoren der Prämisse auch in A1aA1b · A2aA2b umstellen und die beiden ersten der obigen Schemata in überschiebender Multiplikation anwenden können.
Etc.
Hiermit sind auch die Sätze D 25 und D 31 von Dedekind’s Schrift bis zu einem gewissen Grade erledigt, nämlich: obzwar unser Satz in einer Richtung mehr noch als die beiden D’schen Sätze bietet, statuirt er diesen gegenüber (wie in § 31 zu sehen) nach einer andern Richtung doch noch zu wenig.
Was die Nomenklatur der Abbildungen unsrer 15 Typen betrifft, so haben bis jetzt erst dreie — auf welche die Überschrift des Paragraphen hinweist — eine besondre Benennung gefunden.
Doch werden sich auch die übrigen mittelst Zusammensetzung aus den durch 0) nahe gelegten Ausdrucksweisen — eventuell unter Mitbenutzung der (drei) vorgenannten — ziemlich kurz mit Worten charakterisiren lassen.
A1 charakterisirte die mindestens eindeutige — auch, wenn man will, die nie versagende (nie versagte, nie undeutige) — Zuordnung,
A2 die höchstens eindeutige (nie mehrdeutige) Zuordnung.
Darnach kann A3 auch als eine umgekehrt mindestens eindeutige (nie versagte) und A4 als umgekehrt höchstens eindeutige Zuordnung bezeichnet werden.
Ein Relativ aber vom Typus A1 A2 heisst „eindeutige Zuordnung (schlechtweg), heisst „Funktion“ (Funktion von-) oder auch „Bild vonim „engsten Sinne“ dieses Wortes.
Jenes motivirt sich augenscheinlich damit, dass, was mindestens eindeutig und höchstens eindeutig zugleich ist, „gerade“ eindeutig, sive eindeutig (schlechtweg) zu nennen sein wird.
Ein Relativ vom Typus A3A4 ist die umgekehrt eindeutige Zuordnung (das Konverse einer Funktion) und heisst dementsprechend „Argument“ (Argument von-), oder „Objekt von-“ in Analogie zur „Vorlage, dem Modell, Vorwurf, Original oder Gegenstand der nach der Natur kopirt resp. abgebildet werden soll in den bildenden, den graphischen und plastischen Künsten.
Ein Relativ vom Typus A1A2A3A4 ist die „auch umgekehrt eindeutige Zuordnung“ und heisst mit einem Worte eine „Substitution“.
Von hause aus war dies heute noch fast allgemein im Gebrauch stehende Wort nicht ganz glücklich gewählt, schon weil es gegenüber dem, was wir unter einer „Einsetzung“ verstehn und mit dem gleichen Fremdwort zu bezeichnen pflegen, einen Doppelsinn schuf — zumal auch in Gestalt des Worts „Permutation“ ein Name bereits zur Verfügung stand, der den Begriff besser deckte.
Neuerdings — vergl. z. B. Heinrich Weber, Lehrbuch der Algebra, Bd. 1, Braunschweig 1895, 653 Seiten — scheint jenes ältere „Substitution“ begonnen zu haben und im Begriff zu stehn durch „Permutation“ verdrängt zu werden.
Obwol auch mir das letztre schon sympathischer ist, werde ich doch gerade da wo es sich um den Anschluss unsrer Theorie an die bekannte Substitutionenlehre handelt, der zur Zeit verbreitetern Benennung noch den Vorzug geben.
Abwägung der Vorzüge und des Unpassenden zwischen beiden betreffend, wäre sachlich zu bemerken:
Allerdings gibt es auch bei der gewöhnlichen „Einsetzung“ immer einen Gesichtspunkt unter dem sie sich als eine math.
Substitution würde ansehn lassen.
Allein dieser Gesichtspunkt (resp. das, was man als die „Elemente“ des Denkbereichs hinstellen müsste) wäre ein von Fall zu Falle wechselnder und verschieden von dem bei der Substitutionentheorie ständig, für ein grösseres Untersuchungsfeld festzuhaltenden.
„Permutation“ — im absoluten Sinne verstanden als eine Knüpfung gegebner Elementbuchstaben in einer bestimmten Anordnung oder Reihenfolge — deckt den math.
Substitutionbegriff auch nicht vollkommen.
Vielmehr verdiente die math.
Substitution eigentlich nur genannt zu werden eine „Permutation in relativem Sinne“; sie ist die vorliegende Anordnung bezogen auf, verglichen oder zusammengehalten mit einer festen, ursprünglichen (einer „standard“-ordre) — wie der Anordnung der Buchstaben nach ihrer alphabetischen Reihenfolge, oder der Indizes nach der Grösse ihrer Zahlwerte.
Auch in diesem Sinne das Wort „Permutation“ zu nehmen, erscheint jedoch wol als das minder Unzuträgliche.
Funktion, Argument und Substitution also sind die drei vorgenannten Abbildungsweisen, welche eine Belegung mit (ebendiesen) Namen schon längst in der Mathematik gefunden haben.
Und es muss gelten:
Das Konverse einer Funktion ist ein Argument, sowie umgekehrt.
Ferner: jede Substitution ist Funktion und Argument zugleich, sowie umgekehrt auch ein Relativ, das sowol Funktion als Argument ist, eine Substitution wird sein müssen.
Das Konverse aber von einer Substitution ist wiederum eine Substitution.
Mit unserm Satze über 11) ist nun insbesondre auch als erwiesen zu erachten:
Eine Funktion von einer Funktion (von irgend einem Argumente) ist immer wieder eine Funktion (von ebendiesem Argumente).
Dieselbe wird (auch) in der Mathematik die aus den beiden vorigen (in der angegebnen Ordnung sive Reihenfolge) „zusammengesetzte“ Funktion genannt.
Ein Argument „von“ einem Argumente ist Argument.
Eine Substitution „von“ einer Substitution — überhaupt: das (relative) Produkt beliebig vieler Substitutionen — ist stets eine Substitution.
Diese letztern sind ja allbekannte Sätze.
Um aber einleuchtend zu machen, dass, oder inwiefern, die drei Begriffe von Funktion, Argument und Substitution, wie sie hier von uns formulirt und als binäre Relative erklärt worden, wirklich zusammenfallen mit den gleichnamigen jedem Mathematiker so vertrauten Begriffen, werden wir noch einige Erwägungen beizubringen haben.
Es hat der Mathematiker, um seine gewohnten Anschauungsweisen mit den in unsrer Theorie der Relative geforderten in Einklang zu bringen, ja zu versöhnen, anfangs gewisse Schwierigkeiten zu überwinden, die ich nunmehr möglichst zu ebnen trachten werde.
Zunächst: Eine „Substitution in der Mathematik“ schreibt vor, gewisse Elemente zu versetzen, m. a. W. ein jedes von ihnen je durch ein bestimmtes Element zu ersetzen.
Die Elemente, deren Versetzung beim Studium und der Anwendung solcher Substitutionen in Betracht kommen kann, mögen irgendwelche sein und können durch Buchstaben A, B, C, … dargestellt werden.
Aus diesen haben wir uns dann den Denkbereich 11 bestehend zu denken.
Ohne das Geringste von der Allgemeinheit der Substitutionentheorie preiszugeben, können wir jedoch auch annehmen, dass die zu versetzenden Elemente immer Zahlen seien, z. B. reelle Zahlen.
Denn nichts hindert, diese Zahlen blos als Zeiger, Indices (Suffixe) eines Buchstabens aufzufassen (resp. sie als solche ausdrücklich hinzustellen), dem es uns freistehn wird je nach seinem Index jede wünschbare Bedeutung unterzulegen.
Steht etwa die Bedeutung eines c2 schon fest, so kann die von c3, c4, … noch nach Belieben festgesetzt werden, und für jeden neuen Index ist über die Bedeutung des mit ihm behafteten Buchstabens noch nichts präjudizirt, kann über das, was darunter verstanden werden solle, von neuem noch frei verfügt werden.
Lassen wir dann ersparnisshalber den etwa einfürallemal gewählten Buchstaben in unsern Elementenamen weg, so wird hingebracht sein, dass — äusserlich betrachtet — unser Denkbereich 11 aus (den) reellen Zahlen besteht, dass seine „Elemente“ immerfort lauter „Zahlen“ sind und dennoch, was man nur immer wünschen mag, vorstellen, repräsentiren können.
Natürlich muss (oder kann) auch die Zahl Null, wie etwa ein Element N, und die Zahl Eins so, wie ein Element E, diesem Denkbereiche angehören oder einverleibt sein.
Nur müssen beide dann, wenn man sich für sie der Zahlzeichen bedienen will, durch den Tupfen als 0̇ und 1̇ ad hoc von den Moduln 0, 1 unsrer Algebra unterschieden werden.
Dies alles bringt uns nun den Vorteil, dass wir bei den mathematischen Substitutionen als deren Elemente dieselben Dinge vor uns haben werden, auf welche auch der Begriff der mathematischen Funktionen sich gründet: die Substitutionen- und die Funktionenlehre werden sich fortan auf den nämlichen Denkbereich, den Denkbereich der Zahlen beziehen.
Denn auch der Begriff der Funktion wird in der Mathematik blos innerhalb des Zahlenreiches erklärt; wir haben es daselbst immer nur zu thun mit Zahlen in ihrer Abhängigkeit von andern (als veränderlich gedachten) Zahlen — den sogenannten „Argumenten“ der „Funktion“.
Und die Anzahl ihrer Argumente bildet den obersten Einteilungsgrund für die Funktionen (deren man solche von 1, 2, 3, ‥ und mehr Argumenten zu unterscheiden hat).
Die Zahlen können ja irgendwelche, z. B. die „gemeinen komplexen Zahlen sein, und sie brauchen für die Triftigkeit dessen, was wir wesentlich zu sagen haben werden, durchaus nicht etwa als „reelle“ Zahlen vorausgesetzt zu werden.
Blos im Hinblick aber auf die leichtere geometrische Veranschaulichung und um gewisse Weiterungen, Umständlichkeiten und Weitläufigkeiten bei den Erörterungen zu sparen resp. zu umgehen, wollen wir uns hier auf die Besprechung des Falles reeller Funktionen von reellen Argumenten beschränken.
Unser Denkbereich 11 ist dann also das Gebiet der reellen Zahlen und kann ein „linearer“ genannt werden, insofern sich die reellen Zahlen bekanntermassen den Punkten einer Geraden, der „Zahlenlinie“, gegenseitig eindeutig zuordnen lassen, also dass die Punkte dieser Geraden durch jene Zahlen gleichsam „numerirt“ werden und jeder Punkt dieser Linie oder x-Axe als „Träger“ einer ganz bestimmten reellen Zahl erscheint.
Darnach muss denn weiter gesagt werden: dass es nur die mathematischen Funktionen eines Argumentes sind, deren Begriff sich mit dem Begriffe der hier als binäre Relative erklärten Funktionen deckt.
Mathematische Funktionen von zwei oder mehr Argumenten fallen ebenso unter die Algebra der ternären oder Relative höherer Ordnung, werden sich ganz analog als Relative in diesen Disziplinen darstellen lassen, und wer von jenen Begriffen die Identität einmal richtig erfasst hat, wird auch die Koinzidenz von diesen sofort intuitiv erkennen.
Es soll also nur mehr von einer mathematischen „Funktion von einem Argumente“: y = f(x), die Rede sein.
Dieselbe werde auch sogleich in einem rechtwinkligen Koordinatensysteme (mit nach rechts gehender positiver x-Axe und nach unten gehender positiver y-Axe) in bekannter Weise graphisch dargestellt gedacht durch die (durch „ihre“) sogenannte „Funktionskurve“.
Diese Figur lässt sich nach S. 53 als die Matrix eines durch sie völlig bestimmten binären Relativs auffassen, welches a heissen möge.
Das Wort „Funktion“ (auch dann, wenn immer nur eine solche von einem Argumente gemeint ist) wird in der Mathematik doch noch in mehr oder minder weitem Sinne gebraucht.
Dort wird auch von Funktionen gesprochen, die überhaupt nur für ein gewisses Intervall von Werten des Argumentes x als solche Erklärung gefunden haben oder „explizirt“ sind, von Funktionen, die blos innerhalb gewisser Grenzen den eigentlichen Funktionscharakter haben; ja man spricht auch von mehrdeutigen, mehrwertigen Funktionen.
Eine fernre Einschränkung des über die Koinzidenz der beiden Funktionsbegriffe (des Funktionsbegriffes in der Mathematik mit demjenigen in der Logik oder Algebra der Relative) Gesagten scheint nun doch darin zu liegen, dass wir konstatiren müssen:
Es ist nur der mathematische Begriff der „Funktion“ in seiner strengsten Fassung, dieselbe nämlich als eine durchaus eindeutige verstanden, der mit dem Begriff eines Relativs vom Typus A1A2 sich decken wird.
Von unsrer Funktionskurve haben wir also noch vorauszusetzen, dass dieselbe von jeder Ordinatenlinie (d. i. Parallelen zur y-Axe) in einem, und nur in einem Punkte geschnitten wird, also dass zu jedem Argumentwerte, zu jeder Abszisse x, wirklich immer eine Ordinate als Funktionswert „gehört“.
Die mit dieser Voraussetzung gegebne Einschränkung ist nur eine scheinbare zu nennen insofern: als allerdings auch in ihrem weitesten Sinne genommen die mathematische Funktion (eines Argumentes) begrifflich zusammenfallen wird mit einem (binären) Relative.
Nur müssen wir in solchem Falle dem letzteren in unsrer Theorie den Namen und die Bezeichnung als eine „Funktion“ (schlechtweg) versagen — indem wir hier den Begriff mit absoluter Konsequenz in seinem strengen Sinne festhalten.
Geometrisch im Hinblick auf 9) formulirt sollte in unsrer Theorie definirt sein:
als Funktion ein binäres Relativ, das lauter einbesetzte Kolonnen hat,
als Argument ein Relativ mit lauter einbesetzten Zeilen,
als Substitution ein Relativ von beiden Eigenschaften zugleich, das also in jeder Kolonne sowol als wie in jeder Zeile ein (und nur ein) Auge (als „Kreuzreiter“) aufweist.
Peirce sagt 5p. 49:
Ein (totally unlimited) Relativ, in welches (d. i. in dessen Ausdruck als eine effektive Summe von Elementepaaren) jeder Elementbuchstabe nur einmal als Relat und nur einmal als Korrelat eingeht, heisst Substitution. —
Der Zusatz — vergl. S. 565 — ist überflüssig, nämlich wohl als ein prädikativer zulässig, nicht aber als ein determinativer erforderlich.
So wenigstens, wofern man die beiden Partikeln „nur“ des Textes als rhetorische Dreingabe auffasst, resp. sie unterdrückt, oder besser noch, sie durch das Adverbium „gerade ersetzt.
Ich wiederhole: Geometrisch ausgedrückt ist „Funktion“ jedes binäre Relativ zu nennen, welches aus lauter einbesetzten Kolonnen besteht.
Die Matrix einer Funktion (d. i. die Funktionskurve) trägt in jeder Kolonne (d. i. auf jeder Ordinatenlinie) ein und nur ein Auge.
Ein in seiner Kolonne vereinzelt (isolirt) stehendes Auge nannte ich einen Kolonnenreiter“.
Dabei können Leerzeilen sowol als mehrbesetzte Zeilen (auch schon bei endlichem Denkbereiche) vorhanden sein.
Ein Grenzfall ist der, wo alle Kolonnenreiter auf der nämlichen Zeile stehn, diese also eine Vollzeile und alle übrigen Zeilen dann notwendig Leerzeilen sind.
In solchem Falle heisst die Funktion eine Konstante und erkennen wir als solche — zunächst mit der geometrischen Anschauung — das „Element“ des ersten Denkbereiches, wie es als ein binäres Relativ im zweiten sich darstellte, d. i. unsern wohlbekannten Einzeiler wieder.
Jeder Einzeiler (Die Konstante) ist eine Funktion.
Ebenso leuchtet nun ein, dass das oben mittelst der Funktionskurve als seiner Matrix definirte Relativ a in der That „Funktion“ in unserm Sinne sein wird.
Um — die Funktionen betreffend — den Rubikon vollends überschritten zu haben, bleibt nunmehr blos noch ein sehr wichtiger Umstand zu beachten:
Der Mathematiker ist gewohnt, sich die Argumentwerte x als Punkte auf der Abszissenaxe, sive Zahlenlinie vorzustellen, das ist nun wesentlich: als Elemente unsres ersten Denkbereiches 11; und er spricht in diesem Sinne von gewissen Stellen, Intervallen etc. der Abszissenaxe oder Zahlenlinie, um zu sagen, wie sich die Funktion daselbst, darin, verhalte.
Für unsre Zwecke ist es aber zumeist erforderlich, dass man sich aus jenem ersten in unsern zweiten Denkbereich 12 verfüge und mit den Betrachtungen ganz im letzteren bewege.
Eine jede Zahl ist alsdann nicht mehr so, wie noch als Element des ersten Denkbereiches, als ein Punkt auf der x-Axe aufzusuchen, sondern sie ist als ein binäres Relativ im zweiten Denkbereiche, als eine „konstante Funktion“ vermittelst ihrer Matrix oder Funktionskurve dargestellt zu denken, welche bekanntlich die Parallele im Abstand x zur y-Axe, d. i. unser Einzeiler sein wird.
Man suche also den Zahlenort des Argumentwerts x hinfort nicht auf der x- sondern vielmehr auf der y-Axe auf und stelle sich die durch diesen Punkt der letztern bestimmte Horizontale vor.
Ebenso wird der Funktionswert an einer bestimmten Stelle x unmittelbar zu denken sein als die durch den zugehörigen Punkt der Funktionskurve hindurchgehende horizontale Gerade.
Mit Schwierigkeiten ist diese Zumutung, die unsre Theorie an den mathematisch gebildeten Studirenden stellt, keineswegs verknüpft.
Wer schon Übung darin besitzt, die Zahlen des (reellen) Zahlengebietes den Punkten einer Linie eineindeutig zuzuordnen, wird dies ebensoleicht mit den Punkten der y-, wie mit denen der x-Axe zu thun vermögen und wird sich in jedem Punkt der erstern die in ihm normal zur y-Axe stehende Gerade hinzuzudenken, ihn durch letztre auch zu ersetzen imstande sein.
Aber immerhin ist es (noch) etwas Ungewohntes und musste deshalb einmal besonders betont werden.
Was früher ein „Intervall“ der x-Axe genannt wurde, erscheint uns jetzt als ein breiter Horizontalstreifen in der Koordinatenebene, etc.; jede Klasse von Werten der unabhängigen Variabeln x ist ein binäres Relativ, ist ein „System“.
Zugleich erhellt, dass die in der Mathematik bei den Funktionen geläufigen Bezeichnungsweisen, wie y = f(x), nicht ohne weitres in unsre Disziplin herübergenommen werden dürfen, sondern derselben in etwas angepasst werden müssen.
Vor allem, und wesentlich müssen die Namen x und y für die unabhängige und für die abhängige Variable hier ersetzt werden durch allgemeine Elementbuchstaben, wie j und i, aus der S. 7 charakterisirten Kategorie 3), sodass die Buchstaben x und y in unsrer Disziplin reservirt beiben für die allgemeinere Verwendungsweise: um nämlich (wie schon oft zuvor) irgendwelche binäre Relative zu bezeichnen, die keine Elemente zu sein brauchen!
Um nicht Missverständnisse geradezu herauszufordern, müssten wir also unbedingt für das „y = f(x)“ der Mathematik hier schreiben oder geschrieben denken: i = f(j).
Weiter aber ist der Funktionsbuchstabe f als ein binäres Relativ zu denken oder durch ein solches zu vertreten.
Wenn wir für dieses, welches oben geometrisch definirt worden, den Namen a vorschlugen, so ist das ein purer Zufall, hervorgegangen daraus, dass wir eingangs unter diesem Namen a eben die verschiedensten Abbildungsprinzipien zu studiren begannen, darunter auch die den Typus A1A2 ausmachenden Funktionen.
Nichts hindert, für dies Relativ a und in identisch der nämlichen Bedeutung den Funktionsbuchstaben f selbst zu verwenden — gleich- wie auch umgekehrt zuweilen in der Mathematik ein a als Funktionsbuchstabe Verwendung findet, und für das f unsrer Betrachtungen von vornherein hätte a gesagt sein können.
Es muss unbedingt gestattet sein: jeden Funktionsbuchstaben der Mathematik als ein Relativ zu deuten oder von vornherein zu verstehen.
Endlich aber hat an die Stelle der Bezeichnung unsrer Funktion mit f(j) resp. a(j) in der Mathematik hiernächst eine andere zu treten: die das Argument umschliessende Klammer ist nämlich ersetzbar und zu vertreten durch das Semikolon, welches uns eine relative Multiplikation andeutet.
Für y = f(x) resp. i = f(j) resp. i = a(j) werden wir mithin schreiben dürfen und in unsrer Disziplin zu schreiben haben: 14) i = f; j resp. i = a; j.
Selbstverständlich soll hiermit nicht darauf hingewirkt werden: die in der Mathematik so bewährten und in der ganzen kultivirten Welt adoptirten Bezeichnungsweisen durch andere, durch die in 14) vorgeschlagenen und für unsre Disziplin ja unentbehrlichen Bezeichnungsweisen zu verdrängen oder definitiv zu ersetzen — so wenig ich mich vermesse ein Gebirge umblasen zu wollen!
Der Bezeichnungswechsel wird vielmehr immer nur ad hoc und überall da vorzunehmen sein, wo von demselben eine Unterstützung, ein Gewinn an Erkenntniss, sei es für die Mathematik, die Zahlen- und Funktionenlehre, sei es für die Logik (im engern Sinne) zu erwarten steht.
Solcher Gelegenheiten werden sich schon in diesem Bande (so bei der weitern Überarbeitung der Dedekind’schen Schrift) nicht wenige darbieten und sie dürften mit der Zeit nach beiden Seiten immer zahlreichere werden.
Wir haben uns bei den bisherigen Betrachtungen über Funktionen — vornehmlich aus didaktischen Gründen — vielfach oder zumeist von der geometrischen Evidenz leiten lassen.
Es wird darum für manches bereits Behauptete auch der analytische Beweis beizubringen, weitres noch hinzuzufügen sein.
So vor allem dafür, dass, wenn a eine (durch A1A2 charakterisirte) Funktion ist, uns a; j stets ein Element vorstellen muss.
[Dass die Argumentwerte stets als Elemente vorgestellt werden müssen, ist bereits als ausreichend begründet zu erachten.]
Dies ist nun aufgrund der mit A1A2 gegebnen Voraussetzung 1' ɟ ā = a in der That leicht zu erhärten.
Nennen wir nämlich: a; j = y, so ist ȳ = ā ɟ j̄ = ā; j und ȳ; 1 = ȳ, also wird 1' ɟ ȳ; 1 = 1' ɟ ȳ = 1' ɟ ā; j = (1' ɟ ā); j = a; j = y mit Rücksicht auf 27) S. 419 und die Voraussetzung.
Damit ist gezeigt, dass y die Charakteristik 7) S. 408 des Elementes:
1' ɟ ȳ; 1 = y erfüllt, wodurch wir die Berechtigung erlangen, den Namen y für a; j durch einen Elementbuchstaben i zu ersetzen, q. e. d.
War a „Funktion“, so musste, wie die Vergleichung von 5), 6) mit 7), 8) erkennen lässt, ă als „Argument“ bezeichnet werden, denn durch Vertauschung von a mit ă geht das eine Paar von Bedingungen in das andere über — vergl. S. 562.
Kraft δ) wird nun namentlich noch hinzutreten der Satz:
Sub A1A2 (i = a; j) = (j = ă; i) d. h. Ist i Funktion von j, so ist j Argument von i. Und vielleicht andres mehr.
Bei beliebigen Relativen x, y würde ein solcher Satz inbezug auf y = a; x und x = ă; y, wie man sogleich übersieht, keineswegs zu gelten brauchen — woraus die Notwendigkeit unsrer Bemerkung S. 574 erhellt, dass für die Funktions- und Argumentwerte Elementbuchstaben verwendet werden müssen.
Von dem Begriff der Funktion als eines binären Relativs, d. i. vom Funktionsbegriff in seiner Anwendung auf den (ersten) Denkbereich 11 der (Zahlen oder) Elemente, ist natürlich der Funktionsbegriff mit Beziehung auf den (zweiten) Denkbereich 12 der binären Relative, d. i. der Begriff der „Relativfunktion“ — wie er S. 35, 153 von uns erklärt worden — wohl zu unterscheiden!
So, wie es bis jetzt für Funktionen und Argumente geschah, wollen wir auch sofort darangehn inbezug auf die Substitutionen alles für den Mathematiker Befremdliche wonicht Anstössige in unsern Aufstellungen S. 569 sq. zu beheben oder aus dem Wege zu räumen und die Überzeugung von der wesentlichen Einheit des Substitutionsbegriffs in den beiderlei Disziplinen zu festigen.
„Befremdliches“ ist auf den ersten Blick nicht wenig vorhanden: der Mathematiker ist es gewohnt mit Substitutionen zu operiren als mit „Produkten“ von „Cyklen“; hier aber werden wir sie erhalten als „Summen von Elementepaaren, die sich in Cyklen ordnen lassen!
Wie ist das zu reimen?
Eine Summe sind wir gewohnt im Aussagenkalkul als eine Alternative zu deuten, und dennoch wird auch unsre Substitution die gleichzeitige Ersetzung gewisser Elemente durch andre, nämlich der Relate in den Elementepaaren durch ihre Korrelate fordern!
Ein „identisches“ kann das Produkt“ der Cyklen, aus denen eine Substitution „besteht“, auch jedenfalls nicht sein, da solche Cyklen niemals ein Auge gemein haben, somit ihr identisches Produkt allemal verschwinden müsste.
Und andres mehr:
Schon dass die Substitution (auch „Permutation“) von Hause aus einen Prozess, Vorgang, eine Operation bedeutet oder vorschreibt, das Relativ aber sich als fertiges Erzeugniss einer solchen, als ein Gebilde darstellt, könnte das behauptete Zusammenfallen beider paradox erscheinen lassen.
Ich will zu dergleichen Fragen zunächst einmal „Stellung nehmen“, die Beweise in aller Form zum Teil später erst erbringend.
Vor allem ist zu sagen:
Der relative Modul 1' ist — beispielsweise — eine Substitution (D 30).
Denn für a = 1' erweisen sich alle vier Bedingungen A in 5) bis 8) auf den ersten Blick als erfüllt.
Derselbe wird auch die identische Substitution genannt und stellt ein Abbildungsprinzip vor, bei welchem jedes Element ausschliesslich Bild von sich selber (desgleichen auch sein eignes Objekt) sein soll.
Eine solche Abbildung, die somit alles ungeändert lässt, pflegt auch die identische Abbildung genannt zu werden.
Die Substitutionentheorie bezeichnet ihn blos mit 1, welchen Namen wir hier dem absoluten Modul beigelegt haben.
Cf. S. 34.
Das über die Einheit der beiden Substitutionsbegriffe (in Mathematik und in unsrer Algebra) oben Gesagte ist, genauer noch, dahin zu präzisiren:
Der mittelst A1A2A3A4 als Substitution erklärte Begriff deckt sich für jeden „endlichen“ Denkbereich vollkommen mit demjenigen, welcher in der mathematischen „Theorie der Substitutionen“ Geltung besitzt.
Auch bei unbegrenztem Denkbereiche begreift er diese „mathematischen Substitutionen“ als „Substitutionen von endlichem Grade“ vollständig unter sich.
Hier aber erscheint unser Begriff als ein weiterer wie der in der Mathematik geläufige, insofern er neben jenen mathematischen Substitutionen (die immer nur mit diskreten Elementen zu thun haben) auch noch „Substitutionen von unbegrenztem (oder unendlich hohem) Grad umfasst (deren Elemente sogar ein Kontinuum bilden mögen) — auf derengleichen die Mathematik ihre Forschungen noch gar nicht ausgedehnt hat, es sei denn unter ganz entlegenem Titel — als Beiträge zu einer Lehre von den eindeutig umkehrbaren Funktionen eines Argumentes.
Es sind also bislang entlegene Untersuchungsgebiete, die unsre Disziplin hier zu vereinigen und unter einen gemeinsamen Gesichtspunkt zu bringen die Kraft und das Verdienst hat.
Überhaupt wird sich die Theorie der binären Relative erkennen lassen als die gemeinsame Wurzel, der Urquell, aus dem die Zahlen-, Funktionen- und Substitutionenlehre naturgemäss entspringt — unbeschadet dessen, dass wir historisch erst von letztern aus zu diesem ihrem Urquell vorzudringen vermochten.
Zur Aufklärung sei nun weiter gesagt:
Das „Konverse einer Substitution“ — nach S. 569 notwendig wiederum eine solche — wird einerlei sein mit dem, was die Mathematik als „die reziproke Substitution“ hinstellt.
Ihrer in dieser Disziplin üblichen Bezeichnung mit s— 1 steht die unsrige mit s̆ gegenüber.
Unsre „relative Multiplikation“ ist die eigentliche „Multiplikation der Substitutionen“ und es wird ein „Produkt von Substitutionen (schlechthin, im Sinne der Mathematik) hier immer als ein relatives aufzufassen sein.
Die Bequemlichkeit, bei der identischen Substitution 1' den Apostroph und bei jedem (relativen) Produkte von Substitutionen die verbindenden Strichpunkte (Semikolons) wegzulassen, will ich natürlich der mathematischen Substitutionentheorie (solang sie, wie bisher, die andern Operationen unsrer Algebra ausser Betracht lässt) — wie schon S. 34 angedeutet — nicht wehren.
Eine spezielle Disziplin mag sich immerhin ihre eigne Symbolik, ihre Kurzschrift schaffen.
Die durch deren spezielle Bequemlichkeitsbedürfnisse motivirten Gepflogenheiten werden aber dann auch nicht beanspruchen dürfen für eine so viel allgemeinere Disziplin, wie die unsrige, unbedingt verbindlich zu bleiben.
Eine solche Disziplin, die einer weiter tragenden Symbolik und ausdrucksvollerer Bezeichnungen bedarf, muss auch ihrerseits berechtigt bleiben sich diese nach ihren eignen höheren Gesichtspunkten selbständig zu gestalten.
Als ein höchst bemerkenswerter wird noch in unsrer Disziplin der Satz zu konstatiren sein:
Jede Substitution ist zugleich die identische Summe der elementefremden Cyklen, aus denen sie „besteht“, und das relative Produkt der diesen zugehörigen Zirkularsubstitutionen.
Behufs Erläuterung müssen wir etwas weiter ausholen und zunächst den Begriff des „Cyklus“ für unsre Disziplin allgemein festlegen.
Unter einem „Cyklus der ersten Ordnung“ verstehen wir ein Relativ der Form A : A, mithin weiter nichts, als wie: ein individuelles Selbstrelativ.
(Für „Ordnung“ darf man hiernächst auch „Grad“ sagen.)
Ein „Cyklus der zweiten Ordnung“ oder eine „nackte Transposition wurde schon S. 137 als ein Relativ der Form A : B + B : A erklärt.
Unter einem „Cyklus der dritten Ordnung“ versteht man ein Relativ der Form A : B + B : C + C : A.
Und so weiter.
„Cyklus“ überhaupt soll ein Relativ, mithin eine Summe von Elementepaaren genannt werden, in welche nur je einmal als Relat und je einmal als Korrelat die Elemente eines ganz bestimmten Systems so eingehen, dass das Gleiche (ebendies, was der kursive Druck hervorhob) nicht schon mit einem echten Teilsystem des genannten der Fall ist.
Dies muss noch näher erläutert werden.
Die Mathematik hat bislang den Cyklusbegriff überhaupt nur erklärt für ein „endliches“ System von Elementen.
Derselbe wird hier erstmals so gefasst, dass er auch auf unbegrenzte Elementereihen, auf unendliche Systeme, anwendbar wird.
Die Definition fiel etwas schwülstig aus.
Um das zu vermeiden, muss man propädeutisch erst einen allgemeinern Begriff definiren, für den zwar ein vom Cyklusbegriffe unabhängiger Name fehlt, nämlich den Begriff der „Cyklensumme“.
(Diese wird ja, als eine eventuell eingliedrige, auch den Cyklus selbst unter sich begreifen.)
Man kann indess von der Zusammensetzungsweise dieses Namens für den Augenblick absehen und wolle denselben zunächst lediglich als ein Ganzes, als einen Hülfsnamen gelten lassen.
„Cyklensumme“ (Cyklenaggregat oder -komplex) nennen wir eine Summe von Elementepaaren in denen jedes „konstitutive“ — d. i. jedes darin vorkommende — Element gerade einmal als Relat und einmal als Korrelat auftritt.
Darnach wird also jede Substitution eine „Cyklensumme“ sein, und zwar eine solche, welche mit allen Elementen des Denkbereiches gebildet ist.
Aber nur mit letzterm Zusatze gilt auch das Umgekehrte:
Eine aus allen Elementen von 12 gebildete „Cyklensumme“ ist eine Substitution.
Der Begriff der Cyklensumme erweist sich als ein weiterer, umfassenderer, als wie der Substitutionsbegriff.
„Cyklus“ nennen wir dann eine „irreduzible“ „Cyklensumme“, d. h. eine solche, in welcher keine aus nur einem Teil der vorkommenden Elemente sich aufbauende „Cyklensumme“ enthalten ist — eine solche also, die, populär zu reden, nicht in einfachere Cyklensummen zerlegt, zerspalten werden kann, aus der sich solche nicht hervorheben, absondern lassen.
Durch jedes Elementepaar i : j, das einer gegebnen „Cyklensumme angehört, ist nun ein „Cyklus“ bestimmt, und in einem solchen müssen sich die Elementepaare stets, und nur auf eine Weise, so anordnen lassen, dass das Korrelat eines jeden mit dem Relate des (eventuell „im Ringe herum“) darauf folgenden übereinstimmt (so nämlich, dass, falls es ein erstes und ein letztes Elementepaar gibt, das erste wiederum als „auf das letzte folgend“ gilt).
Ist nämlich i : j ein Glied unsrer „Cyklensumme“ — worin also i als das Relat und j als das Korrelat erscheint — so kann und muss es nach deren Begriffe nur noch ein Elementepaar h : i und ein Elementepaar j : k geben, worin i resp. j überhaupt vorkommt, und in allen andern Elementepaaren der Cyklensumme werden die Elemente verschieden von i sowol als von j sein müssen.
Das eine Elementepaar aber wird i als Korrelat, das andre wird j als Relat aufweisen müssen, weil beide Elemente bezüglich in der andern Eigenschaft bereits in i : j vorgekommen.
Jenes h : i nennen wir das dem i : j vorangehende, dieses j : k das demselben folgende Elementepaar.
Wenn in zwei Elementepaaren das Korrelat des einen mit dem Relate des andern übereinstimmt, werden wir sie hier „benachbart“ nennen.
Demnach sind sowol h : i und i : j als i : j und j : k benachbarte Elementepaare.
Solche können noch auf zwei Arten nebeneinandergestellt, zu wirklichen Nachbarn gemacht werden.
Geschieht das so (wie vorstehend), dass das Korrelat des zuerst gelesenen mit dem Relate des zweiten übereinstimmt (nicht aber umgekehrt), so sagen wir ausserdem, dass sie „Anschluss an einander haben“.
Zwei Sonderfälle müssen jetzt erst besprochen werden.
Es konnte von vornherein j = i sein.
Dann ist i : i unser Elementepaar, worin denn i bereits als Relat sowol wie als Korrelat vorkommt.
Es kann daher in den übrigen Elementepaaren i nicht weiter vorkommen.
Und leicht wäre es, auch aufgrund unsrer allgemeinen Cyklusdefinition strenge zu beweisen, dass i : i schon selbst ein Cyklus ist.
Diesen Cyklus „erster Ordnung“ wird dann unsre „Cyklensumme“ enthalten, folglich, wenn sie noch andre Elementepaare mitumfasst, jedenfalls kein Cyklus sein.
Man dürfte das Elementepaar i : i als das auf sich selber folgende und sich selbst vorangehende bezeichnen — eine Erlaubniss von der jedoch kein Gebrauch zu machen ist.
Bei j ≠ i konnte ferner h = j, oder auch k = i sein.
Beidemal kommen wir auf den „Cyklus zweiter Ordnung“ i : j + j : i als auf einen Teil unsrer Cyklensumme.
In diesem kann jedes der beiden Elementepaare als auf das andre folgend hingestellt werden.
Wir sahen, durch ein Elementepaar einer „Cyklensumme“ ist immer das ihm vorangehende und das ihm nachfolgende Elementepaar unzweifelhaft bestimmt — diejenigen beiden Elementepaare, die rückwärts resp. vorwärts Anschluss an dasselbe finden.
Hebt man diese genannten und, eventuell unbegrenzt, fort und fort die Elementepaare hervor, die sich nach beiden Seiten an die bisherigen „anschliessen“, so erhält man als Bestandteil unsrer Cyklensumme eine Summe von Elementepaaren, die ich, ohne wiederum auf die Zusammensetzungsweise des Namens vorerst zu achten, einen „geordneten Cyklus“ nennen will.
Von jedem Elementepaar desselben mögen wir sagen, dass es von i : j (oder irgend einem andern seiner Elementepaare) aus „erreichbar“ sei, m. a. W. dass es an i : j sich wenigstens mittelbar“ anschliesse.
Inbezug auf irgend ein Elementepaar m : n unsrer „Cyklensumme sind nun blos zwei Fälle denkbar: entweder es ist von i : j aus erreichbar und gehört somit unserm „geordneten Cyklus“ selbst an, oder dies ist nicht der Fall.
Im erstern Falle ist leicht zu zeigen, dass die Elemente m, n ausserhalb jenes „geordneten Cyklus“ in unsrer Cyklensumme nicht mehr vorkommen können, im letztern, dass sie innerhalb dieses „geordneten Cyklus überhaupt nicht vorkommen können.
Denn da zu einem jeden Elementepaar des „geordneten Cyklus“ auch das vorangehende und das nachfolgende demselben angehören muss, so würde zugleich mit m : n auch ein p : m und ein n : q demselben angehören und kann daher m sowie n sonst nicht mehr in unsrer „Cyklensumme vorkommen.
Gehört aber das m : n unsrer Cyklensumme dem aus i : j erreichbaren „geordneten Cyklus“ nicht an, so kann innerhalb des letztern auch m nicht etwa als Korrelat und n nicht mehr als Relat auftreten; denn einem Gliede p : m in ihm müsste ein andres m : r mit r ≠ n nachfolgen, wo wir dann m zweimal als Relat haben würden, was dem Begriff der „Cyklensumme widerspricht, etc.
Auf dieselbe Weise beweist sich der Satz:
Ist eine „Cyklensumme echter Teil einer andern „Cyklensumme“, so kann ein in der erstern vorkommendes Element ausserhalb derselben weder als Relat noch als Korrelat in der letztern vorkommen; vielmehr muss diese dann in zwei „elementefremde“ „Cyklensummen“ zerfallen.
Denn nach ihrem Begriffe kommt jedes in der ersten Cyklensumme auftretende Element schon als Relat sowol wie als Korrelat in ihr vor, und kann daher nicht weiter mehr, auch ausserhalb nicht, vorkommen.
Und ein ausserhalb der ersten „Cyklensumme“, des Teiles, im Ganzen vorkommendes Element tritt innerhalb des Teiles überhaupt nicht auf und muss deshalb sowol als Korrelat wie als Relat im Reste vorkommen.
Darum muss nun unser „geordneter Cyklus“ auch wirklich ein „Cyklus sein.
Denn liesse sich aus ihm noch eine „Cyklensumme“ absondern, so müsste auch der Rest wieder eine Cyklensumme sein, und die beiden wären „elementefremde“, sodass kein in der einen (als Relat sowie Korrelat) auftretendes Element auch in der andern vorkäme.
Es fände dann zwischen Elementepaaren der einen und solchen der andern „Cyklensumme“ niemals Anschluss statt, und diese wären von jenen aus nicht „erreichbar“ — entgegen dem Begriffe unsres „geordneten Cyklus“.
Damit ist erkannt:
Ein jedes Elementepaar einer „Cyklensumme“ bestimmt einen („geordnet“ denkbaren) Cyklus als die Summe derjenigen Elementepaare, die von ihm aus erreichbar sind — was gegenseitig — sodass derselbe Cyklus von jedem seiner Elementepaare bestimmt wird; und es kommen die im Cyklus auftretenden (m. a. W. seine „konstitutiven“) Elemente ausserhalb desselben nicht mehr in der „Cyklensumme“ vor.
Und ferner folgt daraus:
Jede „Cyklensumme“ ist (wirklich) eine Summe von lauter — „elementefremden“ — Cyklen, d. h. von solchen, deren niemals zweie ein konstitutives Element gemeinsam haben — die vielmehr aus durchweg verschiednen Elementen aufgebaut erscheinen.
Dasselbe gilt demnach auch von den Substitutionen (im Sinne unsrer Disziplin) — mag auch der Denkbereich sogar ein „Kontinuum“ sein.
Somit wäre denn für’s erste erwiesen, dass unsre Substitution eine identische Summe ist von lauter elementefremden Cyklen. —
Ich bitte nicht zu übersehen: dass die ganze Betrachtung vom Absatz auf S. 576 an blos durch das eingangs derselben erwähnte didaktische Motiv der Aussöhnung mit dem Mathematiker veranlasst ist.
Sie bleibt für die Weiterentwicklung unsrer Theorie nach deren urwüchsigem Plane vorderhand nebensächlich und bildet nur eine Digression.
Die Betrachtungen sind eigentlich verfrüht und dürften systematisch jedenfalls nicht vor der Theorie der einfach unendlichen Systeme und legitimirender Einführung der Ordinalzahlen zu bringen sein, an die wir erst in der zweiten Abteilung des Bandes herantreten — vergleiche die Bemerkung auf S. 179 im Kontext.
Man könnte die gelieferten Beweise in der That noch mannigfach ergänzungsbedürftig nennen und sie vollständiger wünschen, z. B. einen förmlichen Beweis für die (obzwar unmittelbar intuitive) Thatsache verlangen, dass, wenn ein Elementepaar (der Cyklensumme) von einem andern aus „erreichbar“ ist, auch gewiss das Umgekehrte stattfindet, dass ferner die Beziehung der „Erreichbarkeit von -…, resp. aus -…“ eine transitive sein muss, und andres mehr.
Auch müsste alles doch in der Zeichensprache unsrer Algebra einmal rechnerisch formulirt werden.
Etc.
Das Beispiel der nach links und rechts unbegrenzten Reihe der ganzen Zahlen zeigt, dass es auch „unendliche“, sive „unbegrenzte“, oder, wenn man so sagen will: „offene“ Cyklen gibt:
ein solcher ist z. B. die Summe der Elementepaare die aus je zwei benachbarten Zahlen dieser Reihe sich bilden lassen: … + (— 3) : (— 2) + (— 2) : (— 1̇) + (— 1̇) : 0̇ + 0̇ : 1̇ + 1̇ : 2 + 2 : 3 + 3 : 4 + …, Und es erscheint die Ausdehnung des „Cyklus“begriffs auf ein „einfach unendliches“ System von konstitutiven Elementen als zweifellos zulässig und sogleich auch anschaulich.
Anders, wenn die konstitutiven Elemente des Cyklus ein unendliches System „der zweiten Art“ bilden, eines, das nicht einfach unendlich“ ist.
Von einem Cyklus aus einem Kontinuum von Elementen habe ich keine Vorstellung, dergleichen ist noch völlig terra incognita, und ich stehe selbst dem Begriffe noch etwas misstrauisch gegenüber.
Darüber wird erst von späteren Forschungen völlige Aufklärung zu erwarten sein.
Um unsern didaktischen Zweck zu erreichen können wir aber, weil auch die Mathematik dergleichen Cyklen noch gar nicht in den Kreis ihrer Betrachtungen zog, von den darauf bezüglichen Fragen hier noch absehen.
Und bei ihrem selbständigen Vorgehen behufs Legung des Grundes zu einer Substitutionenlehre bräuchte sich unsre Disziplin um die mathematische Substitutionentheorie prinzipiell überhaupt nicht zu kümmern.
Wir fahren hienach in unsrer Digression fort.
Die Mathematik bezeichnet einen Cyklus, wie A : B + B : C + C : D + D : A bekanntlich einfacher mit (A, B, C, D), oder auch (B, C, D, A), (C, D, A, B), (D, A, B, C), sonach: indem sie die konstitutiven Elemente desselben, mit irgend einem von ihnen beginnend, (durch Kommata getrennt) in eine Klammer setzt in derjenigen Reihenfolge, in der sie im „geordneten“ Cyklus (ein jedes zweimal: erst als Korrelat, dann als Relat) gelesen werden.
Nennen wir den Cyklus, als binäres Relativ betrachtet, für den Augenblick a, so braucht der allgemeine Koeffizient ai j nun blos gedeutet zu werden als die Aussage: „das Element i soll (in jedem Ausdrucke, auf den man den Cyklus wirken lassen mag) durchweg ersetzt werden durch das Element j“ — damit sich die Identität unsres Cyklusbegriffs mit demjenigen der Mathematik offenbare.
Denn die Ersetzung wird nur dann wirklich zu vollziehen sein, wenn ai j = 1 ist, d. h. wenn das mit dem Faktor ai j behaftete Elementepaar i : j ein „effektives“ Glied der Summe a = Σi jai j(i : j), mithin unsres Cyklus, ist.
Was unsre „Cyklensumme“, nämlich Summe von „elementefremden Cyklen, betrifft, so gilt ein Gleiches: man erkennt, falls sie a genannt wird, bei der angegebnen Deutung von ai j, ihre Identität mit dem „Produkte“ ebendieser Cyklen in der Mathematik.
Nach der Bemerkung S. 48 zu 3) des § 4 wird nämlich unsre „Cyklensumme“, obzwar als die identische Summe aus den effektiven Elementepaaren erscheinend, nicht etwa alternative, sondern simultane (gleichzeitige) Ausführung der vorgeschriebnen Ersetzungen oder Elementvertauschungen fordern.
Es muss selbst das Π nach ij der sämtlichen von 0 verschiednen ai j gleich 1 sein.
Daraus erhellt denn auch schon die Identität unsres Substitutionsbegriffes mit dem der Mathematik — sofern ja unsre Substitution auch eine „Cyklensumme“, die mathematische ein sogenanntes „Cyklenprodukt“ ist. —
Wir haben jetzt noch zu reden von Zirkularsubstitutionen.
Ein Cyklus (sofern in ihm nicht schon sämtliche Elemente des Denkbereiches vorkommen) ist noch keine „Substitution“.
(Ebensowenig die „Cyklensumme“ beim gleichen Vorbehalt.)
Er kann aber jederzeit leicht zu einer solchen ergänzt werden — die alsdann die ihm zugehörige „Zirkularsubstitution“ zu nennen sein wird, und zwar, indem man ihm additiv hinzufügt die Cyklen erster Ordnung oder individuellen Selbstrelative von all den Elementen des Denkbereichs, deren Versetzung er nicht fordert, die m. a. W. nicht (als „konstitutive“ Elemente) in ihm vorkommen.
Die zu einem Cyklus erster Ordnung gehörige Zirkularsubstitution, namentlich, ist allemal „die identische Substitution“ 1'.
Die zu einem Cyklus der zweiten Ordnung (also unsrer „nackten Transposition“) gehörige Zirkularsubstitution heisst Transposition (schlechtweg).
Beide sind wohl zu unterscheiden.
Ist jene z. B. das aus nur zwei Augen bestehende Relativ A : B + B : A, so wird diese das Relativ sein:
A : B + B : A + C : C + D : D + E : E + … und eventuell unendlich viele Augen haben.
Jede Transposition (schlechtweg) ist eine Substitution, nämlich eine „Cyklensumme“ in der die sämtlichen Elemente des Denkbereichs vertreten erscheinen.
Sie schreibt vor, zwei bestimmte Elemente mit einander zu vertauschen und alle übrigen ungeändert zu lassen (d. i. „mit sich selbst zu vertauschen“).
Durch letztere stillschweigend gemachte Unterstellung wandelt eigentlich die mathematische Substitutionentheorie schon jeden Cyklus in eine (die zugehörige) Zirkularsubstitution um, und sie braucht zwischen beiden kaum je einen Unterschied zu machen.
In diesem Betreff wird unsre Disziplin genötigt sein, strenger zu unterscheiden.
Dass nun in der That — wie oben S. 578 behauptet — unsre Substitution auch das relative Produkt ihrer elementefremden »Cyklen sein muss — wofern diese »Cyklen« — im Sinne der mathematischen Substitutionentheorie — sämtlich als Substitutionen aufgefasst werden, d. h. genauer gesagt: dass eine Substitution, definirt als Summe von lauter elementefremden Cyklen in deren Gesamtheit jedoch alle Elemente des Denkbereichs vertreten sind, einerlei sein muss mit dem relativen Produkt der zugehörigen Zirkularsubstitutionen — dies lässt sich unschwer durch (relatives) Ausmultipliziren der letztern gemäss 4) des § 6 aufgrund von 30) und 31) S. 440 einsehn und beweisen wie folgt.
Stellt c einen (wirklichen, oder „nackten“) Cyklus vor, so ist c; 1 das System der Zeilen und 1; c das System der Kolonnen in welchen überhaupt Augen dieses Cyklus stehen, m. a. W. c; 1 ist das System der Relate, 1; c das Systemkonvers der Korrelate unsres Cyklus.
Mithin wird der Ausdruck (c; 1 + 1; c)1' diejenigen Augen der Hauptdiagonale angeben, die mit den Augen des c in einer sei es horizontalen sei es vertikalen Flucht liegen. M. a. W. dieses Relativ stellt vor: die Summe der individuellen Selbstrelative die aus den konstitutiven Elementen unsres Cyklus gebildet sind.
Und darum wird das Relativ — es heisse zur Abkürzung 1'γ̄: (c̄ ɟ 0)(0 ɟ c̄)1' = 1'γ̄ ausschliesslich bestehn aus den individuellen Selbstrelativen derjenigen Elemente, die im Cyklus c nicht vorkommen — geometrisch gesprochen: aus den Augen der Hauptdiagonale die mit keinem Auge des Cyklus in einer Flucht liegen.
[Davon, dass allerdings nach dem Begriff des Cyklus daz System c̆; 1 von dessen Korrelaten einerlei sein muss mit dem Systeme c; 1 von dessen Relaten, d. h. dass c̆; 1 = c; 1 ist, was nach sich zieht, dass auch 1'γ = 1'(c; 1 + c̆; 1) = 1' · c; 1 = 1' · c; 1 · c̆; 1 = 1' · c; 1 · 1; c = 1' · c; 1; c, sowie 1'γ̄ = 1'(c̄ ɟ 0)(c̄̆ ɟ 0) = 1'(c̄ ɟ 0) = 1'(c̄ ɟ 0 + 0 ɟ c̄) = 1'(c̄ ɟ 0 ɟ c̄) — davon brauchen wir hiernächst keinen Gebrauch zu machen.]
Folglich wird c + 1'(c̄ ɟ 0)(0 ɟ c̄) = c + 1'γ̄ die zum Cyklus c gehörige Zirkularsubstitution vorstellen.
Stellt uns nun s = c1 + c2 + c3 + … irgend eine Substitution vor (bei deren Gliedern wir dieselben Bezeichnungsprinzipien wie vorstehend bethätigen), so wird zu zeigen sein, dass p, = (c1 + 1'γ̄1); (c2 + 1'γ̄2); (c3 + 1'γ̄3); … gleich s sein muss.
Man stelle sich hierbei die relativen Faktoren jeweils als die Summen ihrer effektiven Elementepaare vor. —
Nun ist: (c1 + 1'γ̄1); (c2 + 1'γ̄2) = c1; c2 + c1; 1'γ̄2 + 1'γ̄1; c2 + 1'γ̄1; 1'γ̄2 = c1 + c2 + 1'γ̄1γ̄2 ndem c1; c2 = 0, c1; 1'γ̄2 = c1, 1'γ̄1; c2 = c2, 1'γ̄1; 1'γ̄2 = 1'γ̄1γ̄2 sein muss.
Denn da c1 und c2 kein konstitutives Element gemein haben, so treffen beim Ausmultipliziren dieser beider immer nur Elementepaare von c1 mit solchen von c2 zusammen, die kein gemeinsames Element aufweisen und folglich keinen Anschluss aneinander haben.
Das relative Produkt solcher Elementepaare muss aber allemal nach 30) S. 440 verschwinden (q. e. d.)
Das Relativ 1'γ̄2 ist lediglich aus individuellen Selbstrelativen zusammengesetzt, und zwar aus allen denen, deren konstitutive Elemente in c2 nicht vorkommen.
Darunter jedenfalls finden sich sämtliche konstitutiven Elemente von c1.
Während für jedes h ≠ j nun (i : j); (h : h) = 0 ist, muss (i : j); (j : j) = i : j sein.
Beim relativen Ausmultipliziren der Summen von Elementepaaren in c1 und 1'γ̄2 reproduziren sich also einfach die effektiven Elementepaare von c1, (q. e. d.).
Weil für jedes h ≠ i auch (h : h); (i : j) = 0, dagegen (i : i); (i : j) = i : j ist und in 1'γ̄1 sämtliche konstitutiven Elemente von c2 durch individuelle Selbstrelative vertreten sein werden, weil sie zu den in c1 fehlenden gehören, so sieht man ebenso, dass beim relativen Ausmultipliziren von 1'γ̄1 mit c2 sich lediglich c2 wiedererzeugen wird, (q. e. d.).
Beim Ausmultipliziren, endlich, der Summen aus individuellen Selbstrelativen 1'γ̄1 mit 1'γ̄2 reproduziren sich nur diejenigen, welche diesen beiden Relativen gemeinsam sind wegen (i : i); (i : i) = i : i, wogegen (i : i); (j : j) für jedes j ≠ i verschwindet, (q. e. d.).
In derselben Weise ist nun zu zeigen, dass: (c1 + c2 + 1'γ̄1γ̄2); (c3 + 1'γ̄3) = c1 + c2 + c3 + 1'γ̄1γ̄2γ̄3, weil 1'γ̄1γ̄2 jedenfalls die konstitutiven Elemente von c3 und 1'γ̄3 die von c1 sowol als von c2 aufweist; denn die von c3 werden weder in c1 noch in c2 vorkommen.
„Und so weiter“.
Es ergibt sich für unser relatives Produkt: p = s + 1'γ̄1γ̄2γ̄3 … wo das letzte Glied ausschliesslich besteht aus den individuellen Selbstrelativen von all den Elementen, die weder in c1, noch in c2, noch in c3, … vorkommen, d. h. die in s nicht vorkommen.
In s müssen aber nach dem Substitutionsbegriffe alle Elemente des Denkbereiches vorkommen als konstitutive Elemente (Relat und Korrelat) eines der Cyklen aus denen diese Substitution besteht (sei das auch nur eines Cyklus erster Ordnung).
Und folglich ist 1'γ̄1γ̄2 … = 0, d. h. es bleibt p = s, wie behauptet worden.
Für diesen letzten Term erhalten wir überdies den Ausdruck:
1'(c̄1 ɟ 0)(0 ɟ c̄1)(c̄2 ɟ 0)(0 ɟ c̄2) … = 1'(c̄1c̄2 ‥ ɟ 0)(0 ɟ c̄1c̄2 …) = 1'(s̄ ɟ 0)(0 ɟ s̄) und kann das Verschwinden desselben auch analytisch aus der Charakteristik A1A2A3A4 der Substitution s gefolgert, nämlich schon aus A1 = (1 = 1; s) oder A3 = (1 = s; 1) in ersichtlicher Weise (mit s̄ ɟ 0 = 0, etc.) geschlossen werden — q. e. d.
Da wo wir oben „U. s. w.“ sagten, konnte wohl der „Schluss von n auf n + 1“ relative Faktoren in aller Form unschwer geleistet werden.
Es wird nur etwas umständlich, und wir unterliessen es um ein übermässiges Anschwellen des Textes zu vermeiden.
Damit wäre dann unser Satz in aller Strenge bewiesen nicht nur — was für den gegenwärtigen Zweck schon genügt — für alle „durchaus endlichen“ oder „mathematischen“ Substitutionen, sondern auch für solche die eventuell Cyklen aus „einfach unendlich vielen“ Elementen in ev. „einfach unendlicher“ Menge enthalten.
Es muss jedoch auch eine Form des Beweises geben, bei welcher aufgrund der Wahrnehmung, dass bei durchweg elementefremden Cyklen c die Reihenfolge relativer Faktoren der Form c + 1'γ̄ gleichgültig ist, vom Schluss der vollständigen Induktion kein Gebrauch gemacht, vielmehr blos nach dem dictum de omni auf die Wirkung jedes relativen Faktors dieser Art argumentirt wird.
Hierauf können wir an dieser Stelle nicht näher eingehn.
Schreibt man bei jeder Substitution s — die nach unsrer Definition ein Relativ Σi : j von gewisser Art ist — die sämtlichen Relate i (etwa alphabetisch resp. numerisch geordnet) in eine obere Zeile und die zugehörigen Korrelate aus den effektiven Gliedern darunter in eine zweite, die untere Zeile, so gelangt man zu der in der math. Substitutionentheorie ursprünglichst üblichen Darstellung s = [Formel] der Substitutionen — welche hier durch das Beispiel (A, B, C)(D)(E, F) = = [Formel] = A : B + B : C + C : A + D : D + E : F + F : E für den Denkbereich von sechs Elementen illustrirt werden möge.
Und man sieht sogleich beim relativen Ausmultipliziren solcher Summen von Elementepaaren, dass dabei das Schema (i : h); (h : j) = i : j unsrer Disziplin genau dem für die (eigentliche) Multiplikation der math. Substitutionen bekannten Schema [Formel] = [Formel] entspricht — nicht minder wie für s = [Formel] dem s— 1 = [Formel] in unsrer Disziplin das zu s = Σi : j gehörige s̆ = Σj : i entsprechen wird.
Die eine Disziplin bedient sich in der That einer nur äusserlich etwas andern Schreibmanier für die Substitutionen, als wie die andre.
Hiermit glauben wir, die beiden Substitutionsbegriffe aus Mathematik und Logik miteinander ausgesöhnt sowie alles für den Mathematiker befremdlich Gewesene in unsern Aufstellungen aufgehellt und acceptabel gemacht zu haben. —
Die Sätze — wie namentlich die Behauptung: die Substitution (sive Permutation) sei Funktion und Argument zugleich — lagen ja eigentlich auf der Hand; doch sind sie bislang noch nirgends ausgesprochen gewesen.
Wir wollen jetzt der Bestimmung eines unbekannten und gesuchten Relativs x durch die typischen Bedingungskombinationen 10) unsre Aufmerksamkeit zuwenden.
Indem also x für a gesagt wird, seien die vier Elementarbedingungen wenigstens in einigen ihrer sozusagen klassischen Formen nochmals hingesetzt: 15)
[Formel]
Darnach wird sein (Begründungen am Schluss der Tafel): 16) [Formel] — das ist Peirce’s „totally unlimited relative“. 17) [Formel] 18) [Formel] 19) [Formel]
Diesem letztern Typ, A2A4, gehört — wie sich in § 31 zeigen wird — Herrn Dedekind’s „ähnliche (oder deutliche) Abbildung“ jederzeit an. 20)
[Formel] 21) [Formel] 22) [Formel] — wo das Wort „eineindeutig“ eine in der Mathematik schon vielfach gebräuchliche Abkürzung ist für „auch umgekehrt eindeutig“.
Begründung für die Angaben 16) bis 22) betreffend ist zu sagen, dass sie aus 15) grösstenteils schon nach den Regeln des identischen Kalkuls in einer ersichtlichen nicht mehr erläuterungsbedürftigen Weise folgen.
Nur bei der ersten Form einer jeden Chiffre, die sich als Subsumtion oder Gleichung mit dem Subjekte 1 präsentirt, kamen ausserdem zum öftern die Sätze 16) S. 445 und 29) S. 215 (links) in Betracht.
Ganz neu trat aber die letzte Ausdrucksform bei 17) für einen jeden dieser beiden wichtigen Typen hinzu.
Die Äquivalenz von dieser mit den vorhergehenden Formen nach Sätzen unsrer Disziplin ohne Zufluchtnahme zur Koeffizientenevidenz nachzuweisen, speziell so {1 ⋹ 1; x(1' ɟ x̄)} = {1' ⋹ x̆; (1' ɟ x̄)} zu beweisen, ist nicht ganz einfach, und würde die Aufgabe ohne jegliche Anleitung vielleicht als eine harte Nuss erscheinen.
Wir werden ihre heuristische Lösung gelegentlich der Auffindung und des Beweises eines noch allgemeinern Satzes im § 31 (implicite mit) geben und begnügen uns zur Stelle mit der Berufung auf einen durch die Koeffizientenevidenz zu erweisenden Hülfssatz: 23) [Formel] für dessen ersten Teil wir in der That haben: R = Πi j (1'i j ⋹ Σhai hbh j) = Πi (1 ⋹ Σhai hbh i) weil die für j ≠ i sich ergebenden Faktoraussagen des Π das Prädikat 0 aufweisen und als selbstverständliche unterdrückbar sind.
Sonach kommt: R = Πj i {1j i ⋹ Σh(ăb)h i = (1; ăb)j i} = L, q. e. d.
Bezüglich dieser bei 17) hinzugekommnen Ausdrucksformen sind wir bei den nachfolgenden Kombinationen 20) bis 22) nicht mehr vollständig gewesen, wie denn mit Rücksicht auf sie z. B. auch sich schreiben lassen würde: A1A2A3 = {1' ⋹ x; x̆ · x̆; (1' ɟ x̄)}, A1A2A4 = {x̆; x ⋹ 1' ⋹ x̆; (1' ɟ x̄)}, A1A2A3A4 = {1' ⋹ (x̄ ɟ 1'); x̆ · x̆; (1' ɟ x̄)}.
Überhaupt soll nicht behauptet sein, dass es ausser den aufgeführten für unsre 15 Typen nicht vielleicht auch noch andre ganz bemerkenswert einfache Ausdrucksformen gebe!
Hervorzuheben ist aber die Einfachheit von einigen der angeführten Formen.
In Gestalt von 1' ɟ x̄ = x ist es hienach mit Aufwand von nur drei Termen (Relativsymbolen, oder — den Modul eingerechnet — Buchstaben) möglich, ein Relativ x als eine Funktion zu charakterisiren, die Funktion ihrem Begriff und Wesen nach (implicite) zu definiren!
Für die Substitution ist ebendazu bei x; x̆ = 1' = x̆; x nur ein Aufwand von fünf Symbolen erforderlich — und für jeden „endlichen Denkbereich würde (nach einer schon S. 567 vorgreifend geäusserten Bemerkung) schon eine dieser beiden Gleichungen allein wie x; x̆ = 1', mithin ein Aufwand von auch nur drei Lettern dazu ausreichen!
Dass irgend eine Disziplin mit noch geringern Mitteln solches verwirkliche, ist kaum mehr denkbar.
Was nun die allgemeinen Wurzeln zu diesen 15 Propositionen anbelangt, so können wir sogleich (und jedesmal in zwei wesentlich verschiednen Formen) befriedigende allgemeine Lösungen für die acht ersten derselben angeben.
Und zwar ist: 24) [Formel] 25) [Formel] 26) [Formel] 27) [Formel] 28) [Formel] .
Beweis dieser Angaben betreffend, sind die ersten Lösungsformen von 24) sowie die sämtlichen von 25) und 27) bereits mit unsern Parallelreihenuntersuchungen gegeben — vergleiche 14) (Aufg. 9) und 27) (Aufg. 23) des § 15, sowie ibidem 34) (Aufg. 31).
Die zweite Form der Lösung von A3 in 24) folgt für a = 1' leicht aus 15) des § 28 S. 477, indem man dort y mit x̆ somit v mit ŭ identifizirt § durch Konjugation dann ebenso die zweite Form von A1.
Was 26) betrifft, so sieht man sogleich, dass die Summe der allgemeinen Wurzeln von A1 und A3 die allgemeine Wurzel von A1A3 sein muss: die identische Summe eines Relativs ohne Leerkolonnen und eines solchen ohne Leerzeilen muss immer ein Relativ sein, das weder Leerzeilen noch Leerkolonnen besitzt, d. h. muss ein Relativ ohne Leerreihen sein; und da mit jener Summe kraft 24) auch die „Probe 2“ stimmt, so stellt sie jedes solche Relativ vor.
Ebenso endlich, was 28) betrifft, sieht man alsbald, dass das identische Produkt der allgemeinen Wurzeln von A2 und A4 die allgemeine Wurzel von A2A4 sein muss.
Jedenfalls kann der Schnitt eines Relativs, welches nur Kolonnenreiter zu Augen hat, mit einem solchen, welches nur Zeilenreiter zu Augen hat, blos ein Relativ sein, welches in seinen besetzten Reihen nur „Kreuzreiter“ trägt (d. h. Augen die sowol in ihrer Zeile als in ihrer Kolonne vereinzelt stehen) — jedoch sonst auch noch mit beliebigen Leerreihen begabt sein kann.
Und da wieder mit jenem Produkte kraft 25) die Probe 2 stimmt, so wird es fähig sein uns auch jede Wurzel zu liefern.
Der zweite Ausdruck der Lösung von 28) fügt den aus u hervorgehobnen Kreuzreitern noch die Kreuzreiter von ū hinzu, die also den „Kreuzlücken von u entsprechen, mithin mit den vorigen in keiner Reihe kollidiren können, und derengleichen es gar nicht gibt, soferne u selbst schon Wurzel von A2A4 war.
Übrigens wäre mit den angegebnen Lösungen bei 26) und 28) auch die Probe 1 in aller Form, rechnerisch, nicht allzu schwer zu machen; q. e. d.
Die der ersten Lösungsform von 28), namentlich, beruht auf dem Satze: (ū ɟ 1')u(1' ɟ ū); (ū̆ ɟ 1')ŭ(1' ɟ ū̆) ⋹ 1' — desgleichen ŭ für u gesetzt.
Nennen wir den ersten relativen Faktor x, so ist in der That nach 5) des § 6 etc. x; x̆ ⋹ u; (ū̆ ɟ 1') ⋹ u; ū̆ ɟ 1' ⋹ ⋹ 0' ɟ 1' = 1', q. e. d.
Und was die zweite Lösungsform anbelangt, so ist, wenn wir noch (u ɟ 1')ū(1' ɟ u) = y nennen, auch (mit der vorigen Bedeutung des x): x; y̆ ⋹ (1' ɟ ū); (ŭ ɟ 1') ⋹ 1' ɟ ū; (ŭ ɟ 1') ⋹ 1' ɟ (ū; ŭ ɟ 1') ⋹ 1' ɟ 0' ɟ 1' = 1' ɟ 1' = 0*, falls der Denkbereich mehr als zwei Elemente enthält, d. h. dann gilt: (ū ɟ 1')u(1' ɟ ū); (ŭ ɟ 1')ū̆(1' ɟ ŭ) = 0 und somit x; y̆ ⋹ 1'.
Ebenso — ŭ für u gesagt — x̆; y ⋹ 1', und nach dem vorhergehenden Schema — ū für u gesagt — gilt auch y; y̆ ⋹ 1', sowie — ū̆ für u gesagt — y̆; y ⋹ 1', q. e. d.
Übrigens hat — im Gegensatz zu 25) und 27) — bei 28) die zweite Lösungsform der ersten gegenüber nur geringern Mehrwert, da, wie geometrisch leicht zu sehn ist, mit dem Vorkommen von Kreuzreitern sich dasjenige von Kreuzlücken gar nicht verträgt — was auch analytisch zu erhärten nicht ohne Interesse wäre.
Verweilen wir noch einen Augenblick bei dem in der ersten Zeile von 27) in der eckigen Klammer gleich x gesetzten Ausdrucke in u, der sich mit acht Termen aufbaut.
Derselbe umfasst, begreift unter sich alle erdenklichen „Funktionen (hier immer: eines Argumentes); er liefert, was immer für ein Wert dem binären Relativ u beigelegt werden mag, uns nur eine Funktion und vermag bei geeigneter Wahl des u jede gewünschte Funktion darzustellen.
Nämlich sooft das arbiträre Relativ u von vornherein als eine „Funktion“ — gleichviel welche — angenommen wird, nimmt er einfach den Wert u selbst an, liefert uns ebendiese.
Wenn aber das Relativ u keine Funktion ist, so konstruirt er uns eine solche, indem er aus u alle diejenigen Augen beibehält, welche darin etwa schon, als „Kolonnenreiter“, vereinzelt in ihrer Kolonne stehen, er hebt m. a. W. alle einbesetzten Kolonnen aus u hervor, tilgt zunächst dessen übrige Kolonnen und ersetzt sie durch lauter solche einbesetzte Kolonnen, welche an ihrer Schnittstelle mit der Hauptdiagonale ein Auge (als Kolonnenreiter) tragen.
Hatte u gar keine einbesetzte Kolonne, so wird x = 1' und präsentirt sich als jene spezielle Funktion, welche mit ihrem Argumente zusammenfällt.
Das Argument der fraglichen „Funktion“ = „Funktion von-“ ist bei diesen Betrachtungen offen gelassen worden und unbenannt geblieben.
Hätten wir in der mehr üblichen Weise mit y, statt mit x, die Funktion bezeichnet, das Argument dann x genannt, so würde y = x die Gleichung der zuletzt erwähnten speziellen Funktion geworden sein.
Der besprochene Ausdruck in 27) kann, weil er sein Wesen als eo ipso „(irgend) eine Funktion“ vorstellend in sich selbst zu erkennen gibt, füglich als der pasigraphische Name des Funktionsbegriffes, als das rationell zusammengesetzte, adäquate Zeichen für das Wort „Funktion von-“ in einer nur über immer weitere Gebiete noch zu erstreckenden allgemein wissenschaftlichen Begriffsschrift hingestellt werden:
Jeder Satz, der von allen Funktionen (eines Argumentes) gilt, muss sich in ihm als eine reine Identität des Aussagenkalkuls nachrechnen, vermittelst der Koeffizientenevidenz verifiziren lassen.
Mit dem Bisherigen sind bereits für fünfe 10, 20, 30, 40, 60 von den neun Abbildungstypen 10) die allgemeinen Ausdrucksformen gefunden.
So erfolgreich vermögen wir aber leider nicht noch weiter fortzuschreiten.
So fehlt uns namentlich noch der pasigraphische Name für „Substitution“, der (als ein expliziter Ausdruck dieses Begriffes durch ein arbiträres Relativ u) dem oben gegebnen für „Funktion entsprechen würde.
Wer etwa versucht, die Gleichung x; x̆ = 1' zum Typ A2A3 von 50 nach x allgemein aufzulösen, wird schon der Schwierigkeiten der Aufgabe inne werden.
[Die allgemeine Wurzel dieser würde wenigstens für die „endlichen“ Denkbereiche zugleich auch den Substitutionsbegriff darstellen.]
Die allgemeine Lösung der Substitutionscharakteristik 22) kann zwar à la rigueur, als eine „rigorose“ angegeben werden in Gestalt von s, oder x = u(0 ɟ F̅ ɟ 0) + 1' · 1; F; 1, wo F = (u; ŭ + ŭ; u)0' + (ū ɟ ū̆)(ū̆ ɟ ū)1', womit indessen nach schon S. 168 gegebnen Ausführungen nicht viel gewonnen ist.
Dieses x wird freilich = u, sobald u als eine Substitution von vornherein angenommen, gebildet ist, und vermag daher x in der That jede Substitution darzustellen.
Für jedes andre u aber, das von vornherein keine Substitution wäre, wird uns x = 1' immer wieder nur die identische Substitution reproduziren.
Aus einem arbiträren Relativ u kann man ja allerdings in Gestalt von v = (ū ɟ 1')u(1' ɟ ū) zunächst einmal dessen „Kreuzreiter“ hervorheben, die als Augen schon isolirt im Mittelpunkte ihres Reihenkreuzes stehen.
Diesen Teil v von u kann man als den ersten Grundstock zu einer noch vollends zu konstruirenden aus u abzuleitenden Substitution festhalten.
Fügt man dann, um die angefangne Substitution zu vollenden, noch weitre Augen hinzu, so muss aber Sorge getragen werden, dass dieselben mit keinem der schon (in v) vorhandnen Augen „kollidiren“, d. h. in eine Flucht zu liegen kommen, ansonst ja mehrbesetzte Reihen entstehen würden.
Das Zeilensystem v; 1 und das Kolonnensystem(konvers) 1; v bildet die Gesamtheit derjenigen Reihen, in denen bereits ein Auge steht.
Dagegen geben die Vollzeilen v̄ ɟ 0 das System der Zeilen, und die Vollkolonnen 0 ɟ v̄ das System(konvers) der Kolonnen an, welche noch eines Auges entbehren.
Nahe liegt wiederum der Gedanke, um diese bis jetzt noch leeren Reihen ebenfalls je mit einem Auge zu versehen: dasselbe jeweils an die Stelle zu verlegen, wo diese Reihen die Hauptdiagonale schneiden.
In Gestalt von (v̄ ɟ 0)1'(0 ɟ v̄) bekommt man so in der That einen zur Vervollständigung unsrer noch unfertigen Substitution ganz brauchbaren Beitrag, nämlich einen Beitrag von Augen, die wiederum Kreuzreiter sein und mit keinem der vorhandnen Augen kollidiren werden.
Sind es ja doch die Augen, in denen bisherige Leerzeilen mit bisherigen Leerkolonnen auf der Hauptdiagonale zusammentreffen!
Anders aber verhält es sich mit denjenigen Stellen der Hauptdiagonle, wo eine Leerzeile von v mit einer besetzten Kolonne des v, oder umgekehrt, zusammentrifft.
Die Augen von (v̄ ɟ 0)1' · 1; v und v; 1 · 1'(0 ɟ v̄) werden zur Ergänzung unsrer Substitution nicht verwendbar sein, weil sie mit schon vorhandnen Augen des v kollidiren.
[Teilweise könnte man vielleicht die Konverse derjenigen Augen verwenden, mit welchen jene kollidiren, eventuell aber, nämlich soferne dadurch neue Kollisionen herbeigeführt werden, auch nicht.]
Am besten wol würde man statt ihrer diejenigen Augen (hinzufügend zu v) verwenden, welche sich als dasjenige präsentiren, was ich für den Augenblick die „ideale Diagonale“ zu v nennen möchte, nämlich die Augen, die auf der Diagonale stehen würden, falls man aus der Tafel 12 die Zeilen des Systems v; 1 sowie die Kolonnen 1; v sämtlich ausmerzte und die übrigen Zeilen sowie Kolonnen „aufschliessen“, d. h. zusammenrücken liesse.
Diese würden aber nur dann als bestimmt erscheinen, falls man ein Relativ a zuhülfe nähme, nämlich als gegeben voraussetzte und zugrunde legte, durch welches sämtliche Elemente des ursprünglichen Denkbereiches in eine bestimmte Ordnung oder Grössenfolge gebracht werden.
Vielleicht gibt diese Bemerkung eine Anregung, das Problem einmal noch weiter zu fördern. —
Für die Anwendungen und häufigen Gebrauch thut man gut, sich gewisse Folgerungen aus den Charakteristiken unsrer vier Grundtypen allgemein zurechtzulegen.
Es stelle x jeweils eine Abbildung vor, welche der links der Formelchiffre beigesetzten Kombination von A-Bedingungen genügt.
Dann haben wir für beliebige a, b sub 29) A1: (x; b ⋹ a) ⋹ (b ⋹ x̆; a), (a; x̆ ⋹ b) ⋹ (a ⋹ b; x) 30) A3: (x̆; a ⋹ b) ⋹ (a ⋹ x; b), (b; x ⋹ a) ⋹ (b ⋹ a; x̆) 31) A2: (b ⋹ x̆; a) ⋹ (x; b ⋹ a), (a ⋹ b; x) ⋹ (a; x̆ ⋹ b) 32) A4: (a ⋹ x; b) ⋹ (x̆; a ⋹ b), (b ⋹ a; x̆) ⋹ (b; x ⋹ a).
Die Beweise ergeben sich leicht im Hinblick auf die in 15) letzts angegebne Form der Bedingungen A nach folgendem Vorbilde, welcheuns der Beweis für die erste und der für die letzte der vorstehenden 8 Behauptungen abgibt: (x; b ⋹ a) ⋹ (b = 1'; b ⋹ x̆; x; b ⋹ x̆; a), (b ⋹ a; x̆) ⋹ (b; x ⋹ a; x̆; x ⋹ a; 1' = a).
Bei den vorstehenden Beweisen sind wir schliessend vorgegangen, indem wir suchten (durch Übermultipliziren der Prämisse)
x und x̆ als relative Faktoren zusammenzubringen in derjenigen Reihenfolge in der sie in der Charakteristik 15) vorkommen, damit diese letztere so zur Gewinnung von Schlussfolgerungen verwertbar wurde.
Stellen a und b Elemente h, k vor, so kann man, um ähnlich schliessend vorzugehen, sich ausserdem auf den Satz 19) des § 25 oder δ) stützen, welcher die Äquivalenz der beiden folgenden Subsumtionen garantirt: δ) (h ⋹ x; k) = (k ⋹ x̆; h).
Ein analoger Satz existirt für die umgekehrten Subsumtionen wie bei ε) gezeigt wurde nicht.
So kommt es, dass nunmehr blos für die beiden Typen A2 und A4 sich ein wichtiger Satz hinzuergibt — der lautet 33) sub A2: (h ⋹ x; k) = (h = x; k) = (k ⋹ x̆; h) 34) sub A4: (k ⋹ x̆; h) = (k = x̆; h) = (h ⋹ x; k).
Beweis.
Zu A2 haben wir: (h ⋹ x; k) = (k ⋹ x̆; h) ⋹ (x; k ⋹ x; x̆; h ⋹ 1'; h = h), also (h ⋹ x; k) ⋹ (x; k ⋹ h), q. e. d.
Und zu A4: (h ⋹ x; k) ⋹ (x̆; h ⋹ x̆; x; k ⋹ 1'; k = k), somit: (k ⋹ x̆; h) ⋹ (x̆; h ⋹ k), q. e. d. — mit Rücksicht auf das Aussagenschema: (a ⋹ β) = (α = αβ) und die Definition der Gleichheit.
Für die Kombinationen unsrer vier Typen folgt nun leicht durch entsprechende Kombination der Sätze 29) bis 32) hinzu, dass gelten wird sub 35) A1A2: (x; b ⋹ a) = (b ⋹ x̆; a), (a ⋹ b; x) = (a; x̆ ⋹ b) 36) A3A4: (a ⋹ x; b) = (x̆; a ⋹ b), (b; x ⋹ a) = (b ⋹ a; x̆) 37) A1A4: (a = x; b) ⋹ (x̆; a = b), (a; x̆ = b) ⋹ (a = b; x), 38) A2A3: (x̆; a = b) ⋹ (a = x; b), (a = b; x) ⋹ (a; x̆ = b).
Bei A1A3 und A2A4 gilt bezüglich a tempo die obere und die untere Hälfte der Äquivalenzen 29) bis 32) und sind dieselben keiner Zusammenziehung fähig.
Nur ist zu bemerken, dass aus 33) und 34) im Hinblick auf δ) der Satz mitfolgt sub: 39) A2A4: (h ⋹ x; k) = (h = x; k) = (k = x̆; h) = (k ⋹ [Formel] vorwärtig sintemal man zu jeder Prämisse linkerhand die Konklusion aus 29) bis 32) als Aussagenfaktor hinzunotiren darf, wonach dann die Def. (1) der Gleichheit anwendbar wird, rückwärtig als selbstverständliche.
Und zwar gelten diese Sätze nicht etwa nur für Systeme, sondern schon für beliebige Relative a, b.
Die Wichtigkeit gerade des Typus A2A4 (für den Eintritt vom Standpunkte unsrer Theorie aus in die Dedekind’schen Forschungen) rechtfertigt ein gelegentlich ausführlicheres Eingehen auf diesen.
So sei denn hier noch darauf aufmerksam gemacht, dass, wenn in 2) und 4)
x für a gesagt wird, diese beiden Forderungen sich auch zusammenziehen zu 42) A2A4 = Πh k l[(h ⋹ x; k) ⋹ {(l ≠ h) ⋹ (l ⋹ x; k)}{(l ≠ k) ⋹ (h ⋹ x; l)}] und dass mit Rücksicht auf die obige aus der Charakteristik von A2A4 vorhin gerechtfertigte Formel 39) diese Forderung hinausläuft auf [Formel] wo der erste Faktor der Thesis sich aus der Hypothesis durch Elimination (Einsetzung des Wertes) von h von selbst versteht, und ebenso der letzte Faktor der Thesis — in der darunter stehenden Form — durch Elimination von k. Sonach ist es auch ein Leichtes, die Grundeigenschaften einer Abbildung vom Typus A2A4 aus deren Charakteristik wieder rückwärts abzuleiten.
Zum Schluss noch einige Sätze über Substitutionen.
Bezeichnen wir eine Substitution, d. h. eine zum Typus 90 oder A1A2A2A4 gehörige Abbildung demnächst mit s, so wird also sein: 43) s; s̆ = 1' und s̆; s = 1'.
Da diese Charakteristik bei Vertauschung von s mit s̆ ungeändert bleibt, nämlich blos die eine Gleichung in die andre, und umgekehrt, übergeht, so haben wir den implicite schon S. 569 miterwähnten Satz:
Das Konvere s̆ einer Substitution s ist auch eine Substitution — es ist die sogenannte reziproke Substitution von s, oder falls die Substitution als eine umkehrbar eindeutige Funktion angesehen wird: die „inverse“ Funktion derselben — wie sich sogleich aus 45) rechtfertigen wird.
Mit Rücksicht hierauf brauchen manche Sätze nicht doppelt, für s und s̆, sondern blos einfach, für s, ausgesprochen zu werden.
Wir haben dann ferner, als sämtlich leicht erweisbare, die Sätze: 44) (a ⋹ s; b) = (s̆; a ⋹ b), (a ⋹ b; s) = (a; s̆ ⋹ b) — die auch rückwärts mit vertauschtem s̆ und s (und eventuell a, b) zu lesen.
Dazu: 45) (a = s; b) = (b = s̆; a), (a = b; s) = (b = a; s̆).
Beweis. (a⋹s; b) ⋹ (s̆; a ⋹ s̆; s; b = 1'; b = b), (s̆; a ⋹ b) ⋹ (a = 1'; a = s; s̆; a ⋹ s; b), Etc.
Darnach ist (a = s; b) = (a ⋹ s; b)(s; b ⋹ a) = (s̆; a ⋹ b)(b ⋹ s̆; a) = (b = s̆; a) q. e. d.
Es ist leicht zu sehn, dass der zweite Satz, sofern er allgemein gelten soll, s als eine Substitution charakterisirt, nämlich dass: 46) [Formel] , etc.
Denn wie wir seine linkseitige Aussage L schon aus der rechtseitigen R soeben abgeleitet haben, so gelingt auch das Umgekehrte durch die auf Einsetzung von b resp. a gegründete Überlegung:
[Formel] .
Und ferner gilt der wichtige Satz — vergl. D 27: 47) (s; a ⋹ s; b) = (a ⋹ b) = (a; s ⋹ b; s).
Denn wie die erste von diesen Äquivalenzen als Subsumtion rückwärtig nach 1) des § 6 ohnehin gilt, so folgt sie auch vorwärtig mit L⋹ (s̆; s; a ⋹ s̆; s; b) = (1'; a ⋹ 1'; b) = (a ⋹ b).
Als Korollar dazu müssen wir nun auch haben: 48) [Formel] und sind diese Sätze samt und sonders durchaus nicht etwa nur auf „Systeme“ a, b beschränkt, sondern gelten für die a, b als beliebige binäre Relative.
§ 31. Dedekind’s ähnliche Abbildung eines Systems in ein anderes.
Ähnliche oder gleichmächtige Systeme.
Wir haben im vorigen Paragraphen die verschiednen Arten von Abbildung betrachtet sozusagen: im absoluten Sinne, nämlich: als durch gewisse Eigenschaften durchgängig, für den ganzen Denkbereich 1, charakterisirte.
In diesem Sinne war z. B. eine gegenseitig eindeutige Abbildung als eine „Substitution“ zu bezeichnen.
Für unsre vornehmsten Zwecke: der Formulirung des Gleichmächtigkeits-, Endlichkeits- und Anzahl-Begriffes, genügt aber solche Betrachtungsweise nicht, sintemal sie dem Abbildungsprinzipe oder Relativ x von vornherein Beschränkungen auferlegt, die dasselbe keineswegs zu erfüllen braucht, ja, bei den Anwendungen oft auch gar nicht erfüllen kann, indem sie mit wesentlichen Voraussetzungen der Untersuchung in Konflikt geraten resp. von vornherein inkompatibel sein werden.
So würden beispielsweise im Gebiet der natürlichen Zahlen durch die Zuordnung der unter einander stehenden Elemente in:
(Bei x Objekt:) 2, 3, 4, 5, 6 (:
Bild bei x̆)
(Bei x Bild:) 5, 6, 7, 8, 9 (: Objekt bei x̆) die beiden Systeme von Zahlindividuen a = 2 bis 6, b = 5 bis 9 in einander gegenseitig eindeutig abgebildet zu nennen sein, ohne dass doch unser Abbildungsprinzip x eine Substitution zu sein brauchte sei es im ganzen Denkbereich der natürlichen Zahlen, sei es auch nur in dem auf die hier in Betracht kommenden Elemente 2 bis 9 beschränkten Denkbereiche!
In der That brauchen nämlich schon im letzteren die Elemente 2, 3, 4 keine x-Bilder zu sein, die 7, 8, 9 gar keine x-Bilder zu haben.
Dass aber eine Substitution im Denkbereich der positiven Ganzzahlen die gegenseitig eindeutige Zuordnung: (Objekt) 1̇, 2, 3, 4, 5, … (x-Bild) 2, 3, 4, 5, 6, … die für den Erweis der einfachen Unendlichkeit dieses Zahlensystemes wesentlich ist, gar nicht zu leisten vermag, ist a priori ersichtlich:
es muss, da die Zahl 1̇ hierbei von keinem Objekte das x-Bild ist, das Relativ x notwendig die erste Zeile zur Leerzeile haben und kann also nicht Substitution sein.
Dies hat auch Herr Hoppe 1 p. 31 richtig herausgefühlt, jedoch daraus der Dedekind’schen Arbeit zu Unrecht den Vorwurf eines innern Widerspruchs gemacht — sintemal in dieser die „ähnliche Abbildung“ ja gar nicht als eine Substitution eingeführt worden!
Aus hiermit angedeuteten Gründen müssen wir die Abbildung, zumal die (einseitig, sowie die) gegenseitig eindeutige, auch noch in relativem Sinne studiren, nämlich als eine solche blos mit Bezug auf ein bestimmtes System a = a ɟ 0 = a; 1 als Objekt und (eventuell auch) ein bestimmtes System b = b ɟ 0 = b; 1 als (dessen x-)Bild.
Bei der speziellen Annahme a = 1 und b = 1 geht diese relative Betrachtungsweise in die frühere absolute über, und werden wir demnach mit einer Verallgemeinerung, Ausdehnung der frühern Ergebnisse (des § 30) zu thun bekommen — die vorausgenommen zu haben gleichwol didaktisch gerechtfertigt bleibt: durch ihre Einfachheit und Wichtigkeit sowol, als wegen der erheblich grössern Leichtigkeit ihrer selbständigen Herleitung etc.
Nimmt man blos b = 1, oder aber a = 1 an, so geht die relative Betrachtungsweise über in eine wenigstens in Hinsicht des Bildes resp. Objektes „absolute“, bleibt sie relativ nur in Hinsicht des Objektes resp. Bildes.
Ich will die in Hinsicht von a sowol als b relativen Forderungen später mit numerirten Buchstaben γ (oder δ, ‥) bezeichnen, um den Buchstaben α ebenso verwenden zu können für blos auf a bezügliche, den β für nur auf b bezügliche Bedingungen oder Forderungen — welche etwa aus den gleichchiffrirten γ (resp. δ, ‥) auf die vorhin geschilderte Weise hervorgehn.
Nun steuerten wir schon in der neunten vorlesung auf das in hohem Maass erstrebenswerte Ziel los, das Wesentlichste aus Dedekind’s fundamentalen Untersuchungen1 unsrer Theorie einzupassen (was sich als nicht ganz leicht erweist), und in der ersten Abteilung dieses Bandes beabsichtigen wir nicht zum wenigsten: die Einfügung noch weiterzuführen bis exclusive zu D 64, nämlich bis zu dem mit „Das Endliche und das Unendliche“ überschriebnen D § 5 hin.
Diese Einverleibung ist ja — bis ebendahin — schon zum weitaus grössten Teile, und nicht ohne manchen Gewinn nach beiden Seiten (insbesondre eine Verallgemeinerung und schliesslich auch Vereinfachung der Kettentheorie) vollzogen.
Um sie vollends durchzuführen, bleibt nur mehr ein Dutzend von Erklärungen oder Sätzen zu erledigen.
Von den ersten Sätzen D 1 bis 63 der oft citirten Schrift hat in der That blos das Dutzend D 21, und 25 bis 35, nicht in der Kettentheorie schon Erledigung gefunden.
Dieser Rest unsrer Aufgabe bietet aber eine Reihe von unerwarteten und nicht zu unterschätzenden Schwierigkeiten dar, die zu überkommen schon an sich nicht wenig lehrreich und förderlich sein wird.
Indem ich demnächst solches darlege, wolle mir jedoch der Studirende nicht unterstellen, dass ich (auch) damit eine Vereinfachung der Dedekind’schen Schlüsse und Betrachtungsweisen (soweit sie hierauf bezüglich) zu geben vermeinte!
Im Gegenteil:
wir werden uns weidlich zu plagen haben, um aus den fundamentalen Festsetzungen unsrer Disziplin in streng analytischer Deduktion Dinge zu beweisen und als denknotwendig mitgegebne zu erkennen oder auch nur bestätigt zu finden, die dem schon mit dem Wesen (gegenseitig) eindeutiger Zuordnung Vertrauten und in ihrer Anschauung Geübten von vornherein auf der Hand zu liegen scheinen.
Wir werden hierin Herrn Dedekind vielleicht ganz ähnlich gegenüberstehn, wie dieser selbst gegenübersteht denjenigen Mathematikern, die sich begnügen, den Begriff der „Anzahl“ („Endlichkeit“ etc.) als etwas schlechthin Gegebnes, ohnehin in allgemeinem Besitze (wie die Luft) Befindliches hinzunehmen, und die auch niemals das Bedürfniss empfunden haben, den Schluss der vollständigen Induktion aus den Prinzipien irgend einer Logik zu rechtfertigen!
Unser Ziel geht in der That noch über jenes Weiterschreiten in Anlehnung an Dedekind hinaus.
Wir wollen auch zu einer sozusagen „pasigraphischen“ Formulirung in der Zeichensprache unsrer Algebra jener fundamentalen Begriffe der „Ähnlichkeit“ oder „Gleichmächtigkeit“ zweier Systeme (sowie der „Endlichkeit“, „einfachen Unendlichkeit“, etc. eines solchen und — im ersten Falle — der „Anzahl“ seiner Elemente!) gelangen.
Dedekind’s Begriff „ähnlicher Systeme“ D 32 deckt sich mit dem Georg Cantor’schen von „Mannigfaltigkeiten“, die „von gleicher Mächtigkeit“ sind.
Nach Cantor sollten solche Mannigfaltigkeiten (vergl. Borchardt’s Journal, Bd. 84, S. 242 sqq.)
(sive Systeme) auch „äquivalent“ genannt werden — welchen Ausdruck zu gebrauchen wir für unsre Disziplin aus naheliegenden Gründen wol ablehnen müssen.
Diese Gleichmächtigkeit oder Ähnlichkeit z. B. muss nun auf eine Relation zwischen den Systemen a und b hinauslaufen, die sich mittelst der Spezies unsrer Disziplin erschöpfend darstellen lässt.
Ihre Ermittelung wird demnächst auf eine Eliminationsaufgabe unsrer Algebra zurückgeführt, und für die niedersten Denkbereiche wird diese auch sogleich explicite gelöst.
Die hohe Wichtigkeit des Gleichmächtigkeitsbegriffs ist dem Mathematiker vertraut.
Es sei gestattet, auch hier auf einiges aufmerksam zu machen, was er alles involvirt — und zwar populär zu reden.
Ähnliche sive gleichmächtige Systeme müssen entweder beide verschwinden, oder alle beide von 0 verschieden sein.
Entweder sind sie beide endlich, oder sie sind beide unbegrenzt, und im erstern Falle müssen beide Systeme aus gleichviel Elementen bestehen (sind sie „gleichzahlige Mengen von Einheiten, oder m. a. W. die Einheiten sind in beiden Mengen „von gleicher Häufigkeit“ — ein Begriff, der dem Anzahlbegriffe vorangeht).
Im andern Falle sind entweder beide Systeme „einfach unendlich“, oder beide sind es nicht und bilden sodann Mannigfaltigkeiten der zweiten Art im G. Cantor’schen Sinne.
Als Beispiel für dieses letztre seien die irrationalen Zahlen — auch schon die transcendent(irrational)en — oder auch die Zahlen überhaupt, die Gesamtheit der Punkte einer Geraden, etc. angeführt.
Als eins der frappantesten Beispiele zu jenem erstern haben Herrn Cantor’s Arbeiten bekanntlich die überraschende Thatsache zutage gefördert: dass das System der rationalen Zahlen (ja sogar das der algebraischen Zahlen) von gleicher Mächtigkeit ist mit dem der positiven ganzen Zahlen.
Wir haben es also zu thun mit einer Erweiterung des Begriffs der Gleichzahligkeit von endlichen Mengen, durch den derselbe auch auf unbegrenzte Systeme anwendbar wird und die zugleich für ihn selber propädeutisch ist — und werden dabei auf Betrachtungen hingeleitet, die nicht verfehlen können, auch der „Mannigfaltigkeitslehre“ und den Theorien des aktual Unendlichen“ den Anschluss an die allgemeine Logik zu sichern und sich in diesen einst noch fruchtbar zu erweisen.
Möge darum der Studirende frei von utilitarischen Rücksichten unsern Ausführungen folgen und als einen Hauptzweck derselben den in’s Auge fassen, dass es sich darum handelt, das Instrument unsrer Algebra zunächst einmal ordentlich in die Gewalt zu bekommen, um auch auf subtilere Aufgaben es anwenden zu lernen.
Sehr viel wird ja schon gewonnen sein und der Descartes- Leibniz’sche Pasigraphiegedanke wird um einen gewaltigen, vielleicht um seinen bedeutungsvollsten und schwersten Schritt gefördert erscheinen, wenn es (in diesem Bande) nur überhaupt gelingt den Nachweis zu liefern: dass das mit unsern Festsetzungen (1) bis (15) geschaffne Bezeichnungskapital (das ich in meiner Annalennote11 auf einer halben — gar nicht sehr dicht bedruckten — Seite übersichtlichst zusammengestellt habe) völlig ausreichend ist, um alle Erklärungen, Sätze und Schlüsse aus dem Gedankenkreise der Dedekind’schen Schrift — mithin die Grundbegriffe der gesamten arithmetischen Wissenschaft — in konziseste Formeln einzukleiden und mit absoluter Konsequenz, exakt und erschöpfend zur Darstellung zu bringen.
Indem wir, etwas abweichend vom Dedekind’schen Gange, die Betrachtung der nur einseitig eindeutigen Zuordnung von Elementen eines Systems zu denen eines andern auf etwas später verschieben, beginnen wir sogleich mit der gegenseitig eindeutigen Zuordnung zwischen den Elementen zweier Systeme und dem Begriff der „ähnlichen“ Systeme D 26, 32 sowie, daran anschliessend, mit der Etablirung der auf letztere bezüglichen Sätze.
Dabei werden wir jedoch mehrere Wege auszugehen haben.
Für die Ähnlichkeitsdefinition drängen sich uns verschiedene Fassungen auf, die auch aufeinander zurückzuführen sein werden.
Notwendige und hinreichende Bedingung für die „Ähnlichkeit sive „Gleichmächtigkeit“ zweier Systeme 0) a = a ɟ 0 = a; 1, b = b ɟ 0 = b; 1 ist (stets) die Existenz, die Möglichkeit einer „ähnlichen (sive deutlichen) Abbildung“ x resp. x̆ dieser beiden Systeme aufeinander, d. i. einer gegenseitig eindeutigen Zuordnung zwischen den sämtlichen Elementen des einen und denen des andern Systems — was nun aber begrifflich noch eingehender zu erläutern bleibt.
Man kann diese Anforderung zunächst „rigoros“ formuliren als eine minimale, so nämlich, dass nicht mehr, als unbedingt erforderlich, verlangt wird, m. a. W. dass der Sachverhalt lediglich als eine „interne Angelegenheit“ der Systeme a und b in’s Auge gefasst und über das externe Verhalten des Abbildungsprinzips x nichts stipulirt wird, es also gänzlich offen gelassen wird, welche x-Bilder die Elemente von nicht-a oder ā noch innerhalb oder ausserhalb b besitzen mögen, sowie von welchen Elementen ausserhalb b (also von b̄) die Elemente sei es von a, sei es von ā auch sonst noch x-Bilder sein mögen.
Vollends: ob es in a Elemente gibt, die keine x-Bilder von andern sind, sowie ob es in b Elemente gibt, von denen kein x-Bild existirt, soll ebenfalls offen, gleichgültig bleiben.
Was verlangt wird, ist (dann) folgendes:
Zu jedem Element h von a soll es innerhalb b ein und nur ein Element k geben, welches ein x-Bild desselben ist, und umgekehrt: zu jedem Element k von b soll es innerhalb a ein und nur ein Element h geben, von welchem jenes k ein x-Bild ist.
Bei der Formulirung werden wir indess das bestimmte Zahlwort „ein (und nur ein)“ vermeiden müssen und die darauf zielende Forderung zu ersetzen haben durch eine andere als die an ihrer Statt zugrund zu legende, welche wesentlich stipulirt, dass zu Andrem (sive Verschiedenem) Andres (Verschiedenes) gehören solle.
Es liegt also wesentlich die Auflage vor:
Zu jedem h ⋹ a gibt es (ein) k ⋹ b und zu jedem k ⋹ b gibt es (ein) h ⋹ a derart dass k⋹x; h (somit h ⋹ x̆; k) ist, während zugleich die Doppelforderung erfüllt ist, die wir ad hoc — um ihren Ausdruck nicht wiederholt anschreiben zu müssen — mit Xk h bezeichnen wollen, dass nämlich [Formel]
In Zeichen drückt sich dies so aus:
[Formel]
Dies vereinfacht sich nun für die Koeffizienten unsrer Relative zu Πh(ah⋹Σkbkxk hXk h)Πk(bk⋹Σhahxk hXk h), wo Xk h = Πm(am0'm h ⋹ x̄k m)Πn(bn0'n k ⋹ x̄n h).
Oder also: Πh{āh + Σkbk(xX)k h} Πk{b̄k + Σhah(xX)k h}, wobei Xk h = Πm(x̄k m + ām + 1'm h)Πn(x̄n h + b̄n + 1'n k) = = [{x̄ ɟ (ā + 1')}{1' ɟ (b̄ + x̄)}]k h nun in der That sich als Koeffizient zum Suffix kh eines von k und h unabhängigen Relativs X nachträglich herausstellt, dessen Bedeutung ersichtlich ist.
Führen wir demnach für xX die Abkürzung y ein, wo dann sein wird: 2) y = {(ā̆ + x̄) ɟ 1'}x{1' ɟ (x̄ + b̄)} = {x̄ ɟ (ā + 1')}x{(1' + b̄̆) ɟ x̄}, so bleibt als Ausdruck unsrer Forderung: Πh(āh + Σkbkyk h)Πk(b̄k + Σhahyk h), = Πk h{(ā̆ + 1; by)(b̄ + ăy; 1)}k h — wie man sieht, wenn man sich die laufenden Zeiger k, h der Σk und Σh in l umgetauft denkt und stetsfort beachtet, dass bei Systemkoeffizienten der zweite Index, bei Systemkonverskoeffizienten der erste Index willkürlich — nach Konvenienz — angesetzt werden darf.
Letztres Π ist nun der allgemeine Koeffizient eines ausgezeichneten Relativs, das bekanntlich diesem selber gleich ist.
Mithin ist 0 ɟ αβ ɟ 0 selbst, oder wenn man will 1 ⋹ 0 ɟ αβ ɟ 0, wo α = ā̆ + 1; by = ā̆ + b̆; y, β = b̄ + ăy; 1 = b̄ + y; a der Ausdruck unsrer Forderung.
Diese zerfällt jedoch in (0 ɟ α ɟ 0)(0 ɟ β ɟ 0), was gleich (α ɟ 0)(0 ɟ β) sintemal hier α Systemkonvers und β System ist.
Zudem läuft sie auf αβ = 1 oder (1 ⋹ α)(1 ⋹ β) äquivalent hinaus.
Wir haben somit als Ausdruck derselben: {1; (ā̆ + by) ɟ 0}{0 ɟ (b̄ + ăy); 1}, = {(ā̆ + 1; by) ɟ 0}{0 ɟ (b̄ + ăy; 1)} = = (b̆; y ɟ ā)(b̄̆ ɟ y; a) = 3) (ā̆ ɟ y̆; b)(b̄̆ ɟ y; a), = (a ⋹ y̆; b)(b ⋹ y; a) — wo zur Erlangung des vorletzten Faktors blos noch die Konversion der in ă ⋹ b̆; y umgeschriebnen Bedingung 1 ⋹ α erforderlich gewesen, links zu beachten war, dass ein ausgezeichnetes Relativ seinem Konversen gleich ist.
Die Formeln 1) enthalten die Einkleidung, die 2) und 3) zusammen die Lösung unsrer Aufgabe.
Drücken wir, dass ein System a „gleichmächtig“ sive „ähnlich“ sei einem Systeme b — mit G. Cantor l. c. p. 249 — durch den Ansatz aus: a ∽ b, so erhalten wir für die Definition der Ähnlichkeit oder Gleichmächtigkeit eines Systems a mit einem System b die folgende „erste Fassung“:
(4)
[Formel] .
Dieser aber wird sich — mittelst Einführung von y statt x — eine sehr viel bequemere Form geben lassen, und zwar in äquivalenter Transformation — behaupten wir — die folgende „zweite Fassung“:
(5)
[Formel] , worin auch rechts das erste b und a durch b̆ resp. ă ersetzbar, und — gleichwie schon in (4) — die beiden letzten Subsumtionen die Kraft von Gleichungen haben müssen.
Dies ist wie folgt zu sehen.
Aus der Gleichung 2) lässt sich zunächst x eliminiren.
Man schliesst: y⋹ (ā̆ + x̄) ɟ 1', y ⋹ x, y ⋹ 1' ɟ (x̄ + b̄), oder y; 0' ⋹ ā̆ + x̄, ăx ⋹ ȳ ɟ 1', ăy ⋹ ăx, ergo ăy ⋹ ȳ ɟ 1', y̆; ăy ⋹ 1', 0'; y ⋹ x̄ + b̄, xb ⋹ 1' ɟ ȳ, yb ⋹ xb, ergo yb ⋹ 1' ɟ ȳ, yb; y̆ ⋹ 1'.
Weil aber a und b Systeme sind, so ist y̆; ăy = y̆; y · ă, yb; y̆ = b · y; y̆ und fassen sich demnach die beiden Teilresultanten zusammen zu: 61) b · y; y̆ + ă · y̆; y ⋹ 1'.
Aus dieser Resultante folgt mittelst Konversion sogleich hinzu, dass auch b̆ · y; y̆ sowie a · y̆; y ⋹ 1' sein muss, so dass man sie auch „voller“ anschreiben könnte in der Form: 6) (b + b̆) · y; y̆ + (a + ă) · y̆; y ⋹ 1', ebensogut aber auch sie schon ausreichend vertreten kann durch den Ansatz: 62) b · y; y̆ + a · y̆; y ⋹ 1'.
Diese Resultante — wie man sieht, der erste Faktor rechts in 5) — ist nun aber die volle.
Denn ist sie durch ein y erfüllt, so gibt es ein x, welches die Gleichung 2) wahr macht, und zwar in Gestalt von x = y selbst.
Dies ist so zu sehn.
Aus der konvertirten 61) b̆ · y; y̆ + a · y̆; y ⋹ 1' folgt: y̆; y ⋹ ā + 1', y; y̆ ⋹ 1' + b̄̆, y ⋹ ȳ ɟ (ā + 1'), y ⋹ (1' + b̄̆) ɟ ȳ, und somit 7) y = {ȳ ɟ (ā + 1')}y{(1' + b̄̆) ɟ ȳ} d. h. für x = y angesetzt, die Gleichung 2) in ihrer zweiten Form.
Die Gleichung 2) für ein arbiträres x angesetzt, muss demnach die allgemeine Wurzel y der Subsumtion 6) vorstellen, wobei es obendrein erlaubt sein muss: einzeln oder gleichzeitig, a durch ă sowie a + ă, und b durch b̆ sowie b + b̆ zu ersetzen.
Verwenden wir, um die chiffrirten Propositionen nicht nochmals in eckige Klammern wiederholt hineinschreiben zu müssen, für diese selbst ihre Chiffren, so ist bis jetzt erwiesen:
[Formel] dazu aber auch 6) = 7), wobei 6) = 61) = 62).
Gibt es nun ein x, welches die rechte Seite der Äquivalenz 4) wahr macht, so gibt es auch ein y, nämlich das durch 2) dargestellte, welches die rechte Seite der Äquivalenz 5) erfüllt, und umgekehrt: gibt es ein der letztern Forderung genügendes y, so auch ein der erstern genügendes x, und zwar mindestens schon in Gestalt von x gleich y.
Die Forderungen 4), 5) bedingen also einander gegenseitig oder sind äquivalent.
Falls man will, kann man auch die eine rechnerisch geradezu in die andre transformiren.
Ersetzt man z. B. in 5) den ersten Aussagenfaktor hinter dem [Formel] , welcher die Subsumtion 6) ist, durch das ihm äquivalent erwiesene [Formel] 2), so kann man diese Σ nach x auf alles folgende beziehen; macht man dann hinter dem [Formel] für y durchweg von dem ihm in 2) gleichgesetzten Ausdrucke in x als dem ausdrucksvolleren Namen Gebrauch, so wird der Aussagenfaktor 2), als eine Identität, gleich 1 und unterdrückbar, ebenso das vorangeschriebene [Formel] als gegenstandslos hinfällig, sintemal der dahinter stehende allgemeine Term konstant bezüglich y, nämlich frei davon geworden, und man hat die Äquivalenz 4).
Um jetzt zu zeigen, dass in 5) die beiden letzten Subsumtionen wie behauptet die Kraft von Gleichungen haben, müssen wir blos aus b⋹y; a und a ⋹ y̆; b vermittelst 6) auch die beiden rückwärtigen Subsumtionen ableiten.
Nun folgt zwar sogleich: y̆; b ⋹ y̆; y; a, y; a ⋹ y; y̆; b.
Doch wird es ohne einen absonderlichen Kunstgriff nicht gelingen.
Zwar lässt sich nämlich in der erstern Subsumtion das Prädikat umgestalten in: y̆; ăy; 1 = (y̆; y)ă; 1 — vergleiche über 61) — was nun kraft 61) sein wird ⋹ 1'; 1 = 1.
Doch gelangt man so blos zu dem wertlosen Schlusse:
b̆; y ⋹ 1!
Um den beabsichtigten Erfolg zu haben, muss man sozusagen eine Tautologie „begehen“ („verüben“), nämlich schreiben: y̆; b ⋹ y̆; yă; a = (y̆; y)ă; a ⋹ 1'; a = a, also y̆; b ⋹ a, y; a ⋹ y; y̆b̆; b = (y; y̆)b̆; b ⋹ 1'; b = b, „ y; a ⋹ b, q. e. d.
Wir haben also als Konsequenz zu 6) oder 2): (b ⋹ y; a) ⋹ (y̆; b ⋹ a), (a ⋹ y̆; b) ⋹ (y; a ⋹ b) und folglich auch (die Prämissen bei den Konklusionen wiederholend):
8) (b ⋹ y; a)(a ⋹ y̆; b) = (b = y; a)(a = y̆; b) sintemal diese Äquivalenz als rückwärtige Subsumtion selbstverständlich.
Um dieses und noch einige fernere Ergebnisse richtig aufzufassen, darf man folgendes nicht übersehen.
Wegen 7) darf in (4) auch x mit y identifizirt werden; allein es muss dieses nicht geschehen.
Thut man es, so wird damit auch über das „externe“ Verhalten des Abbildungsprinzips x einschränkend verfügt.
Für das lediglich den Forderungen 1) oder (4) unterworfene x sind noch Bestimmungen wie diese zulässig: 9)
[Formel] welche sich als die hier angegebnen — für a, b statt a, b̄ oder ā, b — auch weiter unten formulirt finden werden.
Dergleichen für das Abbildungsprinzip y zu fordern wäre nun nicht angängig, weil eine Forderung wie y; a ⋹ b augenscheinlich in Widerspruch mit der oben erwiesenen y; a = b treten würde.
Bei y ist also über das externe Verhalten unsres Abbildungsprinzips schon in gewissem Sinne verfügt — jedoch blos in einer Weise, von der man sicher sein darf, dass die Verfügung jederzeit getroffen werden kann, was bei der engeren Fassung des Abbildungsprinzips als einer „Substitution“, wie wir S. 596 im Kontext gesehen haben, nicht zuträfe.
Im Gegensatz zu einer Stipulation der letzteren Art müssen uns solche Einschränkungen des Abbildungsprinzips in Hinsicht seines externen Verhaltens zu den ähnlichen Systemen a, b, welche die Garantie ihrer Zulässigkeit in sich tragen, hier hochwillkommen sein, und können sie uns ähnliche Vorteile sichern, wie bei Aufgaben der analytischen Geometrie die Wahl eines passenden Koordinatensystems!
Natürlich darf jedoch (mit derartigen Verfügungen) über das interne Verhalten des Abbildungsprinzipes, d. h. über die Frage: zwischen welchen Elementen von a und welchen Elementen von b die Zuordnung bestehen solle, nichts präjudizirt werden, damit den Ergebnissen der Untersuchung die volle Allgemeinheit der Anwendung gesichert bleibe.
In dieser Hinsicht dürfte es sich empfehlen — mit G. Cantor l. c. p. 242 — die Bemerkung einzuschalten, dass, wenn zwischen den Elementen allen von a und b eineindeutige Zuordnung überhaupt auf eine Art möglich ist, dieselbe immer noch auf viele andre Weisen geschehen kann.
Und diese Frage bleibt ganz unabhängig von den „Fassungen“ in welchen wir — mit Rücksicht auf das externe Verhalten des Abbildungsprinzips — die (eine bestimmte) Zuordnungsweise formuliren mögen.
In diesem Sinne muss es nun sogleich als eine erhebliche Vereinfachung unsrer Ähnlichkeitsbedingung begrüsst werden, dass sie sich auch in der folgenden „dritten Fassung“ darstellen lässt: (10) [Formel] , welche die Existenz eines a in b abbildenden und schlechtweg, im ganzen Denkbereiche, zum Typus A2A4 des § 30 gehörigen Relativs z fordert, das auch umgekehrt (als z̆) unser b in a abbilde.
Beweis.
Es muss (10) ⋹ (5) und (5) ⋹ (10) erhärtet werden.
Gibt es nun ein (10) erfüllendes z, so gibt es auch in Gestalt von y = z ein (5) erfüllendes y, sintemal ja b · z; z̆ ⋹ z; z̆, und ebenso mit z̆; z ⋹ 1' a fortiori auch a · z̆; z ⋹ 1' gegeben ist.
Mit (10) gilt also (5).
Umgekehrt: wenn es ein (5) erfüllendes y gibt, so gibt es auch in Gestalt von 11) z = ăby, z̆ = ab̆y̆ ein (10) erfüllendes z.
Denn einerseits ist geradezu (b ⋹ y; a) = (b ⋹ b · y; a) = (b ⋹ ăby; a) = (b ⋹ z; a), (a ⋹ y̆; b) = (a ⋹ a · y̆; b) = (a ⋹ ab̆y̆; b) = (a ⋹ z̆; b), andrerseits haben wir: (b · y; y̆ + a · y̆; y ⋹ 1') ⋹ (bb̆ · y; ay̆ + aă · y̆; by ⋹ 1') = = (ăby; ab̆y̆ + ab̆y̆; ăby ⋹ 1') = (z; z̆ + z̆; z ⋹ 1') — jenes, weil ay̆ ⋹ y̆, b · y; ay̆ ⋹ b · y; y̆, etc., q. e. d.
Auf die Fassung (10) der Ähnlichkeitsbedingung kommt man auch direkt, wenn man — über das externe Verhalten des Abbildungsprinzips x in 1) in etwas verfügend — bei der Formulirung der dortigen Doppelforderung Xk h die beschränkenden Voraussetzungen m ⋹ a und n ⋹ b fallen lässt (wogegen die h ⋹ a und k ⋹ b noch bestehen bleiben), was denselben Effekt haben muss, als wenn man dort (bei Xk h) a = b = 1 genommen hätte. M. a. W.: wenn man die Verschiedenheit der x-Bilder zu verschiednen der in Betracht kommenden Objekte, und der Objekte zu verschiednen der in Betracht kommenden x-Bilder, nicht blos für die Elemente von b resp. von a, sondern für die Elemente des ganzen Denkbereiches von vornherein fordert.
An Stelle von 1) erhalten wir dann: 12) [Formel] und an Stelle von 2) weit einfacher: 13) y = (x̄ ɟ 1')x(1' ɟ x̄), an Stelle von (4) also als „vierte Fassung“ der Ähnlichkeitsbedingung: (14) [Formel] , worin das x nun allerdings ein andres, beschränkteres Relativ sein wird, als das x in den früheren Formeln, jedoch — in 12) bis 14) das x auch durchweg mit unserm z identifizirt werden darf.
Wir werden die Formeln so (für z statt x angeschrieben gedacht) zuweilen citiren, und ist namentlich zu beachten, dass gleichwie die Forderung 12) — mit davor geschriebnem [Formel] — sich in die rechte Seite der Ähnlichkeitsbedingung (14) oder (10) äquivalent hat umschreiben lassen, so auch umgekehrt die folgerungen 12) (in z angeschrieben) mittelst äquivalenter Transformation aus (10) hervorzugehen nicht verfehlen können.
Zur Entdeckung des Zusammenhanges 11) zwischen y und z, und damit zur Fassung (10), kann man endlich auch von (5) aus heuristisch gelangen, indem man über y gewisse „externe“ Verfügungen trifft, nämlich die „adventive“ forderung aufstellt: dass die ausserhalb a befindlichen Elemente des Denkbereichs, die Elemente von ā, gar keine y-bilder haben, sowie die ausserhalb b befindlichen oder Elemente von b̄ gar keine y-Bilder sein sollen.
Solches drücken die beiden Ansätze aus: 15) Πh{(h⋹ā) ⋹ (y; h = 0)} = 0 ɟ ȳ ɟ a = (y ⋹ ă), Πk{(k ⋹ b̄) ⋹ (ȳ; k = 0)} = 0 ɟ ȳ̆ ɟ b = (y ⋹ b), deren Begründung gemäss ϱ) S. 557 mit Πh{āh⋹ (ȳ̆ ɟ 0)h} = Πh(a + ȳ̆ ɟ 0)h = 0 ɟ (a + ȳ̆ ɟ 0) = ă ɟ ȳ̆ ɟ 0, etc. leicht zu geben ist.
Werden beide Anforderungen gleichzeitig gestellt, so folgt also y⋹ăb oder y = ăby = z, d. h. es kann das genannter Auflage unterworfene y als unser z bezeichnet werden.
Für dieses z gilt natürlich dann auch 16) z⋹ăb oder z = ăbz, und z; ā = 0, z̆; b̄ = 0 — sintemal letztres nach dem ersten Inversionstheoreme auf z ⋹ 0 ɟ ă = ă, z̆ ⋹ 0 ɟ b̆ = b̆, z ⋹ b hinausläuft.
Noch einfacher kann aber mit z ⋹ ă, ā̆z = 0 auch geschlossen werden z; ā = ā̆z; 1 = 0; 1 = 0, etc.
Diese Relationen 16) lassen zwar keineswegs schon aus der rechten Seite von (10) sich ableiten Ein unsrer dritten Fassung (10) genügendes z braucht sie nicht zu erfüllen.
Allein, wenn es ein ihr genügendes z überhaupt gibt, so gibt es auch in Gestalt von ăbz ein solches Relativ welches, wenn einfach z genannt, neben (10) die Relation 16) noch obendrein erfüllt.
Wir können daher diese Relation 16) in die Ähnlichkeitsbedingung (10) als eine adventive Forderung noch mit aufnehmen, und gelangen zur folgenden „fünften Fassung“ der Ähnlichkeitsdefinition D 32: (17) [Formel] , in der durch die weitestgehenden, maximalen Anforderungen das Abbildungsprinzip am meisten eingeschränkt, am engsten gefasst erscheint: als ein solches, welches populär zu reden die Elemente von a und b, und nur diese, einander (irgendwie gegenseitig eindeutig) zuordnet.
[Aus dieser Zuordnung müssen alle erdenklichen der gleichen Einschränkung unterworfnen Zuordnungen zwischen den Elementen der beiden Systeme durch blosse Permutation der Elemente des einen von ihnen hervorgehn.]
Die Fassung (17) wollen wir die Normalform der Ähnlichkeitsdefinition nennen.
Man unterscheidet in ihr vier Teilbedingungen, deren erste als die „Charakteristik“ des Abbildungsprinzips bezeichnet werden kann, während die letzte eine „Adventivbedingung“ dazu vorstellt; die beiden andern mögen die „Hauptbedingungen“ heissen.
Aus unsrer Normalform (17) erhellt zugleich: dass dem Begriff der Ähnlichkeit zwischen zwei Systemen a, b keine „Relativität“ (im Sinne Hoppe’s) zufolge der Bezugnahme auf einen bestimmten, nämlich den zugrunde gelegten Denkbereich anhaftet.
Denn jedem Denkbereiche 11, in welchem die Ähnlichkeit von a und b auch immer statuirt werden möge, müssen doch die Elemente von a und b selbst zum allerwenigsten angehören, und dem zugehörigen 12 gehören also auch die Systeme a, b sowie deren Konverse an.
Da nun unser z in (17) ganz und gar eingeordnet dem Augenquaderrelativ ăb ist, so wird es, wenn in irgend einem, so auch in jedem solchen Denkbereiche 12 ein Relativ z geben, das die Bedingungen (17) erfüllt.
Die Bevorzugung der Normalform — oder manchmal auch schon der Form (10) — erleichtert alle Beweisführungen für die Sätze, die wir jetzt aufzustellen haben.
Als ein erstes Korollar zu (17) resp. (10) haben wir den Satz: 18) a ∽ a d. h. Jedes System ist sich selber ähnlich, m. a. W. die Beziehung der Ähnlichkeit gehört zu den selbstrelativischen.
Beweis aus (10) durch den Hinweis darauf, dass für b = a schon die identische Abbildung z = 1' den Bedingungen der Ähnlichkeitsdefinition genügt, q. e. d.
Behufs Beweises aus (17) muss die eben erwähnte schlechtweg (oder im absoluten Sinne) „identische“ Abbildung ersetzt werden durch eine (in relativem Sinne nämlich blos) „binnen a identische“ Abbildung z = a1' = = ă1' = ăa1', und hat man nachzusehen, dass sowol a = ă1'; a = a1'; a = = a · 1'; a = aa = a, als auch ă1'; a1' = a1'; ă1' = a · 1'; 1' · ă = a1'ă ⋹ 1' identisch ist, während auch die Adventivforderung ăa1' ⋹ ăa sich augenscheinlich erfüllt.
Als zweites Korollar gilt der Satz: 19) (a ∽ b) = (b ∽ a) d. h. die Ähnlichkeit ist eine symmetrische sive gegenseitige Beziehung.
Wenn a ähnlich b ist, so muss auch b ähnlich a sein und umgekehrt Dieser Umstand gibt uns erst das Recht zu sagen: die Systeme a und b seien „einander ähnlich“.
Zum Beweise genügt die Wahrnehmung, dass die rechte Seite von (10) oder (17), und zwar zunächst das Aussagenprodukt, welches das allgemeine Glied der Summe nach z ebenda bildet, nur in sich selbst übergeht, wenn man a mit b und zugleich z mit z̆ vertauscht.
Der erste Aussagenfaktor, der das Abbildungsprinzip z charakterisirt, geht durch letztere Vertauschung nur in sich selbst über.
Der zweite und dritte Aussagenfaktor wechselt den Platz.
Bei (17) geht die vierte zur Charakterisirung des z hinzugekommne (adventive) Faktoraussage in die beiderseits konvertirte und damit äquivalente über.
Freilich verkehrt sich aber die Σ nach z in eine solche nach z̆.
Dies muss indessen irrelevant sein.
Denn wenn es einen Wert, ein Relativ gibt, welches irgend eine für z stipulirte Forderung erfüllt, so muss es auch — in Gestalt von dessen Konversem — ein Relativ geben, welches ebendiese für z̆ formulirt gedachte Forderung erfüllt.
[Jede Bedingung für z kann ja — indem man z = w̆, z̆ = w nennt — auch angesehen werden als eine Bedingung (für w, mithin) für z̆.]
D 33. Satz.
Die Ähnlichkeit ist auch eine transitive Beziehung, m. a. W. Sind a, b ähnliche Systeme, so ist jedes mit b ähnliche System auch mit a ähnlich: 20) (a ∽ b)(b ∽ c) ⋹ (a ∽ c),
Ähnliches mit Ähnlichem ist Ähnliches.
Beweis.
Dass — im Hinblick auf (17):
[Formel] sein müsse, folgt durch die Wahrnehmung, dass unter den linkseitigen Voraussetzungen gewiss z = y; x, z̆ = x̆; y̆ den Forderungen rechterhand genügt, und zwar der ersten, wie implicite schon im § 30 gezeigt ist, hier aber mit: y; x; x̆; y̆ + x̆; y̆; y; x ⋹ y; 1'; y̆ + x̆; 1'; x = y; y̆ + x̆; x ⋹ 1' nochmals gezeigt werden mag; den beiden folgenden mit c = y; x; a und a = x̆; y̆; c, wie durch Einsetzung, Elimination von b aus den Prämissengleichungen ersichtlich; endlich der letzten, adventiven, mit y; x ⋹ ăc, weil aus y ⋹ c, x ⋹ ă folgt: y; x ⋹ c; ă = că, q. e. d.
Diese letzte Betrachtung, gleichwie die Mitanführung der drei adventiven Forderungen, konnte bei Berufung auf (10) statt (17) auch (wenn man will) gespart werden. —
Versucht man jedoch, den Transitivitätsbeweis auf eine der übrigen Fassungen der Ähnlichkeitsdefinition zu gründen — einschliesslich einer weiter unten gegebnen (39) — so stösst man auf grosse Schwierigkeiten.
Leicht zwar sind für das Abbildungsprinzip z, das als y; x aus den beiden in unsern Prämissen vorausgesetzten Abbildungsprinzipien sich zusammensetzt, wiederum die beiden Forderungen als erfüllt nachzuweisen, welche in solchem Falle die obigen Gleichungen oder Subsumtionen c ⋹ z; a und a ⋹ z̆; c vertreten.
Dagegen gelingt solches zumeist nicht für denjenigen Teil der resultirenden Ähnlichkeitsbedingung, welcher als die Charakteristik dieses zusammengesetzten Abbildungsprinzips erwartet werden sollte und dann die Stelle „der Forderung A2A4 mitnebst der Adventivforderung in unsrer Normalform der Ähnlichkeitsbedingung“ vertreten wird.
Dies kann nur daran liegen, dass das „externe Verhalten“ des z = y; x inbezug auf a und c nicht von derselben Art ist, wie das für x inbezug auf a und b sowie das für y inbezug auf b und c vorausgesetzte — ein Umstand, der wol verdiente in ferneren Forschungen noch eingehender verfolgt und völlig aufgehellt zu werden. —
Der hier von uns zu 20) gegebne Beweis unterscheidet sich nicht unwesentlich von Dedekind’s Gedankengang bei seinem Beweise zu D 33 aufgrund des die Zusammensetzung zweier ähnlichen Abbildungen zu einer dritten statuirenden Satzes D 31 — wo er auf die Elemente argumentirend vorgeht.
Auf diesen kommen wir, nachdem wir etwas weiter ausgeholt haben werden, weiter unten S. 621 zurück.
Wir dürfen nun im Fall des Erfülltseins der Prämissen von 20) auch die drei Systeme a, b, c einander ähnlich nennen.
Und durch eine Wiederholung der Schlüsse, wie sie inbezug auf Gleichungen geläufig sind, für unsre Ähnlichsprechungen oder Ähnlichkeitsbehauptungen gelangt man leicht zur Ausdehnung dieses Begriffes des „Einanderähnlichseins“ von dreien auf eine beliebige Menge, eventuell auch ein unbegrenztes System von „Systemen“ — als eines Begriffes, der unabhängig ist von der Reihenfolge ihrer Aufzählung oder Namhaftmachung.
D 34. Erklärung.
Man kann daher alle Systeme in Klassen einteilen, indem man in eine bestimmte Klasse alle und nur die Systeme (a), b, c, … aufnimmt, welche einem bestimmten System a, dem Repräsentanten der Klasse, ähnlich sind; nach dem vorhergehenden Satze D 33 ändert sich die Klasse nicht, wenn irgend ein andres ihr angehöriges System b als Repräsentant gewählt wird.
D 35. Satz.
Sind a, b ähnliche Systeme, so ist jedes Teilsystem von a auch einem Teilsystem von b, jedes echte Teilsystem von a einem echten Teilsystem von b ähnlich: 21) [Formel] , 22) [Formel] .
Will man, dass a, b, c, d als Systeme zu denken seien, auch in die Formeln aufnehmen, so braucht man nur deren Namen — mit Ausnahme des d unter dem Σ — durch resp. a; 1, b; 1, c; 1, d; 1 zu ersetzen.
Beweis des ersten Satzes.
Zu den Voraussetzungen gehört:
[Formel] , wobei die — unterwellte — Adventivforderung auch unberücksichtigt bleiben könnte und vorerst bleiben möge.
Ist nun ferner c ⋹ a, so kann man z; c = d nennen, dann folgt: z; c ⋹ z; a, also d⋹b, b = d + b = d + d̄b.
Weiter kann man (was imgrunde überflüssig) mit z̆; d = z̆; z; c ⋹ 1'; c = c auch leicht die Einordnung:
z̆; d ⋹ c beweisen.
Wichtiger, und nicht ganz so nahe liegend ist der Beweis der umgekehrten Subsumtion, welche ja dann ohnehin die Kraft einer Gleichung besitzen muss.
Er gelingt (ohne Argumentiren auf Elemente) wie folgt.
Nach η) des § 30, S. 555 ist die in der obigen Gleichung mitgegebene Subsumtion z; c ⋹ d äquivalent mit z̆; d̄ ⋹ c̄.
Darnach aber rechtfertigt sich der letzte von den nachstehenden Schlüssen: c⋹a = z̆; b = z̆; d + z̆; d̄b ⋹ z̆; d + z̆; d̄ ⋹ z̆; d + c̄ und mit c ⋹ z̆; d + c̄ ist denn in der That gerechtfertigt dass: c⋹z̆; d.
In Zusammenstellung der gewonnenen Schlüsse haben wir also: d⋹b und (z; z̆ + z̆; z ⋹ 1')(c = z̆; d)(d = z; c), d. h. c ∽ d, q. e. d.
Die in der normalen Ähnlichkeitsbedingung für c und d vorgesehene Adventivforderung z ⋹ c̆d ist durch das bisherige z, welches a und b „normal“ aufeinander abbildet, nicht erfüllt.
Will man auch ihr genügen, so braucht man blos c̆dz als ein neues z einzuführen. —
Dass für die mit z, z̆ ähnlich aufeinander abgebildeten gleichmächtigen Systeme a und b mit 23)
c⋹a und z; c = d immer z̆; d = c und d ⋹ b — sowie umgekehrt — gegeben ist, thut man vielleicht gut, sich als Korollar des Satzes noch besonders zu merken. —
Die Umkehrung folgt — wofern man nicht zu den gegebnen völlig analoge Schlüsse durchführen will — aus der Symmetrie der Prämissen hinsichtlich der Relative b, d, z und a, c, z̆.
Bei dem zweiten Satze, 22), tritt einfach zur Hypothesis von 21) noch die Annahme c ≠ a als ein Aussagenfaktor hinzu, und ebenso zur Thesis hinter dem Summenzeichen noch die Behauptung d ≠ b.
Diese kann leicht apagogisch bewiesen werden.
Wäre nämlich d = b, so hätten wir mit z; c = d nach Obigem auch c = z̆; b = a also c = a im Widerspruch gegen die Annahme.
Auch die vorstehenden Beweise differiren wesentlich von denen Dedekind’s zu D 35 — auf die wir weiter unten S. 622 auch noch eingehen wollen.
Mit dem Bisherigen jedoch erscheinen bereits die wichtigsten Sätze dieses Autors über ähnliche Abbildung und ähnliche Systeme — diejenigen, denen die andern blos zur Vorbereitung dienten — aus dem eingangs abgegrenzten Teile seiner Schrift in unsre Disziplin aufgenommen und in ihrem Geiste gerechtfertigt, legitimirt!
Nichtsdestoweniger haben wir noch eine ganze Reihe von Studien zu der Materie beizubringen.
Um bei jeder ähnlichen Abbildung „Argumentationen auf die Elemente“ zu erleichtern oder für unsre Disziplin zu legitimiren, dürften — in Ergänzung zu 42) des § 30 — die folgenden Betrachtungen von Belang sein.
Unter den in (17) statuirten Voraussetzungen gilt: 24) [Formel] wo die Subsumtion der zweiten Zeile blos als äquivalente Form der darüberstehenden in Erinnerung gebracht sein soll.
Wir wollen dies zunächst (auf eine Weise) für das untere oder Subsumtionszeichen beweisen.
Sind h, k Elemente und ist k ⋹ z; h, so muss erstens h ⋹ a sein.
Denn wäre h ⋹ a, so hätten wir h ⋹ ā und z; h ⋹ z; ā, was ⋹ 0 nach 16) sein muss; wir kämen damit auf den Widerspruch k ⋹ 0, q. e. d.
Zweitens muss k ⋹ b sein; denn andernfalles gälte mit k ⋹ b̄ auch z̆; k ⋹ z̆; b̄ = 0 und damit h ⋹ 0, was unmöglich — q. e. d. Endlich folgt nicht minder: z̆; k ⋹ z̆; z; h ⋹ 1'; h = h, wie z; h ⋹ z; z̆; k ⋹ 1'; k = k, q. e. d.
Bei (17) müssen also Einordnungen wie (k ⋹ z; h), = (z; h = k), (h ⋹ z̆; k), = (z̆; k = h) allemal die Kraft von Gleichungen haben, Gleichungen wie die beiden in (z; h = k) = (z̆; k = h) einander äquivalent sein.
Was aber die Einordnungen der umgekehrten Form z; h ⋹ k betrifft, so hatten wir nach ϑ) des § 30: (z; h ⋹ k) = (z; h = 0) + (z; h = k), ebenso (z̆; k ⋹ h) = (z̆; k = 0) + (z̆; k = h).
Soferne h nicht dem a resp. k nicht dem b angehört, kann alsdann nur — und muss kraft 16) — die erste Alternative rechts eintreten.
Um hingegen den Schluss auf die zweite Alternative, d. i. die letzte Gleichung ziehen zu können, werden wir sonach der Prämisse noch die Voraussetzung h ⋹ a resp. k ⋹ b beizufügen haben. D. h.
Es ist weiter zu statuiren der Satz: 25) Πh k{(z; h ⋹ k)(h ⋹ a) ⋹̿ (k ⋹ b)(k ⋹ z; h)}{(z̆; k ⋹ h)(k ⋹ b) ⋹̿ (h ⋹ a)(h ⋹ z̆; k)} — wobei die rückwärtigen Subsumtionen bereits mit der vorwärtigen 24) a fortiori bewiesen erscheinen.
Ebenso ist klar, dass mit 25) auch 24) als rückwärtige Subsumtion, also Gleichung, mitbewiesen sein wird.
Der Beweis von 25) kann wiederum durch reductio ad absurdum strenge geführt werden wie folgt — obwol er mich in methodologischer Hinsicht so noch nicht ganz befriedigt:
Wäre bei h ⋹ a etwa z; h = 0, so erhielten wir — weil nach 1) für z gleichwie für x sein muss: (h ⋹ a) ⋹ Σk(k ⋹ b)(k ⋹ z; h) — für das die rechte Seite wahr machende k [welches von dem in 25) vorkommenden unabhängig, vielleicht verschieden, zu denken] den Schluss k ⋹ z; h ⋹ 0, also k = 0 im Widerspruch mit dem bekannten Satze k ≠ 0, q. e. d. Ebenso, wenn z̆; k = 0 und k ⋹ b sein sollte, so müsste ein h ⋹ a existiren, welches verschwände, was widersinnig, q. e. d.
Unter den Annahmen h ⋹ a und k ⋹ b, oder wenigstens einer bestimmten von ihnen, muss daher Äquivalenz bestehen zwischen je zweien, mithin sämtlichen von den sechs Propositionen der folgenden Thesis: 26) [Formel] .
Dies — 24) bis 26) — alles formulirt gibt eine Reihe von als gültig (d. i. = 1) erkannten ausgezeichneten Relativen.
Indem wir dieselben aufstellen, und zusehn, wie sie sich auch ohne Koeffizientenevidenz aus der Ähnlichkeitsdefinition ableiten lassen, werden wir unser Erkenntnisskapital über die ähnliche Abbildung z vermehren und zugleich die obigen paar apagogischen Beweise durch bessere, direkte ersetzen.
24) als vorwärtige Subsumtion gibt nach ο) des § 30: Πh k{z̄k h + ahbk(1' ɟ z̄)k h(1' ɟ z̄̆)h k} = Πh k{z̄ + ăb(z̄ ɟ 1')(1' ɟ z̄)}k h = = 0 ɟ {idem} ɟ 0 = {z ⋹ ăb(z̄ ɟ 1')(1' ɟ z̄)}.
Im zweiten Glied der (zweiten oder dritten) geschweiften Klammer kann man aber den Faktor z (als das Negat des ersten Gliedes) zufügen, und da (z̄ ɟ 1')z(1' ɟ z̄) = z nach der Charakteristik von A2A4 in (17) ist — vergl. die auch für x = y = z gültige Formel 13) — so läuft die Behauptung auf 0 ɟ (z̄ + ăbz) ɟ 0, = 0 ɟ (z̄ + ăb) ɟ 0 = (z ⋹ ăb), d. i. auf die Adventivbedingung hinaus.
Auch in ihrer letzen obigen Form zerfällt sie in die evidentermaassen gültigen Teilsubsumtionen z⋹ă, z⋹b, z⋹z̄ ɟ 1', z = 1' ɟ z̄, q. e. d.
Die erste Behauptung 25) als Subsumtion formulirt sich gemäss ο) § 30 zu: Πh k{(1' ɟ z̄)k hah ⋹ bkzk h} = Πh k{(0'; z)k h + āh k + (bz)k h} = = Πk h(0'; z + ā̆ + bz)k h = 0 ɟ (ā̆ + bz + 0'; z) ɟ 0 = = {0 ɟ (ā̆ + b + 0'; z) ɟ 0}{0 ɟ (ā̆ + z + 0'; z) ɟ 0} = (b̆ ɟ 0'; z ɟ ā)(1; z ɟ ā) = = (ā̆ ɟ z̆; 0' ɟ b)(ā̆ ɟ z̆; 1) = (ăb̄ ⋹ 0'; z)(ă ɟ 1; z) = (ab̄̆ ⋹ z̆; 0')(a ⋹ z̆; 1).
Ebenso, nur a mit b zugleich z mit z̆ vertauscht, die zweite Behauptung 25) zu: (b̄̆ ɟ z; 0' ɟ a)(b̄̆ ɟ z; 1) = (ā̆b ⋹ z; 0')(b ⋹ z; 1).
Von den vier Ergebnissen rechtfertigen sich nun die beiden folgenden sogar als Gleichungen: 25α) a = z̆; 1, b = z; 1 gemäss 16) leicht mit a = z̆; b = z̆; b + 0 = z̆; b + z̆; b̄ = z̆; (b + b̄) = z̆; 1, b = z; a = z; a + z; ā = z; 1.
Die beiden andern können mit Rücksicht hierauf, weil z; 0' ⋹ z; 1 = b, 0'; z ⋹ 1; z = ă, sogleich zu den Doppelsubsumtionen ergänzt werden 25β) ā̆b⋹z; 0' ⋹ b, ăb̄ ⋹ 0'; z ⋹ ă und beweisen sich ihre ersten Teile in den Formen b ⋹ z; 0' + ă, a ⋹ z̆; 0' + b̆ wie folgt: b = z; 1 = z; 0' + z ⋹ z; 0' + 1; z = z; 0' + ă, a = z̆; 1 = z̆; 0' + z̆ ⋹ z̆; 0' + 1; z̆ = z̆; 0' + b̆, q. e. d.
Diese Beweise von 24), 25) müssen als befriedigende anerkannt werden.
[Um möglichst versirt zu sein, formulire man diese Behauptungen auch unter Benutzung des Schemas ξ) statt ο) des § 30).
Man findet auf Umwegen und unter Benutzung leicht erweislicher Hülfssätze, wie Πi(ĭ; a + ī̆; b) = 0 ɟ (a + 0'; b), Πia; i = a ɟ 0 dieselben ausgezeichneten Relative, wie oben.]
Was endlich 26) betrifft, so möge die Thesis der Aussagensubsumtion hinter dem Πzeichen Zk h genannt werden.
Dann soll gezeigt werden, dass: Πh k(ahbk⋹Zk h), = Πh k(āh + b̄k + Zk h) = Πk h(ā̆ + b̄ + Z)k h = = 0 ɟ (ā̆ + b̄ + Z) ɟ 0 = b̄̆ ɟ Z ɟ ā = (b; 1; ă ⋹ Z) = (ăb ɟ Z).
Für Z können wir nun nach φ6) des § 30 das alle übrigen unter den Chiffren φ) ebenda in sich zusammenfassende Relativ nehmen:
Z = z; 0' · z̄ · 0'; z + (z̄ ɟ 1')z(1' ɟ z̄) = z; 1; z · {z̄ + (z̄ ɟ 1')(1' ɟ z̄)}.
Alsdann zerfällt die Behauptung ăb ⋹ Z in: 26α) ăb⋹z · 1, ăb ⋹ 1; z, ăb ⋹ z̄ ɟ 1' + z̄, ăb ⋹ z̄ + 1' ɟ z̄, welche Teilforderungen man auch erhält, wenn man Z identifizirt mit den ersten vier der 6 Relative φ) § 30 — immer z für das dortige a gesagt.
Durch deren zwei letzte kommt noch hinzu: 26β) ăb⋹z̄ ɟ 1' + 0'; z, ăb ⋹ z; 0' + 1' ɟ z̄, und sollen alle 6 Relationen sofort aus den in der normalen Ähnlichkeitsbedingung (17) über z enthaltnen Voraussetzungen direkt gerechtfertigt werden.
Die beiden ersten 26α) verstehen sich wegen ăb ⋹ b und ⋹ ă aus 25α) von selbst, die beiden letzten 26α) daraus, weil ihr Prädikat nach der Charakteristik z ⋹ z̄ ɟ 1', etc. von z gleich 1 sich erweist.
Endlich von den beiden 26β) als ăb · z; 0' ⋹ 0'; z, ăb · 0'; z ⋹ z; 0' ist die erste wegen 25α) äquivalent mit: z; 1 · 1; z · z; 0' = z; 0' · 1; z = z; 0' · (z + 0'; z) = z; 0' · 0'; z ⋹ 0'; z — weil auch z; 0' · z = 0 gewesen; ebenso die zweite mit z; 0' · 0'; z ⋹ z; 0' — was ersichtlich, q. e. d.
Man kann auch so nachweisen, dass unser Z über 26α) die Eigenschaft hat dass Z ⋹ (z; 0' + 1' ɟ z̄)(z̄ ɟ 1' + 0'; z), also Z = Z mal der rechten Seite ist: Wir müssen haben Z · (z̄ ɟ 1') · 0'; z = 0, denn wegen Zusammentreffens von 1' ɟ z̄ mit 0'; z fällt zunächst das zweite Glied von Z weg und in der einen angegebnen Form des ersten trifft dann noch z; 1 · z̄ = z; 0' · z̄ mit z̄ ɟ 1' zusammen.
Etc. q. e. d.
In seiner Erklärung D 26 der ähnlichen Abbildung von a (in b) hat Dedekind das Wesen derselben, wodurch sie sich vor der blos eindeutigen Abbildung hervorthut, darein verlegt: dass verschiednen Elementen von a stets verschiedne Bilder entsprechen sollen, folglich — wie apagogisch einzusehn: die Gleichheit der Bilder zweier Elemente h, k von a stets die Identität dieser Elemente nach sich zieht.
Indem wir auch dies formuliren, erhalten wir den Satz: 27) Πh k{(h + k ⋹ a)(z; h = z; k) ⋹ (h = k)}, also nach ψ) des § 30: Πh k[ahak{(z̄̆ ɟ z)(z̆ ɟ z̄)}h k ⋹ 1'h k] = Πh k{āh k + āk h + (z̆; z̄ + z̄̆; z)h k + 1'h k} = = 0 ɟ (ā + ā̆ + z̆; z̄ + z̄̆; z + 1') ɟ 0 = ā̆ ɟ (z̆; z̄ + z̄̆; z + 1') ɟ ā = (a; 1; ă ⋹ z̆; z̄ + z̄̆; z + 1').
Es erscheint mithin: 27α) 0'aă ɟ z̆; z̄ + z̄̆; z als die konziseste Einkleidung in die Zeichensprache unsrer Algebra für die oben aufgestellte Forderung.
Blos mit z; h ⋹ z; k als zweiter Prämisse gilt sogar 27) — cf. χ) des § 30 — schon als 27β) 0'aă ⋹ z̆; z̄.
Diese Relation kann dann noch — wie weiter unten bei 31) zu finden — mit der durch Konversion aus ihr hervorgehenden 0'aă ⋹ z̄̆; z vereinigt werden, und wie für a und z mit 27, ‥ 27β), so werden auch in b und z̆ drei analoge Formeln gelten.
Da wir eine etwas andre Fassung der Ähnlichkeitsdefinition zugrunde gelegt haben, so müssen wir nun aus der unsrigen den Satz 27β) beweisen, mit dem die zwei vorhergehenden a fortiori gegeben sind.
Dies geht sehr leicht wie folgt.
Aus der Identität 0'aă ⋹ 0'a geht durch Einsetzung rechterhand von a = z̆; 1 = z̆; (z̄ + z) aus 25α) hervor: 0'aă ⋹ 0' · (z̆; z̄ + z̆; z), wo nun wegen z̆; z ⋹ 1' das letzte Glied wegfällt, und im verbleibenden ersten rechts der Faktor 0' als selbstverständlich unterdrückbar ist — q. e. d. Aufgrund von 27) aber können wir nun auch die Sätze D 27 bis 30 in Dedekind’s Argumentation erledigen.
Unter c = c; 1, d = d; 1 Systeme verstanden, ist 28) D 27. (c + d ⋹ a)(z; c ⋹ z; d) ⋹ (c ⋹ d), (c + d ⋹ b)(z̆; c ⋹ z̆; d) ⋹ (c ⋹ d), 29) D 28. (c + d ⋹ a)(z; c = z; d) ⋹ (c = d), (c + d ⋹ b)(z̆; c = z̆; d) ⋹ (c = d) für uns der Ausdruck der beiden erstgenannten.
Beweis zu 28).
Denn wenn h ein Element von c also auch von a ist, so ist z; h ein Element von z; c also auch von z; d, mithin = z; k, wo k ein Element von d also auch von a ist.
Da aber aus z; h = z; k nach 27) immer h = k folgt, so ist jedes Element h von c auch Element von d, wie zu beweisen war.
Mit Rücksicht auf die Definition (1) der Gleichheit ist der nächste Satz, D 28, sodann ein ganz nahe liegendes Korollar des vorhergehenden.
Die Voraussetzungen c + d ⋹ a, etc. dürfen hierbei nicht unterdrückt werden, denn da die z-Bilder für alle ausserhalb a befindlichen Elemente (wegen z; ā = 0) verschwinden, so bräuchte in der That ein dem a nicht angehöriger Teil von c durchaus nicht in d enthalten zu sein.
Anders beim nächsten Satze, weil da die z-Bilder der ausserhalb a befindlichen Teilsysteme von c, d, cd, … ohnehin wegfallen: 30) D 29. z; cd ‥ = z; c · z; d …, z̆; cd ‥ = z̆; c · z̆; d …
Diese Gleichungen verstehen sich als vorwärtige Subsumtionen nach 5) des § 6 ohnehin.
Um sie als rückwärtige zu beweisen, kann man mit Dedekind überlegen:
Jedes Element von z; c · z; d … ist jedenfalls in z; a enthalten, also das Bild k = z; h eines in a enthaltnen Elements h. Da aber z; h gemeinsames Element von z; c und z; d, ‥, so muss nach 28) h gemeinsames Element von c und d, ‥ sein.
Mithin ist jedes Element k von z; c · z; d … das z-Bild eines Elementes h von cd ‥, also Element von z; cd ‥ — q. e. d.
Zweifellos würden sich für die drei letzten Sätze mit vorangeschriebnem Π nach c, d, ‥ auch noch andre analytische Beweise, die, statt auf die Elemente zu argumentiren, mehr rechnerisch zuwerke gingen, liefern lassen.
Mit 30) erscheint eine Bemerkung auf S. 354 oben gerechtfertigt.
Der Satz D 30 statuirt blos, dass die identische Abbildung eines Systems a auch eine ähnliche Abbildung desselben sei — und ist für uns nicht minder selbstverständlich.
In b hinein ist eine solche jedoch nur möglich soferne a ⋹ b ist.
Ist a ∽ b und das Abbildungsprinzip z durch die normalen Bedingungen (17) charakterisirt, so darf man überhaupt von jeder der nachfolgend im Überblick zusammengestellten Relationen Gebrauch machen: 31) [Formel] [Formel] [Formel] . Von diesen zur Bequemlichkeit des Studirenden hier zusammengestellten Formeln sind die ersten lediglich aus Früherem resumirt, resp. aus der Charakteristik und Adventivbedingung ersichtlich folgend — mit Rücksicht auch auf 6), 8) des § 30.
Die vom Striche ab werden dagegen erst in einer weiter unten folgenden Untersuchung gewonnen.
Die beiden letzten Zeilen über dem Striche ergeben sich so.
Aus z ⋹ z̄ ɟ 1' folgt z ɟ 1' ⋹ z̄ ɟ 1' ɟ 1' = z̄ ɟ 0*, sofern der Denkbereich aus mehr als zwei Elementen besteht.
Ist aber zeilenschematisch z = 1αβγ0, so läuft die Forderung z ɟ 1' ⋹ z̄ ɟ 0 als 1ᾱ000 ⋹ 00001 auf z ɟ 1' ⋹ 0 augenscheinlich hinaus.
Und wegen z ɟ 0 ⋹ z ɟ 1' ist dann auch a fortiori z ɟ 0 = 0. Wegen z; z̆ ⋹ 1' folgt dann ebenso z ɟ z; z̆ ⋹ z ɟ 1' = 0. Etc.
Noch haben wir mit einer — (die „explizite“ vorbehalten) letzten — Fassung der Ähnlichkeitsdefinition Bekanntschaft zu machen:
Man kann die vier Bedingungen, aus denen sich die Forderung der ähnlichen Abbildung von a in b zusammensetzt, auch einzeln formuliren (analog den A1 bis A4 des § 30) und sie dann erst nachträglich zusammenfassen.
Es bedeute:
γ1 die Bedingung:
Zu jedem Element h von a gibt es mindestens ein Element k von b derart, dass k ⋹ x; h,
γ2 = Zu jedem Element h von a gibt es höchstens ein Element k von b so, dass k ⋹ x; h,
γ3 = Zu jedem Element k von b gibt es mindestens ein Element h von a so, dass k ⋹ x; h,
γ4 = Zu jedem Element k von b gibt es höchstens ein Element h von a derart, dass k ⋹ x; h.
So ist
32)
[Formel]
Man findet dann (siehe Kontext weiter unten): 33) [Formel]
Doch lassen sich für γ2 und γ4 alsbald auch noch die einfacheren Ausdrucksformen gewinnen: 34) [Formel] oder auch: 35) [Formel]
Begründung.
Diese braucht nur für γ1 und γ2 selbständig gegeben zu werden, weil aus den für diese beiden Bedingungen erlangten Ausdrucksformen und Sätzen diejenigen für γ3 und γ4 durch die Vertauschung von a, h, m, x mit resp. b, k, n, x̆ hervorgehn, wie ein Blick auf 32) erkennen lässt, sobald man sich bei γ3 und γ4 die Aussagen k ⋹ x; h und k ⋹ x; m in die damit äquivalenten h ⋹ x̆; k und m ⋹ x̆; k umgeschrieben denkt.
Nach 32) haben wir nun in den Koeffizienten:
γ1 = Πh(ah ⋹ Σkbkxk h) = Πh(āh + Σkbk hxk h) = Πi h{āh i + (1; bx)i h} = = Πi h(ā̆ + 1; bx)i h = 0 ɟ (ā̆ + 1; bx) ɟ 0 = (ā̆ + 1; bx) ɟ 0 = b̆; x ɟ ā = = ā̆ ɟ x̆; b = (1 ⋹ ā̆ ɟ x̆; b) = (a; 1 ⋹ x̆; b) = (a ⋹ x̆; b),
γ2 = Πh k n(ahbkxk hbn0'n k ⋹ x̄n h) = Πh k{āh + b̄k + x̄k h + Πn(b̄n + 1'k n + x̄n h)} = = Πh k[āh k + (b̄ + x̄)k h + {1' ɟ (b̄ + x̄)}k h] = Πk h{ā̆ + b̄ + x̄ + 1' ɟ (b̄ + x̄)}k h = = 0 ɟ {ā̆ + b̄ + x̄ + 1' ɟ (b̄ + x̄)} ɟ 0 = b̄̆ ɟ {x̄ + 1' ɟ (b̄ + x̄)} ɟ ā = = ā̆ ɟ {(x̄̆ + b̄̆) ɟ 1' + x̄̆} ɟ b̄ = (1 ⋹ idem) = {a; 1; b̆ = ab̆ ⋹ (x̄̆ + b̄̆) ɟ 1' + x̄̆} = = (x̆b̆; 0' · x̆b̆a = 0)
q. e. d. das heisst:
es sind damit die Angaben 33) erwiesen.
Um nun jene zwei von diesen auch noch auf die Formen 34), 35) zu bringen, statuiren wir den Hülfssatz: 36) [Formel]
Es soll darin a ein beliebiges Relativ, und b; 1 nur irgend ein System vorstellen, das also auch durch b ɟ 0 vertreten werden konnte.
Obwol für a = 1αβγ0 ist: a; 0' · a = 1αβ00, dagegen a; 0' ɟ 0 = 11100, demnach die beiden Subjekte in 36) differiren, muss dieser Satz doch gelten, und liesse er sich schon zeilenrechnerisch einsehn.
Eleganter ist er als L = R so zu beweisen.
Wegen a; 0' · a ⋹ a; 0' ɟ 0 folgt L aus R, d. h. gilt R ⋹ L a fortiori.
Umgekehrt folgt aus L auch (a; 0')a; 1 ⋹ b; 1, was wegen (a; 0')a; 1 = a; 0' ɟ 0, vergl. 30) des § 15, S. 216, in R übergeht, d. h. es gilt auch L ⋹ R, q. e. d.
Nach diesem Schema 36) verwandelt sich nun z. B. γ4 aus 33), geschrieben als xă; 0' · xă ⋹ b̄(= b̄; 1), mit Leichtigkeit in xă; 0' ɟ 0 ⋹ b̄, d. h. in 34) — und konjugirt entsprechend γ2 aus 33) in 34), sowie umgekehrt, q. e. d.
Von 34) aber ist 35) nur eine naheliegende Umformung nach bekannten Sätzen über Systeme.
Sehr beachtenswert ist, dass, während als Relation zwischen den Systemen a und b betrachtet, die Beziehungen γ1 und γ3 transitive sind, ein gleiches mit denen γ2 und γ4 keineswegs der Fall ist.
Jenes ist mit den a fortiori gültigen Folgerungen: (a ⋹ x̆; b)(b ⋹ y̆; c) ⋹ (a ⋹ x̆; y̆; c), = (a ⋹ z̆; c) für z = y; x, (b ⋹ x; a)(c ⋹ y; b) ⋹ (c ⋹ y; x; a), = (c ⋹ z; a) „ „ sofort analytisch beweisbar, wie es denn auch ohne weitres einleuchtet, dass, wenn zu jedem a (nach einer Vorschrift x) mindestens ein b gehört, und zu jedem b (nach einer andern Vorschrift y) mindestens ein c gehört, dann auch zu jedem a (nach beiden Vorschriften zusammen) mindestens ein c gehören müsse.
Ersetzt man hierin das Wort „mindestens“ durchweg durch „höchstens“, so findet vielleicht Mancher den Satz ganz ebenso einleuchtend.
Dennoch hat die rhetorische Evidenz hierbei nur irre geführt (es können nämlich zu solchen a, zu denen — als „höchstens ein“ — kein b gehört, vielmehr direkt doch beliebig viele c gehören!).
Auch lässt sich zeigen, dass ein Schluss von (x; 0'a ɟ 0 ⋹ b̄)(y; 0'b ɟ 0 ⋹ c̄) auf z; 0'a ɟ 0 ⋹ c̄ weder mit z = y; x, noch mit sonst einem z, zwingend sein kann, indem die fragliche Konklusion ja eine Resultante der Elimination von b aus den Prämissen sein müsste.
Eine solche ist aber gar nicht vorhanden, weil die Prämissen sich für b = 0 als stets erfüllt erweisen.
Die Konklusion müsste sonach als eine Relation nichtssagend sein, m. a. W. für beliebige a, c und z wie eine allgemeine Formel gelten, was leicht als absurd zu erkennen.
Anders verhält sich die Sache für a = b = c = 1.
Da gilt wirklich: 37) (x; 0' ɟ 0 = 0)(y; 0' ɟ 0 = 0) ⋹ (y; x 0' ɟ 0 = 0) — wie man durch zeilenrechnerischen Erweis der ersten von den Äquivalenzen: 38) (a; 0' ɟ 0 = 0) = (a ⋹ ā ɟ 1') = (ă; a ⋹ 1') — oder auch durch ihre Ableitung aus 36) mit der Annahme b = 0 — am bequemsten dann so, wie S. 567 gezeigt, sieht.
Gehört in der That nach einem ersten Prinzip zu jedem Element des Denkbereichs wiederum höchstens ein Element aus diesem ganzen Denkbereiche, ebenso nach einem zweiten Prinzip, so auch nach dem aus beiden zusammengesetzten Prinzipe.
Mit den Resultaten 32) bis 35) ist nun selbständig die folgende neue Fassung der Ähnlichkeitsforderung für a und b gewonnen:
[Formel] , d. h. die Systeme a und b werden ähnlich zu nennen sein dann und nur dann, wenn es ein Abbildungsprinzip x gibt, das inbezug auf sie die Forderungen γ1 bis γ4 alle viere gleichzeitig erfüllt.
Wir haben also als die „sechste Fassung“: (39) [Formel] .
Hatten wir zuerst, bei 1), die Ähnlichkeitsforderung imgrunde so gefasst:
Zu jedem Element h von a soll es innerhalb b (mindestens) ein Element k geben, welches „einzig ein x-Bild von ihm, und von ihm allein ist (und umgekehrt — nur „x̆-Bild“ gesagt), so leuchtet es zwar schon dem gemeinen Verstande ein: dass es daneben ein zweites Element k' von b nicht geben kann, welches „mehrzig“ (d. h. neben andern) ein x-Bild von ihm (jenem h), oder auch von ihm und noch andern Elementen des a wäre.
Und man fühlt oder glaubt zu fühlen, dass die frühere Fassung mit der diesmal formulirten doch wesentlich zusammenfallen muss, obwol letztre die betreffende Forderung nicht als abhängige (von gewissen Voraussetzungen) — in einem Relativsatze — sondern selbständig aufstellt.
Allein mit solcher Intuition dürfen wir uns hier nicht zufrieden geben, müssen vielmehr die Äquivalenz der letzten Fassung mit irgend einer der früheren Fassungen auch analytisch nachweisen.
Dies gelingt mittelst Zurückführung von (39) auf (10) oder (17) wie folgt.
Wegen xăb; 0' = xb; 0'a ⋹ x; 0'a und xăb ⋹ b folgt mit (x; 0'a ɟ 0)b = 0 a fortiori auch: (xăb; 0' ɟ 0)xăb = 0, und ebenso mit (x̆; 0'b ɟ 0)a = 0 auch (x̆ab̆; 0'
ɟ 0)x̆ab̆ = 0. Nennt man daher: xăb = z, so lehrt die letzte Forderung in (39) dass: (z; 0' ɟ 0)z = 0 und (z̆; 0'
ɟ 0)z̆ = 0 ist.
Nach 32) S. 216 ist aber allgemein (a; 0' ɟ 0)a = a; 0' · a, mithin muss gelten z; 0' · z + z̆; 0' · z̆ = 0, was in z; z̆ + z̆; z ⋹ 1' sich leichtlich umwandelt, indem z. B. aus dem Verschwinden des ersten Gliedes folgt: z ⋹ z̄ ɟ 1', z̆; z ⋹ 1', etc.
Dass ferner die beiden ersten Forderungen in (39) für obigen Zusammenhang zwischen z und x ohne weitres in die beiden letzten von (10) übergehen, haben wir schon S. 605 (wo nur unser jetziges x durch y vertreten war) gezeigt.
Aus (39) folgt also (10), d. h.: gibt es ein x, welches inbezug auf gegebne Systeme a und b die Forderung (39) erfüllt, so gibt es auch ein z(= ăbx), welches inbezug auf ebendiese Systeme die Forderung (10) ja sogar (17) erfüllt.
Umgekehrt: wenn irgend ein z der Bedingung (10) genügt, so muss x = z selbst auch der Bedingung (39) genügen, was inbezug auf deren beide ersten Forderungen ersichtlich ist, bezüglich der letzten aber sich wie folgt zeigen lässt.
Wir haben z; 0' · z = 0, also auch z; 0' · z ⋹ b̄.
Nach unserm Satze 36) ist dies äquivalent mit z; 0' ɟ 0 ⋹ b̄ und hieraus folgt a fortiori: z; 0'a ɟ 0 ⋹ b̄, d. h. (z; 0'a ɟ 0)b = 0.
Und ganz ebenso zeigt man, dass auch (z̆; 0'b ɟ 0)a = 0 sein muss, q. e. d.
Das der normalen Ähnlichkeitsbedingung (17) genügende Abbildungsprinzip z erfüllt hienach jedenfalls auch die in irgend einer andern unsrer Fassungen für das Abbildungsprinzip (x oder y) ausgesprochnen Bedingungen — aber nicht umgekehrt. —
Wir sind jetzt in der Lage, auch die Dedekind’schen Beweise zu D 31, 33, 35 mit ihrer Argumentation auf die Elemente aufnehmen zu können.
Satz D 31, der für unsre Disziplin massgebenden Terminologie näher angepasst, lautet:
Ist x eine ähnliche Abbildung von a in b und y eine ähnliche Abbildung von b in c, so ist die aus x und y zusammengesetzte Abbildung z = y; x eine ebenfalls ähnliche Abbildung von a in c.
Beweis.
Denn verschiednen Elementen h, h' von a entsprechen als Elemente von b verschiedne Bilder k = x; h, k' = x; h' und diesen wieder als Elemente von c verschiedne Bilder l = y; k = y; x; h, l' = y; k' = y; x; h', also ist z = y; x eine ähnliche Abbildung von a in c.
Ausserdem geht jedes Element l von c durch y̆ in ein Element y̆; l = k von b, und dieses durch x̆ in ein Element x̆; y̆; l = x̆; k = h von a über, sodass uns z̆ = x̆; y̆ zugleich eine ähnliche Abbildung von c in a vorstellt.
Verschiednen Elementen von c müssen ja dergestalt auch verschiedne Elemente von b resp. a als Bilder entsprechen, ansonst die umgekehrten Schlüsse zu einem Widerspruch führen müssten. —
Die Bündigkeit dieser Beweisführung beruht, wie man sieht, wesentlich auf der Berechtigung: die Beziehung zwischen Bildelement und Objektelement vermittelst des Abbildungsprinzips in Gestalt einer Gleichung anzusetzen — was wir analytisch unter 26) sichergestellt haben.
Nun ist auch die in D 33 statuirte Transitivität der Ähnlichkeitsbeziehung zwischen den Systemen a, b, c offenbar.
Denn wenn es eine ähnliche Abbildung x von a in b und eine solche y von b in c gibt, so gibt es nach D 31 auch in Gestalt von y; x eine ähnliche Abbildung z von a in c, q. e. d.
Etwas mehr Umstände macht uns der Beweis von D 35, S. 610.
Zu dem Ende mögen wir uns etwa die Ähnlichkeitsdefinition in der Fassung aus 1) und (4) vergegenwärtigen: 40) (a ∽ b) = [Formel] , wo für Zh k = Πm{(m ≠ h) ⋹ (k ≠ z; m)}Πn{(n ≠ k) ⋹ (n ≠ z; h)} etwas bequemer wie bei 1) der in 12) für Zk h gegebne Ausdruck genommen werden mag, und wo die Ersetzung der Einordnungszeichen und ihrer Negation bei den Thesen (sive Aussagensubsumtionsprädikaten, wie k ⋹ z; h) durch Gleichheitszeichen und deren Negation aus 26) bereits gerechtfertigt erscheint.
Wenn nun gemäss der zur Voraussetzung erhobnen rechten Seite von 40) z das System a ähnlich in das b abbildet, also b = z; a, z̆; b = a ist und c = c; 1 ⋹ a ein Teilsystem von a vorstellt, so folgt auch z; c ⋹ z; a, und falls z; c = d genannt wird: d ⋹ b.
Es wird nun zu zeigen sein, dass dieses System d = z; c ähnlich mit c sein, mithin gelten muss: Πh{(h⋹c) ⋹Σk(z; h = k ⋹ d)Zk h}Πk{(k ⋹ d) ⋹ Σh(z̆; k = h ⋹ c)Zk h}.
Da nun mit h ⋹ c, resp. k ⋹ d, a fortiori auch h ⋹ a resp. k ⋹ b folgt, so erscheinen in der That mit Einschluss von Zk h sämtliche Teilbehauptungen unsrer Thesis mit 40) sogleich verbürgt bis auf diese beiden, dass links k ⋹ d, rechts h ⋹ c sei.
[In dem Πh und dem Πk sind h und k durch verschiedne Voraussetzungen eingeführt, haben also a priori verschiedne Bedeutungen und nichts miteinander zu schaffen.
Wenn nun für das erstre h, welches ⋹ c ⋹ a, sogleich feststeht, dass es ein k ⋹ b gebe so, dass z; h = k ist, so sind wir doch nicht am Ziele, weil ja zu beweisen bleibt, dass dieses k sogar ⋹ d sei.
Etc.]
Nun gilt: (k ⋹ d) + (k ⋹ d̄), (h ⋹ c) + (h ⋹ c̄), ebenso für das schon dem System b erwiesnermaassen angehörige Element k: (k ⋹ bd = d) + (k ⋹ bd), und für das dem a angehörige h: (h ⋹ ac = c) + (h ⋹ ac̄), wobei jeweils die beiden Möglichkeiten einander ausschliessen.
Hiefür unterlässt Herr Dedekind leider eine Begründung anzugeben, indem er p. 10 das System sogleich mit dem prädikativen Attribute als das „mit c ähnliche System“ z; c einführt.
Es ist ja freilich, ebenso wie schon der ganze Satz D 35, aus der Anschauung der gegenseitig eindeutigen Zuordnung ohne weitres einleuchtend.
Die Behauptung sollte gleichwol, als beweisbar, nicht ohne Beweis gelassen werden, und dass sie eines solchen im Sinne unsrer Disziplin bedarf, wird die Fortsetzung der Überlegung zeigen.
Wäre nun links k ⋹ d̄ wo d = z; c, so folgte: k⋹z̄ ɟ c̄ also z̆; k ⋹ c̄, und da mit z; h = k also k ⋹ z; h auch h ⋹ z̆; k gilt, a fortiori: h ⋹ c̄ im Widerspruch mit der Voraussetzung h ⋹ c.
Wäre rechts h ⋹ c̄, so können wir nicht ebenso einfach weiter schliessen, weil für c die Darstellung als z̆; d hier noch nicht verfügbar ist — es sei denn, dass man sie erst so, wie S. 610 von uns geschehn, beweise — vielmehr wird, wenn wir beim Argumentiren auf die Elemente bleiben wollen, nun so zum Ziel zu kommen sein.
Mit k ⋹ d = z; c und z̆; k = h folgt: z̆; k ⋹ z̆; z; c ⋹ 1'; c = c also h ⋹ c auch in direktem Beweise.
Ebenso wäre auch für die vorige Behauptung statt des apagogischen ein direkter Beweis erbringlich — wofern wir dort wie hier von der Charakteristik A2A4 oder z; z̆ + z̆; z ⋹ 1' des Abbildungsprinzips Gebrauch machen.
Und dies scheint wenigstens im letzten Falle unumgänglich zu sein. Q. e. d.
Die Bedingung für die Ähnlichkeit oder Gleichmächtigkeit zweier Systeme a und b ist als eine Relation rein logischer Art zwischen diesen anzusehn, zu deren adäquatem Ausdruck unsre Disziplin die Mittel besitzt.
Sie präsentirt sich als die Resultante der Elimination des Abbildungsprinzips x, resp. y oder z, aus den Forderungen unsrer Ähnlichkeitsdefinition in irgend einer ihrer Fassungen.
Solange die Elimination nicht wirklich vollzogen, die Σ oder Π, mit Hülfe deren sich die Resultante ja nach allgemeinen Sätzen darstellen lässt, nicht ausgewertet sind — kurz: solange der Name des Abbildungsprinzips als eines unbestimmten binären Relativs noch im Ausdruck dieser Resultante figurirt — mögen wir die Ähnlichkeitsdefinition noch eine implizite nennen.
Um die Elimination vorzubereiten, wird man etwa die vereinigte Nullgleichung sämtlicher Teilbedingungen unsrer Ähnlichkeitsforderung bilden: f(z) = 0, wobei man jedoch unter mancherlei Ausdrücken für deren Polynom f(z) noch die Wahl haben wird, selbst wenn man eine bestimmte wie (10) oder (17) von unsern Fassungen zugrunde legt.
Die Charakteristik z; z̆ + z̆; z ⋹ 1' setzt man am besten wol in der Form an z; 0' ɟ 0 + 0 ɟ 0'; z = 0, weil man dadurch den Vorteil erreicht, dass in jedem Gliede von f(z) der Name des Eliminanden z blos einmal vorkommt.
Man kann ferner die beiden Hauptbedingungen in (10) etc. blos als Subsumtionen, oder aber auch als Gleichungen berücksichtigen, wobei erstres insofern als das einfachere erscheint als man (um zweie) weniger Glieder bei f(z) bekommt.
Auch die Adventivbedingung in (17) kann mitberücksichtigt oder unterdrückt werden.
Als einfachster Ausdruck von f(z) dürfte sonach dieser hinzustellen sein: 41) f(z) = z; 0' ɟ 0 + 0 ɟ 0'; z + a(z̄̆ ɟ b̄) + b(z̄ ɟ ā).
Hinzugefügt darf jedoch noch werden: ā · z̆; b + b̄ · z; a + (ā̆ + b̄)z, sowie 0' · z; z̆ + 0' · z̆; z und andres mehr.
Dann ist: 42) [Formel] .
Oder (a ∽ b) = (L = 0) wo [Formel] , und U = 1; f(u); 1 was nach 41) unter Konversion des dritten Gliedes gibt:
U = 1; (u; 0' ɟ 0) + (0 ɟ 0'; u); 1 + (b̄̆ ɟ ū); a + b̆; (ū ɟ ā) und wozu noch hinzugefügt werden dürfte: + b̆; u; ā + b̄̆; u; a + b̄̆; u; 1 + 1; u; ā wovon offenbar die beiden ersten Terme in den zwei letzten eingehen.
Jedoch kann man jene auch mit den beiden letzten Gliedern von U nach dem Korollar zu 38) S. 449 zusammenziehen zu (b̄̆; u + 0 ɟ ū); a + b̆; (u; ā + ū ɟ 0) und sie dann erst eingehn lassen — sodass sich auch nehmen liesse:
U = 1; (u; 0' ɟ 0) + (0 ɟ 0'; u); 1 + b̆; (ū ɟ 0) + (0 ɟ ū); a + b̄̆; u; 1 + 1; u; ā, und andres mehr.
Was nun die expliziten Ähnlichkeitsbedingungen betrifft, so lassen erstlich gewisse (zwei) partielle oder Unterresultanten sich allgemein sogleich angeben.
Zudem sind wir imstande für die niedersten Denkbereiche, ja — theoretisch wenigstens — für jeden endlichen Denkbereich, die Ähnlichkeitsbedingung wirklich in geschlossner Form, „explizite“, aufzustellen.
Zu dem Ende braucht man ja in der That nur die Bedingung f(z) = 0 in den Koeffizienten als Πi j[{f(z)}i j = 0] oder Σi j{f(z)}i j = 0 ausgerechnet hinzuschreiben und aus dieser vereinigten Nullgleichung, in der die Summe über alle Suffixe ij unsres (endlichen) Denkbereichs sich erstreckt, die Koeffizienten zh k des Abbildungsprinzips oder Eliminanden sämtlich (nötigenfalls successive) nach den bekannten Methoden zu eliminiren.
Ich will diese explizite Ähnlichkeitsbedingung für die vier niedersten Denkbereiche zunächst als solche angeben.
Es ist: 43) (a ∽ b) äquivalent mit sub 1 [Formel] (1; a = 1; b) was hier mit (0 ɟ a = 0 ɟ b) zusammenfällt.
„ 1 ½) (1; a = 1; b)(0 ɟ a = 0 ɟ b) 1 ⅓) (1; a = 1; b)(0 ɟ 0'; a = 0 ɟ 0'; b)(0 ɟ a = 0 ɟ b) oder „ {1; (1' ɟ a) = 1; (1' ɟ b)} sub 1 ¼) (1; a = 1; b)(0 ɟ 0'; a = 0 ɟ 0'; b){1; (1' ɟ a) = 1; (1' ɟ b)}(0 ɟ a = 0 ɟ b).
Ich wage aber nicht „u. s. w.“ zu sagen, denn wie es weiter gehen wird, ist noch in Dunkel gehüllt.
Sub 1 ⅕ würde zu den vier vorstehenden Forderungen noch eine fünfte in der Mitte hinzu kommen, deren Auffindung sehr instruktiv zu sein verspricht.
Obwol ein gangbarer Weg dazu vorgezeichnet ist, dürfte die Frage doch einer Akademie als zu stellende Preisaufgabe zu empfehlen sein; denn ohne ganz besondres Geschick dürfte niemand mit der hier geforderten Elimination von 25 (mit doppeltem Suffix behafteten) Unbekannten z11, z12, … z55 zustreiche kommen — resp. von 20 solchen, sofern die Koeffizienten der individuellen Selbstrelative von z (hier fünf an Zahl) sich auch bei voraussetzungslosem Denkbereiche noch allgemein eliminiren lassen würden.
Man kann sich die rasch und crescendo entsetzlich mühsam werdenden Rechnungen bis hierher (bis inklusive 1 ¼) noch durch kolonnenschematische Überlegungen ersparen — freilich nicht ohne an den gemeinen Verstand, der „bis auf vier (oder wenigstens bis über eins) zählen kann“, zu appelliren.
Ich will dazu für den letzten Fall die volle Anleitung geben.
Als „gleichviel“ Elemente enthaltend bestehen die Systeme a und b gleichzeitig aus entweder 0, 1, 2, 3 oder allen 4 Elementen, die jedoch — die beiden äussersten Fälle ausgenommen — bei b (ganz) andre Elemente als wie bei a sein können.
Zugleich müssen ā und b̄ bezüglich (alle) 4, 3, 2, 1, 0 Elemente enthalten.
Es würden sich die fünf Möglichkeiten, die bei a vorliegen können, darstellen lassen durch die Ansätze: a = 0, a = i, a = i + j = h̅ +̅ k̅, a = i + j + h = k̄, a = i + j + h + k = 1, mit der Unterstellung: dass die Elementbuchstaben i, j, h, k durchweg verschiedne Elemente bedeuten sollen.
Hiefür wollen wir ad hoc kürzer schreiben: a = 0i = 0, a = 1i = i, a = 2i, a = 3i, a = 4i = 1.
Jede dieser fünf Möglichkeiten inbezug auf das System a ist nun charakterisirt durch ein andres Wertsystem der vier ausgezeichneten Relative nämlich bei sintemal für a = k1αβγ0 ist: 1; a = 11110, 0 ɟ 0'; a = 11100, 1; (1' ɟ a) = = 11000, 0 ɟ a = 10000.
1; a, 0 ɟ 0'; a, 1; (1' ɟ a), 0 ɟ a, a = 0 durch 0, 0, 0, 0 a = i „ 1, 0, 0, 0 a = 2i „ 1, 1, 0, 0 a = 3i „ 1, 1, 1, 0 a = 4i „ 1, 1, 1, 1,
Besteht nun a aus einer Vollzeile, so ist jede Kolonne von a als eine einbesetzte zur Kolonnenkategorie γ gehörig und wird im Relative 0 ɟ 0'; a abgeworfen, weshalb dieses alsdann verschwindet.
Besteht aber a aus mehr als einer Vollzeile, so gehört jede Kolonne dieses Systems (und alle Kolonnen eines solchen müssen ja kongruent sein) als eine mehrbesetzte zu einer der drei ersten Kolonuenkategorien 1, α, β, welche das Relativ 0 ɟ 0'; a in Vollkolonnen verwandelt, und muss letztres folglich = 1 sein.
Besteht a aus gerade zwei Vollzeilen, so hat es in unserm Denkbereiche 1 ¼ auch ebensoviele Leerzeilen; seine Kolonnen gehören dann zur Kategorie β der mehrlückig mehrbesetzten, werden in 0 ɟ 0'; a in Vollkolonnen verwandelt, dagegen in 1; (1' ɟ a) noch abgeworfen, gleichwie auch in letzterem die einbesetzten Kolonnen des a abgeworfen wurden; also während jenes = 1 ist, muss dieses verschwinden.
Besteht endlich a aus drei Vollzeilen (nebst also einer Leerzeile), so gehören die Kolonnen des a als einlückige zur Kategorie α und werden sie auch im Relative 1; (1' ɟ a) in Vollkolonnen verwandelt, dagegen in 0 ɟ a, welches nur die (blos bei a = 1 vorhandnen) Vollkolonnen von a beibehält, noch abgeworfen — wie zunächst einzusehn gewesen.
[Im letzten Falle hätte man auch, statt neu denselben zu überlegen, auf das Relativ ā die frühere Überlegung anwenden und ihr Ergebniss kontraponiren können.]
Es ist also unsre Tabelle gerechtfertigt.
Umgekehrt charakterisiren nun auch aufgrund von 43) sub 1 ¼ die Wertsysteme obiger Tabelle als einer ebenso für b gültigen ihrerseits wieder die Zusammensetzung oder Bildungsweise von b als 0, 1j, 2j, 3j, resp. 4j.
Und es leuchtet damit ein, dass in der That die vier Bedingungen zusammengenommen den notwendigen und hinreichenden Ausdruck für die Gleichzahligkeit der Elemente in a und b sub 1 ¼ ausmachen.
Die erste 1; a = 1; b dieser Bedingungen ist äquivalent mit 1; a; 1 = 1; b; 1 und läuft also hinaus auf 44) (a = 0) = (b = 0) somit (a ≠ 0) = (b ≠ 0) d. h. sie fordert immer gleichzeitiges Verschwinden oder Nichtverschwinden bei den ähnlichen Systemen a und b.
Die zweite Bedingung:
0 ɟ 0'; a = 0 ɟ 0'; b drückt für sich allein aus, dass a und b immer nur gleichzeitig mehr als ein Element resp. nicht mehr als ein Element enthalten dürfen (sofern sie ähnlich sein sollen).
In Verbindung mit der ersten Bedingung ist sie aber auch der ausreichende Ausdruck für die Forderung, dass, sobald das System a aus gerade einem Element besteht (sonach selbst Element ist), dann auch b aus gerade einem Element bestehn (ebenfalls irgend ein Element sein) muss, sowie umgekehrt.
Diese beiden Bedingungen nun gelten (offenbar) für jeden, auch für den voraussetzungslosen Denkbereich, und werden wir sie nachher auch noch analytisch aus unsrer Ähnlichkeitsdefinition (17) abzuleiten haben.
Anders die beiden letzten Bedingungen sub 1 ¼ in 43).
Die letzte 0 ɟ a = 0 ɟ b von diesen, äquivalent mit 0 ɟ a ɟ 0 = 0 ɟ b ɟ 0 läuft hinaus auf (a = 1) = (b = 1), also auch (a ≠ 1) = (b ≠ 1) und besagt, dass, wenn von zwei ähnlichen Systemen das eine die sämtlichen Elemente des Denkbereiches umfasst, dies auch beim andern der Fall sein müsse, und wenn dort nicht, so auch hier nicht.
In Verbindung mit dieser letzten sagt die vorletzte Bedingung 1; (1' ɟ a) = = 1; (1' ɟ b) oder 0 ɟ 0'; ā = 0 ɟ 0'; b̄ aus, dass ferner, wenn a sämtliche Elemente des Denkbereiches bis auf eines enthält, dann auch b sämtliche Elemente mit Ausnahme von irgend einem enthalten müsse, und andernfalles nicht — sowie umgekehrt.
Diese beiden Bedingungen werden aber in der That nur für einen „endlichen“ Denkbereich, und für jeden solchen, gültig sein.
Sie können für einen unbegrenzten Denkbereich unmöglich Geltung haben, weil von solchem bekannt ist, dass er auch in echte Teile seinerselbst eineindeutig oder ähnlich abgebildet werden kann (S. 596).
Ebensowenig also werden diese beiden „letzten“ Bedingungen für den voraussetzungslosen Denkbereich Geltung beanspruchen dürfen; sie können durchaus nicht etwa zwingende Konklusionen aus unsrer Ähnlichkeitsdefinition sein und lassen sich als solche in der That auch nicht beweisen.
Allgemein hat man sich etwa in der Mitte der zu 1 ¼ gemachten Angabe 43) eine Cäsur, einen Einschnitt angebracht und in die Öffnung Punkte „…“ hineingesetzt zu denken, welche bei den höhern Denkbereichen durch immer mehr noch weiter einzuschaltende bislang noch unbekannte Bedingungen ersetzt zu denken sind, während die beiden ersten Bedingungen (als partielle Resultanten) für jeden Denkbereich bestehen und sich forterhalten müssen.
Überspringen wir nun die Punkte …, so wird auch die vorletzte und die letzte von den vier sub 1 ¼ angeführten Bedingungen in jedem begrenzten Denkbereiche noch Geltung behalten und die Reihe der Partialresultanten abschliessen.
Dagegen wird man sich vorzustellen haben, dass, wenn bei ev. unbegrenztem Denkbereiche auf dem hier betretnen Wege die explizite Ähnlichkeitsdefinition mittelst Hinzufügung von immer weitren Bedingungen (als Partialresultanten) zu den beiden ersten sub 1 ¼ in 43) angeführten jemals ihre Ergänzung (zur vollen Resultante), deren sie noch bedarf, finden sollte: alsdann die beiden „letzten“ Bedingungen von ebenda „niemals kommen“ werden. —
Die erste Bedingung und Partialresultante: 45) (a ∽ b) ⋹ (1; a = 1; b) = (ă; a = b̆; b) = etc. — deren noch andere Formen wir bereits in den zwei ersten Zeilen unter dem Strich in 31) S. 617 aufgeführt — statuirt, wie gesagt:
Ähnliche Systeme können nur gleichzeitig verschwinden, und müssen andernfalles allesamt von 0 verschieden sein.
Sie lässt sich leicht und auf verschiedne Weisen aus unsrer Ähnlichkeitsdefinition folgern.
Man hat erstlich zu den beiden Hauptbedingungen von (17) a ⋹ z̆; b, b ⋹ z; a die Einzelresultanten (der Elimination von z): a ⋹ 1; b, b ⋹ 1; a.
Da aber nach 49) S. 453: (a ⋹ 1; b) = (1; a ⋹ 1; b) und ebenso (b ⋹ 1; a) = = (1; b ⋹ 1; a), so gibt die Vereinigung dieser beiden eben die Gleichung 1; a = 1; b, q. e. d.
Es konnte aber auch a ⋹ 1; b in a = a · 1; b = a; b umgeschrieben werden, sodass (a = a; b)(b = b; a) eine andre Schreibweise derselben Resultante vorstellt.
Jedoch gelten die beiden Hauptbedingungen auch als Gleichungen: a = z̆; b, b = z; a und geben als solche die Einzelresultanten: a = (a ɟ b̄̆); b, b = (b ɟ ā̆); a — cf. § 19.
Da unser a ɟ b̄̆ = a ɟ 0 ɟ b̄̆ = a ɟ 0 + 0 ɟ b̄̆ = a + b̄̆, und b̄̆; b = 1; b̄b = 0 ist, so leuchtet überdies die Identität dieser beiden letztern mit den vorigen a = a; b, etc. unmittelbar ein.
Konvertirt man die erstere Gleichung, so gelangt man mit ă = b̆; z, b = z; a durch Einsetzung zu dem Schlusse:
b̆; b = b̆; z; a = ă; a, womit ă; a = b̆; b gewonnen ist.
[Denselben Schluss konnte man auch — anstatt in z — mit dem Werte 13) von y ausführen, wobei dann das blos in der Verbindung φ(x) = (x̄ ɟ 1')x(1' ɟ x̄) in der Ähnlichkeitsbedingung (14) vorkommende x zugleich mit diesem φ(x)(= y) vollständig eliminirt erscheint.
Dass aber, wenn x blos als Baustein, Argument eines Ausdrucks φ(x) vorkommt, die Resultante der Elimination von φ(x) noch lange nicht die Resultante von x, sondern blos eine Unterresultante von dieser vorstellt, hatten wir schon S. 287, Fussnote Gelegenheit zu betonen und finden wir hier bestätigt.
Denn die Bedingung ă; a = b̆; b genügt bei weitem nicht, um die Ähnlichkeit von a und b zu verbürgen.
Vielmehr ist dieselbe blos äquivalent mit 44).]
In der That ist auch ă; a = 1; aa = 1; a, mithin die Aussage ă; a = b̆; b von 1; a = 1; b nicht wesentlich verschieden.
Die in 31) mitangeführte Resultante ă; 1; a = b̆; 1; b ergibt sich, indem man die letzte mit der beiderseitig konvertirten übermultiplizirt, desgleichen auch indem man sie in der Form ă; 1'; a = b̆; 1'; b zu der nachher zu rechtfertigenden ă; 0'; a = b̆; 0'; b überschiebend addirt.
Als zweite Bedingung und Partialresultante war 46) (a ∽ b) ⋹ (0 ɟ 0'; a = 0 ɟ 0'; b) = (ă; 0'; a = b̆; 0; b) = etc. mit noch viel anderen schon in 31) gegen Schluss mit aufgezählten Ausdrucksformen zu notiren.
Was sie stipulirt, haben wir bereits im Kontext erörtert.
Dieselbe — was uns jetzt noch obliegt — aus (17) zu beweisen, fiel nicht ganz leicht
Ich werde drei Beweise geben, auch eines Fehlversuchs erwähnen der lehrreich war, sofern er zahlreiche neue Ausdrucksformen und Relationen offenbarte.
Zunächst beachte man, dass nach bekanntestem Satze über Systeme:
ă; 0'; a = 1; a(0'; a) = 0 ɟ 0'; a — letztres gemäss 30) S. 216 ist.
Die beiden in 46) angeführten Formen fallen also gänzlich zusammen, und mit 0'; a = 0'ă; 1 erhält man die Form hinzu: 1; 0'aă; 1 = 1; 0'bb̆; 1.
Es würde sonach blos (0'aă = 0) = (0'bb̆ = 0) zu beweisen sein, was man leicht auch auf die Formen der letzten Zeile 31) zurückführt.
Da ferner 0'; a sowie a · 0'; a(= a0'; a) System ist, so wird das ausgezeichnete Relativ 0 ɟ 0'; a nur dann nicht 0 sein, wenn 0'; a = 1 ist, weshalb die Behauptung auch auf (1 ⋹ 0'; a) = (1 ⋹ 0'; b) hinausläuft; und ferner wird das ausgezeichnete Relativ 1; a(0'; a) nur dann nicht 1 sein, wenn a(0'; a) = 0 ist, weshalb dieselbe auch mit (a · 0'; a = 0) = (b · 0'; b = 0) äquivalent sein muss.
Damit erscheinen die unter 31) aufgeführten Formen, soweit z nicht in ihnen vorkommt, nun aufeinander zurückgeführt.
Wegen b = z; a, a = z̆; b, 0'; z ⋹ z̄ und z̄; z̆ ⋹ 0', etc. kann man schliessen: 47) [Formel] Sintemal hier Anfangssubjekt und Endprädikat übereinstimmen, müssen alle zwischenliegenden Termini diesem und unter sich gleich sein — womit sich, wenn man noch z; a = z; 1 und z̆; b = z̆; 1 berücksichtigt, eine grosse Reihe von andern in 31) angegebnen Ausdrucksformen mit hinzuergibt, sobald unsre Behauptung 46) anderweitig gerechtfertigt sein wird.
Diese selbst ergibt sich auf diesem Wege nicht, es sei denn, dass es gelänge, die Gleichheit zwischen irgend einem Ausdruck der einen und der andern Zeile von 47) erst darzuthun — wie z. B. der Gleichung:
0 ɟ z̄; a = 0 ɟ 0'; a.
Nun kann man zwar durch die Schlüsse:
z̄; a = z̄; z̆; b ⋹ 0'; b, 0'; b = 0'; z; a ⋹ z̄; a unschwer beweisen dass: 48) z̄; a = 0'; b und analog z̄̆; b = 0'; a sein muss.
Allein damit liefe die letzte Behauptung doch nur auf eine petitio principii hinaus.
Indessen wird mit 48) und dem Satze 46) auch der Rest seiner Ausdrucksformen in 31) — bis auf die zwei ersten Formeln der viertletzten Zeile — gesichert sein.
[Es käme nun also darauf an, etwa die Äquivalenz (1 ⋹ z̄; a) = = (1 ⋹ 0'; a) zu beweisen.
Fehlversuche betreffend sei erwähnt, dass zwar zu zeigen gelingt: 49) (1 ⋹ 0'; a) = (z̄̆ ⋹ 0'; a), (1 ⋹ z̄; a) ⋹ (z̆; 1 ⋹ 0'; a) = (a ⋹ 0'; a), damit aber eine Annäherung zwischen den beiden Aussagen herbeizuführen erst recht erschwert erscheint.
Jenes so: (1 ⋹ 0'; a) = (1'; 1 ⋹ 0'; a; 1) = (1' ⋹ 0'; a; 1 ɟ 0 = 0'; a; 1 = 0'; a) = = (1' ⋹ 0'; a) = (1' ⋹ 0'; a + 0 ɟ z) = (1' ⋹ 0'; a ɟ 0 + 0 ɟ z) = (1' ⋹ 0'; a ɟ 0 ɟ z) = = (1' ⋹ 0'; a ɟ z) = (1'; z̄̆ ⋹ 0'; a) = (z̄̆ ⋹ 0'; a) weil 0 ɟ z = 0 — cf. 31) — und 0'; a System ist.
Dieses so: (1 ⋹ z̄; a) = {1 ⋹ (z̄ ɟ 0'); a ⋹ z̄ ɟ 0'; a} ⋹ (1 ⋹ z̄ ɟ 0'; a) = (z̆; 1 ⋹ 0'; a).
Aufgrund von 48) gilt zwar für a ∽ b gewiss: (1 ⋹ 0'; b) = (1 ⋹ z̄; a).
Zu sagen, dass, weil a ∽ a, für b = a nun auch sein müsse (1 ⋹ 0'; a) = = (1 ⋹ z̄; a), würde jedoch ein Fehlschluss sein, weil es zwar in der That ein z̄ resp. z derart geben wird, dieses aber als a auf sich selbst vollgedeckt abbildend ein anderes — Z — sein wird als unser a in b (und eventuell in a hinein) abbildendes z.
Also auf diesen Wegen kommt man nicht zum Ziele.]
Um erstmals in der Form (1 ⋹ 0'; a) = (1 ⋹ 0'; b) unsern Satz 46) zu beweisen, wird es der Symmetrie halber genügen, blos zu zeigen, dass (1 ⋹ 0'; a) ⋹ (1 ⋹ 0'; b), d. h. Πi(1 ⋹ Σl0'i lal) ⋹ Πi(1 ⋹ Σl0'i lbl).
Damit für jedes l die Σl0'i lal = aA + aB + … (ohne ai) gleich 1 sein könne, muss nach l mehr als ein al gleich 1 sein.
Denn wäre blos ein al — sagen wir ai — gleich 1, so verschwände für dieses i die Summe; und wäre gar kein al gleich 1, so müsste sie ja für jedes i verschwinden.
Es gibt also mindestens zwei Werte h und m, wo h ≠ m, von l, für welche al = 1 ist, d. h. wir haben ah = 1 und am = 1 oder sowol h ⋹ a als m ⋹ a mit h ≠ m.
Nach der ursprünglichen Fassung des Begriffs der ähnlichen Abbildung z gibt es nun auch ein k ⋹ b und ein n ⋹ b derart, dass k = z; h und n = z; m, und zwar muss wegen h ≠ m auch k ≠ n sein.
Es sind also nach l mindestens zwei bl nämlich bk und bn gleich 1 und ist damit auch die Σl0'i lbl für jedes i gleich 1, q. e. d.
Und vice versa.
Dieser Beweis, obzwar bindend, ist aber methodologisch nicht befriedigend, weil er auf dem Argumentiren auf Elemente und Unterscheidung von Einzahl und Mehrzahl bei diesen beruht.
Analytisch gelingt der Beweis unsrer Behauptung 46) in der Gestalt:
(0'aă = 0) = (0'bb̆ = 0) zweitens wie folgt.
Sei 0'aă = 0, so ist 0'bb̆ = 0' · z; a · ă; z̆ = 0' · z; a; ă; z̆ = 0' · z; aă; z̆ = 0' · z; (1'aă + 0'aă); z̆ = = 0' · z; 1'aă; z̆ ⋹ 0' · z; 1'; z̆ = 0' · z; z̆ ⋹ 0' · 1' = 0, also auch 0'bb̆ = 0, q. e. d. Desgleichen umgekehrt.
Ein dritter Beweis soll direkt für die Form ă; 0'; a = b̆; 0'; b gegeben werden.
Wegen a = z̆; 1, b = z; 1 ist ă; 0'; a = 1; z; 0'; z̆; 1, b̆; 0'; b = 1; z̆; 0'; z; 1, mithin die Gleichheit der beiden rechten Seiten darzuthun, oder der erste von den vier Ausdrücken auch in den letzten noch zu transformiren.
Wir haben auch: ă; 0'; a = 1; 0'aă; 1 = 1; 0'(z̆; 1; z); 1. Zerlegen wir hier die mittlere 1 in 0' + 1', so muss wegen z̆; 1'; z = = z̆; z ⋹ 1' der letzte Teil wegfallen und kommt: ă; 0'; a = 1; 0'(z̆; 0'; z); 1.
Aber mit 0'; z ⋹ z̄ = z̄ ɟ 0' folgt auch z̆; 0'; z ⋹ 0', also 0'(z̆; 0'; z) = = z̆; 0'; z selbst.
Somit bleibt ă; 0'; a = 1; z̆; 0'; z; 1 = b̆; 0'; b, q. e. d.
Auch mit 0'; z ⋹ z̄, ergo z̆; 0'; z ⋹ z̆; z̄ ⋹ 0', etc. lässt sich die unterwegs hierbei gebrauchte Relation 50) z; 0'; z̆ + z̆; 0'; z ⋹ 0' rechtfertigen, womit nun die Formeln 31) auch sämtlich bewiesen worden.
Um übrigens die Gleichung 1; z; 0'; z̆; 1 = 1; z̆; 0'; z; 1 unmittelbar zu rechtfertigen, wozu der Beweis derselben als (vor- oder) rückwärtiger Subsumtion, d. h. von z̆; 0'; z ⋹ 1; z; 0'; z̆; 1 genügt, kann man auch die Koeffizientenevidenz anrufen: Σh kzh i0'h kzk j⋹Σh m n kzh m0'm nzk n. Falls nun i ≠ j, so findet sich jedes Glied zh izk j (wo h ≠ k) der linken Seite auch rechterhand vor, und zwar mit m = i, n = j, weil dann 0'm n = 0'i j = 1 sein wird.
Falls dagegen j = i, so finden zwar die Glieder der linken Seite zh izk i (wo k ≠ h) sich rechterhand nicht vor, allein die Summe jener muss dann verschwinden:
es muss Σh kzh i0'h kzk i = (z̆; 0'; z)i i = = (1' · z̆; 0'; z)i j = 0 sein wegen 50).
Q. e. d.
Das vorstehend über die „explizite“ Darstellung der fundamentalen Ähnlichkeits- oder Gleichmächtigkeitsbedingung Vorgetragene ist übrigens blos das, was sich mir sozusagen auf den ersten Anlauf ergab, und es ist noch nicht die Hoffnung aufzugeben: dass sich bei tieferm Eingehen auf das S. 624 charakterisirte Eliminationsproblem als solches — nach den noch weiter auszugestaltenden Methoden am Schlusse des § 29 — auch allgemein eine konzise Ausdrucksform für die explizite Bedingung gewinnen lassen könnte.
Dies würde freilich ein grosser Triumph für unsre Disziplin sein: noch ohne den Begriff der Zahl und Anzahl, vielmehr propädeutisch für diese, den Begriff der Gleichzahligkeit (und, mehr noch: der Gleichmächtigkeit) zweier Systeme auch explizite zu formuliren!
Die Möglichkeit, solch Ideal zu verwirklichen, scheint mir durch die schon realisirte implizite Fassung dieses Begriffs bereits erwiesen.
Denn wenn wir, unabhängig von den übrigen, jeden einzelnen z-Koeffizienten eliminiren können, so müssen sich doch auch sämtliche z-Koeffizienten eliminiren lassen!
Es eröffnet sich sogar die Aussicht: durch „Auflösung“ gedachter Ähnlichkeitsbedingung nach den Unbekannten a und b jedes mögliche Paar von gleichmächtigen Mannigfaltigkeiten durch zwei arbiträre Parameter u and v dereinst ausdrücken zu lernen. —
Haben wir nun mit dem Bisherigen vom Standpunkt unsrer Theorie alles das mit erledigt, was in der Dedekind’schen Schrift über „ähnliche“ Systeme und über „ähnliche“ oder gegenseitig eindeutige Abbildung gesagt ist, so wollen wir nun auch den Sätzen dieser Schrift uns zuwenden, welche auf die eventuell nur einseitig eindeutige Abbildung Bezug haben.
Diese gehen jenen in ihr voran, und sofern diese blos als Propädeutik für jene (jene als der Endzweck von diesen) angesehen werden dürfen, erscheinen sie bei unsrer Anordnung als eigentlich entbehrlich gemacht.
D 21 gibt die »Erklärung« der »Abbildung« — oder, wie wir vollständiger hier sagen müssen: der „eindeutigen Abbildung“ eines Systems a = a; 1 von Elementen h durch ein Relativ x.
Mutatis mutandis sei zuvörderst citirt:
Unter einer eindeutigen Abbildung x eines Systems a = a; 1 wird ein »Gesetz« (binäres Relativ) verstanden, nach welchem zu jedem bestimmten Element h von a ein bestimmtes »Ding« (für uns wiederum „Element“ k des Denkbereiches 1) gehört, welches das x-Bild von h heisst und mit x; h bezeichnet wird; wir sagen auch, dass (k =)x; h dem Element h entspricht, dass x; h durch die Abbildung x aus h entsteht oder erzeugt wird, dass h durch die Abbildung x in x; h übergeht.
Ist nun c(= c; 1 ⋹ a) irgend ein Teilsystem von a, so ist in der Abbildung x; a wegen x; c ⋹ x; a zugleich eine bestimmte »Abbildung« von c »enthalten«, welche »der Einfachheit wegen« wol mit demselben Zeichen x bezeichnet werden darf, und darin besteht, dass jedem Element i des Systems c dasselbe Bild x; i entspricht, welches i als Element von a besitzt; zugleich soll das System, welches aus allen Bildern x; i besteht, das x-Bild von c heissen und mit x; c bezeichnet werden, wodurch auch die Bedeutung von x; a erklärt ist.
»Als ein Beispiel einer Abbildung eines Systems ist schon die Belegung seiner Elemente mit bestimmten Namen oder Zeichen anzusehen.
Die einfachste Abbildung eines Systems ist diejenige, durch welche jedes seiner Elemente in sich selbst übergeht; sie soll die identische Abbildung heissen.«
Wir wollen nun dasjenige, was vorstehend von der eindeutigen Abbildung eines Systems a gefordert ist, in Formeln bringen, und zwar, parallel dem über die ähnliche Abbildung Vorangegangnen, auf mehrere Arten und wiederum relativ inbezug auf ein bestimmtes zweites System b als den Rezipienten, Empfänger der x-Bilder von a.
Hierbei wird eine (eindeutige) Abbildung mittelst x „von a auf b nicht zu verwechseln sein mit einer solchen „von a in b hinein“.
Bei jener würde (auch umgekehrt) jedes Element von b ein x-Bild zu Elementen von a sein müssen.
Bei dieser braucht blos jedes Element von a ein x-Bild innerhalb b zu haben, und ist es zunächst diese letztre als die minder enge Forderung, die für uns von Interesse.
Als die minimale oder am weitesten gefasste Bedingung dafür, dass x das System a in das System b hinein eindeutig abbilde, erscheint diese:
Zu jedem Element h von a soll es mindestens ein Element k von b geben, welches dessen x-Bild ist, während zugleich die Forderung Xk h erfüllt ist, dass ein jedes von k verschiedene Element n von b nicht dessen x-Bild ist. M. a. W.:
Es soll zu jedem Element h von a innerhalb b ein und nur ein Element k, welches ⋹ x; h ist, geben.
Damit allein wird über das externe Verhalten von x zu a und b in keiner Weise präjudizirt sein.
— Obiges liefert nun: 51) [Formel] Πh(āh + Σkbkxk hXk h) wo Xk h = Πn(b̄n + 1'k n + x̄n h) = {1' ɟ (b̄ + x̄)}k h, und wird xX = y genannt, so kommt: Πh(āh + Σkbkyk h) = 0 ɟ (ā̆ + 1; by) ɟ 0 = b̆; y ɟ ā = ā̆ ɟ y̆; b = (a ⋹ y̆; b).
Unser Ergebniss ist somit: 52) [Formel]
Als Resultante der Elimination von x muss gelten: a ⋹ 1; b, d. h. es darf b nicht ohne a verschwinden.
Diese wollen wir fortan als erfüllt voraussetzen.
Es wird sich zeigen, dass sie die volle Resultante gewesen, d. h. dass es dann immer auch zu irgendwie gegebnen a und b eine Abbildung x gibt, welche den Anforderungen genügt:
In ein nicht verschwindendes System b hinein kann jedes System a eindeutig abgebildet werden.
Aus der Gleichung für y lässt sich nun x eliminiren wie folgt: y⋹ 1' ɟ (b̄ + x̄), y ⋹ x, 0'; y ⋹ b̄ + x̄, b · 0'; y ⋹ x̄ ⋹ ȳ, also by · 0'; y = 0. [Oder auch bx ⋹ 1' ɟ ȳ, aber by ⋹ bx, also a fortiori:] by⋹ 1' ɟ ȳ, by; y̆ ⋹ 1', b · y; y̆ ⋹ 1', und diese in zweierlei Formen gefundne Resultante ist die volle, denn falls sie erfüllt, so genügt auch x = y der Gleichung für y.
Es kann daher auch 52) äquivalent ersetzt werden durch: 52α) (b · y; y̆ ⋹ 1')(a ⋹ y̆; b) oder (by · 0'; y = 0)(a ⋹ y̆; b).
Hieraus folgt aber mit: y; a ⋹ b, nämlich: y; a ⋹ y; y̆; b = (y; y̆)b̆; b ⋹ ⋹ 1'; b = b, sintemal sich durch Konversion auch b̆ · y; y̆ ⋹ 1' ergibt.
Wir mögen daher unser Ergebniss auch „voller“ noch in der Form notiren: 53) {(b + b̆) · y; y̆ ⋹ 1'}(a ⋹ y̆; b)(y; a ⋹ b).
Bei der Annahme b = 1 verbleiben, als nur mehr relativ inbezug auf das System a, die beiden Forderungen: 54) A2, = (y; y̆ ⋹ 1') nebst a ⋹ y̆; 1, welch erstre y als eine nie mehrdeutige Abbildung charakterisirt, während letztre — als mit Πh{(h ⋹ a) ⋹ Σk(k ⋹ y; h)}, = 1; y ɟ ā = ā̆ ɟ y̆; 1 äquivalent — garantirt: dass die Elemente von a wenigstens Bilder haben oder wirklich abgebildet werden, es nämlich zu jedem h ⋹ a ein k gibt so, dass h ⋹ y̆; k, k ⋹ y; h ist. —
Da y = x(1' ɟ x̄) die allgemeine Wurzel von A2 ist, so kann natürlich, wie auch aus 52) für b = 1 ersichtlich, 54) auch vertreten werden durch: 54α) a⋹ (x̄̆ ɟ 1')x̆; 1 was in (ă ⋹ 1; x){ă ⋹ 1; (1' ɟ x̄)} nach 29) S. 215 zerfällbar — welcher Satz nur ein Sonderfall des unten gegebnen 60) ist. —
Nennen wir ăby = z, wo dann sein wird: z⋹ăb, z; ā = 0, z̆; b̄ = 0, so wird ähnlich wie früher (vergl. S. 605): (a ⋹ y̆; b) = (a ⋹ a · y̆; b) = (a ⋹ ab̆y̆; b) = (a ⋹ z̆; b), (y; a ⋹ b) ⋹ (b · y; a ⋹ b) = (byă; a ⋹ b) = (z; a ⋹ b), {(b + b̆) · y; y̆ ⋹ 1'} ⋹ (bb̆ · y; y̆ ⋹ 1') = (by; b̆y̆ ⋹ 1') ⋹ (ăby; ab̆y̆ ⋹ 1') = (z; z̆ ⋹ 1') und folgt: 55) (z; z̆ ⋹ 1')(a ⋹͇ z̆; b)(z; a ⋹ b)(z ⋹ ăb) (z; ā = 0)(z̆; b̄ = 0) und dieses z, für y gesetzt, genügt a fortiori auch den vorigen Forderungen 53, 54).
Dass die zweite Subsumtion in 55) auch als Gleichung gilt folgt daraus, dass mit z̆ ⋹ a auch z̆; b ⋹ a; b = a · 1; b, mithin z̆; b ⋹ a gelten muss.
Wir wollen vorstehende 55) die „Normalbedingung für die eindeutige Abbildung mittelst z des Systems a in das b hinein“ nennen.
Zu ihr kann man auch noch auf folgenden wesentlich andern Wegen und mit zum Teil neuen Ausdrucksformen gelangen.
Einmal, indem man von vornherein die zwei von den vier S. 617 formulirten Forderungen γ kombinirt: 56) γ1γ2 = {(x̆; 0'b ɟ 0)a = 0}(a ⋹ x̆; b).
Auch dieser Ansatz ist ein Ausdruck dafür, dass mittelst x das System a in b hinein eindeutig abgebildet werde.
Doch ist das externe Verhalten des gegenwärtigen x inbezug auf a und b von dem der früheren x, y, z in 51) bis 55) eventuell verschieden.
Nennt man indess auch hier ăbx = z, so gelangt man ebenfalls zur Normalform 55).
Inbezug auf den letzten Faktor rechts und die Adventivforderung ist dies wiederholt (so gerade vorhin in y statt x) gezeigt, und was den ersten Faktor betrifft eigentlich auch schon, und zwar auf S. 620. —
Ferner kann man auch selbständig die Forderung aufstellen, dass es zu jedem Element h von a ein Element k von b gebe derart, dass das x-Bild von h gleich k sei.
Damit wird das Vorhandensein von noch andern Elementen k' des b, sei es als x-Bilder von h, sei es auch als solchem x; h blos eingeordnet, von selber ausgeschlossen, weil in diesen Fällen (k' ⋹ k also) k' = k folgen müsste.
Notwendige und hinreichende Bedingung dafür, dass a durch x in b hinein eindeutig abgebildet werde, muss also auch sein: 57) Πh{(h⋹a) ⋹Σk(k⋹b)(x; h = k)}.
Jenachdem wir nun für den Ausdruck des letzten Thesisfaktors das Schema ο) oder das ξ) des § 30 benutzen, ergeben sich ganz verschiedne Ausdrucksformen dieser Bedingung, die es verlohnt beide aufzusuchen.
Mit ersterem entsteht: 58) b̆; x(1' ɟ x̄) ɟ ā, = ā̆ ɟ (x̄̆ ɟ 1')x̆; b = {a ⋹ (x̄̆ ɟ 1')x̆; b} = (a ⋹ x̆; b){a ⋹ (x̄̆ ⋹ 1'); b}, mit letztrem dagegen: 59) ā̆ ɟ 1'{(x̄̆ ɟ 1'); xb}; 1, = {1'a ⋹ (x̄̆ ɟ 1'); xb}.
Dies ist zunächst herzuleiten, dann aufeinander zurückzuführen, was nicht ganz leicht, aber lehrreich ist.
Zu 58) haben wir: Πh[āh + Σkbk{x(1' ɟ x̄)}k h] = Πh k{ā̆ + 1; bx(1' ɟ x̄)}k h = {ā̆ + b̆; x(1' ɟ x̄)} ɟ 0, weil 0 ɟ vor einem Systemkonvers unterdrückbar.
Damit ist die erste Form gewonnen, welche sich konvertirt in die zweite, dann, als Prädikat zu 1 gesetzt, nach dem ersten Inversionstheorem auch in die dritte umsetzt.
Die Äquivalenz dieser mit der letzten Subsumtion und vierten Form aber beruht auf einem allgemeinen Satze: 60) [Formel] — demgegenüber ein analoger Satz für a(1' ɟ ā); b jedoch nicht gelten muss.
Er beweist sich mit:
Li j = ΣhΠk(āi k + 1'k h)ai hbh j, Ri j = ΣlΠk(āi k + 1'k l)bl jΣhai hbh j = = Σh lΠk(āi k + 1'k l)ai hbh jbl j in Anbetracht dass aus der letztern Doppelsumme alle die Glieder herausfallen müssen, in denen l ≠ h ist, sintemal sie wegen k ≠ l dann āi h zum effektiven Faktor des Π haben und dieser mit ai h zusammentrifft; und wird nun l = h gesetzt, so fällt Ri j völlig mit Li j zusammen, q. e. d.
Der Satz schliesst sich augenscheinlich gewissen in § 29, S. 525 sq. gegebnen Sätzen an. —
Zu 59) haben wir zunächst: Πh{āh + Σkbk · k̆; x; h · (k̆ ɟ x̄; h)} = Πh{āh + Σkk̆; bx; h · (k̆ ɟ x̄; h)}, weil nämlich bk = bk h = k̆; b; h sowie bkxk h = (bx)k h etc.
Hiernach erwächst uns zunächst die Hülfsaufgabe: die Summation im letzten Gliede auszuführen, d. i., etwas allgemeiner gefasst, eine Summe von folgender Form: z = Σiĭ; a · (ĭ ɟ b) bei beliebigen a, b in geschlossner Form auszuwerten.
Behufs deren Lösung bilden wir ihren allgemeinen Koeffizienten zum Suffix hk: zh k = Σi(ĭ; a)h k(ĭ ɟ b)h k = ΣiΣlil hal kΠm(im h + bm k) = = Σi l1'i lal kΠm(1'i m + bm k) = Σiai k(1' ɟ b)i k = {1; a(1' ɟ b)}h k, womit z gefunden ist.
Es verdient somit der Satz notirt zu werden: 61) [Formel] Nach dem ersten dieser Schemata wird unsre Σk gleich 1; (bx; h)(1' ɟ x̄; h) = h̆; b̆x̆; (1' ɟ x̄); h = h̆; (x̄̆ ɟ 1'); xb; h — vergl. 9) des § 27, S. 444 und 27) des § 25, S. 419.
[Darnach darf insbesondre — für b = 1 — das Schema notirt werden: 62) Σk(x; h = k) = h̆; (x̄̆ ɟ 1'); x; h = {(x̄̆ ɟ 1'); x}h h.]
Unsre Bedingung wird hiermit: Πh{ā + (x̄̆ ɟ 1'); xb}h h = ā̆ ɟ 1'{(x̄̆ ɟ 1'); xb}; 1.
Denn wenn wir für den Augenblick den Inhalt der geschweiften Klammer c nennen und das zweite Glied in derselben d, so ist erstlich: Πhch h = Πh k(1'c; 1)h k = 0 ɟ 1'c; 1, sintemal das ɟ 0 am Ende unterdrückbar.
Dazu zerfällt 1'c; 1 = 1'ā; 1 + 1'd; 1, und da ā System ist, haben wir 1'ā; 1 = ā · 1'; 1 = ā, also entsteht 0 ɟ (ā + 1'd; 1) = ā̆ ɟ 1'd; 1, was zuvörderst zu zeigen gewesen.
Unsre Bedingung läuft demnach auf a ⋹ 1'd; 1 hinaus.
Nun ist beachtenswert, dass solche Bedingung bei beliebigem d, falls a System ist, äquivalent sein muss der einfacheren: 1'a ⋹ d, sintemal alsdann: (1'a ⋹ d) = (a; 1 ⋹ d + 0') = {a ⋹ (0' + d) ɟ 0 = 1'd; 1}.
Es liesse sich demnach der Satz notiren: 63) (a; 1 ⋹ 1'b; 1) = (1' · a; 1 ⋹ b) und nach diesem erhalten wir endlich aus der zuletzt gefundenen auch die zweite Form 59) unsrer Bedingung, q. e. d.
Um die beiden Formen 58), 59) direkt aufeinander zurückzuführen, kann man sich erstlich an die ausgezeichneten Relative halten, zweitens auch an die Subsumtionenform unsrer Bedingung.
In erstrer Hinsicht ist für beliebige a, b, c leicht aus der Koeffizientenevidenz der Satz zu beweisen, dass: 64) 1' · a; cb = 1' · ac̆; b — was ja einfach auf (c̆)i l = cl i hinauskommt.
Darnach ist schon für sich: 1' · (x̄̆ ɟ 1'); xb = 1' · (x̄̆ ɟ 1')x̆; b, und da das letzte relative Produkt wegen b = b; 1 System ist, so wird, wenn dasselbe e genannt wird, 1'e; 1 = e sein müssen, mithin sich ohne weitres das ausgezeichnete Relativ 59) in das 58) verwandeln, q. e. d.
In letztrer Hinsicht ist der Satz zu etabliren: 65) [Formel] als gültig für beliebige Relative a, b.
Von diesen Äquivalenzen bedarf blos die erste eines Beweises, und zwar als vorwärtige Subsumtion, da sie als rückwärtige sich von selbst versteht.
Hier ist L = (1'a ⋹ 1'b; 1 ɟ 0) = (1'a ⋹ 1'b; 1) als ⋹ (1'a ⋹ 1'b) = R nachzuweisen.
Dies gelingt mit L = L(1'a ⋹ 1') = (1'a ⋹ 1'b; 1 · 1' = 1'b; 1' = 1'b) = R.
Um nun aus der ersten Subsumtion 58) — sage L — die letzte 59) — sage R — und umgekehrt zu gewinnen, schliesse man unter Gebrauch der obigen Abkürzungen d = (x̄̆ ɟ 1'); xb und e = (x̄̆ ɟ 1')x̆; b wie folgt: L = (a ⋹ e) ⋹ (1'a; 1 ⋹ 1'e; 1), wo nun nach 64) 1'e = 1'd sein muss, also L ⋹ (1'a; 1 ⋹ 1'd; 1) = (1'a ⋹ 1'd) = (1'a ⋹ d) = R, q. e. d. Und umgekehrt: R = (1'a ⋹ d) = (1'a ⋹ 1'd = 1'e) = (1'a ⋹ e) ⋹ (1'a; 1 ⋹ e; 1), was, da a und e Systeme sind, einerlei ist mit (a ⋹ e) = L.
Damit ist denn L ⋹ R und R ⋹ L also L = R bewiesen, q. e. d.
Mit der so nachgewiesnen Äquivalenz der Subsumtionen in 58), 59) ist auch — für a = b = 1 — die Zurückführung der beiden äussersten Formen der Charakteristik von A1A2 in 17) des § 30, S. 587 gegeben und damit eine heuristische Herleitung der letztern von diesen, den Gedankengang darlegend, durch den ich sie gefunden hatte.
Nachdem somit diese immerhin instruktiven Herleitungsdetails erledigt sind, sehen wir uns die Resultate näher an.
Der Ansatz 58) oder 59) ist ebenfalls ein Ausdruck für die Forderung, dass durch x das System a eindeutig in b hinein abgebildet werde.
Dieses x braucht dabei ersichtlich nicht einmal eine Abbildung im Sinne des § 30 zu sein, denn die Forderung deckt sich mit der Charakteristik von keinem unsrer 15 Typen.
Dieselbe ist aber auch von allen vorhergehenden 51, 52, 53, 55) wesentlich verschieden, was daraus zu begreifen ist, dass sie wiederum ein andres externes Verhalten von x in Hinsicht des a und b gestattet.
Nennt man jedoch x(1' ɟ x̄) = y, so kommt: 66) a⋹y̆; b, wo y = x(1' ɟ x̄) oder y; y̆ ⋹ 1', und gelangt man auch von hier durch den Ansatz ăby = z zu unsrer Normalform 55) zurück.
Auch mit der Form 59) lässt sich zeigen, dass, wenn ein x die Forderung erfüllt, dann auch z = ăbx dieselbe erfüllen muss, und umgekehrt (wo das Umgekehrte für x = z sofort ersichtlich).
Es ist also aufgrund von 59) darzuthun, dass für unser z auch 1'a ⋹ (z̄̆ ɟ 1'); zb(= R) sein müsse.
In der That ist R = {(ā + b̄̆ + x̄̆) ɟ 1'}; ăbx = {ā + (b̄̆ + x̄̆) ɟ 1'}; bx · ă.
Mithin zerfällt die Behauptung in 1'a ⋹ ă, was wegen 1'a = 1'ă ersichtlich, und in [Formel] , was mit der Einordnung von 1'a schon unter den unterwellten Teil der rechten Seite kraft 59) a fortiori gilt.
Nunmehr haben wir noch ein paar Sätze zu beweisen.
Dem Satze D 35 bei der ähnlichen entspricht für die blos eindeutige Abbildung der von Dedekind nicht besonders chiffrirte sondern nebenher in D 21 mitaufgenommene
Satz.
Wird ein System a durch x, resp. y oder z eindeutig in b hinein abgebildet, so wird ebendadurch auch jedes Teilsystem c von a eindeutig in b hinein abgebildet.
Beweis.
Dies folgt (bei c = c; 1) mit c ⋹ a aus a ⋹ y̆; b und y; a ⋹ b in 53) a fortiori als c ⋹ y̆; b und y; c ⋹ y; a ⋹ b, während die dortige nur auf b bezügliche Charakteristik von y für das Teilsystem von a dieselbe bleibt wie für a — q. e. d.
Ähnliches gilt auch für die „normal“ eindeutige Abbildung z von a in b hinein bei 55), jedoch mit einer Ausnahme.
Falls nämlich c ein echtes Teilsystem von a, so wird z; c̄ keineswegs = 0 sein, überhaupt die Adventivforderung als z ⋹ c̆b, nämlich die Teilforderung z ⋹ c̆ derselben, nicht gelten, und somit im Allgemeinen nicht zu gelten brauchen.
Aus z ⋹ ă und c̆ ⋹ ă ist ja solcher Schluss nicht ziehbar.
Vielmehr zerfällt z; c̄ = z; (ā + ac̄) = z; ac̄ [was ≠ 0, weil jedes Element von a ein wirkliches Bild hat], sintemal c = ac, c̄ = ā + c̄ = ā + ac̄ und z; ā = 0 war.
Eine inbezug auf ein System normal ähnliche Abbildung ist mithin zwar eine ähnliche aber nicht eine normal ähnliche inbezug auf ein (echtes) Teilsystem von jenem.
Doch würde natürlich auch eine solche in Gestalt von c̆z sich wieder aus ihr ableiten lassen.
Dedekind’s »Erklärung und Satz« D 25 betrifft die „Zusammensetzung“, Komposition zweier eindeutigen Abbildungen zu einer dritten sowie das solche Kompositionen beherrschende Assoziationsgesetz.
Durch De Morgan-Peirce’s schon für die relative Multiplikation von binären Relativen überhaupt erwiesenes Assoziationsgesetz 6) des § 6 ist es überflüssig gemacht, dasselbe für den Sonderfall von Abbildungen nochmals hervorzuheben.
Auch bedarf die Komposition oder relative Multiplikation für uns keiner Erklärung mehr.
Bleibt somit für uns als Kern des Satzes die Behauptung der Transitivität der eindeutigen Abbildung bestehen — was den Sätzen D 31, 33 bei der ähnlichen Abbildung entspricht.
Sofern die „eindeutige Abbildung“ „im absoluten Sinne“ als eine auf den ganzen Denkbereich bezügliche verstanden, das Wort also synonym mit „Funktion“ genommen wird, ist auch diese Frage durch unsern allgemeinern Satz auf S. 567 bereits erledigt.
Anders, wenn die eindeutige Abbildung blos „relativ“ verstanden wird:
als solche von einem bestimmten System in ein andres hinein.
Hier ist zu statuiren der
Satz.
Wird ein System a durch ein Relativ x eindeutig abgebildet in ein System b hinein und dieses durch y eindeutig in ein System c hinein, so wird auch das System a durch das aus beiden zusammengesetzte Relativ (z =)y; x eindeutig in c hinein abgebildet.
Dies gilt in der That für die gemäss der Fassung 55) als „normal eindeutige charakterisirten Abbildungen x, y, z, wo wir für z = y; x in Formeln haben: (x; x̆ ⋹ 1')(a ⋹ x̆; b)(x; a ⋹ b)(x ⋹ ăb)(y; y̆ ⋹ 1')(b ⋹ y̆; c)(y; b ⋹ c)(y ⋹ b̆c) ⋹ ⋹ (z; z̆ ⋹ 1')(a ⋹ z̆; c)(z; a ⋹ c)(z ⋹ ăc) und die drei ersten Teile der Behauptung mit y; x; x̆; y̆ ⋹ 1', a ⋹ x̆; y̆; c, y; x; a ⋹ y; b ⋹ c wie bisher leicht erweislich erscheinen; aber auch die Adventivbedingung betreffend mit x ⋹ ă, x ⋹ b, y ⋹ b̆, y ⋹ c sich schliessen lässt: y; x ⋹ y; ă ⋹ c; ă = că, also z ⋹ ă und z ⋹ c, q. e. d.
Der Satz gilt aber wiederum nicht für die in unsern andern, den weiteren Fassungen als eindeutige definirten Abbildungen.
Vielmehr ist (auffallenderweise) zu seiner Geltung erforderlich, dass das externe Verhalten der Abbildungsprinzipien hinsichtlich a, b, c so, wie es eben bei der normalen Fassung 55) geschah, eingeschränkt werde.
Indem man in 55) b = 1 nimmt, kann man diese Definition der eindeutigen Abbildung auch als eine solche fassen, die blos relativ ist inbezug auf das Objekt derselben [nicht aber auch, wie 55), inbezug auf das Bild oder den Rezipienten von diesem], und zwar in Gestalt von: 67) (z; z̆ ⋹ 1')(a ⋹ z̆; 1)(z ⋹ ă), = (z; z̆ ⋹ 1')(z ⋹ ă = 1; z) was die normale Form zu 54) ist.
Auch mit dieser Fassung wird man leicht den Satz beweisen:
Wird das System a durch x, dessen Bild x; a durch y eindeutig abgebildet, so wird auch a durch (z =)y; x eindeutig abgebildet. D. h. (x; x̆ ⋹ 1')(x ⋹ ă = 1; x)(y; y̆ ⋹ 1')(y ⋹ ă; x̆ = 1; y) ⋹ (z; z̆ ⋹ 1')(z ⋹ ă = 1; z) für z = y; x.
In der That folgt sowol mit x ⋹ ă, also x; ā = 0 auch y; x; ā = 0 also y; x ⋹ ă, als auch mit den andern Voraussetzungen:
1; y; x = ă; x̆; x = 1; x; x̆; x = 1; x̆; x = 1; x = ă nach 26) S. 447 — q. e. d.
Sehr schön lässt sich der Beweis des letzten Satzes auch mittelst Argumentation auf die Elemente im genauen Anschluss an Dedekind’s Räsonnement in unsrer Zeichensprache liefern, indem man die Fassung 57) für b = 1 zugrund legt.
Wir haben dann:
[Formel] , wo die unterwellten Aussagen blos Anmerkungen sein sollen, die auch unterdrückbar wären, jedoch hingesetzt erkennen lassen, dass durch die Thesis der ersten Prämisse (vor dem Πk) zugleich die Hypothesis der zweiten (hinter dem Πk) als erfüllt verbürgt wird.
Gemeinhin zu reden:
Gibt es zu jedem Element h des Systems a ein (und nur ein) Element k (im Denkbereiche), welches dessen x-Bild ist (mithin wegen x; h ⋹ x; a auch im x-Bilde von a enthalten sein wird), und gibt es zu jedem Element k des Systems x; a ein (und nur ein) Element l (im Denkbereiche), welches dessen y-Bild ist, so muss es auch zu jedem Element h von a ein (und nur ein) Element l geben, welches das y-Bild von dessen x-Bilde, d. h. dessen y; x-Bild ist, q. e. d.
Die Aussage hinter dem Σk kann eo ipso nur für ein k erfüllt sein; denn wäre sie es auch noch für ein zweites: k', so würde aus x; h = k und x; h = k' ja k' = k folgen.
Gar nicht leicht dagegen scheint es, bei Zugrundelegung etwa der Fassung 59) für b = 1, aus den Prämissen:
1'a ⋹ x̆; (1' ɟ x̄) und 1' · x; a ⋹ y̆; (1' ɟ ȳ) auf 1'a ⋹ x̆; y̆; (1' ɟ ȳ ɟ x̄) direkt zu schliessen.
Die Aufgabe sei Forschern hiemit empfohlen, und eine ähnliche Aufgabe wäre auch an die Fassung 58) für b = 1 zu knüpfen.
In letztrer Hinsicht ist zwar der eine Teil der Behauptung, nämlich: (ă ⋹ 1; x)(ă; x̆ ⋹ 1; y) ⋹ (ă ⋹ 1; y; x) unschwer so beweisbar:
Aus der ersten Prämisse folgt ă = ă · 1; x, aus der zweiten: ă; x̆; x ⋹ 1; y; x.
Nach 20) S. 254 ist aber: ă · 1; x ⋹ ă; x̆; x — womit sich die Konklusion nun a fortiori ergibt.
Den andern Teil der Behauptung:
{ă ⋹ 1; (1' ɟ x̄)}{ă; x̆ ⋹ 1; (1' ɟ ȳ)} ergo {ă ⋹ 1; (1' ɟ ȳ ɟ x̄)} scheint es dagegen nicht leicht, vielleicht unmöglich, analytisch zu beweisen, was ja erst dann ausführbar sein muss, wenn man links noch die Prämissen aus der vorigen Behauptung hinzunimmt.
Soll ein System a in ein System b hinein überhaupt eindeutig abbildbar sein, so muss zwischen a und b eine gewisse Relation bestehn, die sich durch Elimination von x resp. y oder z aus der Fassung unsrer relativen Abbildungsdefinition ergibt.
Dieselbe lautet: 68) 1; a ⋹ 1; b und besagt lediglich: dass b nicht ohne a verschwinden dürfe.
Enthält in der That b auch nur ein Element, so hindert nichts, ebendieses als das Bild zu jedem Element von a hinzustellen.
Nehmen wir nun diese Relation als erfüllt an, so lässt sich auch das allgemeinste Relativ x ermitteln, welches a eindeutig in b hinein abbildet, und zwar eignet dazu sich am besten die Fassung 59), indem sie in den Koeffizienten fordert: ai i⋹ΣhΠkbh ixh i(1'i k + x̄k i) — wobei wir die rechte Seite in b̆x̆; (1' ɟ x̄) konvertirt genommen haben.
Hierin figuriren nun als Unbekannte lediglich die Koeffizienten der iten Kolonne von x.
Für jedes i, wo ai i = ai = 0, bleiben diese xh i = uh i vollkommen bestimmungslos.
Das Systemkonvers 1; ā1' erhält daher in x eine willkürliche Besetzung, oder es muss 1; ā1' · u ein integrirender Bestandteil unsres gesuchten Relativs x sein.
Für solche i jedoch, wo ai i = ai = 1 ist, muss auch mindestens ein Glied bh ixh ix̄A ix̄B i…(ohne x̄h i) der Σh gleich 1 und damit bh i = bh = = 1, xh i = 1, xA i = xB i = ‥ (ohne xh i) ‥ = 0 sein.
Gab es solche i, so war 1; a = 1 und kraft 68) auch 1; b = 1, d. h. es gibt gewisse h, für welche in der That bh i = bh = 1 ist, während für andre h dann auch bh i = bh = 0 sein mag.
Man braucht alsdann blos in dieser Kolonne ĭ dem x ein Auge zu erteilen an irgend einer der Stellen wo sie von den Vollzeilen des Systems b geschnitten wird, während alle übrigen Stellen dieser Kolonne bei x Leerstellen bleiben müssen, sodass die Kolonne ĭ bei x eine einbesetzte wird.
Ungeachtet solcher Durchsichtigkeit des Baues von x scheint sich ein allgemeiner, jede Wurzel der Proposition 59) darstellender Ausdruck für x doch nur für den Fall b = 1 ohne erhebliche Weiterungen aufstellen zu lassen.
In diesem Falle nämlich müssen die Kolonnen des Systemkonverses 1; a1' bei x nur einfach irgendwie einbesetzte sein, d. h. wir haben x = 1; ā1' · u + 1; a1' · f, wenn f die allgemeinste „Funktion“, d. h. ein Relativ mit lauter einbesetzten Kolonnen vorstellt.
Den (pasigraphischen) Ausdruck dieses f haben wir in 27) S. 589 gegeben.
Da jedoch a und ā Systeme sind, so vereinfacht sich noch: 1; ā1' = ā̆, 1; a1' = ă, indem z. B. 1; a1' = 1; ă1' = 1; (1; ă)1' = 1; 1' · 1; ă = 1 · ă, und somit ist 69) x = ā̆u + ă[u(1' ɟ ū) + {0 ɟ (ū + 0'; u)}1'] = = (ā̆ + 1' ɟ ū)u + a1'{0 ɟ (ū + 0'; u)} die allgemeine Wurzel der Bedingung 70) 1'a ⋹ x̆; (1' ɟ x̄) oder a ⋹ 1; x · 1; (1' ɟ x̄) für a = a; 1.
Den Fall b ≠ 1 zu verfolgen sei Forschern empfohlen. —
Wie den Begriff der „eindeutigen“, so kann man auch den der identischen“ Abbildung — statt wie bisher als 1' „absolut“ — blos relativ“ fassen, nämlich unter Bezugnahme auf ein bestimmtes System a als des Substrates (Objektes sowol als Bildes) der Abbildung im Denkbereiche.
Das System b als etwaigen Rezipienten des Bildes von a kann man dabei aus dem Spiele lassen; denn ist a nicht ⋹ b, so ist die Aufgabe unmöglich, und ist a ⋹ b, so erledigt sich die Sache von selber sobald wir a nur überhaupt (in den Denkbereich 1 hinein) identisch abbilden.
Ein Relativ x wird inbezug auf ein System a = a; 1 (dessen) identische Abbildung zu nennen sein, wenn — nicht etwa nur im Ganzen x; a = a, sondern vielmehr wenn — jedem Element h von a als das x-Bild desselben h selbst entspricht — mögen die Elemente von ā dabei irgendwie, wenn überhaupt, abgebildet werden.
Diese Forderung formulirt sich zu 71) Πh{(h⋹a) ⋹ (x; h = h)}, = Πh[āh + {x(1' ɟ x̄)}h h] gemäss π) des § 30, wofür jedoch auch Πh{ā + xh h(h̆ ɟ x̄; h)} genommen werden kann.
Beide letzten Π zerfallen in Πh(ā + x)h h = 0 ɟ (ā + 1'x; 1) und Πh(ā + 1' ɟ x̄)h h = 0 ɟ {ā + 1'(1' ɟ x̄); 1} resp. Πh(āh + h̆ ɟ x̄; h) = 0 ɟ (1' + x̄) ɟ ā, was nach einem allgemeinen, unschwer zu findenden Schema: 72) Πi(ĭ; a + ĭ ɟ b; i) = 0 ɟ (1' + b) ɟ a sich ergibt.
Setzt man jeden Faktor nun also als Prädikat zum Subjekte 1 an, so ergibt sich zum ersten: 1 ⋹ ā̆ ɟ 1'x; 1, oder a; 1 = a = = 1'a; 1 ⋹ 1'x; 1, was nach 65) auf 1'a ⋹ x hinausläuft; zum zweiten: 1 ⋹ ā̆ ɟ 1'(1' ɟ x̄); 1 oder a = 1'a; 1 ⋹ 1'(1' ɟ x̄); 1, d. h. ebenso 1'a ⋹ 1' ɟ x̄, 1'ă ⋹ 1' ɟ x̄, 0'; x ⋹ 0' + ā̆, x ⋹ 1' ɟ (0' + ā̆) = 1' ɟ 0' + ā̆ = 1' + ā̆, resp. (kürzer): 1 ⋹ (1' + x̄) ɟ ā, 1; ă = ă ⋹ 1' + x̄, ăx ⋹ 1', was auf dasselbe hinausläuft.
Beidemal haben wir also insgesamt: 73) 1'ă ⋹ x ⋹ 1' + ā̆, woraus sich nach den Regeln des identischen Kalkuls berechnet: x = 1'ă + u(1' + ā̆) oder: 74) x = 1'ă + uā̆ als das allgemeinste Relativ, welches ein System a identisch abbildet, und 73) ist die Charakteristik eines solchen.
Man sieht auf den ersten Blick, dass (D 30) letztre durch x = 1' bei jedem a identisch erfüllt ist.
Auch kann man die allgemeine Wurzel 74) derselben benutzen, um nachzurechnen, dass unser x auch die Charakteristik der ähnlichen Abbildung (für b = a) — wie sich a priori versteht — erfüllen muss.
Lehrreicherweise gelingt indessen letztres nur, wenn man die „erste Fassung 4) der Ähnlichkeitsdefinition, in der über das externe Verhalten des Abbildungsprinzips x gar nichts präjudizirt ist, zugrunde legt, würde dagegen mit den andern Fassungen — wie z. B. (10) — worin darüber schon einigermaassen präjudizirt ist, (wie leicht zu sehn) durchaus nicht gelingen.
Fügt man, um die „Normalform“ der relativ identischen Abbildung von a zu erhalten, den bisherigen Bedingungen noch die Forderung x; ā = 0 oder x ⋹ ă (als eine adventive) hinzu, so muss uā̆ ⋹ ă, also uā̆ ⋹ ăā̆ = 0 sein, und bleibt: 75) x = a1' als Ausdruck für die völlig bestimmte Abbildung, welche blos a identisch abbildet.
Dieselbe wird auch jedes echte Teilsystem identisch (aber nicht „normal identisch“) abbilden.
Auch genügt sie offenbar der für b = a in Anspruch genommenen Ähnlichkeitsbedingung in ihrer „normalen“ Fassung (17). —
Soweit die Einverleibung in unsre Disziplin der Erklärungen, Sätze und Schlüsse von Dedekind’s Schrift bis zu dem S. 597 angegebnen Punkte, d. h. bis zu D 64, uns als ein Ziel mit vorschwebte, sind wir hiermit zu Ende, und man wird die Sätze:
[Formel] in den für unsern Standpunkt erforderlichen Modifikationen aufgenommen, dargestellt und erledigt finden.
Um jedoch eine Idee zu geben von der Mannigfaltigkeit der Bedingungen, die sich einer Abbildung x (im weitesten Sinn genommen) auferlegen lassen, und um zugleich dem Studirenden ein umfassenderes Übungsmaterial zur Verfügung zu stellen, sei es zur Einkleidung von Bedingungen in die Form von affirmativen oder aber negirten Subsumtionen sowie auch von ausgezeichneten Relativen, sei es zur Deutung, Interpretation der letzteren, wollen wir hiernächst noch eine Reihe der bemerkenswertesten Forderungen durchgehen und in der Zeichensprache unsrer Disziplin formulirt aufstellen.
Da immer 0 ⋹ x; a gilt, so ist es nichtssagend, zu verlangen, dass „ein“ x-Bild von a verschwinde, und hat solches vielmehr nur einen Sinn, wenn man es in Gestalt von x; a = 0 von „dem“ x-Bilde von a fordert.
Seien nun a = a; 1 und b = b; 1 Systeme, und bethätigen wir bei der Chiffrirung der Forderungen die S. 597 im Kontext angegebnen Bezeichnungsgrundsätze, so ist zunächst folgendes ein Überblick über naheliegende Forderungsmöglichkeiten und deren Formulirung.
Das x-Bild jedes Elements von a verschwindet: α1 = Πh{(h ⋹ a) ⋹ (x; h = 0)} = 0 ɟ x̄ ɟ ā = (x; a = 0) = (x ⋹ ā̆).
Es gibt Elemente von a, deren x-Bild nicht verschwindet: ᾱ1 = Σh(h ⋹ a)(x; h ≠ 0) = 1; x; a = (x; a ≠ 0) = (x ⋹ ā̆).
Das x-Bild keines Elements von a verschwindet: α2 = Πh{(h ⋹ a) ⋹ (x; h ≠ 0)} = 1; x ɟ ā = (a ⋹ x̆; 1).
Es gibt Elemente von a, deren x-Bild verschwindet: ᾱ2 = Σh(h ⋹ a)(x; h = 0) = (0 ɟ x̄); a = (a ⋹ x̆; 1).
Zu bemerken ist, dass die universalen Urteile α1 und α2 auch zutreffen für a = 0, d. h. wenn es gar kein Element von a gibt.
Dann gilt im Geiste unsrer Algebra der Logik von „jedem“ Element von a bekanntlich alles Erdenkliche: sowol dass es verschwindet, als auch dass es nicht verschwindet.
Alsdann ist α1 mit α2 (besagend: dass das x-Bild jedes Elements von a nicht verschwinde) verträglich.
Analog haben wir, a mit b, x mit x̆ (und h mit k) vertauschend: β1 = Πk{(k ⋹ b) ⋹ (x̆; k = 0)} = 0 ɟ x̄̆ ɟ b̄ = (x̆; b = 0) = (x ⋹ b̄). β̄1 = Σk(k ⋹ b)(x̆; k ≠ 0) = 1; x̆; b = (x̆; b ≠ 0) = (x ⋹ b̄). β2 = Πk{(k ⋹ b) ⋹ (x̆; k ≠ 0)} = 1; x̆ ɟ b̄ = (b ⋹ x; 1). β̄2 = Σk(k ⋹ b)(x̆; k = 0) = (0 ɟ x̄̆); b = (b ⋹ x; 1).
Man ziehe die Konklusionen (siehe hernach unter γ): ᾱ2⋹ (1 = x̄; a), β̄2 ⋹ (1 = x̄̆; b).
— Die folgenden Bezeichnungen γ1 bis γ4 sind unabhängig von den S. 617 sqq. schon vorgekommen.
Das x-Bild jedes Elements von a hat nichts mit b gemein = = „ „ „ keines „ „ „ „ etwas „ „ „:
γ1 = Πh{(h ⋹ a) ⋹ (x; h ⋹ b̄)} = b̄̆ ɟ x̄ ɟ ā = (x; a ⋹ b̄) = (x ⋹ b̄ + ā̆) = (ăbx = 0) = (= δ1) = Πk{(k ⋹ b) ⋹ (x̆; k ⋹ ā)} = ā̆ ɟ x̄̆ ɟ b̄ = (x̆; b ⋹ ā) = (x̆ ⋹ ā + b̄̆) = (ab̆x̆ = 0).
Es gibt Elemente in a, deren x-Bild etwas mit b gemein hat:
γ̄1 = Σh(h ⋹ a)(x; h ⋹ b̄) = b̆; x; a = (x; a ⋹ b̄) = (x ⋹ b̄ + ā̆) = (ăbx ≠ 0) = (= δ̄1) = Σk(k ⋹ b)(x̆; k ⋹ ā) = ă; x̆; b = (x̆; b ⋹ ā) = (x̆ ⋹ ā + b̄̆) = (ab̆x̆ ≠ 0).
Das x-Bild jedes Elements von a hat etwas mit b gemein: γ2 = Πh{(h ⋹ a) ⋹ (x; h ⋹ b̄)} = b̆; x ɟ ā = (a ⋹ x̆; b).
Dies γ2 ist unser früheres γ1 von S. 617 sq.
Es gibt Elemente von a, deren x-Bild nichts mit b gemein hat: γ̄2 = Σh(h ⋹ a)(x; h ⋹ b̄) = (b̄̆ ɟ x̄); a = (a ⋹ x̆; b).
Analog x mit x̆ und a mit b vertauscht: δ2 = Πk{(k ⋹ b) ⋹ (x̆; k ⋹ ā)} = ă; x̆ ɟ b̄ = b̄̆ ɟ x; a = (b ⋹ x; a), wo dies δ2 sich deckt mit dem γ3 von S. 617 sq. δ̄2 = Σk(k ⋹ b)(x̆; k ⋹ ā) = (ā̆ ɟ x̄̆); b = b̆; (x̄ ɟ ā) = (b ⋹ x; a).
Aus γ1 geht α1, aus γ2 unser α2 für b = 1 hervor, ebenso aus (δ1 =)γ1 unser β1, aus δ2 unser β2 für a = 1.
In der gleichen Weise aus den noch folgenden mit γ, δ chiffrirten Forderungen die entsprechenden α, β abzuleiten und zu diskutiren, überlassen wir dem Leser.
Da (b̄̆ ɟ x̄); a ⋹ b̄̆ ɟ x̄; a, so haben wir nebenbei a fortiori die Konklusionen: γ̄2⋹ (b ⋹ x̄; a), ebenso: δ̄2 ⋹ (a ⋹ x̄̆; b).
Statt wie oben zu sagen: „das“ x-Bild des Elements h von a habe etwas mit b gemein, kann man auch sagen: „ein“ x-Bild von h sei Teil von b, oder: es gebe Elemente (h) in a, von denen „ein“ x-Bild in b enthalten ist.
Indem nämlich gemäss υ) S. 558 und 27) S. 419: (x; h ⋹ b̄) = (b̄̆ ɟ x̄); h = = b̄̆ ɟ x̄; h sein muss, werden wir — auch analytisch — haben: (x; h · b ≠ 0) = (x; h ⋹ b̄) = b̆; x ɟ h̄ = b̆; x; h = = Σk(k ⋹ x; h)(k ⋹ b) = Σkxk hbk = (x̆b̆; 1)h = (x̆; b)h.
Also zeigen sich in der That als mit den vorigen wesentlich übereinstimmende die Forderungen:
Es gibt kein Element in a, von dem ein Element des b ein x-Bild wäre: Πh k{(k⋹b)(k⋹x; h) ⋹ (h ⋹ a)} = γ1(= δ1).
Es gibt Elemente in a, von denen Elemente in b ein x-Bild sind: Σh k(h⋹a)(k⋹b)(k⋹x; h) = γ̄1(= δ̄1).
Von jedem Element in a ist ein x-Bild in b enthalten = Von jedem Element in a ist das eine oder andre Element von b ein x-Bild: Πh{(h⋹a) ⋹Σk(k⋹b)(k⋹x; h)} = γ2.
Es gibt Elemente in a, von denen kein Element des b ein x-Bild ist = Von gewissen Elementen in a ist kein Element in b ein x-Bild: Σh(h⋹a)Πk{(k⋹b) ⋹ (k ⋹ x; h)} = γ̄2.
Der Studirende wird es schon nicht ganz leicht finden, die für die beiden letzten Formen behauptete Äquivalenz rechnerisch nachzuweisen.
Als Gegenstücke zu den beiden letzten Forderungen drängen sich indess bei ihrer gegenwärtigen Fassung sogleich noch auf:
Es gibt kein Element in a, wovon jedes Element in b ein x-Bild wäre = Von jedem Element in a ist das eine oder andre Element von b kein x-Bild: γ3 = Πh[Πk{(k ⋹ b) ⋹ (k ⋹ x; h)} ⋹ (h ⋹ a)] = b̆; x̄ ɟ ā = (a ⋹ x̄̆; b).
Es gibt Elemente in a, von denen jedes Element von b ein x-Bild ist = Von gewissen Elementen in a ist jedes Element von b ein x-Bild: γ̄3 = Σh(h ⋹ a)Πk{(k ⋹ b) ⋹ (k ⋹ x; h)} = (b̄̆ ɟ x); a = (a ⋹ x̄̆; b).
Analog: δ3 = Πk[Πh{(h ⋹ a) ⋹ (h ⋹ x̆; k)} ⋹ (k ⋹ b)] = b̄̆ ɟ x̄; a = (b ⋹ x̄; a). δ̄3 = Σk(k ⋹ b)Πh{(h ⋹ a) ⋹ (h ⋹ x̆; k)} = b̆; (x ɟ ā) = (b ⋹ x̄; a).
Wohl hievon zu unterscheiden sind aber die Forderungen, welche sich um die Existenz von solchen Elementen h des Systems a drehen, dass (anstatt „ein“ — vielmehr) „das“ x-Bild von h in b enthalten ist.
In letztrer Hinsicht kann man in der That stipuliren:
Für kein Element von a ist das x-Bild Teil von b: γ4 = Πh{(h ⋹ a) ⋹ (x; h ⋹ b)} = b̄̆; x ɟ ā = (a ⋹ x̆; b̄).
Es gibt in a Elemente, deren x-Bild Teil von b ist: γ̄4 = Σh(h ⋹ a)(x; h ⋹ b) = (b̆ ɟ x̄); a = (a ⋹ x̆; b̄).
Das x-Bild jedes Elements von a ist Teil von b: γ5 = Πh{(h ⋹ a) ⋹ (x; h ⋹ b)} = b̆ ɟ x̄ ɟ ā = (x; a ⋹ b) = (ăx ⋹ b).
Es gibt in a Elemente, deren x-Bild nicht Teil von b ist: γ̄5 = Σh(h ⋹ a)(x; h ⋹ b) = b̄̆; x; a = (x; a ⋹ b) = (ăx ⋹ b).
Analog: δ4 = Πk{(k ⋹ b) ⋹ (x̆; k ⋹ a)} = b̄̆ ɟ x; ā = (b ⋹ x; ā). δ̄4 = Σk(k ⋹ b)(x̆; k ⋹ a) = b̆; (x̄ ɟ a) = (b ⋹ x; ā). δ5 = Πk{(k ⋹ b) ⋹ (x̆; k ⋹ a)} = b̄̆ ɟ x̄ ɟ a = (x̆; b ⋹ a) = (bx ⋹ ă). δ̄5 = Σk(k ⋹ b)(x̆; k ⋹ a) = b̆; x; ā = (x̆; b ⋹ a) = (bx ⋹ ă).
Wird dagegen im Text zu den sechs Forderungen γ1 bis γ3 vom Striche auf S. 645 ab für „ein x-Bild“ noch „das x-Bild“ gesagt, so ist gemäss π) S. 557, wonach (k = x; h) = {x(1' ɟ x̄)}k h gegenüber (k ⋹ x; h) = xk h sein muss, der Effekt blos der, dass man x durch x(1' ɟ x̄) zu ersetzen haben wird.
Z. B. also formulirt sich:
Es gibt kein Element in a, von dem ein Element von b das x-Bild wäre = Von jedem Element von a wird das eine oder andre Element von b nicht das x-Bild sein, als: Πh k{(k⋹b)(k = x; h) ⋹ (h ⋹ a)} = b̄̆ ɟ (x̄ + 0'; x) ɟ ā = (ăbx ⋹ 0'; x).
Etc.
Die Stipulationen aus dem vorstehenden sich verbal-logisch oder rhetorisch motivirenden Gedankenkreise führen, wie man sieht, alle auf eines von den sechs (zwei Gespanne bildenden) ausgezeichneten Relativen: worin a, b durch ein verwandtes der Systeme a, b vertreten und zwar das erste ein Systemkonvers, das letzte ein System ist, und y ein (einfaches, mit x verwandtes, oder auch ein zusammengesetztes, aus x sich irgendwie ableitendes) Abbildungsprinzip vorstellt.
a ɟ y ɟ b, a; y; b,
(a ɟ y); b, a; y ɟ b,
a ɟ y; b, a; (y ɟ b),
Wegen der Mannigfaltigkeit der angedeuteten Vertretungsmöglichkeiten ist die Menge der Urteilsformen hier eine grosse und nicht leicht zu übersehende. Dieselben sechs Formen werden sich jedoch in der zweiten Abteilung unsres Buches erweisen als die überaus einfache Grundlage einer Lehre (Syllogistik) von den „doppelt universal- oder partikularen“ (genauer: den universal-universalen, den universal-partikularen, den partikularuniversalen und den partikular-partikularen) Urteilen — wodurch auf die letzten Betrachtungen noch weitres Licht fällt.
Will man — was so oft verlangt wird — ein ausgezeichnetes Relativ, welches ein relatives Produkt ist, in eine gewöhnliche Aussage umsetzen wie z. B. das (a ɟ y); b, so steht für 1 ⋹ (a ɟ y); b kein Inversionstheorem zum Herüberschaffen des b zur Verfügung.
Wohl aber würde das bei (a ɟ y); b ⋹ 0 der Fall sein, wo wir a ɟ y ⋹ 0 ɟ b̄̆ = b̄̆, also b̆ ⋹ ā; ȳ schliessen dürften.
Unser ausgezeichnetes Relativ muss nun der Verneinung dieser Aussage äquivalent sein, und wird also auf eine Unsubsumtion, hier b̆ ⋹ ā; ȳ hinauslaufen. —
Propädeutisch für’s Folgende lege man sich zunächst zurecht, dass: Alsdann wird es eine gute Übung sein, die folgenden unter analytischem Gesichtspunkte sich darbietenden 16 Bedingungen (denen sich noch weitre anschliessen werden) verbal zu formuliren, sie auf die angegebne Form eines ausgezeichneten Relativs zu bringen, sowie sie auf ihre daneben gestellte einfachste(?) Aussagenform zu reduziren, und überhaupt: sich in ihre Bedeutung und Tragweite hineinzudenken: Σh[(h ⋹ a) ⋹ Σk{(k ⋹ b) ⋹ (k ⋹ x; h)}] = 1; (ā̆ + x + b̄); 1 = {(a = b = 1)(x = 0) = 0}, Σh „ Πk „ = 1; (ā + x̆ ɟ b̄) = {(a = 1)(1 = x̄̆; b) = 0}, Πh „ Σk „ = 1; (b̄ + x) ɟ ā = {ă(0 ɟ b) ⋹ 1; x} = = {(b = 1) ⋹ (ă ⋹ 1; x)}, Πh „ Πk „ = b̄̆ ɟ x ɟ ā = (ăb ⋹ x). Σh(h ⋹ a)Σk{(k ⋹ b) ⋹ (k ⋹ x; h)} = 1; (b̄ + x); a = {(a = 0) + (b = 1) ⋹ (x ⋹ ā̆)}, Σh „ Πk „ = (b̄̆ ɟ x); a = (a ⋹ x̄̆; b), Πh „ Σk „ = {1; (b + x) ɟ 0}(0 ɟ a) = (a ≠ 0){(b = 0) ⋹ (1 = 1; x)}, Πh „ Πk „ = 0 ɟ a(x̆ ɟ b̄) = (a = 1)(b ⋹ x). Σh{(h ⋹ a) ⋹ Σk(k ⋹ b)(k ⋹ x; h)} = 1; (ā + x̆; b) = {(a = 1)(bx = 0) = 0}, Σh „ Πk „ = 1; (ā + x̆b̆ ɟ 0) = {(a = 1) ⋹ (b = 1 = x; 1)}, Πh „ Σk „ = b̆; x ɟ ā = (a ⋹ x̆; b), (= γ2), Πh „ Πk „ = 0 ɟ bx ɟ ā = (1; a ⋹ b)(ă ⋹ x). Σh(h ⋹ a)Σk(k ⋹ b)(k ⋹ x; h) = b̆; x; a = (ăbx ≠ 0), (= γ̄1), Σh „ Πk „ = (0 ɟ bx); a = {ă(0 ɟ b)(0 ɟ x) ≠ 0}, Πh „ Σk „ = 0 ɟ a(x̆; b) = (a = 1 = x̆; b), Πh „ Πk „ = 0 ɟ ăbx ɟ 0 = (a = b = 1 = x).
Wenn man in den beiden ersten Quadrupeln anstatt der letzten sekundären Subsumtion die umgekehrte, mithin: {(k ⋹ x; h) ⋹ (k ⋹ b)} setzte, so würde der Effekt blos der sein, dass sich x mit x̄ und b mit b̄ vertauschte.
Mit den vorstehenden zugleich sind also noch 8 weitre (zusammen 24) Arten von Aussagen erledigt — ungerechnet deren Negationen, und die sich mittelst Vertauschung von a, (h), x mit b, (k), x̆ ergebenden.
Die Wirkung einer Ersetzung der Subsumtion k ⋹ x; h durch die Gleichung k = x; h haben wir oben S. 646 angegeben.
Σk{(k⋹b) ⋹ (k ⋹ x; h)} = {(x̆ + b̄̆); 1}h Σk(k⋹b)(k⋹x; h) = (x̆; b)h, Πk „ „ „ = (x̆ ɟ b̄)h Πk „ „ = (x̆b̆ ɟ 0)h.
Eine grosse Mannigfaltigkeit von möglichen Bedingungen ergäbe sich noch, wenn man darauf eingehen wollte, ob verschiednen Elementen in a nie, manchmal, oder stets verschiedne Elemente in b als ein x-Bild derselben, resp. als deren x-Bild entsprechen — eventuell auch blos sofern die Bilder von 0 verschieden sind.
Doch wollen wir dieses reiche Feld von Übungen im Einkleiden und Interpretiren von Forderungen, im äquivalenten Umformen derselben und im Ziehen von Folgerungen — dem ja durch unsre Einleitung im § 30 auch schon vorgearbeitet ist — lieber nicht mehr betreten.
Um nunmehr die ähnliche Abbildung eines Systems a(= a; 1) in sich selbst zu charakterisiren, wenden wir — zum Schlusse — die Normalform (17) der Ähnlichkeitsbedingung auf ein dem a ähnliches System b an, welches als ⋹ a gedacht wird.
Man könnte — unter u(= u; 1) ein unbestimmtes System verstehend — einfach b = u a in jene Formel eintragen, und müsste nur dem vorgeschriebenen [Formel] dann noch ein [Formel] beigesellen.
Besser fügen wir aber die Forderung b ⋹ a hinzu, und merzen den Namen b, indem wir ihn durch das ihm gleiche z; a durchweg ersetzen, vollständig aus.
So kommt: 76) [Formel] , wo der unterwellte Faktor die adventive Forderung ausdrückt und als solcher auch unterdrückbar wäre.
Derselbe könnte jedoch auch noch voller durch (z ⋹ aă · z; a) ersetzt werden, sintemal mit z ⋹ z; a und z; a ⋹ a auch noch z ⋹ a hinzufolgt.
Die hier implizite mit gegeben sein sollende Äquivalenz der allgemeinen Terme in den beiden [Formel] wird als solche ebenfalls oft gebraucht werden.
Die Formel 76) nun wird den Ausgangspunkt für weitre wichtige Betrachtungen in der zweiten Abteilung des Bandes bilden.
Daselbst werden wir sehen, wie einfach sich mit dem geringen Bezeichnungskapital unsrer Disziplin wol die meisten zahlentheoretischen sowie alle arithmetischen Grundbegriffe — einschliesslich des „Geordnetseins“, „Diskretseins“, „Dichtseins“ und der „Stetigkeit“ etc. einer Menge — sozusagen pasigraphisch formuliren lassen, und wie die Ziele des Folgerns und Schliessens durch solche Darstellung gefördert werden.
